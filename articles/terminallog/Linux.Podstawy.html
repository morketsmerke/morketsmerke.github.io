<!DOCTYPE html>
	<html>
		<head>
			<meta charset="utf-8" />
			<link rel="icon" type="image/png" href="https://i.ibb.co/khy45hh/mm.png">
      <link rel="stylesheet" type="text/css" href="/style.css">
			<style>
				.code-block {
					text-align: left;
				}
				ul {
					text-align: left;
				}
        p { 
          text-align: justify; 
        }
        body {
          width: 99%;
          height: 100vh;
        }
        .main {
          width: 100%;
        }
			</style>
		</head>
		<body>
			<div class="main">
       <div id="tableOfContent">
          <h1>Linux. Podstawy.</h1>
          <ul class="toc">
            <li><a href="#1.howlinuxismade">1. Budowa systemu Linux<a>
              <ul class="toc">
                <li><a href="#1.1.hardware">1.1. Sprzęt</a>
                  <ul class="toc">
                    <li><a href="#1.1.1.ram">1.1.1. Pamięć operacyjna</a>
                  </ul>
                </li>
                <li><a href="#1.2.kernel">1.2. Jądro</a>
                <li><a href="#1.3.userspace">1.3. Przestrzeń użytkownika</a>
                <li><a href="#1.4.users">1.4. Użytkownicy</a>
              </ul></li>
              <li><a href="#2.linuxbasics">2. Podstawy obsługi Linuksa</a>
                <ul class="toc">
                  <li><a href="#2.1.shells">2.1. Powłoka</a></li>
                  <li><a href="#2.2.shellusage">2.2. Korzystanie z powłoki</a>
                    <ul class="toc">
                      <li><a href="#2.2.1.catcommand">2.2.1. Polecenie cat</a></li>
                      <li><a href="#2.2.2.stdinstdout">2.2.2. Standardowe wejście i standardowe wyjście</a></li>
                    </ul></li>
                  <li><a href="#2.3.basicscommands">2.3. Podstawowe polecenia</a></li>
                  <li><a href="#2.4.commandsworksondir">2.4. Polecenia działające na katalogach</a>
                    <ul class="toc">
                      <li><a href="#2.4.1.globbing">2.4.1. Nazwy wieloznaczne</a></li>
                    </ul></li>
                  <li><a href="#2.5.proxycommands">2.5. Polecenia pośredniczące</a></li>
                  <li><a href="#2.6.passwdandchsh">2.6. Zmiana hasła i powłoki</a></li>
                  <li><a href="#2.7.dotfiles">2.7. Plik z kropką</a></li>
                  <li><a href="#2.8.shellandenvvars">2.8. Zmienne środowiskowe i powłoki</a></li>
                  <li><a href="#2.9.path">2,9, Ścieżka poleceń</a></li>
                  <li><a href="#2.10.specialchars">2.10. Znaki specjalne</a></li>
                  <li><a href="#2.11.commadlineedit">2.11. Edycja wiersza poleceń</a></li>
                  <li><a href="#2.12.texteditors">2.12. Edytory tekstu</a></li>
                  <li><a href="#2.13.gettinghelp">2.13. Uzyskiwanie pomocy</a></li>
                  <li><a href="#2.14.shellio">2.14. Wejście i wyjście powłoki</a>
                    <ul class="toc">
                      <li><a href="#2.14.1.stderr">2.14.1. Standardowy strumień błędów</a></li>
                      <li><a href="#2.14.2.stdin">2.14.2. Przekierowanie standardowego wejścia</a></li>
                    </ul></li>
                  <li><a href="#2.15.readingerrors">2.15. Odczytwanie komunikatów o błędach</a></li>
                  <li><a href="#2.16.manipulatingprocesses">2.16. Przeglądanie procesów i manipulowanie nimi</a>
                    <ul class="toc">
                      <li><a href="#2.16.1.processkilling">2.16.1. Przerywanie działania procesów</a></li>
                      <li><a href="#2.16.2.jobcontrol">2.16.2. Kontrola zadań</a></li>
                      <li><a href="#2.16.3.processinbg">2.16.3. Procesy działające w tle</a></li>
                    </ul></li>
                  <li><a href="#2.17.filemodeandpermissions">2.17. Tryb pliku i uprawnienia</a>
                    <ul class="toc">
                      <li><a href="#2.17.1.modifypermissions">2.17.1. Modyfikacja uprawnień</a></li>
                      <li><a href="#2.17.2.sylinks">2.17.2. Dowiązania symboliczne</a></li> 
                    </ul></li>
                  <li><a href="#2.18.archvesandcompression">2.18. Archiwizowanie i kompresowanie danych</a>
                    <ul class="toc">
                      <li><a href="#2.18.1.tarprogram">2.18.1. Program tar</a></li>
                      <li><a href="#2.18.2.gzipprogram">2.18.2. Program gzip</a></li>
                      <li><a href="#2.18.3.compressedarchives">2.18.3. Skompresowane archiwa</a></li>
                      <li><a href="#2.18.4.othercommpression">2.18.4. Inne metody kompresji</a></li>
                    </ul></li>
                  <li><a href="#2.19.filesystemhierarchy">2.19. Hierarchia katalogów</a>
                    <ul class="toc">
                      <li><a href="#2.19.1.othermainsubdirs">2.19.1. Pozostałe katalogi główne</a></li>
                      <li><a href="#2.19.2.usrdirectory">2.19.2. Katalog /usr</a></li>
                      <li><a href="#2.19.3.kernelplace">2.19.3. Umiejscowienie jądra w systemie</a></li>
                    </ul></li>
                  <li><a href="#2.20.runitasroot">2.20. Uruchamianie poleceń przez superużytkownika</a>
                    <ul class="toc">
                      <li><a href="#2.20.1.sudoersfile">2.20.1. Plik /etc/sudoers</a></li>
                    </ul></li>
                  <li><a href="#2.21.summary">2.21. Podsumowanie</a></li>
                </ul></li>
              <li><a href="#3.devices">3. Urządzenia</a>
                <ul class="toc">
                  <li><a href="#3.1.devicefiles">3.1. Pliki urządzeń</a>
                  <li><a href="#3.2.sysfsdevicepath">3.2. Ścieżka urządzeń sysfs</a></li>
                  <li><a href="#3.3.ddcommand">3.3. Polecenie dd</a></li>
                  <li><a href="#3.4.namingsummary">3.4. Podsumowanie nazewnictwa urządzeń</a>
                    <ul class="toc">
                      <li><a href="#3.4.1.makedev">3.4.1. Tworzenie plików urządzeń</a></li>  
                    </ul></li>
                  <li><a href="#3.5.udev">3.5. System udev></a>
                    <ul class="toc">
                      <li><a href=#3.5.1.devtmpfs">3.5.1. System plików devtmpfs</a></li>
                    </ul></li>
                </ul></li>
              <li><a href="#4.disksandfs">4. Dyski i systemy plików</a>
                <ul class="toc">
                  <li><a href="4.1.paritioning">4.1. Partycjonowanie</a>
                    <ul class="toc">
                      <li><a href="4.1.1.listingpartitiontable">4.1.1. Przeglądanie tablicy
                        partycji</a></li>
                      <li><a href="4.1.2.modifypartition">4.1.2. Modyfikowanie tablicy partycji</a></li>
                    </ul></li>
                  <li><a href="4.2.filesystems">4.2. Systemy plików</a>
                    <ul class="toc">
                      <li><a href="#4.2.1.fstypes">4.2.1. Typy systemów plików</a></li>
                      <li><a href="#4.2.2.createfs">4.2.2. Tworzenie systemów plików</a></li>
                      <li><a href="#4.2.3.mountfs">4.2.3. Montowanie systemów plików</a></li>
                      <li><a href="#4.2.4.uuid">4.2.4. Identyfikator UUID systemu plików</a></li>
                      <li><a href="#4.2.5.diskcache">4.2.5. Buforowanie dysku i systemu pliku</a></li>
                      <li><a href="#4.2.6.mountoptions">4.2.6. Opcje montowania</a></li>
                      <li><a href="#4.2.7.remount">4.2.7. Ponowne montowanie systemu plików</a></li>
                      <li><a href="#4.2.8.fstabfile">4.2.8. Tablica systemów plików /etc/fstab</a></li>
                      <li><a href="#4.2.9.fscapacity">4.2.9. Pojemność systemu plików</a></li>
                      <li><a href="#4.2.10.fsrescue">4.2.10. Sprawdzenie i naprawianie systemu plików</a></li>
                      <li><a href="#4.2.11.specialfs">4.2.11. Systemy plików o specjalnym znaczeniu</a></li>
                    </ul></li>
                  <li><a href="#4.3.swapspace">4.3. Przestrzeń wymiany</a>
                    <ul class="toc">
                      <li><a href="#4.3.1.swappartition">4.3.1. Wykorzystanie partycji jako przestrzeni wymiany.</a></li>
                      <li><a href="#4.3.2.swapfile">4.3.2. Wykorzystanie pliku jako przestrzeni wymiany</a></li>
                      <li><a href="#4.3.3.swapsize">4,3,3, Jak dużej przestrzeni wymiany potrzebuje</a></li>
                    </ul></li>
                  <li><a href="#4.4.fsfuture">4.4. Przyszłość systemów plików</a></li>
                </ul></li>
            <li><a href="#5.startingkernel">5. Uruchamianie jądra Linux</a>
              <ul class="toc">
                <li><a href="#5.1.dmesg">5.1. Komunikaty rozruchowe</a></li>
                <li><a href="#5.2.kernelinitandbootoptions">5.2. Inicjowanie jądra i opcje rozruchu</a></li>
                <li><a href="#5.3.kernelparameters">5.3. Parametry jądra</a></li>
                <li><a href="#5.4.bootloaders">5.4. Programy rozruchowe</a></li>
                <li><a href="#5.5.practicalusagegrub">5.5. Praktyczne użytcie programu rozruchowego GRUB</a>
                  <ul class="toc">
                    <li><a href="#5.5.1.firstcontactwithgrub">5.5.1. Pierwszym kontakt z GRUB</a></li>
                    <li><a href="#5.5.2.grubinstallationinbiosmode">5.5.2. Instalacja GRUB w trybie BIOS</a></li>
                    <li><a href="#5.5.3.grubinstallationinefimode">5.5.3. Instalacja GRUB w trybie UEFI</a></li>
                    <li><a href="#5.5.4.changegruborder">5.5.4. Zmiana kolejności w menu GRUB</a></li>
                  </ul></li>
                <li><a href="#5.6.usagerefindasbootmanager">5.6. Wykorzystanie rEFInd jako menedżer rozruchu.</a></li>
              </ul></li>
            <li><a href="#6.startinguserspace">6. Uruchamianie przestrzeni użytkownika</a>
              <ul class="toc">
                <li><a href="#6.1.initprocess">6.1. Proces init</a></li>
                <li><a href="#6.2.runlevels">6.2. Poziomy uruchomienia</a></li>
                <li><a href="#6.3.initidentify">6.3. Rozpoznawanie programu typu init</a></li>
                <li><a href="#6.4.introductiontochoosedinitprograms">6.4. Wprowadzenie do wybranych programów typu init</a>
                  <ul class="toc">
                    <li><a href="#6.4.1.systemd">6.4.1. Systemd</a></li>
                    <li><a href="#6.4.2.sysvinit">6.4.2. Proces typu init w stylu System V</a></li>
                  </ul></li>
                <li><a href="#6.5.shutdownthesystem">6.5. Wyłączenie systemu</a></li>
                <li><a href="#6.6.initramfs">6.6. Początkowy system plików w pamięci RAM</a></li>
                <li><a href="#6.7.oneusermode">6.7. Tryb jednego użytkownika</a></li> 
              </ul></li>
              <li><a href="#7.systemconfigurationandusers">7. Konfiguracje systemowe oraz użytkownicy</a>
              <ul class="toc">
                <li><a href="#7.1.etcdirectory">7.1. Katalog /etc</a></li>
                <li><a href="#7.2.syslog">7.2. syslog</a></li>
                <li><a href="#7.3.userconfig">7.3. Konfiguracja użytkowników</a>
                  <ul class="toc">
                    <li><a href="#7.3.1.passwdfile">7.3.1. Plik /etc/passwd</a></li>
                    <li><a href="#7.3.2.shadowfile">7.3.2. Plik /etc/shadow</a></li>
                    <li><a href="#7.3.3.changingusers">7.3.3. Manipulowanie użytkownikami i hasłami</a></li>
                    <li><a href="#7.3.4.groups">7.3.4. Grupy</a></li>
                  </ul>
                </li>
                <li><a href="#7.4.gettyandlogin">7.4. Getty oraz login</a></li>
                <li><a href="#7.5.time">7.5. Ustawienia czasu.</a>
                  <ul class="toc">
                    <li><a href="#7.5.1.timezonesandtimerepresentation">7.5.1. Strefy czasowe i reprezentacja czasu</a></li>
                    <li><a href="#7.5.2.settingntptime">7.5.2. Czas sieciowy</a></li>
                  </ul>
                </li>
                <li><a href="#7.6.cron">7.6. Tworzenie powtarzalnych zadań za pomocą cron</a>
                  <ul class="toc">
                    <li><a href="#7.6.1.instalationofcrontab">7.6.1. Instalacja tablicy cron.</a></li>
                    <li><a href="#7.6.2.systemwidecrontab">7.6.2. Systemowa tablica zadań crontab.</a></li>
                    <li><a href="#7.6.3.futureofcron">7.6.3. Przysłość narzędzia cron.</a></li>
                  </ul>
                </li>
                <li><a href="#7.7.at">7.7. Planowanie jednorazowych zadań.</a></li>
                <li><a href="#7.8.switchinguids">7.8. Identyfikatory użytkowników oraz ich przełączanie.</a>
                  <ul class="toc">
                    <li><a href="#7.8.1.processowneranduids">7.8.1. Właściciel procesu oraz identyfikatory użytkownikow</a></li>
                  </ul>
                </li>
                <li><a href="#7.9.identifyandauthtenticate">7.9. Identyfikacja i uwierzytelnianie</a></li>
                <li><a href="#7.10.pamsystem">7.10. System PAM</a>
                  <ul class="toc">
                    <li><a href="#7.10.1.pamconfig">7.10.1. Konfiguracja PAM</a></li>
                    <li><a href="#7.10.2.pamnotices">7.10.2. Uwagi dotyczące PAM</a></li>
                    <li><a href="#7.10.3.pamandpasswords">7.10.3. System PAM i hasła</a></li>
                  </ul>
                </li>
              </ul>
              </li>
              <li><a href="#8.processandresourcemonitoring">8. Procesy oraz monitorowania zasobów</a>
                <ul class="toc">
                  <li><a href="#8.1.processtracking">8.1. Śledzenie procesów</a></li>
                  <li><a href="#8.2.lsof">8.2. Wyszukiwanie otwartych plików z pomocą polecenia lsof</a></li>
                  <li><a href="#8.3.tracingprogramexecutionandsystemcalls">8.3. Śledzenie wykonania programów oraz wywołań systemowych</a>
                    <ul class="toc">
                      <li><a href="#8.3.1.stracecommand">8.3.1. Polecenie strace</a></li>
                      <li><a href="#8.3.2.ltracecommand">8.3.2. Polecenie ltrace</a></li>
                    </ul>
                  </li>
                  <li><a href="#8.4.threads">8.4. Wątki</a>
                    <ul class="toc">
                      <li><a href="#8.4.1.oneormultithreadprocess">8.4.1. Procesy jedno oraz wielowątkowe</a></li>
                      <li><a href="#8.4.2.displaingthreads">8.4.2. Wyświetlanie wątków.</a></li>
                    </ul>
                  </li>
                  <li><a href="#8.5.resourcemonitoring">8.5. Monitorowanie zasobów</a></li>
                  <li><a href="#8.6.measuringprocessorusage">8.6. Pomiar czasu procesora</a></li>
                  <li><a href="#8.7.processprioritization">8.7. Priorytetyzacja procesów</a></li>
                  <li><a href="#8.8.loadaverages">8.8. Średnie obciążenia</a></li>
                  <li><a href="#8.9.operating memory">8.9. Pamięc</a>
                    <ul class="toc">
                      <li><a href="#8.9.1.memorymanagement">8.9.1. Zarządzenie pamięcią</a></li>
                      <li><a href="#8.9.2.pageserrors">8.9.2. Błędy stron</a></li>
                    </ul>
                  </li>
                  <li><a href="#8.10.vmstat">8.10. Monitorowanie wydajności za pomocą polecenia vmstat</a></li>
                  <li><a href="#8.11.iomonitoring">8.11. Monitorowanie operacji wejścia-wyjścia</a>
                    <ul class="toc">
                      <li><a href="#8.11.1.iostat">8.11.1. Polecenie iostat</a></li>
                      <li><a href="#8.11.2.iotop">8.11.2. Polecenie iotop</a></li>
                    </ul>
                  </li>
                  <li><a href="#8.12.pidstat">8.12. Monitorowanie procesów za pomocą narzędzia pidstat</a></li>
                  <li><a href="#8.13.extrainfo">8.13. Informacje dodatkowe</a></li>
                </ul>
              </li>
              <li><a href="#9.network">9. Sieć</a>
                <ul class="toc">
                  <li><a href="#9.1.networkbasics">9.1. Podstawy sieci</a>
                    <ul class="toc">
                      <li><a href="#9.1.1.packages">9.1.1. Pakiety</a></li>
                      <li><a href="#9.1.2.tcpstack">9.1.2. Stos TCP/IP</a></li>
                    </ul>
                  </li>
                  <li><a href="#9.2.networklayer">9.2. Warstwa sieciowa</a>
                    <ul class="toc">
                      <li><a href="#9.2.1.ipaddresses">9.2.1. Adresacja IP</a></li>
                      <li><a href="#9.2.2.routingtable">9.2.2. Routowanie oraz tabela routingu</a></li>
                      <li><a href="#9.2.3.defaultgateway">9.2.3. Brama domyślna</a></li>
                    </ul>
                  </li>
                  <li><a href="#9.3.ipv6">9.3. Adres IPv6</a>
                    <ul class="toc">
                      <li><a href="#9.3.1.showipv6">9.3.1. Wyświetletnie adresów IPv6</a></li>
                    </ul>
                  </li>
                  <li><a href="#9.4.basictoolkiticmpanddns">9.4. Podstawowe narzędzia ICMP oraz DNS</a>
                    <ul class="toc">
                      <li><a href="#9.4.1.ping">9.4.1. Narzędzie ping</a></li>
                      <li><a href="#9.4.2.host">9.4.2. Narzędzie host</a></li>
                    </ul>
                  </li>
                  <li><a href="#9.5.ethernet">9.5. Warstwa fizyczna</a></li>
                  <li><a href="#9.6.kernelnetworkinterfaces">9.6. Sieciowe interfejsy jądra</a></li>
                  <li><a href="#9.7.interfaceconfig">9.7. Konfiguracja interfejsu sieciowego</a>
                    <ul class="toc">
                      <li><a href="#9.7.1.manualifconf">9.7.1. Ręczna konfiguracja interfejsu</a></li>
                    </ul>
                  </li>
                  <li><a href="#9.8.networkifacebootconfig">9.8. Konfiguracja interfejsów sieciowych podczas rozruchu</a></li>
                  <li><a href="#9.9.networkconfigmanagers">9.9. Menedżery konfiguracji sieciowe</a>
                    <ul class="toc">
                      <li><a href="#9.9.1.interactionwithnm">9.9.1. Interakcja z Network Manager</a></li>
                      <li><a href="#9.9.2.nmconfiguration">9.9.2. Konfiguracja NetworkManager</a></li>
                    </ul>
                  </li>
                  <li><a href="#9.10.nameresolution">9.10. Rozwiazywanie nazw hostów.</a>
                    <ul class="toc">
                      <li><a href="#9.10.1.dnsfiles">9.10.1. Pliki biorące udział w działaniu systemu DNS</a></li>
                      <li><a href="#9.10.2.configlessdnsandcache">9.10.2. Buforowanie oraz bezkonfiguracyjne systemy DNS</a></li>
                    </ul>
                  </li>
                  <li><a href="#9.11.localhost">9.11. Host lokalny</a></li>
                  <li><a href="#9.12.transportlayer">9.12. Warstwa transportowa oraz usługi</a>
                    <ul class="toc">
                      <li><a href="#9.12.1.tcp">9.12.1. TCP - Transmission Control Protocol</a></li>
                      <li><a href="#9.12.2.udp">9.12.2. UDP - User Datagram Protocol</a></li>
                      <li><a href="#9.12.3.ports">9.12.3. Porty</a></li>
                      <li><a href="#9.12.4.printconnections">9.12.4. Wyświetlanie połączeń sieciowych w systemie</a></li>
                    </ul>
                  </li>
                  <li><a href="#9.13.dhcp">9.13. Protokół dynamicznej konfiguracji hosta - DHCP</a></li>
                  <li><a href="#9.14.linuxasrouter">9.14. Konfiguracja systemu Linux jako router</a>
                    <ul class="toc">
                      <li><a href="#9.14.1.linuxdistroforrouters">9.14.1. Oprogramownie główne</a></li>
                      <li><a href="#9.14.2.additionalsoftware">9.14.2. Oprogramowanie dodatkowe</a></li>
                      <li><a href="#9.14.3.linuxrouterconfig">9.14.3. Konfiguracja dystrybucji jako router</a></li>
                    </ul>
                  </li>
                  <li><a href="#9.15.ipoverethernet">9.15. Sieci IP oparte na Ethernet. Protokół ARP i NDP</a></li>
              </ul>
            </li>
            <li><a href="#10.applicationlayer">10. Warstwa aplikacji - usługi sieciowe</a>
              <ul class="toc">
                <li><a href="#10.1.httpanalysis">10.1. Analiza HTTP</a></li>
                <li><a href="#10.2.networkservers">10.2. Serwery sieciowe</a></li>
                <li><a href="#10.3.openssh">10.3. Serwer bezpiecznej powłoki - implementacja openssh</a>
                  <ul class="toc">
                    <li><a href="#10.3.1.sshcommand">10.3.1. Aplikacja klienta - polecenie ssh</a></li>
                    <li><a href="#10.3.2.sshd">10.3.2. Demon serwera - sshd</a></li>
                    <li><a href="#10.3.3.fail2ban">10.3.3. Zabezpieczenie fail2ban</a></li>
                    <li><a href="#10.3.4.othersshusage">10.3.4. Pozostałe metody użycia SSH</a></li>
                  </ul>
                </li>
                <li><a href="#10.4.inetd">10.4. Demony internetowe - inetd, xinetd</a></li>
                <li><a href="#10.5.diagnostictools">10.5. Narzędzia diagnostyczne</a>
                  <ul class="toc">
                    <li><a href="#10.5.1.lsofcommand">10.5.1. Polecenie lsof</a></li>
                    <li><a href="#10.5.2.tcpdump">10.5.2. tcpdump</a></li>
                    <li><a href="#10.5.3.netcat">10.5.3. Program netcat</a></li>
                    <li><a href="#10.5.4.nmap">10.5.4. Program nmap - skanowanie portów</a></li>
                  </ul>
                </li>
                <li><a href="#10.6.rpc">10.6. Zdalne wywołanie procedury - RPC</a></li>
                <li><a href="#10.7.networksecurity">10.7. Zabezpieczenie sieci</a>
                  <ul class="toc">
                    <li><a href="#10.7.1.usualsecuritythreads">10.7.1. Typowe zagrożenia</a></li>
                  </ul>
                </li>
                <li><a href="#10.8.netsockets">10.8. Gniazda sieciowe</a></li>
                <li><a href="#10.9.unixsockets">10.9. Gniazda uniksowe</a></li>
              </ul>
            </li>
           <li><a href="#11.networkfilesharing">11. Udostępnianie plików w sieci</a>
              <ul class="toc">
                <li><a href="#11.1.simplehttp">11.1. Proste udostępnienie z pośrednictwem WWW</a></li>
                <li><a href="#11.2.remotesync">11.2. Synchronizacja katalogu zdalnego - program rsync</a></li>
                <li><a href="#11.3.filesharingentrance">11.3. Wprowadzenie do udostępniania plików</a></li>
                <li><a href="#11.4.samba">11.4. Współdzielenie plików między wszystkimi platformami</a>
                  <ul class="toc">
                    <li><a href="#11.4.1.generalsambaconfig">11.4.1. Ogólna konfiguracja serwera Samba</a></li>
                    <li><a href="#11.4.2.sambaauthconfig">11.4.2. Konfiguracja uwierzytelniania użytkowników na serwerach Samba</a></li>
                    <li><a href="#11.4.3.sambasharedcatalogs">11.4.3. Współdzielenie katalogów - udziały Samby</a></li>
                    <li><a href="#11.4.4.sambaprinters">11.4.4. Współdzielenie drukarek przy użyciu pakietu Samba</a></li>
                    <li><a href="#11.4.5.addingsambausers">11.4.5. Dodawanie użytkowników Samby</a></li>
                    <li><a href="#11.4.6.sambashareusage">11.4.6. Użycie protokołu samby</a></li>
                  </ul>
                </li>
                <li><a href="#11.5.sshfs">11.5. Bezpieczenie współdzielenie plików - SSHFS</a></li>
                <li><a href="#11.6.nfs">11.6. Współdzielenie plików między dwoma Uniksami</a></li>
                <li><a href="#11.7.currentmethodsoffilesharing">11.7. Jak wygląda współdzielenie plików dzisiaj?</a></li>
              </ul>
            </li>
          <li><a href="#12.userenv">12. Konfiguracja środowiska użytkownika</a>
            <ul class="toc">
              <li><a href="#12.1.shellsmode">12.1. Rodzaje powłok</a></li>
              <li><a href="#12.2.userenvfiles">12.2. Pliki środowiska użytkownika</a></li>
              <li><a href="#12.3.extendinguserenv">12.3. Rozszerzenie domyślnego środowiska użytkownika</a></li>
            </ul>
          </li>
          <li><a href="#13.userinterface">13. Interfejs użytkownika i drukowanie</a>
            <ul class="toc">
              <li><a href="#13.1.uimajorelements">13.1. Elementy składowe interfejsu graficznego</a>
                <ul class="toc">
                  <li><a href="#13.1.1.framebuffer">13.1.1. Bufory ramki</a></li>
                  <li><a href="#13.1.2.displayingmethods">13.1.2. Mechnizm wyświetlania</a></li>
                  <li><a href="#13.1.3.windowmanager">13.1.3. Mendżery okien</a></li>
                  <li><a href="#13.1.4.graphicalinterfacelibrary">13.1.4. Biblioteki interfejsu graficznego</a></li>
                  <li><a href="#13.1.5.graphicaluserinterfaces">13.1.5. Graficzny interfejs użytkownika</a></li>
                  <li><a href="#13.1.6.guiapps">13.1.6. Aplikacje</a></li>
                </ul>
              </li>
              <li><a href="#13.2.determinigdisplayserwer">13.2. Określenie mechanizmu wyświetlania</a></li>
              <li><a href="#13.3.waylandprotocol">13.3. Protokół Wayland</a>
                <ul class="toc">
                  <li><a href="#13.3.1.compositionmanager">13.3.1. Menedżer kompozycji</a></li>
                  <li><a href="#13.3.2.libinput">13.3.2. Biblioteka libinput</a></li>
                  <li><a href="#13.3.3.waylandcompatibiltywithX">13.3.3. Zgodność Wayland z system X Window</a></li>
                </ul>
              </li>
              <li><a href="#13.4.xwindow">13.4. System X Window</a>
                <ul class="toc">
                  <li><a href="#13.4.1.displaymanagers">13.4.1. Menedżery wyświetlaczy</a></li>
                  <li><a href="#13.4.2.xwindownetworking">13.4.2. Właściwości sieciowe serwera X Window</a></li>
                  <li><a href="#13.4.3.xwindowclients">Przegląd klientów X Window</a></li>
                  <li><a href="#13.4.4.xwindowevents">13.4.4. Zdarzenia serwera X</a></li>
                  <li><a href="#13.4.5.settingxwindowpreferences">13.4.5. Ustawianie preferencji i dane wejściowe serwera X</a></li>
                </ul>
              </li>
              <li><a href="#13.5.d-busservice">13.5. Usługa D-Bus</a>
                <ul class="toc">
                  <li><a href="#13.5.1.systemandsessiond-businstance">13.5.1. Instancja systemowa oraz instancja sessji</a></li>
                  <li><a href="#13.5.2.d-busservicemessagesmonitoring">13.5.2. Monitorowanie komunikatów usługi D-Bus</a></li>                                                                                                                       </ul>
              </li>
              <li><a href="#13.6.printing">13.6. Drukowanie</a>
                <ul class="toc">
                  <li><a href="#13.6.1.cups">13.6.1. CUPS</a></li>
                  <li><a href="#13.6.2.conversionsandprintfilters">13.6.2. Konwersja formatów i filtry wydruku</a></li>
                </ul>
              </li>
            </ul>
           </li>
          <li><a href="#14.programmingtools">14. Narzędzia programistyczne</a>
            <ul class="toc">
              <li><a href="#14.1.ccompiler">14.1. Kompilator języka C</a>
                <ul class="toc">
                  <li><a href="#14.1.1.amanyfilecompilation">14.1.1. Kompilowanie wielu plików źródłowych</a></li>
                  <li><a href="#14.1.2.linkingwithlibs">14.1.2. Konsolidacja z bibliotekami</a></li>
                  <li><a href="#14.1.3.sharedlibraries">14.1.3. Biblioteki współużytkowane</a></li>
                  <li><a href="#14.1.4.headersfiles">14.1.4. Pliki nagłówkowe</a></li>
                </ul>
              </li>
              <li><a href="#14.2.make">14.2. Narzędzie make</a>
                <ul class="toc">
                  <li><a href="#14.2.1.examplemakefile">14.2.1. Przykładowy plik Makefile</a></li>
                  <li><a href="#14.2.2.updatemakedeps">14.2.2. Aktualizacjia zależności</a></li>
                  <li><a href="#14.2.3.makecommandargs">14.2.3. Argumenty i opcje wiersza poleceń programu make</a></li>
                  <li><a href="#14.2.4.makestdmacrosandvars">14.2.4. Standardowe makra i zmienne</a></li>
                  <li><a href="#14.2.5.makecommoncomptarget">14.2.5. Typowe cele kompilacji</a></li>
                  <li><a href="#14.2.6.makefilesstyles">14.2.6. Organizowanie pliku Makefile</a></li>
                </ul>
              </li>
              <li><a href="#14.3.lexandyacc">14.3. Lex i Yacc</a></li>
              <li><a href="#14.4.scriptlanguages">14.4. Języki skryptowe</a></li>
              <li><a href="#14.5.java">14.5. Język Java</a></li>
            </ul>
           </li>
           <li><a href="#15.introducingtoccsourcecodesoftware">15. Wprowadzenie do kompilacji oprogramowania kodu źródłowego C</a>
            <ul class="toc">
              <li><a href="#15.1.softwarebuildsystems">15.1. Systemy do budowania oprogramowania</a></li>
              <li><a href="#15.2.sourcecodeunpack">15.2. Rozpakowywanie kodu źródłowego.</a></li>
              <li><a href="#15.3.gnuautconf">15.3. GNU autoconf</a>
                <ul class="toc">
                  <li><a href="#15.3.1.sampleusageofgnuautoconf">15.3.1. Przykładowe użycie systemu GNU autoconf</a></li>
                  <li><a href="#15.3.2.installationviapackagestool">15.3.2. Instalacja za pomocą narzędzia do tworzenia pakietów</a></li>
                  <li><a href="#15.3.3.configureoptions">15.3.3. Opcje skyptu configure</a></li>
                  <li><a href="#15.3.4.configureenv">15.3.4. Zmienne środowiskowe</a></li>
                  <li><a href="#15.3.5.gnuautoconfcreatedtargets">15.3.5. Cele tworzone przez GNU autoconf</a></li>
                  <li><a href="#15.3.6.gnuautoconflogfile">15.3.6. Plik dziennika systemu GNU autoconf</a></li>
                  <li><a href="#15.3.7.pkg-configtool">15.3.7. Narzędzie pkg-config</a></li>
                </ul>
              </li>
              <li><a href="#15.4.manualinstallationprosandcons">15.4. Zalety i wady ręcznej instalacji</a></li>
              <li><a href="#15.5.usingpatches">15.5. Stosowanie poprawek</a></li>
            </ul>
           </li>
           <li><a href="#16.virtualisation">16. Wirtualizacja</a>
              <ul class="toc">
                <li><a href="#16.1.virtualmachines">16.1. Maszyny wirtualne</a>
                  <ul class="toc">
                    <li><a href="#16.1.1.hypervisors">16.1.1 Hipernadzorcy</a></li>
                    <li><a href="#16.1.2.vmhardware">16.1.2. Sprzęt maszyny wirtualnej</a></li>
                    <li><a href="#16.1.3.vmusege">16.1.3. Użycie maszyn wirtualnych</a></li>
                  </ul>
                </li>
                <li><a href="#16.2.containers">16.2. Kontenery</a>
                <ul class="toc">
                  <li><a href="#16.2.1.dockerandpodman">16.2.1. Docker i Podman</a></li>
                  <li><a href="#16.2.2.dockerusage">16.2.2. Użycie Dockera</a></li>
                  <li><a href="#16.2.3.lxc">16.2.3. LXC</a></li>
                </ul>
                </li>
                <li><a href="#16.3.venv">16.3. Wirtualizacja oparta na środowisku uruchomieniowym</a></li>
              </ul>
            </li>
            <li><a href="#17.summary">Podsumowanie</a>
              <ul class="toc">
                <li><a href="#17.1.whatnext">17.1. Co dalej?</a></li>
              </ul>
            </li>
            <li><a href="#18.appendixa">18. Dodatek A. Podstawy programowania skryptów w powłoce BASH</a>
              <ul class="toc">
                <li><a href="#18.1.bashscriptsbasics">18.1. Podstawy tworzenia skryptów</a>
                  <ul class="toc">
                    <li><a href="#18.1.1.beginingofscript">18.1.1. Początek skryptu</a></li>
                    <li><a href="#18.1.2.simplescript">18.1.2. Prosty skrypt.</a></li>
                    <li><a href="#18.1.3.runascript">18.1.3. Uruchomienie skryptu</a></li>
                    <li><a href="#18.1.4.scriptdebug">18.1.4. Debugowanie skryptów.</a></li>
                  </ul>
                </li>
                <li><a href="#18.2.basicshellinstructions">18.2. Podstawowe instrukcje powłoki.</a>
                  <ul class="toc">
                    <li><a href="#18.2.1.variables">18.2.1. Zmienne</a></li>
                    <li><a href="#18.2.2.comments">18.2.2. Komentarze</a></li>
                    <li><a href="#18.2.3.pipelines">18.2.3. Potoki</a></li>
                    <li><a href="#18.2.4.commandsubstitution">18.2.4. Podstawienie polecenia</a></li>
                    <li><a href="#18.2.5.subshellsubstitution">18.2.5. Wyrażenie nawiasów okrągłych</a></li>
                    <li><a href="#18.2.6.quotation">18.2.6. Znaki cytowania</a></li>
                    <li><a href="#18.2.7.positionalparams">18.2.7. Parametry pozycyjne</a></li>
                    <li><a href="#18.2.8.parameterexpression">18.2.8. Wyrażenie parametru</a></li>
                    <li><a href="#18.2.9.exitcode">18.2.7. Exitcode - wartość zwracana przez program</a></li>
                  </ul>
                </li>
                <li><a href="#18.3.condtionalexpressions">18.3. Wyrażenia warunkowe</a>
                  <ul class="toc">
                    <li><a href="#18.3.1.conditionalinstructions">18.3.1. Instrukcje warunkowe</a></li>
                    <li><a href="#18.3.2.if">18.3.2. Konstrukcje warunkowa - if</a></li>
                    <li><a href="#18.3.3.case">18.3.3. Konstrukcja warunkowa - case</a></li>
                  </ul>
                </li>
                <li><a href="#18.4.loops">18.4. Pętle</a>
                  <ul class="toc">
                    <li><a href="#18.4.1.whileloop">18.4.1. Pętla while</a></li>
                    <li><a href="#18.4.2.forloop">18.4.2. Pętla for</a></li>
                    <li><a href="#18.4.3.otherloops">18.4.3. Inne pętle oraz instrukcje sterujące</a></li>
                  </ul>
                </li>
                <li><a href="#18.5.functions">18.5. Funkcje</a>
                  <ul class="toc">
                    <li><a href="#18.5.1.fdefinitionandexecution">18.5.1. Definicja oraz wywołanie funkcji</a></li>
                    <li><a href="#18.5.2.includescripts">18.5.3. Dołączanie plików skryptów</a></li>
                  </ul>
                </li>
                <li><a href="#18.6.otherusefulltools">18.6. Inne przydatne narzędzia</a>                                                                                                                                                                <ul class="toc">
                    <li><a href="#18.6.1.cut">18.6.1 Polecenie cut</a></li>
                    <li><a href="#18.6.2.awk">18.6.2. AWK</a></li>
                    <li><a href="#18.6.3.sed">18.6.3. sed</a></li>
                    <li><a href="#18.6.4.wc">18.6.4. wc</a></li>
                  </ul>
                </li>
                <li><a href="#18.7.summary">18.7. Podsumowanie</a></li>
              </ul>
            </li>
          </ul>
          <p>
            Źródła:
          </p>
          <ol>
            <li><strong>Jak działa Linux.</strong><br />
                Podręcznik administratora. Wydanie II.<br />
                <em>Brian Ward</em></li>
            <li><strong>Jak działa Linux.</strong><br />
                Podręcznik administratora. Wydanie III.<br />
                <em>Brian Ward</em></li>
          </ol>
          <p class="footer">
            ~xf0r3m<br />
            2024; COPYLEFT; ALL RIGHTS REVERSED;
          </p>
        </div>
        <div id="content">
        <div id="contentHeader">
<pre id="divisionBaner">
    __    _                       ____            __     __                      
   / /   (_)___  __  ___  __     / __ \____  ____/ /____/ /_____ __      ____  __
  / /   / / __ \/ / / / |/_/    / /_/ / __ \/ __  / ___/ __/ __ `/ | /| / / / / /
 / /___/ / / / / /_/ />  <_    / ____/ /_/ / /_/ (__  ) /_/ /_/ /| |/ |/ / /_/ / 
/_____/_/_/ /_/\__,_/_/|_(_)  /_/    \____/\__,_/____/\__/\__,_/ |__/|__/\__, (_)
                                                                        /____/   

</pre>
<p id="contentHeaderLink" class="header_link">
	&#9760;&nbsp;<a href="https://morketsmerke.github.io">morketsmerke</a>&nbsp;&#9760;
</p>

        </div>
        <p>
          Opisywany tutaj materiał będzie kompatybilny z dystrybucjami 
          pochodnymi od GNU/Linux Debian zarówno tymi opartymi na 
          <em>systemd</em> jak <em>sysvinit</em> oraz tymi z rodziny
          <em>RHEL</em>/<em>Fedora</em>/<em>CentOS</em>. 
        </p>
        <p>
          GNU/Linux czy raczej sam Linux? Sama nazwa, jest już tematem dość
          kontrowersyjnym. Ludzie związani z projektem GNU twierdzą, że ta
          pierwsza liczba jest właściwa ponieważ wskazuje ona na to, że isotne
          elemnty projektu GNU zostały wykorzystane do stworzenia tego systemu.
          W mowie potocznej jednak przyjęło się użycie tej drugiej nazwy. Jest
          to jedno, łatwe do zapamiętania słowo. Jeśli mówimy następujące
          zdanie wyrażające chęć zainstalowania na jakiejś maszynie omawianego
          tutaj systemu, mówimy że "zainstalujemy jakiegoś Linuksa". Słowo
          "jakiegoś" zostało tu użyte w kontekscie wyboru konkretnej
          dystrybucji. Co to dystrybucja wyjaśnie za chwilę. Bez projektu GNU
          niebyło by Linuksa. Wydaje mi się, że każdy kto jest nieco bardziej
          związany z tym środowiskiem o tym wie. Ja również jestem tego świadom
          dla tego też w tym dokumencie użyje nazwy Linux. Poprostu.
        </p>
        <h1 id="1.howlinuxismade">1. Budowa systemu Linux</h1>
        <p>
          Nie zagłebiając się w szczegóły, to Linux składa się z 
          <strong>jądra</strong> oraz
          <strong>przestrzeni użytkownika</strong>. Oba kompomenty rezydują w 
          pamięci więc
          wiele, nie które teksty popularno-naukowe mogą włączać pamięć lub
          ogólnie sprzęt do składowych systemu operacyjnego Linux, w mojej
          opinii jest raczej cecha wykorzystywanych przez nas komputerów
          konwencjonalnych. 
        </p>
        <p>
          Mówiąc o jądrze możemy wskazać konktretny program, konkretny plik.
          W przypadku przestrzeni użytkownika, w systemie nie istnieje żaden
          namacalny byt cyfrowy jak w przypadku jądra. Przestrzeń użytkownika
          jest bowiem <strong>warstwą abstrakcji</strong> - czyli terminem,
          bądź założeniem wykorzystywanym w celu określenia czynności, funkcji,
          zjawiska bez wdawania się w szczegóły. Przestrzeń użytkownika jest
          miejscem uruchamiania <strong>procesów</strong> użytkownika. Procesy
          to nic innego jak wystąpienia programów uruchomionych przez
          użytkownika. Nie wszystkie procesy są programami użytkownika w
          dosłownym tych słów znaczeniu. Część tych procesów to programy
          wspomagające wykorzystanie komputera i jego zasobów. Bez nich systemy
          operacyjne dalej mogły by spełniać swoją rolę, jednak nie miały by
          powszechnie znanej nam dzisiaj formy. Przestrzeń użytkownika  składa 
          się z wielu ogólno dostępnych kompnentów ich istnienie w danej wersji
          systemu oraz ich konfiguracja sprawia, iż nie mamy doczynienia z
          gotowym jednolitym produktem, ale z dystrybucją. Z jedną z wersji, 
          gdzie ktoś
          wziął jądro, które jest ogolno dostępne i skomponował przestrzeń
          użytkownika. Obecnie na rynku mamy dostępnych ok. 600 dystrybucji.
          Wiekszość z nich to pochodne innych, oryginalnych rozwiązań
          rozwijanych przez setki osób na całym świecie. Kilka takich głównych
          dystrybucji, znajduje się w tabeli poniżej. Przejrzałem większość z
          nich, a z częsci osobiście korzystałem. 
        </p>
        <table border="1">
          <thead>
            <th>Logo</th>
            <th>Nazwa</th>
            <th>Opis</th>
          </thead>
          <tbody>
            <tr>
              <td><img src="https://i.ibb.co/GspTqqK/linux-mint-logo32.png" alt="linux-mint-logo32" border="0"></td>
              <td>Linux Mint</td>
              <td>
                Dystrybucja bardzo przyjazna użytkownikowi. Wykorzystywana 
                przez nowych niedoświadczonych użytkowników system Linux. 
                Pod czas
                instalacji mogą być instalowane nie wolne moduły oraz nie
                wolne oprogramownie. Jej głównym zadaniem jest sprzyjanie
                użytkownikowi i umożliwienie mu wykorzystanie Linuksa przy
                codziennym wykorzystaniu komputera. Mint rozwijany jest przez
                społeczność zebraną wokół niego.
              </td>
            </tr>
            <tr>
              <td><img src="https://i.ibb.co/ckrkfjX/ubuntu-logo32.png" alt="ubuntu-logo32" border="0"></td>
              <td>Ubuntu</td>
              <td>
                  Podobnie jak Linux Mint, Ubuntu również jest skierowane dla
                  osób ceniących sobie wygodne i prostę rozwiązania. Jest
                  przyjazna użytkownikowi, ma nieco bardziej konserwatywne
                  podejście do ideii wolnego oprogramowania, jądro może
                  zawierać nie wolne moduły, jednak zamknięte oprogramowanie
                  nie jest domyślnie instalowane. Ubuntu rozwijane jest przez 
                  firmę
                  Canonical. Jej technologię są wdrażane do Ubuntu, dzięki
                  czemu może ona uchdzić za system klasy <em>enterprise</em> 
                  wśród
                  dystrybucji opartych o GNU/Linux Debian. Poza wersją na
                  komputery biurkowe istnieją również wersja skierowana
                  na serwery oraz inne wersje z preinstalowanymi różnymi
                  środowiskami graficznymi czy wersja skierowana do obróbki
                  multimediów zawierająca pozwalające do tego oprogramowanie.
                  Społeczność zebrana
                  wokół systemu Linux zarzuca jej siłowe próby wdrożenia
                  manedżera oprogramowania <em>Snap</em>, rozwijanego przez tę 
                  firmę
                  przez co może ona pretendować do stopniowego zarzucenia
                  klasycznego schematu dystrybucji pakietów rozwijanego wraz
                  z GNU/Linux Debian.
              </td> 
            </tr>
            <tr>
              <td><img src="https://i.ibb.co/v4026kk/fedora-logo32.png" alt="fedora-logo32" border="0"></td>
              <td>Fedora Linux</td>
              <td>
                  Fedora jest dystrybucją skierowaną do różnej maści
                  użytkowników, ponieważ istnieje w kilku głównych wersjach.
                  oraz wiele wersji pobocznych tzw. <em>spins</em>. Fedora ma
                  najprzyjźniejszy instalator chyba ze wszystkich możliwych
                  dystrybucji. Wymaga on głównie wybrania miejsca instalacji
                  i kliknięcia przycisku dalej. Fedora została stworzona i jest
                  rozwiajana przez firme Red Hat Inc. (obecnie IBM) jako
                  <em>upstream</em> (poligon doświadczalny dla zmian), dla 
                  glównego produktu tej firmy Red Hat Enterprise Linux - 
                  płatnej dystrybucji skierowanej do środowisk produkcyjnych 
                  (100$ rocznie). Jest to system o dużej stabilości ze
                  wsparciem dla najnowszego sprzetu. Fedora również
                  charakteryzuje się wprowadzeniej jako pierwsza środowiska
                  GNOME w najnowszej wersji 41 oraz innych nowych technologi
                  wśród otwartego oraz wolnego oprogramowania. 
              </td>
            </tr>
            <tr>
              <td><img src="https://i.ibb.co/Q965txs/debian-logo32.png" alt="debian-logo32" border="0"></td>
              <td>GNU/Linux Debian</td>
              <td>
                  Debian jest jedną z pierwszy dostępnych dystrybucji, początek
                  jej istnienia jest datowany na 1993 rok. Dystrybucja 
                  konserwatywna, posiadała w pierwszych latach swojego 
                  istnienia aprobatę FSF (Free Software Fundation). Jednak
                  została ona wycofana, za zezwolenie na instalację zamkniętego
                  oprogramowania. Kernel przygotowywany przez twórców tej
                  dystrybucji pozbawiony jest tzw. blobów binarnych (nie
                  wolnych prekompilowanych modułów, używanych przy budowaniu
                  jądra.) Bloby najczęściej dotyczą sterowników sprzętu.
                  Dystrybucja charkteryzuje się wysoką stabilnościa
                  porównywalną z RHEL, wsparciem dla starszego sprzętu. Jedną
                  z cech, która może odstraszać potencjalnych użytkowników
                  od niej jest długi cykl wydawniczy (co dwa lata) oraz
                  używanie sprawdzone oprogramowania czy technologii (pozostaje
                  dość mocno w tyle jeśli chodzi o najnowsze wersje
                  oprogramowania). Wydaje mi się, że niema
                  stabilniejszego gotowego rozwiązania niż GNU/Linux Debian.
                  Debian wymaga nieco większego zaawansowania niż dystrybucje
                  podane do tej pory. Stosowany jest częściej w środowiskach
                  produkcyjnych niż np. Ubuntu. Rozwój Debiana opiera się
                  na zaangażowaniu społeczności z całego świata.
              </td>
            </tr>
            <tr>
              <td><img src="https://i.ibb.co/MpCcKqy/arch-linux-logo32.png" alt="arch-linux-logo32" border="0"></td>
              <td>Arch Linux</td>
              <td>
                  Dystrybucja skierowana do zaawansowanych użytkowników.
                  Charakteryzuje się wysoką konfigurowalnością oraz
                  dostępnością najnowszych wersji oprogramowania. Nie posiada
                  oficjalnego instalatora, choć można pobrać skrypt z sieci.
                  Instalacji dokonuj się ręcznie, wpisującac kolejne polecenia
                  z podręcznika instalacji w środowisku LiveCD, gdzie
                  przygotowuje się dysk, pobiera się pakiety i je konfiguruje.
                  Instalacja i konfiguracji Arch Linux nie jest tak
                  pracochłonna jak innych dystrybucji, można by powiedzieć,
                  meta-dystrybucji. Dość ciekawą cechą jest społeczność zebrana
                  wokół niej, która przechwalająca się swoją wyższością na
                  innymi (ponieważ przebrneli przez proces instalacji) 
                  używając frazy "I use Arch BTW.". Dystrybucja rozwijana
                  jest przez społeczność na całym świecie.
              </td>
            </tr>
            <tr>
              <td><img src="https://i.ibb.co/vz98yMx/void-linux-logo32.png" alt="void-linux-logo32" border="0"></td>
              <td>Void Linux</td>
              <td>
                  Nie zależna dystrybucjna, trochę odmienna od inny dystrybucji
                  głównego nurtu. Systemd zastąpiono programem <em>runit</em>,
                  zamiast OpenSSL, użyto projektu OpenBSD LibreSSL jak jedyna
                  z dystrybucji Linuksa. Kernel Void-a pozbawiony jest blobów,
                  a domyślna instalacja zawiera tylko wolne oprogramowanie,
                  posiada on jednak oficjalne repozytorium z zamkniętym
                  oprogramowaniem. Instalacja pakietów opiera się stworzonym
                  dla Void menedżerze pakietów XBPS. Pakiety są wydawane stylu
                  <em>rolling release</em>, co daje szybkie i stabline
                  aktualizacje. Obok standardowej biblioteki języka C -
                  GNU libc, mamy również bibliotekę <em>musl</em>. Za pomoca
                  programu <em>xbps-src</em> możemy tworzyć z kodu źródłowego
                  własne pakiety XBPS. 
              </td>
            </tr>
            <tr>
              <td><img src="https://i.ibb.co/0QsPfPh/gentoo-linux-logo32.png" alt="gentoo-linux-logo32" border="0"></td>
              <td>Gentoo Linux</td>
              <td>
                  Gentoo jest dystybucją na tyle zaawansowaną, że można by się
                  pokusić o nazwanie jej meta-dystrybucją. Jest ona bowiem
                  jedną z najbardziej konfigurowalnych dystrybucji. Jedną z
                  ciekawszych czynności, jakie należy wykonać podczas
                  instalacji, to ręczna kompliacja jądra. Dystrybucja
                  skierowana do jeszcze bardziej zaawansowanych użytkowników
                  niż w przypadku Arch Linux. Instalacja Gentoo na maszynie
                  wirtualnej wraz z poradnikiem, zajeło mi to jakieś dwie
                  godziny. 
              </td>
            </tr>
            <tr>
              <td><img src="https://i.ibb.co/hKwFYQh/lfs-logo32.jpg" alt="lfs-logo32" border="0"></td>
              <td>Linux from scratch</td>
              <td>
                  LFS to w zasadzie projekt, a niżejli sama dystrybucja.
                  Umożliwia on stworzenie oraz skonfigurowanie własnej
                  dystrybucji. Na stronie projektu zawarte są wskazówki, co
                  należy zrobić, aby stworzyć rozwiązanie najbardziej
                  elastyczne dla siebie. LFS z pewnością może nosić miano
                  meta dystrybucji.
              </td>
            </tr>
          </tbody>
        </table> 
        <p>
          W powyższej tabeli przedstawiłem  dystrybucje, na które
          warto zwrócić uwagę. Teraz prawdopodobnie czekać będzie Cię duży
          dylemat, którą wybrać. W pierwszej kolejności ważny jest sprzęt,
          na którym będziemy z tego systemu korzystać. Część sprzętu, 
          z którego chcemy korzystać może 
          nie działać <em>out of box</em>, wowczas potrzebne będą sterowniki,
          które mogą być własnościowe (nie wolne, generalnie być zamkniętym 
          oprogramowaniem), jeśli zależy nam na prywatności, to lepiej upewnić
          się z jakiego rodzaju sprzętem będzie mieć doczynienia, ponieważ 
          każde zamknięte oprogramowanie można teoretycznie uznać za
          oprogramowanie szkodliwe. Dobrym wyborem może być zakup Thinkpada z
          przed 2008 roku. Wówczas będziemy mogli bez obaw wybrać Debiana i
          zainstalować np. XFCE (to dość lekkie środowisko graficzne, nadające
          się do codziennej pracy, bez zniechęcania się). Kolejną rzeczą do
          wyboru dystrybucji jest zapał do pracy. Mimo iż opisując dystrybucje
          napisałem że ta jest dla początkujących, a ta dla zaawansowanych to 
          żadna z
          nich nie jest ani dla jednych ani dla drugich. Obsługa czego kolwiek
          związanego z komputerami wymaga przeczytania dokumentacji ze
          zrozumieniem i umiejętności radzenie sobie z ewentualnymi problemami.
          Dlatego dlaczego by nie wybrać Gentoo, zainstalować go 
          z poradnikiem, skonfigurować, a wrazie problemów użyć Googla, lub
          poprość kogoś ze społeczności o pomoc.  
        </p>
        <p>
          Dość częstym zjawiskiem, wśród społeczności użytkowników Linuksa jest
          tzw. <em>distro-hopping</em>, czyli przesiadanie się z jednej
          dystrybucji na drugą. Jest to normalne zjawisko, chciaż można
          powszechną opinia jego jest raczej negatywna, głównym argumentem
          oponetów jest stwierdzenie, że przez to nie uczymy się niczego. Moim
          zdaniem, możemy dojść do wniosku, że tak naprawdę nie ma dystrybucji
          tylko produkt w ciągłej ewolucji z dostępnym takim a takim
          oprogramowaniem. Nie mam mendżera pakietów, mam program do instalacji
          i konfiguracji oprogramowania, nieważne czy jest apt, dnf, yum czy
          pacman. Mam stronę podręcznika i znajduj sobie potrzebne opcje. Mam
          dostęp do internetu, i wystarczy wyszukać konkretną potrzebną 
          czynność np.: "Remove packages with all dependencies pacman". I mam
          gotowy wynik. Wiele miesięcy błądziłem słuchając mendrców jak RMS
          (<em>Richard Matthew Stallman</em>). Myślcie samodzielnie, 
          przeskakujcie z distro na distro i bawcię się dobrze.
        </p>
        <h2 id="1.1.hardware">1.1. Sprzęt</h2>
        <p>
          Sprzęt sam w sobie nie mozę wchodzić z skład systemu operacyjnego,
          to jego elementy jak pamieć operacyjna, procesor czy pamięć masowa
          odgrywają w nim bardzo ważna rolę.
        </p>
        <h3 id="1.1.1.ram">1.1.1. Pamięć operacyjna</h3>
        <p>
          W działaniu systemów operacyjnych takich jak Linux, najważniejszym
          komponentem sprzętowym może być pamięć operacyjna, ponieważ to w
          niej rezyduje jądro oraz przestrzeń użytkownika. Dane zapisane w
          pamięci nie są niczym innym jak zbiorem zer i jedynek określanych
          mianem <strong>bitów</strong> (najmniejsze przetwarzanej ilości
          informacji). Procesy oraz jądro są jednymi z takich zbiorów. Takie
          zbiory określa się mianem <strong>obrazu</strong>. 
        </p>
        <h2 id="1.2.kernel">1.2. Jądro</h2>
        <p>
          Jądro Linux jest to nadrzędy proces w całym systemie, realizuje swoje
          działania w czterech obszarch funkcjonalności systemu operacyjnego.
        </p>
        <ul>
          <li><strong>Zarządzanie procesami</strong> - jądro jest
            odpowiedzialne za uruchamianie, wstrzymywanie, ponowne uruchomienie
            oraz kończenie pracy procesów. Korzystając ze współczesnych
            systemów operacyjnych możemy mieć wrażenie uruchomione przez nas
            programy (a co za tym idzie ich procesy) mogą działać jednocześnie.
            Dzieje się tak dlatego, iż jądro uruchamia kod procesu na ułamek
            sekundy, po upłynięciu danego przez jądro <strong>wycinka czasu</strong>
            stan procesora wykonującego kod danego procesu zapisywany jest
            w pamięci, a jądro wybiera kolejny proces i ładuje stan procesora
            po czym wznawia jego wykonanie. Tych czynności jest znacznie więcej
            zostało tu wymionionych. Te
            czynności nazywane są <strong>przełączaniem kontekstu</strong>.
            Na współczesnych procesorach dzieje się to tak szybko, że możemy
            mieć złudzenie <strong>wielozadaniowości</strong>. W przypadku 
            maszyn wielordzeniowych jak i wieloprocesorowych jądro nie musi
            zwalniać wykorzystywanego procesora (rdzenia), ale robi to aby
            jak najlepiej wykorzystać zasoby.</li>
          <li><strong>Zarządzanie pamięcią</strong> - każdy proces jest obrazem
            w pamięci, każdy proces również potrzebuje pamięci na swoje
            obliczenia. Zadaniem jądra jest przydzielanie, zwalnianie jak i
            ochrona (przed tym aby proces nie uzyskał dostępu do obszaru
            innego procesu) przekazanych procesom obszarów. Czynności z tym
            związane są dość złożone, ale jądro może posiłkować się 
            rozszerzenim MMU we współczesnych procesorach. Pozwala ono podczas
            dzielenia pamięci wykorzystać metodę <strong>pamięci wirtualnej</strong>,
            polegającej na zamianie adresów pamięci, przez co proces jest
            skonfigurowany, że "tak jakby" miał do dyspozycji całą pamięć
            fizyczną maszyny. Zamiana adresów wiąże się z potrzebą posiadania
            map (czy też tabel), pozwalających na odzorowanie adresów, co
            dokłada czynność aktualizacji mapy podczas przełączania kontekstu.
            Mapy adresów nazywane są <strong>tablicami stron</strong>.
          <li><strong>Sterowniki urządzeń</strong> - zadaniem sterowników
            jest dostarczenie identycznego interfejsu do komunikacji z
            poszczególnymi urządzeniami zainstalowanymi w komputerze. Za racji
            to iż swobodny dostęp do sprzetu jest potencjalnie niebezpieczny,
            to jaka kolwiek próba komunikacji z urządzeniem odbywać się
            zawsze będzie za pośrednictwem jądra systemu. Sterowniki w systemie
            Linux są częścią jądra, nie oznacza to jednak, że nie możemy
            jakiegoś brakującego do instalować. Sterowniki są przechowywane w
            postaci modułów, które są ładowane podczas uruchamiania jądra, a
            nie które znich mogą być ładowane podczas pracy systemu.</li>
          <li><strong>Wywołania systemowe</strong> - są to funkcje udostępnione
            przez jądro procesom użytkownika. Wywołania realizują zadania,
            które są trudne do zrealizowania przez procesy użytkownika lub w
            ogóle nie wykonalne. Przykładem wykonywania wywołań systemowych
            jest obsługa plików (otwieranie, odczyt czy zapis), innymi
            bardzo często wykorzystywanymi wywołaniami są <em>fork()</em> oraz
            <em>exec()</em>, wykonywane są za każdym wydanym poleceniem w
            powłoce.</li> 
        </ul>
        <p>
          Inną ciekawą cechą jądra są <strong>pseudourządzenia</strong>.
          Procesy widzą takie urządenia jak każde inne, jednak występują on
          wyłącznie w warstwie programowej, dzięki temu nie muszą być częścią
          jądra, ale ze względów praktycznych się je tam umieszcza. Inna
          implementacja urządzenia <em>/dev/random</em> - służacego
          do generowania liczb pseudolosowych, które jest urządzeniem 
          programowym mogłoby nie być zbyt bezpieczne.
        </p>
        <h2 id="1.3.userspace">1.3. Przestrzeń użytkownika</h2>
        <p>
          Przestrzeń użytkownika formalnie jest obszarem pamięci, w którym
          spedzimy 99% czasu pracy na Linuksie. Wewnątrz przestrzeni
          użytkownika znajdują się procesy definiujące dystrybucje wykonujące
          różne zadania dla użytkownika, teoretycznie są one wobec siebie
          równe, to jednak przestrzeń użytkownika można podzielić na trzy
          warstwy, na której warstwie będzie znajdować się proces zależy jak
          bardzo skomplikowane zadania wykonuje. Przeglądarka sieci WWW, może
          się taka nie wydawać ale to potężny subsystem więc będzie znajdować
          na najwyższej warstwie, z kolei proces służący za rejestrowanie
          logów, tzw. protokół diagnostyczne będzie znajdować się na najniższej
          warstwie blisko jądra, ponieważ nie jest on zbyt skomplikowany w
          porównaniu do na przykład przeglądarki, warstwa środkowa
          zarezerowana jest dla różnej maści serwerów. Najproście rzecz ujmując
          podstawowe usługi znajdują się na najniższej warstwie, usługi
          pomocnicze na warstwie środkowej, a aplikacje, które kontroluje już
          sam użytkownik będą znajdować się na samej górze. Procesy mogą
          komunikować się z innymi procesami o ile te znajdują się na tym
          samym lub niższym poziomie. Używanie tego rozdzaju podziału, może
          być kłopotliwe ponieważ obecne serwery nie są już tak prostym
          oprogramowaniem więc powinny znajdować się tej samej warstwie co
          przeglądarka czy klient pocztowy, jednak to te aplikacje mogą
          wykorzystywać serwery do realizacji zadań użytkownika, więc ich
          miejsce jest raczej na warstwie centralnej (środkowej).
        </p>
        <h2 id="1.4.users">1.4. Użytkownicy</h2>
        <p>
          Użytkownicy w Linksie są odwzorowaniem rzeczywistych obiektów, czyli
          <em>encją</em>. Użytkownicy mają prawo do uruchamiania procesów oraz
          posiadnia (bycia właścielem) plików. Jądro nie rozpoznaje
          użytkowników po ich nazwach, tak jak mają w zwyczaju to ludzie,
          używa ono identyfikatorów <strong>userid</strong> w skrócie
          <strong>UID</strong>. Identyfikatory są przedstawiane za pomocą 
          liczb. 
        </p>
        <p>
          Użytkownicy istnieją wyłącznie po to aby wyznaczać granice. Każdy
          proces ma swojego właściela, dlatego też mówi się że proces
          uruchamia się z uprawnieniami takiego a takiego użytkownika.
          Użytkownicy mogą uruchamiać i konczyć procesy w własnych granicach
          (tylko te, których są właścicielami), przez co nie mogą wpływać na
          procesy innych użytkowników. Poza procesami, użytkownicy mogą 
          tworzyć własne pliki, których automatycznie stają się właścicielami.
          Mogą oni decydować czy chcą się nimi dzielić, ustalając im
          odpowiednie uprawnienia.
        </p>
        <p>
          Poza użytkownikami przypisanymi do konkretnych osób (raczej
          spotkamy jednego), istnieje kilku dodatkowych specjalnych 
          użytkowników, głównie mają oni na celu ograniczenie uprawnień
          serwerów. Po za tymi specjalnymi istnieje jeszcze użytkownik
          <strong>root</strong>, którego nie tyczą się zapisane powyżej
          ograniczenia dlatego jest on nazywany <em>superużytkownikiem</em>.
        </p>
        <p>
          Osoba pracująca na koncie użytkownika <em>root</em>, nazywana jest
          <em>administratorem systemu</em>. <em>Root</em> może kończyć
          procesy innych użytkowników, przeglądać cudze pliki czy instalować
          oprogramowanie z repozytorium. Praca na tym koncie jest dość
          niebezpieczna z punktu widzenia systemu, ponieważ ten użytkownik
          jest wstanie wykonać czynności prowadzące do zniszczenia całego
          systemu. Na Linuksie <em>root</em> ma do tego pełne prawo, dlatego
          projektancji dystrybucji starają się ograniczyć konieczność pracy
          z wykorzystaniem tego użytkownika.
        </p>
        <p>
          Innym tworem podobnym to użytkowników są <strong>grupy</strong>.
          Grupy są zbiorem użytkowników, a ich zadaniem jest współdzielenie
          plików wewnątrz jednej grupy, między jej użytkownikami.
        </p>
        <h1 id="2.linuxbasics">2. Podstawy obsługi Linuksa</h1>
        <p>
          W tym rozdziale przedstawione zostaną podstawy obsługi systemu
          Linux, oczywiście z poziomu powłoki, ponieważ inne sposóby
          zależą w dużej mierze od programów, które do tego celu będziemy
          wykorzystywać. Takich programów może być kilka, powłok
          również dostępnych jest kilka rodzajów, jednak sam program powłoki
          nie będzie wpływać na prezentowane w tym rozdziale czynności. Ten
          rozdział zaczniem od tego czy jest powłoka.
        </p>
        <h2 id="2.1.shells">2.1. Powłoka</h2>
        <p>
          <strong>Powłoka</strong> jest chyba jednym z najistoniejszych 
          komponentów systemu
          Linux, pozwala ona na uruchamianie róznych poleceń wydawanych przez
          użytkownika. Powłoki są również małymi środowiskami programistycznymi.
          Nie które narzędzia systemowe są <strong>skryptami powłoki</strong> - 
          plikami tekstowymi zawierającymi zbiór wykonywanych kolejno (jedno po
          drugim) poleceń powłoki.
        </p>
        <p>
          Pierwotną powłoką była <strong>powłoka Bourna</strong>, opracowana
          jeszcze dla systemu UNIX w laboratoriach <em>Bell Labs</em>. Mimo
          niezbyt częstego wykorzystywania, powłoka ta jest stałym kompenetem
          nie tylko systemu Linux, ale i innych systemów uniksopodbnych.
          Obecnie wykorzystywaną powłoką jest <strong>BASH</strong> - 
          ulepszona wersja oryginalnej powłoki. Korzystając z róznych
          dystrybucji, domyślna powłoka może być inna. Ten materiał zakłada
          wykorzystanie powłoki BASH, szczególnie w rozdziale poświęconym 
          skryptom powłoki.
        </p>
        <h2 id="2.2.shellusage">2.2. Korzystanie z powłoki</h2>
        <p>
          Dostęp do powłoki może odbywać się w dwojaki sposób wykorzystać
          możemy wbudowaną w każdą dystrybucję konsole, nie zależnie od
          instalacji wybranej przez nas dystrybucji. Jeśli jest to dystrybucja
          skierowana do komputery biurkowe, to możemy skorzystać z wbudowanego
          programu <em>terminal</em>. Po uruchomieniu okna powłoki, w prawym
          górnym rogu pojawi się <strong>symbol zachęty</strong>. Jest to ciąg
          znaków wskazujący wiersz, w którym będziemy wprowadzać polecenia.
          Znak zachęty może przyjmować różną formę:
        </p>
        <ul>
          <li><code class="code-inline">użytkownik@host:ścieżka$</code> - 
            <code class="code-inline">użytkownik</code> - nazwa użytkownika,
            <code class="code-inline">host</code> - nazwa komputera,
            <code class="code-inline">ścieżka</code> - obecna ścieżka
            (czym jest ścieżka, będzie za chwilę). Tego typu symbol zachęty
            stosowany jest w dystrybucjach opartych na GNU/Linux Debian takich
            Linux Mint (Mint oparty jest na Ubuntu, a Ubuntu na GNU/Linux
            Debian) czy Ubuntu.</li>
          <li><code class="code-inline">[użytkownik@host:katalog]$</code> -
            <code class="code-inline">użytkownik</code> i
            <code class="code-inline">host</code> podobnie jak wyżej,
            <code class="code-inline">katalog</code> - katalog w którym się
            obecnie znajdujemy, z tego typu znakiem zachęty spotkamy się
            w dystrybucjach RHEL/Fedora/CentOS oraz Arch Linux.</li>
          <li><code class="code-inline">bash-wersja$</code> - Originalny symbol
            zachęty powłoki BASH, <code class="code-inline">wersja</code>
            przedstawia wersję wykorzystywanej powłoki, spotkamy go
            w ręcznych instalacjach powłoki (kompilacji kodu źródłowego)</li>
          <li><code class="code-inline">$</code> - symbol zachęty
            wykorzystywany w celu zaoszczędzenia miejsca w wierszu polecenia.</li>
        </ul>
        <p>
          W tych symbolach jeden element jest stały jest to znak dolara
          (<strong>$</strong>), oznacza on że polecenia wydawane będą jako
          zwykły użytkownika, innym symbolem jest znak krzyżyka
          (<strong>#</strong>), który mówi nam że polecenia będą uruchamiane
          przez superużytkownika. Najprostsze polecenie jakie możemy wydać
          jest użycie polecenia <strong>echo</strong>, które zwraca na
          standardowe wyjście podajny mu jako argument ciągu znaków:
        </p>
<pre class="code-block">
$ echo Witaj świecie.
</pre>
        <p>
          W przykładach w tym materiale, jeśli polecenia ma zostać wydane z
          uprawnieniami zywkłego użytkownika, przed poleceniem będzie
          pojawiać się znak dolara (<strong>$</strong>), a jeśli polecenie ma 
          być uruchomione z wyższymi uprawnieniami, będą one poprzedzone 
          znakiem krzyżyka (<strong>#</strong>) oznaczający uprawnienia 
          użytkownika <em>root</em>.
        </p>
        <h3 id="2.2.1.catcommand">2.2.1. Polecnie cat</h3>
        <p>
          Polecenie <strong>cat</strong> wypisuje na standardowe wyjście
          podane w argumentach pliki jeden po drugim dokonując tym samym
          połączenia (konkatenacji - stąd nazwa polecenia) na jednym
          strumieniu zawartości tych wszystkich plików.
        </p>
<pre class="code-block">
$ cat plik1 plik2 plik3 ...
</pre>
        <h3 id="2.2.2.stdinstdout">2.2.2. Standardowe wyjście i standardowe
        wejście</h3>
        <p>
          Użyłem powyższego polecenia <em>cat</em>, aby nakreślić kontekst dla
          omówienia dwóch podstawowcyh strumieni. Linux wykorzystuje strumień
          wejściowy do odczytu danych, a strumień wyjściowy do ich zapisu. 
          Źródłem strumienia wejściowego może być plik, urządzenie, terminal czy
          strumień wyjściowy innego procesu. 
        </p>
        <p>
          Strumień wejściowy możemy zaobserować poprzez uruchomienie polecenia
          <em>cat</em> bez żadnego pliku. Program nie zwróci od razu znaku
          zachęty, ponieważ oczekuje na dane. Możemy wpisać co kolwiek, a po
          naciśnięciu klawisza <em>enter</em> polecenie powtórzy ten wpisany
          tekst. Z racji tego iż nie podaliśmy mu żadnego pliku polecenie
          zaczęło korzystać ze strumienia <strong>standardowego wejścia</strong>,
          przekazanego
          mu przez jądro, w tym przypadku był to terminal, którym zostało
          uruchomione to polecenie. Aby zakończyć to polecenie należy wciśnąć
          kombinacje klawiszy <em>Ctrl+d</em>, która oznacza koniec 
          danych ze standardowego wejścia. 
        </p>
        <p>
          Ze <strong>standardowym wyjściem</strong> jest podobnie, jądro
          przezkazuje strumień standardowego wyjścia procesom, do którego
          mogą one zapisywać swoje dane. Polecenie <em>cat</em> zawsze 
          wypisuje swoje
          dane na standardowe wyjście, które przez uruchomienie polecenia w
          terminalu jest do niego podłączone. Dzięki temu mogliśmy zobaczyć
          wypisywane przez polecenie dane.
        </p>
        <p>
          Standardowe wyjście oraz standardowe wejście możemy zapisać
          skrótowo <strong>stdout</strong> oraz <strong>stdin</strong>.
          Takich nazw również należy się spodziewać w wszelakiej dokumentacji.
        </p>
        <p>
          Prócz wspomanianych strumieni istnieje jeszcze trzeci strumień
          wejścia-wyjścia - <strong>standardowy strumień błędów</strong>.
          Opiszę go nieco później.
        </p>
        <p>
          Strumienie są dość elastycznym mechanizem, można je zmusić do
          odczytywania i zapisywania danych z innych miejsc niż terminal.
          O przekierowaniach strumienii będzie nieco poźniej w tym rozdziale.
        </p>
        <h2 id="2.3.basicscommands">2.3. Podstawowe polecenia</h2>
        <p>
          Poniżej znajduje się pogrupowane przedstawienie najbardziej
          podstawowych poleceń niezbędnych do pracy w powłoce systemu Linux.
        </p>
        <ul>
          <li>polecenie <strong>ls</strong> - wypisuje zawartość katalogu.
            Najważniejsze opcje:
            <ul>
              <li><strong>-a</strong> - powoduje wyświetlenie wszystkich
              elementów, łącznie z tzw. <em>dot-files</em> (plikami ukrytymi,
              plikami konfiguracyjnymi</li>
              <li><strong>-l</strong> - wyświetlenie zwartości katalogu w
              postaci kilku kolumnowej tabeli zawierającej m.in uprawnienia,
              czas ostatniej modyfikacji plików, wielkość czy przypisanie 
              pliku, katalogu do użytkownika oraz grupy.
            </ul></li>
          <li>polecenie <strong>cp</strong> - kopiujej pliki
            Najważniejsze opcje:
            <ul>
              <li><strong>-p</strong> - zachowuje atrybuty kopiowanych plików,
                na przykład takie jak uprawnienia czy przypisanego właściela i
                grupę</li>
              <li><strong>-r</strong> - kopiowanie rekurencyjne, kopiuje całe
                katalogi wraz z podkatalogami oraz ich zawartością.</li>
              <li><strong>-v</strong> - włącza komunikaty diagostyczne,
                polecenie wypisuje co, gdzie kopiuje. Normalnie program nie
                zwraca nic poza znakiem zachęty po zakończonym kopiowaniu.</li>
            </ul></li>
          <li>polecenie <strong>mv</strong> - w najprostszym przypadku
            polecenie służy do zmiany nazwy pliku, jednak gdy drugim
            argumentem będzie katalog, plik zostanie przeniesiony do tego
            katalogu. Najważniejsze opcje:
            <ul>
              <li><strong>-v</strong> - włącza komunikaty diagnostyczne,
                identycznie jak w przypadku <em>cp</em>.</li>
            </ul></li>
          <li>polecenie <strong>touch</strong> - aktualizuje czas modyfikacji
            pliku, jeśli plik nie istnieje to zostanie utworzony pusty plik o
            podanej w argumencie nazwie.</li>
          <li>polecenie <strong>rm</strong> - polecenie służy do kasowania
            plików. Kombinacja opcji <strong>-rf</strong> wykorzystywana jest
            kasowania całych katalogów z podkatalogami. Najważniejsze opcje:
            <ul>
              <li><strong>-r</strong> - umożliwia, kasowanie rekurencyjne,
                całych katalogów z podkatalogami.</li>
              <li><strong>-f</strong> - przed każdym kasowaniem pliku polecenie
                pyta czy jesteśmy pewni, że chcemy skasować ten plik. Ta opcja
                pomija to pytanie wymusząjąc tak jakby kasowanie.</li>
            </ul></li>
          <li>polecenie <strong>echo</strong> - polecenie wypisuje ciąg znaków
            podany jako argument na standardowe wyjście. Najważniejsze opcje:
            <ul>
              <li><strong>-n</strong> - ta opcja wyłącza przechodzenie
                do nowej linii, po wypisaniu ciągu znaków.</li> 
            </ul></li>  
        </ul>
        <h2 id="2.4.commandsworksondir">Polecenia działające na katalogach</h2>
        <p>
          Uniksy w tym i Linux, korzystają ze standardu hierarchi katalogów,
          aby utrzymać w porządku dane przestrzeni użytkownika. Za początkowy
          katalog uznaje się <strong>katalog główny</strong> oznaczany prawym 
          ukośnikiem lub
          slashem (<strong>/</strong>), wewnątrz tego katalogu znajdują się
          pod katalogi, przechowujące konkretny rodzaj czy typ plików zgodny
          z ich przeznaczeniem.
        </p>
        <p>
          Droga do konkretnego katalogu nosi nazwę <strong>ścieżki</strong>.
          Jeśli ścieżki zaczynają się od <em>/</em>, czyli od katalogu głównego
          mamy doczynienia ze <strong>ścieżką bezwzględną</strong>. Elementy 
          katalogów na
          ścieżkach katalogi mogą być również wyrażane z pomocą jednej lub 
          dwóch kropek.
          Dwie kropki (<strong>..</strong>) oznaczają katalog nadrzędny
          względem aktualnego katalogu, zaś jedna kropka oznacza
          (<strong>.</strong>) aktualny katalog. Ścieżki nie zawierające
          slasha na początku, czyli nie zaczynające się od katalogu głównego
          są wówczas określane mianem <strong>ścieżki względnej</strong>.
        </p>
        <ul>
          <li>polecenie <strong>cd</strong> - polecenie służy do zmiany
            aktualnego katalogu, jako argument przyjmuje katalog, do którego
            checemy przejść, równie dobrze możemy przenieść się w dowolne
            miejsce w systemie plików (w katalogu głównym) podając jako
            argument ścieżkę. Nie podanie argumentu spowowduje przejście do
            katalogu domowego użytkownika.</li>
          <li>polecenie <strong>mkdir</strong> - polecenie tworzy nowy katalog.
            Jako argument przyjmuje nazwę katalogu lub ścieżkę. Najważniejsze 
            opcje:
            <ul>
              <li><strong>-p</strong> - opcja tworzy katalogi nadrzędne podane
                w ścieżce o ile te nie istnieją. Za pomocą odpowiednich
                podstawień powłoki oraz tej opcji można tworzyć całe struktury
                katalogowe.</li>
            </ul></li>
          <li>polecenie <strong>rmdir</strong> - usuwa katalog po warunkiem, że
            jest on pusty. W przeciwnym razie polecenie zwróci błąd. Chcąc
            usuwać całe katalogi z danymi oraz podkatalogami należy użyć
            polecenia <em>rm -rf</em>.</li>
        </ul>
        <h3 id="2.4.1.globbing">2.4.1. Nazwy wieloznaczne.</h3>
        <p>
          Dzięki możliwością powłoki możemy porównywać proste wzorce z nazwami
          plików w obrębie aktualnego katalogu roboczego (katalogu w którym
          się znajdujemy) czynność ta nazywana jest rozwijaniem nazw lub
          <em>globbingiem</em>. Jednym z elementów biorących udział w 
          rozwiązywaniu nazw jest gwiazdka (<strong>*</strong>) oznaczająca
          dowolną ilość dowolnych znaków. Dla przykładu poniższe polecenie:
        </p>
<pre class="code-block">
$ echo *
</pre>
        <p>
          Zwróci nazwy wszystkich plików i katalogów  znajdujących się w 
          katalogu. Innym
          znakiem wykorzystywanym przy nazwach wieloznacznych jest
          znak zapytania (<strong>?</strong>) reprezentuje on jeden dowolny
          znak, dla wzorca <em>b?at</em> pasującymi nazwami mogą być
          <em>blat</em> oraz <em>brat</em>. Rozwinięcia nazw dokonuje powłoka
          przed uruchomieniem, więc jeśli chcemy aby, któreś ze znaków 
          wieloznacznych trafiło do polecnie to należy umieść je w pojedyńczych
          cudzysłowach.
        </p>
        <h2 id="2.5.proxycommands">2.5. Polecenia pośredniczące</h2>
        <ul>
          <li>polecenie <strong>grep</strong> - wyszukuje wzorzec
          w podanym pliku. Polecenie to korzysta z systemu wzorców nazwanych
          <strong>wyrażeniami regularnymi</strong>. Najważniejszymi opcjami:
          <ul>
            <li><strong>-i</strong> - wyłącza rozróżnianie małych i
            wielkich liter.</li>
            <li><strong>-v</strong> - podwoduje odwrócenie wyszukiwania,
            zwracane są wyniki nie pasujące do wzorca.</li>
            <li><strong>-e</strong> - wykorzystuje rozszerzony zestaw 
            instrukcji pozwalajacych na tworzenie wyrażeń regularnych.</li>
            <li><strong>-o</strong> - opcja powoduje zwrócenie dokładnie
            tylko tych znaków pasujących do wzorca. Normalnie polecenie zwraca
            linię z elementami pasującymi do wzorca, w przypadku wielu plików
            zwraca również nazwę pliku.</li>
          </ul>
          Tworzenie wyrażeń regularnych oraz więcej opcji tego polecenia
          znajduje się na stronie podręcznika uruchamianej poleceniem:
<pre class="code-block">
$ man grep
</pre>
          Do najważniejszych wyrażeń, które każdy powinien znać należą:
          <ul>
            <li><strong>.*</strong> - oznaczające dowolną ilość dowolnych
              znaków.</li>
            <li><strong>.</strong> - oznacza jeden dowolny znak.</li>
          </ul></li>
          <li>polecenie <strong>less</strong> - wypisuje dane z pliku, lub
            ze strumienia wykorzysując podział na strony. Jedna strona to jeden
            ekran. Następne strony są wyświetlane za naciśnięciem <em>spacji</em>
            stronę możemy cofnąć klawiszem <em>b</em>, zakończyć przeglądanie
            danych klawiszem <em>q</em>. Dane możemy przeglądać linia po linii
            używając strzałek. Możliwe jest również wyszukiwanie fraz w danych
            za pomocą <em>/</em> (wyszukiwanie w przód) lub za pomocą 
            <em>?</em> (wyszukiwanie w tył).</li>
          <li>polecenie <strong>pwd</strong> - wyświetla obecny katalog
            roboczy powłoki (świeżkę na której się znajdujemy). Polecenie
            niepozorne choć przydatne, ze względu na dowiązania symboliczne
            (będzie o nich w dalszej części materiału), które mogą przesłaniać
            ścieżkę wyświetlaną w znaku zachęty. Najważnejsza opcja jest
            uruchamiana, gdy nie ma żadnej opcji, więc jej opis pominę.
            Warto dodać, że obecne systemy posiadają polecenie <em>pwd</em>
            wbudowane w powłokę. Dlatego też opcja <strong>-P</strong>
            rozwijająca fizyczne ścieżki nie jest automatycznie uruchamiana
            w przypadku poprostu wydania polecenia <em>pwd</em>, prawdziwe
            polecenie <em>pwd</em> uruchamiamy:
<pre class="code-block">
$ /usr/bin/pwd
</pre>
          </li>
          <li>polecenie <strong>diff</strong> - wszukuje różnice pomiędzy
            dowoma plikami tekstowymi. Polecenie to posiada wiele różnych opcji
            formatowania danych wyjściowych, najbardziej czytelnym pozostaje
            chyba użycie opcji <strong>-u</strong>. Polecenie wykorzystywane
            programistów oraz system kontroli wersji git.</li>
          <li>polecenie <strong>file</strong> - polecenie zwraca format pliku
            podanego jako argument. W uniksach nie potrzeby stosowania
            rozszerzeń plików, więc to polecenie może pomóc nam dowiedzieć
            się co zawiera plik.</li>
          <li>polecenie <strong>find</strong> i <strong>locate</strong> -
            polecenia te służą do wyszukiwania plików w systemie. Polecenie
            <em>find</em> wymaga podania katalogu po nazwie polecenia, nazwy
            wyszukiwanego pliki po opcji <strong>-name</strong> oraz opcji
            <strong>-print</strong>, która powoduje wyświetlenie na strumieniu
            standardowego wyjścia nazw plików pasujących do wzorca podanego w
            opcji <em>-name</em>. Polecenie <strong>locate</strong> na podobne
            zastosowanie jak <em>find</em> działa jednak od niego szybciej
            ponieważ bazuje na indeksie przygotowywanym co jakiś czas przez
            system operacyjny. Może być ono bezużyteczne, kiedy szukamy nowych
            plików, gdyż mogą być one nie ujęte jeszcze w indeksie.</li>
          <li>polecenie <strong>head</strong> i <strong>tail</strong> -
            te polecenia służa do prezentowania wycinka danych czy to ze
            strumienia lub z pliku. W przypadku polecenia <em>head</em>
            prezentowane jest <em>n</em> pierwszych linii, domyslnie 10;
            z kolei polecenie tail prezentuje <em>n</em> koncowych linii.
            Liczbę linii podajemy bezpośrednio po znaku myślnika
            (<strong>-</strong>). Z tych dwóch poleceń polecenie <em>tail</em>
            ma nieco większe zastosowanie niż polecenie <em>head</em>. Mozemy
            wywołać to polecenie aby wyświetlić dane od linii, numer linii
            podajemy po znaku plusa (<strong>+</strong>), inna właściwością
            chyba najważniejszą jest wyświetlanie danych na żywo, używając
            opcji <strong>-f</strong>, a następnie nazwy pliku lub myślnika
            gdy dane pochodzą ze strumienia wyjściowego innego polecenia.</li>
          <li>polecenie <strong>sort</strong> - układa wiersze z pliku
            tekstowego w porządku alfabetycznym, jeśli na początku wierszy
            znajdują się liczby to aby je posortować należy użyć opcji
            <strong>-n</strong>, aby odwrócić sortowanie możemy użyć opcji
            <strong>-r</strong>.</li>
        </ul>
        <h2 id="2.6.passwdandchsh">2.6. Zmiana hasła i powłoki</h2>
        <p>
          W celu zmiany hasła należy użyć polecenia <strong>passwd</strong>.
          Polecenie poprosi o podanie obecnego hasła, po zatwierdzeniu go
          zostaniemy poproszeni o nowe hasło i jego potwierdzenie (wpisanie
          ponowne nowego hasła).
        </p>
        <p>
          Zmiana aktywnej powłoki odbywa się za pomocą polecenia
          <strong>chsh</strong>, albo użyć poleceń odpowiadających nazwom
          innych powłok, kolejno <strong>ksh</strong> - Korn SHell,
          <strong>tcsh</strong> - TENEX C SHell. Użycie tych poleceń w 
          aktywnej powłoce, spowoduje uruchomienie podpowłoki. Zamkniecie
          jej spowoduje powrót do pierwotnej powłoki.
        </p>
        <h2 id="2.7.dotfiles">2.7. Pliki z kropką</h2>
        <p>
          Przeglądając pliki nawet w własnym katalogu domowym możemy znaleźć
          pliki, których nazwa zaczyna się od kropki. Nie które źródła mówią
          tym o że te pliki są ukryte. Do takich wniosków może dojść,
          ponieważ te pliki nie są domyślnie wyświetlane przez polecenie
          <em>ls</em> bez opcji <em>-a</em> lub przez menedżery plików dostępne
          w desktopowych wersja Linuksa. Jednak te pliki nie różnia się niczym
          od inny plików, poza właśnie tym przypadkiem opisanym powyżej.
          Oprócz plików, nazwy katalogów również mogą zaczynać się od kropki.
          Za pomocą prostego wzorca możemy wyświetlić wszystkie <em>dot-files</em>,
          jeśli wsród nich trafi się katalog, wówczas zostanie wyświetlona jego
          nazwa a pod nią jego zawartość. 
        </p>
<pre class="code-block">
$ ls .??*
</pre>
        <h2 id="2.8.shellandenvvars">2.8. Zmienne środowiskowe i powłoki</h2>
        <p>
          Powłoka może przechowywać zmienne tymczasowe, które mogą przechowywać
          różne wartości, mogą one kontrolować zachowanie samej powłoki jedną
          z takich zmiennych jest zmienna <strong>PS1</strong> zawierająca
          znak zachęty. Takie zmienne najczęsćiej wykorzystywane są w 
          skryptach powłoki i nazywane są <strong>zmiennymi powłoki</strong>.
          Definicja zmiennych tego składa się z nazwy zmiennej, operatora
          przypisania (znaku równości <strong>=</strong>) oraz wartości samej
          zmiennej.
        </p>
<pre class="code-block">
$ zmienna=12
</pre>
        <p>
          Odwołać się do wartości zmiennej możemy w dowolnym momencie, podając
          jej nazwę poprzedzoną znakiem dolara (<strong>$</strong>).
        </p>
<pre class="code-block">
$ echo $zmienna
</pre>
        <p>
          <strong>Zmienna środowiskowa</strong> jest podobna do zmiennej
          powłoki, ale nie jest ściśle związana z powłoką, bowiem do pamięci
          zmiennych środowiskowych systemach uniksopodobnych mają wszystkie
          aplikacje, system operacyjny przezkazuje je do każdego programu
          uruchomionego w powłoce, programy te nie mają jednak dostępu do
          zmiennych powłoki. Zmienne środowiskowe definiuje się w ten sam 
          sposób
          jak zmienne powłoki, jedna aby taka zmienna stała się zmienną
          środowiskową musi zostać przeniesiona do pamięci tych zmiennych
          za pomocą polecenia <strong>export</strong>.
        </p>
<pre class="code-block">
$ zmienna=21
$ export zmienna
</pre>
        <p>
          Nie które programy mogą wykorzystywać zmienne środowiskowe do
          własnej konfiguracji. Dla przykładu niektóre programy uruchamiane
          w powłoce korzystają ze zmiennej środowiskowej <em>EDITOR</em>
          definiujące domyślny program do edycji plików tekstowych.
          Wykorzystanie zmiennych środowiskowych zapewne jest opisane w
          na stronie podręcznika programu.
        </p>
        <h2 id="2.9path">2.9. Ścieżka poleceń</h2>
        <p>
          Istnieje specjalna zmienna środowiskowa <strong>PATH</strong>,
          przechowywująca katalogi, w których to powłoka będzie szukać
          programów odpowiadających wpisanym poleceniom. Jeśli wśród
          przeszukiwanych katalogów znajduje się kilka programów o tej samej
          nazwie to powłoka uruchomi pierwszy przez nią znaleziony. Ścieżki
          katalogów w tej zmiennej odzielone są dwukropkiem (<strong>:</strong>).
          Posiadając swoje programy, możemy również umieść katalog z nim
          wewnątrz zmiennej <em>$PATH</em>. Opcje dodanie katalogu są dwie
          i mogą mieć wpływ na funkcjonowanie systemu. Możemy dodać nasz
          katalog na początku zmiennej, wówczas powłoka zacznie od niego
          poszukiwania, jednak należy pamiętąc przy tym, aby nazwy programów
          nie pokrywały się istniejącymi dotychczas poleceniami.
        </p>
<pre class="code-block">
$ PATH=kat:${PATH}
</pre>
        <p>
          Na powyższym przykładzie <code class="code-inline">kat</code>, to 
          nasz katalog z oprogramowaniem. Możemy jednak skorzystać
          bezpieczeniejszego rozwiązania - dopisać nasz katalog na końcu listy
          katalogów zmiennej <em>PATH</em>, wówczas nawet jeśli nasz program 
          będzie
          nazywać się jak jedno z instniejących już poleceń w systemie, nie
          będzie miało to wpływu na działanie systemu.
        </p>
<pre class="code-block">
$ PATH=${PATH}:kat
</pre>
        <p>
          Na powyższych przykładach użyłem znaku dolara wraz z nawiasami
          klamrowymi. Jest to sposób na separacje nazwy zmiennej od innych
          znaków, po to aby powłoka nie potraktowała jak w przykładzie powyżej
          ciągu znaków ":kat" jak części nazwy zmiennej. Przedstawione w
          przykładach polecenia są nie groźne, jeśli uszkodzimy zawartość
          zmiennej <em>PATH</em>, to należy zamknąć okno terminala i otworzyć
          nowe. 
        </p>
        <h2 id="2.10.specialchars">2.10. Znaki specjalne</h2>
        <p>
          W systemach uniksopodbnych wiele znaków ma szczególne znaczenie.
          Poniżej znajduje się tabela przedstawiająca wykorzystwane podczas
          używania systemu znaki specjalne.
        </p>
        <table border="1">
          <thead>
            <tr>
              <th>Znak</th>
              <th>Nazwa</th>
              <th>Opis</th>
            </tr>
          </thead>
          <tbody>
            <tr>
              <td><strong>*</strong></td>
              <td>gwiazdka</td>
              <td>Wyrażenie regularne, znak nazwy wieloznacznej</td>
            </tr>
            <tr>
              <td><strong>.</strong></td>
              <td>kropka</td>
              <td>Aktualny katalog, ogranicznik nazwy pliku lub hosta</td>
            </tr>
            <tr>
              <td><strong>!</strong></td>
              <td>wykrzyknik</td>
              <td>Negacja, historia poleceń</td>
            </tr>
            <tr>
              <td><strong>|</strong></td>
              <td>potok</td>
              <td>Potoki poleceń</td>
            </tr>
            <tr>
              <td><strong>/</strong></td>
              <td>slash</td>
              <td>Ogranicznik katalogów, polecenie szukania</td>
            </tr>
            <tr>
              <td><strong>\</strong></td>
              <td>backslash</td>
              <td>Literały, makra (nigdy katalogi)</td>
            </tr>
            <tr>
              <td><strong>$</strong></td>
              <td>dolar</td>
              <td>Oznaczenie zmiennych, koniec wiersza</td>
            </tr>
            <tr>
              <td><strong>'</strong></td>
              <td>pojedynczy cudzysłów</td>
              <td>Ciągi znaków literałów</td>
            </tr>
            <tr>
              <td><strong>`</strong></td>
              <td>lewy cudzysłów</td>
              <td>Podmiana polecenia</td>
            </tr>
            <tr>
              <td><strong>"</strong></td>
              <td>podwójny cudzysłów</td>
              <td>Ciągi znaków pseudoliterałów</td>
            </tr>
            <tr>
              <td><strong>^</strong></td>
              <td>daszek</td>
              <td>Negacja, początek wiersza</td>
            </tr>
            <tr>
              <td><strong>~</strong></td>
              <td>tylda</td>
              <td>Negacja, skrót katalogu</td>
            </tr>
            <tr>
              <td><strong>#</strong></td>
              <td>krzyżyk</td>
              <td>Komentarze, dyrektywy preprocesora, podmiany</td>
            </tr>
            <tr>
              <td><strong>[]</strong></td>
              <td>nawiasy kwadratowe</td>
              <td>Zakresy</td>
            </tr>
            <tr>
              <td><strong>{}</strong></td>
              <td>nawiasy klamrowe</td>
              <td>Bloki poleceń, zakresy</td>
            </tr>
            <tr>
              <td><strong>_</strong></td>
              <td>podkreślenie</td>
              <td>Prosty zamiennik spacji</td>
            </tr>
          </tbody>
        </table>
        <p>
          Często możemy napotkać symbol daszka (<strong>^</strong>) zastępujący
          klawisz <em>Control</em>, przez co zapis <em>^C</em> jest równe
          kombinacji klawiszy <em>Ctrl+C</em>.
        </p>
        <h2 id="2.11.commandlineedit">2.11. Edycja wiersza poleceń</h2>
        <p>
          Znak zachęty wskazuje wiersz polecenia, który możemy edytować
          przesuwając kursor za pomocą strzałek. Chcąc powtórzyć jakąś czynność
          nie musimy pisać na nowo tego polecenia, możemy wybrać je z historii
          poleceń za pomocą strzałek w góre i w dół. Warto jednak obsługę
          wiersza poleceń za pomocą strzałek odstawić na bok. Wykorzystując
          skróty z poniższej tabeli, możemy nimi śmiało zastąpić strzałki. 
          Istnieją ku temu dwa powody. 
        </p>
        <ul>
          <li>Nie wszystkie klawiatury posiadają strzałki, lub ich użycie jest
            strasznie nie konfortowe.</li>
          <li>Wiele programów uniksowych (w tym i linuksowych) obsługuje się
            za pomocą tzw. biblioteki <strong>GNU Readline</strong> (skróty
            klawiszowe w tabeli poniżej), a nie za pomocą strzałek.</li>
        </ul>
        <table border="1">
          <thead>
            <tr>
              <th>Klawisze</th>
              <th>Operacja</th>
            </tr>
          </thead>
          <tbody>
            <tr>
               <td><em>Ctrl+b</em></td>
               <td>Przesunięcie kursora w lewo</td>
            </tr>
            <tr>
              <td><em>Ctrl+f</em></td>
              <td>Przesunięcie kursora w prawo</td>
            </tr>
            <tr>
              <td><em>Ctrl+p</em></td>
              <td>Powrót do poprzedniego polecenia (lub przesunięcie kursora
                w górę)</td>
            </tr>
            <tr>
              <td><em>Ctrl+n</em></td>
              <td>Przejście do następnego polecenia (lub przesunięcie klawisza
                w dół)</td>
            </tr>
            <tr>
              <td><em>Ctrl+a</em></td>
              <td>Przesunięcie kursora na początek wiersza</td> 
            </tr>
            <tr>
              <td><em>Ctrl+e</em></td>
              <td>Przesunięcie kursora na koniec wiesza</td>
            </tr>
            <tr>
              <td><em>Ctrl+w</em></td>
              <td>Usunięcie słowa poprzedzjącego kursor</td>
            </tr>
            <tr>
              <td><em>Ctrl+u</em></td>
              <td>Usunięcie tekstu od kursora do początku wiersza</td>
            </tr>
            <tr>
              <td><em>Ctrl+k</em></td>
              <td>Usunięcie tekstu od kursora do końca wiersza</td>
            </tr>
            <tr>
              <td><em>Ctrl+Y</em></td>
              <td>Wyklejanie usuniętego tekstu (na przykłda usuniętego
                poleceniem <em>Ctrl+u</em>)</td>
            </tr>
            <tr>
              <td><em>Ctrl+h</em></td>
              <td>Substytut klawisza <em>Backspace</em></td> 
            </tr>
            <tr>
              <td><em>Ctrl+d</em></td>
              <td>Substytut klawisza <em>delete</em></td>
            </tr>
            <tr>
              <td><em>Ctrl+j, Ctrl+m</em></td>
              <td>Substytut klawisza <em>enter</em></td>
            </tr>
          </tbody>
        </table>
        <h2 id="2.12.texteditors">2.12. Edytory tekstu</h2>
        <p>
          Na Linuksie mamy podobną ilość edytorów tekstowych do wyboru jak w
          przypadku systemów MS Windows czy Apple macOS. Jak nie więcej.
          Co ciekawe macOS, również jest system uniksopodobnym. Więc to co
          zostało omówione w tym rozdziale również będzie kompatybilne z tym
          systemem. Wracając jednak do edytorów tekstu. Tak naprawdę to
          istnieją dwa, na które warto zwrócić uwagę, oba są standardem jeśli
          chodzi o edycje tekstu i oba wymagają nauki obsługi. Wybór
          pozostawiam do roztrzygniecia Tobie. 
        </p>
        <ul>
          <li><strong>GNU Emacs</strong> - edytor w którym można zrobić
            wszystko, od pisania tekstów do wykorzystania go jako menedżer
            okien. Jego obsługa nie jest zbyt szybka i często by się
            wydawało proste czynności wymagają użycia kliku poleceń. Wydaje
            mi się, że nie ma bardziej rozbudowanego uniksowego programu.
            Pomoc w obsłudze tego edytora, możemy uruchomić naciskając
            <em>Ctrl+H</em> następnie klawisz <em>t</em>.</li>
          <li><strong>VIm</strong> - szybki edytor uruchamiany w terminalu,
            choć można zainstalować wersję graficzną. Obsługuje się go trochę 
            jak grę. VIm, jest nieco bardziej intuicyjny od Emacsa. Warto
            dodać, że edytor ten bywa domyślnie doinstalowywany do wielu
            dystrybucji jak i innych systemów uniksowych, choć tam może
            występować w podstawowej wersji <strong>Vi</strong>. Chcąc
            nauczyć się edytora <em>Vim</em>, możemy skorzystać z
            z instalowanego wraz z edytorem tutoriala, uruchamianego poleceniem
            <strong>vimtutor</strong>.</li>
        </ul>
        <p>
          Jeśli potrzebujemy edytora, który jest wstanie zatąpić nam
          środowisko graficzne, wybierzmy edytor <em>Emacs</em>. Jeśli jednak 
          chcemy
          poprostu edytować pliki, w każdym możliwym środowisku wybierzmy
          edytor <em>Vim</em>. Osobiście jestem przyzwyczajony już do edytora
          <em>Vim</em>.
        </p>
        <h2 id="2.13.gettinghelp">2.13. Uzyskiwanie pomocy</h2>
        <p>
          Dystrybucje Linuksa są rozporowadzane z dużą ilością różnej
          dokumentacji. Informacje temat poleceń możemy znaleźć na stronach
          podręcznika, wydając polecenie <strong>man</strong> i podając jako
          argument interesujące nas polecenie. Na przykład:
        </p>
<pre class="code-block">
$ man ls
</pre>
        <p>
          W ten sposób uruchomimy stronę podręcznika polecenia <em>ls</em>.
          Większosć stron podręcznika podaje suche informacje na temat
          polecenia, nie ma co tam szukać jakiś samouczków. Opcje podawana są
          usystematyzowany sposób (najczęściej alfabetyczny), nie które
          strony podręcznika mogą zawierać przykłady.
        </p>
        <p>
          Strony podręcznika możemy przeszukać pod kątem słowa kluczowego, za
          pomocą opcji <strong>-k</strong>, polecenia <em>man</em>. Wynikiem
          tego polecenie jest lista poleceń, oraz krótki opis zawierający
          podane słowo kluczowe, ciekawa jest liczba podana w nawiasie obok
          nazwy polecenia, jest to <strong>numer rozdziału</strong>.
        </p>
        <p>
          Strony podręcznika są podzielone rozdziały oznaczone numerami, każdy
          z nich zawiera innego rodzaju strony podręcznika. Rozdziały
          zostały opisane w tabeli poniżej. 
        </p>
        <table border="1">
          <thead>
            <tr>
              <th>Rozdział</th>
              <th>Opis</th>
            </tr>
          </thead>
          <tbody>
            <tr>
              <td><strong>1</strong></td>
              <td>Polecenia użytkownika</td>
            </tr>
            <tr>
              <td><strong>2</strong></td>
              <td>Niskopoziomowe wywołania systemowe</td>
            </tr>
            <tr>
              <td><strong>3</strong></td>
              <td>Dokunentacja wysokopoziomowych bibliotek Uniksa</td>
            </tr>
            <tr>
              <td><strong>4</strong></td>
              <td>Informacje o interfejsach urządzeń i sterownikach</td>
            </tr>
            <tr>
              <td><strong>5</strong></td>
              <td>Opisy plików (konfiguracji systemu)</td>
            </tr>
            <tr>
              <td><strong>6</strong></td>
              <td>Gry</td>
            </tr>
            <tr>
              <td><strong>7</strong></td>
              <td>Formaty plików, konwencje i kodowaniaa (ASCII, przyrostki itd)</td>
            </tr>
            <tr>
              <td><strong>8</strong></td>
              <td>Polecenia systemowe i serwery</td>
            </tr>
          </tbody>
        </table>
        <p>
          Jak uzupełnienie tego materiału świetnie sprawdzą się rodziały
          1,5,7 i 8. Wywołanie konkretnej strony a danego rozdziału wymaga
          podania jego numeru jak pierwszego argumentu, wówczas polecenie
          będzie wszukać informacji na temat podanego słowa w danym rodziale.
          Świetnym przykładem może być, chęć sprawdzenia na stronach
          podręcznika pliku <em>/etc/passwd</em>. Należy wydać polecenie:
        </p>
<pre class="code-block">
$ man 5 passwd
</pre>
        <p>
          Dość często wykorzystywanym sposóbem na uzyskanie informacji o
          poleceniach mogą być same polecenia, sprawdźmy czy możemy je
          uruchomić z opcją <strong>-h</strong> lub <strong>--help</strong>.
        </p>
        <p>
          Projekt GNU jakiś czas temu zadecydował, że będzie używać innego
          formatu plików pomocy niż strony podręcznika, format nazywana jest
          <strong>info</strong> lub <strong>texinfo</strong>. Format ten
          zawiera więcej informacji choć jest od niego bardziej skomplikowany.
          Przypomina prostą stronę internetowa, otworzoną w terminalowej
          przeglądarce. Tego typu pliki pomocy uruchamiane są za pomocą
          polecenia <strong>info</strong>, po czym podaje mu się jako argument
          interesujące nas polecenie. 
        </p>
        <p>
          Nie które z pakietów umieszczają swoją dokumentację w katalogu
          <em>/usr/share/doc</em> nie zwracając uwagi na format. Warto
          pamiętać o tych miejscach szukając pomocy, oczywiście pozostaje na
          do dyspozycji jeszcze internet.
        </p>
        <h2 id="2.14.shellio">2.14. Wejście i wyjście powłoki</h2>
        <p>
          Omawiając po krótce powłokę, wspomniałem o strumieniach standardowego
          wejścia i wyjścia. Wiele poleceń używa wyjścia aby wypisywać
          wyniki działa lub komunikaty diagonstyczne. Jeśli nie chcemy ich
          widzieć lub nie nadąrzymy ich analizować możemy je przekierować
          na przykład do pliku, za pomocą znaku przekierowania (<strong>&gt;</strong>).
        </p>
        <p>
          Używając tego znaku musimy omówić sobie jedną ważną rzecz, znak ten
          powoduje nadpisanie wszystkiego co znajduje się w pliku. Tego typu
          czynność nazywana jest <strong>wymazywaniem</strong>
          (ang. <em>clobbering</em>). Możemy jednak zablokwać to działanie
          za pomocą odpowiednich ustawień powłoki, dla BASH wystarczy użyć
          polecenia <code class="code-inline">set -C</code>. Poza blokowaniem
          wymazywania, istnieje jeszcze jeden znak przekierowania, który
          powoduje dopisanie przekierowanego wyjścia do pliku:
          <strong>&gt;&gt;</strong>.
        </p>
        <p>
          Za pomocą przekierowań możemy w prosty sposób połączyć wyjście
          jednego polecenia z wejściem innego. Służy temu znak <strong>potoku</strong>
          (<strong>|</strong>). Postawienie ponowej kreski, pomiędzy
          poleceniami w wierszu polecenia połączy wyjście pierwszego z wejściem
          drugiego.
        </p>
        <h3 id="2.14.1.stderr">2.14.1 Standardowy strumień błędów</h3>
        <p>
          Korzystając powyższych znaków przekierowania polecenia, dane
          wyjściowe programów zostaną przekierowane np. do pliku. Ale
          komunikaty diagnostyczne nadal są wyświetlane. Dzieje się to dlatego
          iż komunikaty diagnostyczny wykorzystują trzeci dodatkowy strumień
          <strong>standardowy strumień błędów</strong> zapisywany skrótowo
          <strong>stderr</strong>, który podobnie do <em>stdout</em> jest
          podłączony do terminala.
        </p>
        <p>
          Do przekierowania tego strumienia musimy użyć identyfikatorów
          strumienii jest to liczba, którą posługuje się jądro do rozrózniania
          strumieni. W fachowej
          literaturze bądź dokumentacji możemy natknąć się na termin
          <strong>deskryptor pliku</strong>. Taki identyfikator dla <em>stderr</em>
          ma wartość <strong>2</strong>, a dla <em>stdout</em> <strong>1</strong>.
          Chcąc przekierować <em>stderr</em> do innego pliku musimy podać jego
          identyfikator przed znakiem przekierowania. Innym przypadkiem jest
          przekierowanie <em>stderr</em> do tego samego pliku co <em>stdout</em>,
          wówczas najprostszym sposób jest podłączenie strumienia błedów do
          standardowego wyjścia za pomocą znaku <strong>&gt;&amp;</strong>
          podając przekierowywany strumień po lewej stronie znaku (przed nim)
          a strumień docelowy po prawej (za nim).
        </p>
<pre class="code-block">
$ ls /ffffffff &gt;p 2&gt;&amp;1
</pre>
        <h3 id="2.14.2.stdin">2.14.2. Przekierowanie standardowego wejścia</h3>
        <p>
          Przekierowanie standardowego wejścia występuję dość rzadko ponieważ
          większość poleceń przyjmuje plik jako argument, jednak może zdarzyć
          się potrzeba przekierowania wejścia do polecenia. Służy temu
          <strong>znak przekierowania wejścia</strong> <strong>&lt;</strong>.
        </p>
        <h2 id="2.15.readingerrors">2.15. Odczytywanie komunikatów o błędach</h2>
        <p>
          Prędzej czy później gdzieś podczas naszej pracy z powłoką zdarzy
          się błąd. Ważne jest aby umieć go odczytać i prawidłowo z
          interpretować.
        </p>
        <p>
          Sam komunikat składa się przeważnie z nazwy polecenia oraz
          komunikatu błędu, w nie których przypadkach w komunikacie
          znajduje się nazwa pliku, jednak dotyczy specyficznych komunikatów
          o błędach. Poniżej znajduje się
          lista, błędów z którym będziemy się spotykać podczas pracy z systemem 
          Linux. 
        </p>
        <ul>
          <li><strong>No such file or directory</strong>
            (<em>nie ma takiego pliku lub katalogu</em>) - występuje gdy
            plik lub katalog podany jak argument nie istnieje. Innym powodem
            występowania takiego błędu może być błędnie zapisana nazwa
            polecenia w skrypcie.</li>
          <li><strong>File exists</strong> (<em>plik istnieje</em>) - ten
            problem występuje w momencie gdy próbujemy stworzyć katalog o
            nazwie pliku, który już istnieje.</li>
          <li><strong>Not a directory</strong> (<em>nie jest katalogiem</em>),
            <strong>Is a directory</strong> (<em>jest katalogiem</em>) - błąd
            występuje w momencie gdy probujemy użycie pliku jak katalogu lub
            katalogu jak pliku.</li>
          <li><strong>No space left on device</strong> (<em>brak miejsca w 
            urządzeniu</em>) - Na pamięci masowej, której próbujemy zapisać
            dane brakuje wolnego miejsca.</li>
          <li><strong>Permission denied</strong> 
            (<em>niewystarczające uprawnienia</em>) - pojawienie się tego błędu
            może mieć dwa powody, pierwszy to zapis lub odczyt informacji z
            pliku, do którego nie mamy żadnych uprawnień; drugim jest próba
            uruchomienia pliku/programu bez ustawionego bitu wykonania. O
            uprawnieniach będzie w dalszej części tego rodziału.</li>
          <li><strong>Operation not permitted</strong> (<em>brak zezwolenia
            na wykonanie operacji</em>) - błąd występuje w momencie gdy
            spróbujemy zakończyć proces nie należący do nas.</li>
          <li><strong>Segmentation fault</strong> (<em>błąd segmentacji</em>) - 
            błąd programisty. Program, który uruchomiliśmy próbował
            użyskać dostęp do wycinka pamięci, którego nie miał żadnych
            uprawnień i jego działanie zostało przerwane przez jądro. 
            Najczęsciej polskie tłumaczenie tego błędu to
            <em>Naruszenie ochrony pamięci</em>.</li>
          <li><strong>Bus Error</strong></li>  (<em>błąd magistrali</em>) błąd
            podobny do <em>Naruszenia ochrony pamięci</em>, jednak w tym
            przypadku chodzi o dostęp do pamięci w sposób niewłaściwy, a nie
            dostęp do innego obszaru pamięci.</li>
        </ul>
        <p>
          Jeśli natrafimy na jeden z dwóch ostatnich błędów, to przyczyną mogą
          być dane przekazane do programu, których on się nie spodziewał.
        </p>
        <h2 id="2.16.manipulatingprocesses">2.16. Przeglądanie procesów i
          manipulowanie nimi</h2>
        <p>
          Każdy proces jest programem. Jądro pododobnie jak użytkowników 
          procesy widzi za pomocą liczbowych identyfikator - 
          <strong>process ID</strong> - <strong>PID</strong>. Za pomocą
          polecenia <strong>ps</strong> możemy wylistować wszystkie procesy
          uruchomione w powłoce. Domyślnie wynik polecenia podzielony jest na
          cztery kolumny.
        </p>
        <ul>
          <li><strong>PID</strong> - identyfikator procesu</li>
          <li><strong>TTY</strong> - urządzenie terminala, na którym działa
            dany proces.</li>
          <li><strong>STAT</strong> - stan procesu, np. <strong>S</strong>
            oznacza uśpieje procesu, zaś <strong>R</strong> - jego dzialanie.
            Wszystkie oznaczenia znajdują się na stronie podręcznika 
            polecenia.</li>
          <li><strong>CMD</strong> - treść polecenia, warto jednak zaznaczyć,
            że procesy mogą ją zmieniać.</li>
             
        </ul>
        <p>
          Polecenie <em>ps</em>, możemy obsługiwać za pomocą opcji zapisanych w
          trzech stylach, jednak najbardziej powszechnym jest styl BSD, i to
          zapis opcji w tym stylu przedstawie.
        </p>
        <ul>
          <li><strong>ps x</strong> - wyświetla wszystkie procesy uruchomione
            przez aktualnego użytkownika.</li>
          <li><strong>ps ax</strong> - wyświetla wszystkie procesy działące
            w systemie.</li>
          <li><strong>ps u</strong> - wyświetla bardziej szczegółowe informacje
            o procesach.</li>
          <li><strong>ps w</strong> - podaje pełne nazwy poleceń, nie
            ograniczając się do pojedyńczego wiersza.</li>
        </ul>
        <p>
          Tak jak w przypadku innych poleceń, w poleceniu <em>ps</em>, również
          możemy łączyć opcje, dla przykładu chcąc wyświetlić wszystkie
          procesy w systemie wraz ze szczegółami należy wydać polecenie
          <code class="code-inline">ps aux</code>.
        </p>
        <p>
          Wyświetlenie informacji na temat, konkertnych procesów polega na
          podaniu po opcjach identyfikatora procesu. 
        </p>
        <h3 id="2.16.1.processkilling">2.16.1. Przerywanie działania procesów</h3>
        <p>
          Możemy zakończyć działanie procesu poprzez wysłanie do niego
          <strong>sygnału</strong> za pomocą polecenia <strong>kill</strong>.
          Wykorzystują to polecenie, jądro systemu proszone jest wysłanie 
          sygnału do wybranego procesu. Domyślnie wysyłanym sygnałem jest 
          <strong>TERM</strong>, a polecenie do swojego działania potrzebuje
          tylko identyfikatora <em>PID</em>. 
        </p>
        <p>
          Proces możemy zatrzymać wysyłając do niego sygnał <strong>STOP</strong>.
          po nazwie sygnału podajemy <em>PID</em>, tak zatrzymany proces da się
          wznowić za pomocą sygnału <strong>CONT</strong>. Nazwy sygnałów
          podajemy po myślniku (<strong>-</strong>).
        </p>
        <p>
          Naciśnięcie kombinacji <em>Ctrl+c</em> podczas działania programu w
          powłoce, jest równoznaczne z wysłaniem sygnału <strong>INT</strong>
          (ang. <em>Interrupt</em> - przerwanie).
        </p>
        <p>
          Jedną z metod zakończenia procesu jest natychmiastowe zakończenie
          jego pracy oraz usunięcie go siłą z pamięci, jest to osiągalne
          poprzez wysłanie do niego sygnału <strong>KILL</strong>. Jest to
          ostateczność, gdy dany proces nie odpowiada na inne sygnały. Inne
          sygnały dają procesom możliwość poprzątania po sobie.
        </p>
        <p>
          Oczywiście nie należy przerywać pracy dowolnym procesom, kiedy nie
          wiemy co robią.
        </p>
        <h3 id="2.16.2.jobcontol">2.16.2. Kontrola zadań</h3>
        <p>
          Powłoki posiadają mechanizm dzięki, któremu możemy zatrzymywać oraz
          wznawiać prace procesów za pomocą kombinacji <em>Ctrl+z</em> oraz
          poleceniami <strong>fg</strong>, <strong>bg</strong>. Ten mechanizm
          nazywa się <strong>kontolą zadań</strong>. Podczas działania procesu
          w powłoce, możemy wysłać sygnał <strong>TSTP</strong> (podobny do
          sygnału STOP), a następnie kiedy zechcemy do niego wrócić to
          wystarczy wydać polecenie <em>fg</em>, które wznowi działanie
          polecenia w terminalu, lub polecenia <em>bg</em> wznawiającego
          działanie procesu w tle.
        </p>
        <p>
          Podobne działanie ma program <em>GNU Screen</em>, który jest
          multiplekserem terminala, a co najlepsze jesteśmy wstanie odłączyć
          sesję programu od pierwszego planu i pozostanie ona w
          niezmienionej postaci, tak długo jak włączony jest komputer.
        </p>
        <h3 id="2.16.3.processinbg">2.16.3. Procesy działające w tle</h3>
        <p>
          Uruchamiając polecenie w powłoce dostęp do znaku zachęty, a co za tym
          idzie wolnego wiersza polecenia otrzymujemy dopiero po zakończeniu
          działania programu. Jednak możemy odłożyć wykonanie polecenia do tła,
          poczym od razu uzyskamy dostęp znaku zachęty. Jest to przydatna
          funkcją, gdy uruchamiamy polecenie, którego wykonanie może
          zająć trochę czasu. Wykonanie odkładamy do tła dopisując
          ampersand (<strong>&amp;</strong>) na końcu polecenia (jako ostatni
          argument). Działanie takiego programu
          może trwać nawet po naszym wylogowaniu. Jeśli proces zakończy
          działanie zostaniemy o tym poinformowani.
        </p>
        <p>
          Problem związanym z procesami działającymi w tle jest, możliwe
          pobieranie informacji z standardowego wejścia. Jeśli nie
          przewidzieliśmy takiego zachowania programu, to wówczas może zostać
          on zatrzymany lub zakończony. Można go wznowić za pomocą polecenia
          <em>fg</em> o ile został zatrzymany. Innym problemem jest wypisywanie
          danych przez proces w tle na standardowe wyjście oraz strumień błędów.
          Przed uruchomieniem takiego polecenia należy przekierować te
          strumienie, ponieważ podczas pracy w terminalu z innymi aplikacjami
          dane ze strumieni mogą zaburzać ich wyświetlanie. Jeśli powłoka 
          będzie dziwnie się zachowywać, wystarczy wydać polecenie 
          <strong>reset</strong> i wszystko wróci do normy.
        </p>
        <h2 id="2.17.filemodandpermissions">2.17. Tryb pliku i uprawnienia</h2>
        <p>
          Każdy plik na Uniksie (więc na Linuksie też), posiada komplet
          <strong>uprawnień</strong> określajacy czy można go odczytać, 
          zapisać do niego lub go
          uruchomić. Pierwsza kolumna wyniku polecenia <code class="code-inline">ls -l</code>
          zawiera tryb pliku. Dane trybu możemy podzielić na cztery części
          <strong>Typ</strong>, <strong>Uprawnienia użytkownika (właściciela)</strong>,
          <strong>Uprawnienia grupy</strong>, <strong>Uprawnienia pozostałych
          użytkowników.</strong>.
        </p>
        <p>
          Pierwszy znak to typ pliku, jesli występuję w nim myślnik (<strong>-</strong>),
          to mamy doczynienia ze zwykłym plikiem, innym typem pliku może być
          litera <strong>d</strong> oznaczająca katalog.
        </p>
        <p>
          Pozostałe znaki, definiują uprawnienia. Dzieli się je na trzy grupy
          wypisane powyżej, po trzy znaki na każdą z nich. W grupie (zestawie
          uprawnień, przeznaczonym dla konkretnej grupy lub osoby) mogą
          wystąpić 4 rodzaje znaków.
        </p>
        <ul>
          <li><strong>r</strong> - oznacza, że plik można czytać.</li>
          <li><strong>w</strong> - oznacza, że do pliku można pisać.</li>
          <li><strong>x</strong> - oznacza, że plik można uruchomić.</li>
          <li><strong>-</strong> - oznacza, brak uprawnienia.</li>
        </ul>
        <p>
          Mówiąc o użytkowniku w pierwszym rodziale, wspomniałem że może być
          on właścicielem pliku i do niego należy pierwszy zestaw uprawnień.
          Drugi zestaw określa uprawnienia dla grupy, jaka została przypisana
          temu plikowi, z tych uprawnień będzie korzystać każdy użytkownik tej
          grupy, próbujący uzyskać dostęp do pliku. Trzeci grupa, należy do
          pozostałych użytkowników systemu. Użytkownika <em>root</em> nie
          obejmują żadne z powyższych grup, choć to może zależć od konfiguracji
          systemu, mimo to superużytkownik może sobie zmieniać dowolnie
          uprawnienia.
        </p>
        <p>
          Nie wymieniony na powyższej liście dodatkowym bitem (o uprawnieniach
          możemy mówić jak o bitach, np. "potrzebuje bitu odczytu aby odczytać
          dane z pliku") jest bit <strong>s</strong> - wybierz identyfikator
          użytkownika. Pojawia się on zamiast bitu wykonywania <em>x</em> i
          tyczy się wyłącznie plików wykonywalnych. Programy z ustawionym tym
          bitem zawsze uruchamiają się z uprawnieniami ich właściciela bez
          znaczenia, kto uruchamia ten program. Wiele programów korzysta z tego
          rozwiązania, aby uzyskać uprawnienia superużytkownika i móc zapisywać
          dane w różnych plikach systemowych.
        </p>
        <h3 id="2.17.1.modifypermissions">2.17.1. Modyfikacja uprawnień</h3>
        <p>
          Do zamiany uprawnień wykorzystamy polecenie <strong>chmod</strong>,
          jako pierwszy podaje się zbiór uprawnień, a następnie bit uprawnienia
          ze znakiem "+" jeśli chcemy dodać ten bit lub "-" jeśli chcemy ten 
          bit
          usunąć. Zbiór uprawnień podajemy za pomocą pierwszych liter 
          angielskich
          nazw <strong>u</strong> (ang. <em>user</em>)- użytkownika/właściciel,
          <strong>g</strong> (ang. <em>group</em>) - grupa, 
          <strong>o</strong> (ang. <em>others</em>)- pozostali użytkownicy 
          systemu.
        </p>
<pre class="code-block">
$ chmod go+r test.sh
</pre>
        <p>
          Zbiory uprawnień można łączyć ze sobą, tak jak na powyższym
          przykładzie lub jeśli chcemy dodać bit do wszystkich zbiorów to
          możemy je pominąć jak na poniższym przykładzie.
        </p>
<pre class="code-block">
-rw-r--r-- 1 xf0r3m xf0r3m 26 03-08 13:13 test.sh
$ chmod +x test.sh
-rwxr-xr-x 1 xf0r3m xf0r3m 26 03-08 13:13 test.sh
</pre>
        <p>
          Przy plikach osobistych, nie warto dawać za dużych oprawnień
          pozostałym użytkownikom. Chociaż obecnie może mieć to jedynie
          znaczenie, gdy z serwera korzysta wielu wyspecjalizowanych 
          użytkowników.
        </p>
        <p>
          Innym sposobem na zmianę uprawnień jest użycie liczb, gdzie każda
          z trzech liczb określa uprawnienia dla jednego zbioru. Liczby te są
          sumami bitów, które reprezentowane są przez poszczególne wartości.
        </p>
        <ul>
          <li><em>r</em> - <strong>4</strong></li>
          <li><em>w</em> - <strong>2</strong></li>
          <li><em>x</em> - <strong>1</strong></li>
          <li><em>-</em> - <strong>0</strong></li>
        </ul>
<pre class="code-block">
$ chmod 644 test.sh 
</pre>
        <p>
          Uprawnienia właściciela mają wartość <code class="code-inline">6</code>.
          co jest równe <em>4+2</em> - <em>u+rw</em>, grupa oraz pozostali mają
          <code class="code-inline">4</code> co jest identyczne z zapisem
          <em>go+r</em>. Liczby wykorzysywane tutaj pochodzą z oktalnego 
          systemu liczbowego. 
        </p>
        <p>
          Zmiana uprawnień nosi nazwę <strong>bezwzględnej</strong>, ponieważ
          zmieniane są uprawnienia wszystkich grup.
        </p>
        <p>
          Odnośnie uprawnień to istnieje bardzo ważna zależność pomiędzy bitami
          odczytu oraz wykonania. Nadając katalogowi domowemu uprawnienia
          <em>rwxr--r--</em> czy <em>744</em>. Pozostali użytkownicy będą
          mogli odczytać zawartości katalog, ale nie uzyskają dostępu do pliku
          podając go w jakimś poleceniu na ścieżce, do tego potrzebny jest 
          jeszcze bit wykonania. 
        </p>
        <p>
          Za pomocą polecenia <strong>umask</strong>, możemy zdefiniować
          domyślne uprawnienia dla plików. Polecenie to przyjmuje jako 
          argument te uprawnienia w postaci bezwględnej, które mają zostać
          usunięte z nowoutworzonych plików i katalogów. Wydanie polecenia
          umask:
        </p>
<pre class="code-block">
$ umask 022
</pre>
        <p>
          Spowoduje, że nowoutworzone pliki i katalogi będą mięc uprawnienia
          w postaci <em>rwxr-xr-x</em> lub <em>755</em>. Może wydawać się zbyt
          liberalne, więc możemy ustawić argument polecenia nas <em>077</em>, 
          wówczas
          wszystkie utworzone pliki i katalogi będą wyłącznie dla nas. 
          Polecenie
          <em>umask</em>, czesto występuje w plikach konfiguracyjnych powłoki.
        </p>
        <h3 id="2.17.2.symlinks">2.17.2. Dowiązania symboliczne</h3>
        <p>
          Dowiązanie syboliczne to jest alias będący plikiem wskazującym na
          inny pliki lub katalog. Można uciec się do jednego słowa, że
          dowiązanie symboliczne jest poprostu skrótem.
        </p>
        <p>
          Jeśli dowiązanie wskazuje na katalog, to przejście do dowiązania
          przeniesie nas w miejsce, na które wskazuje. Cel dowiązania nie
          musi nawet istnieć, jeśli jednak spróbuje przejść pod takie
          dowiązanie wówczas uzyskamy typowy błąd, o tym że katalog nie
          istnieje. Dowiązania uniemożliwają również sprawdzenie 
          charakterystyki
          wskazywanego elementu, nie będzie wiadomo czy jest to plik, katalog
          czy inne dowiązanie. Wiele połączonych ze sobą dowiązań symbolicznych
          nazywane jest <strong>łańcuchem dowiązań</strong>
        </p>
        <p>
          Dowiązania symboliczne tworzone są za pomocą polecenia <strong>ln</strong>
          z opcją <strong>-s</strong> (<strong>Ważne, aby użyć tej opcji</strong>).
          Argumentami jest na początku <strong>cel</strong> a poźniej nazwa
          dowiązania. Zachowanie kolejności argumentów jest ważne, ponieważ
          możemy utworzyć dowiązanie, które prowadzi do nikąd i wprowadza
          bałagan (być może w plikach systemowych).
        </p>
        <p>
          Mimo swoich wad dowiązanią są wygodną metodą na współdzielenie plików
          oraz dodatkowo rozwiązują kilka drobnych problemów.
        </p>
        <h2 id="2.18.archivesandcompression">2.18. Archiwizowanie i
        kompresowanie danych</h2>
        <p>
          Przesyłając duża ilość małych plików przez sieć czy tez na pamięć
          masową, możemy odczuć że trwa to wieki, na pewno trwa to dłużej niż
          przesłanie jednego dużego pliku. Tutaj przedstawię sposoby na
          stworzenie
          jednego większego pliku z całego katalogu, przy czym użyjemy jeszcze
          kilku algorytmów kompresii, przez co zaoszczędzimy na czasie i trochę
          na zajmowanym miejscu. 
        </p>
        <h3 id="2.18.1.tarprogram">2.18.1. Program tar</h3>
        <p>
          Pierwsze narzędzie będzie służyć do tworzenia archiwum. Archiwa
          łączą pliki i katalogi w jeden plik. <strong>Tar</strong> jest 
          standardowym program do archiwizacji na uniksach. 
          Tworzenie archwium za pomocą <em>tar</em> wymaga kilku
          opcji. Natomiast składania polecenia jest następująca:
        </p>
<pre class="code-block">
$ tar -cvf archiwum.tar plik1 plik2...
</pre>
        <p>
          Opcja <code class="code-inline">-c</code> mówi programowi, że
          tworzone będzie nowe archiwum, opcja <code class="code-inline">-v</code>
          włącza komunikaty diagnostyczne wyświetlać one będą po kolei pakowane
          do archiwum pliki; opcja <code class="code-inline">-f</code>
          przekazuje programowi informacje o tym, że archwium będzie plikiem.
          Domyślnie <em>tar</em> tworzył archiwa na taśmach. Obecnie pominięcie
          tej opcji kończy pracę programu z komunikatem o błędzie. Możemy 
          natomiast użyć <em>stdout</em> podajac zamiast nazwy archiwum
          myślnik (<strong>-</strong>). Póki co to archiwum nie jest jeszcze 
          skompresowane.
        </p>
        <h4>Rozpakowywanie pliku</h4>
        <p>
          Rozpakowawanie różni się tylko jedną opcją - zamiast <em>-c</em> jest
          <strong>-x</strong>. Następnie podajemy pozostałe opcje, a na końcu
          nazwę pliku archiwum.
        </p>
        <h4>Wyświetlenie zawartości archiwum</h4>
        <p>
          Wypakowanie całego archiwum może nie być do końca porządane, załóżmy
          że potrzebujemy tylko jednego pliki. Za pomocą polecenia <em>tar</em>
          z odpowiednim przełącznikiem możemy wyświetlić listę plików w 
          archiwum. Zamiast <em>-x</em>, używamy
          <strong>-t</strong> reszta pozostaje taka sama, jeśli archiwum jest
          duże to możemy podłączyć wyjście <em>tar</em> potokiem do polecenia
          <em>less</em>. Samego wypakowania dokonujemy podając wypakowywanego
          pliku za nazwą archiwum.
        <p>
        <p>
          Ostanią dość istotną opcję jest <strong>-p</strong>, która powoduje
          zachowanie oryginalnych atrybutów plików, jakie miały podczas
          pakowania. Kiedy superużytkownika używa <em>tar</em>, ta opcja jest
          domyślnie włączona.
        </p>
        <h3 id="2.18.2.gzipprogram">2.18.2. Program gzip</h3>
        <p>
          Program <strong>gzip</strong> (<em>GNU zip</em>) jest standardowym 
          narzędziem kompresującym w systemach uniksowych. Pliki skompresowane
          za jego pomocą otrzymują rozszerzenie <strong>.gz</strong>.
          Dekompresuje się je za pomocą polecenia <strong>gunzip</strong>, jako
          argument podaje się nazwę pliku. Natomiast kompresji dokonuje za
          pomocą polecenia <strong>gzip</strong>, podając plik do 
          skompresowania jako argument. 
        </p>
        <h3 id="2.18.3.compressedarchives">2.18.3. Skompresowane archiwa
          <em>tar.gz</em></h3>
        <p>
          Obsługę skompresowanych archwów przy użyciu <em>gzip</em>,
          rozpoczniemy od rozpakowania takiego archiwum. Nie ma sensu używania
          do tego dwóch osobnych poleceń, jest to z resztą marnowanie zasobów.
          Chcąc rozpakować skompresowane <em>gzip</em> archiwum, należy użyć
          polecenia <em>tar</em> a po opcji
          <em>-x</em> dodać, opcję <em>-z</em> następnie pozostałe czyli
          <em>-vf</em> i na końcu podać nazwę archiwum. Tak jak na przykładzie: 
        </p>
<pre class="code-block">
$ tar -xzvf archiwum.tar.gz
</pre>
        <p>
          Przy tego typu archiwach, możemy spodziewać się rozszerzenia
          <strong>.tgz</strong>. Są to te same archiwa, jak te mające 
          rozszerzenie <em>tar.gz</em>.
        </p>
        <p>
          Przy wyświetlaniu zawartości takiego archiwum, zamieniamy opcję
          <strong>-x</strong> na <strong>-t</strong>. A chcąc takie archwiwum
          utworzyć to opcję <strong>-x</strong> na opcję <strong>-c</strong>
          oraz podać katalog lub listę plików, która ma zostać umieszczona w
          archiwum po jego nazwie.
        </p>
        <h3 id="2.18.4.othercompression">2.18.4. Inne metody kompresji</h3>
        <p>
          Poza archiwami spakowanymi za pomocą <em>gzip</em>, możemy też
          spotkać archiwa spakowane za pomocą <strong>bzip2</strong> oraz
          <strong>xz</strong>. W przypadku <em>bzip2</em>, to programem
          dekompresującym jest <strong>bunzip2</strong>, a opcją programu
          <em>tar</em> jest <strong>-j</strong> (mała litera j). Jeśli
          natrafimy na archiwum skompresowane <em>xz</em>, to programem
          dekompresującym jest <strong>unxz</strong>, a opcją programu
          <em>tar</em> jest <strong>-J</strong> (wielka litera j). 
        </p>
        <p>
          Część dystrybucji wyposażona jest w program <em>unzip</em>
          pozwalający na rozpakowanie plików <em>.zip</em> przygotowanych
          pod systemem MS Windows, jak i samo rozpakowywujących się plików
          <em>.exe</em>. 
        </p>
        <h2 id="2.19.filesystemhierarchy">2.19. Hierarchia katalogów</h2>
        <p>
          Struktura katalogów głównego, jest utworzona na
          podstawie <strong>standardu hierarchii systemu plików</strong>,
          określającego jakie podkatalogi ma zawierać katalog główny, oraz
          co te podkatalogi mają przechowywać. Poniżej opisano na ten czas
          najważniejsze z nich.
        </p>
        <ul>
          <li><strong>/bin</strong> - przechowuje pliki binarne przygotowane
            przez kompilator języka C, w nowocześniejszych systemach mogą to 
            być
            skrypty powłoki. W nim przechowywane są te najprostsze polecenia
            jak <em>cp</em>.</li>
          <li><strong>/dev</strong> - przechowuje pliku urządzeń.</li>
          <li><strong>/etc</strong> - katalog zawierający najważniejsze pliki
            konfiguracji systemu. Znajdują się tutaj pliki haseł, konfiguracji
            uruchamiania systemu, urządzeń, sieci i innych elementów systemu.</li>
          <li><strong>/home</strong> - zbiorczy katalog, katalogów domowych
            użytkowników. Standard wśród wszystkich nowoczesnych uniksów.</li>
          <li><strong>/lib</strong> - katalog przechowywujący biblioteki.
            Te pliki przechowują kod, który może być wykorzystywany przez 
            pliki wykonywalne. Biblioteki możemy podzielić na statyczne lub
            współdzielone. Tylko biblioteki współdzielone powinny znajdować
            się w tym katalogu, pozostałe pliki tego typu znajdują się
            w katalogu <em>/usr/lib</em>.</li>
          <li><strong>/proc</strong> - udostępnia statystyki o systemie w 
            postaci interfejsu plików i katalogów.
          </li>
          <li><strong>/sys</strong> - ten katalog jest podobny do katalogu
            <em>/proc</em>, z tym, że tworzy interfejs dla urządzeń oraz
            systemu. Wiecej informacji na ten temat, znajduje się w następnym
            rozdziale.
          </li>
          <li><strong>/sbin</strong> - w tym katalogu zapisane są systemowe
            pliki wykonywalne. Programy znajdujące się w katalogach
            <em>/sbin</em> przeznaczone są do zarządzania systemem, dlatego
            ten katalog nie występuje na ścieżce zwykłego użytkownika a wiele
            narzędzi będzie działać tylko z kontem <em>root</em>.
          </li>
          <li><strong>/tmp</strong> - w tym katalogu możemy umieszczać pliki
            tymczasowe, którymi nikt się nie będzie przejmować. Każdy
            użytkownik może zapisywać i odczytywać pliki z katalogu w tym
            katalogu, ale nikt nie ma dostępu do plików zapisanych przez innych
            użytkowników. Nie które programy wykorzystują, ten katalog jako
            przestrzeń roboczą. Nie należy zapisywać ważnych danych do tego
            katalogu, gdyż jego zawartość jest przez wiekszość dystrybucji 
            czyszczona podczas uruchamiania systemu, inne mogą usuwać 
            starsze pliki co jakiś czas.</li>
          <li><strong>/usr</strong> - W tym katalogu znajdziemy rozbudowaną,
            strukturę katalogów, bardzo podobną to katalogu głównego. W tym
            katalogu zapisana jest większa części systemu Linux.</li>
          <li><strong>/var</strong> - podkatalog zawierający "zmienne" dane
            zapisywane przez programy w czasie swojego działania. Tutaj 
            znajdują się m.in. pliki dzienników systemowych.</li>
        </ul>
        <h3 id="2.19.1.othermainsubdirs">2.19.1. Pozostałe katalogi główne</h3>
        <ul>
          <li><strong>/boot</strong> - przechowuje plik ładujące jądro systemu
          w czasie uruchamiania komputera. W większości dystrybucji w tym
          katalogu przechowywane są właściwe pliki jądra oraz początkowego
          systemu plików w pamięci RAM. Początkowy system plików pamięci RAM
          zostanie omówiony w dalszej materiału.</li>
          <li><strong>/media</strong> - w wielu dystrybucjach jest to główny
          punkt przyłączania wszystkich mediów wymiennych, takich jak
          karty pamięci Flash.</li>
          <li><strong>/opt</strong> - może przechowywać dodatkowe
          oprogramowanie firm trzecich. W wielu systemach katalog <em>/opt</em>
          nie jest wykorzystywany.</li>
        </ul>
        <h3 id="2.19.2.usrdirectory">2.19.2. Katalog /usr</h3>
        <p>
          To właśnie w katalogu <em>/usr</em> znajduje się większość programów
          i danych przestrzeni użytkownika, a są one rozlokowane po jego
          podkatalogach. Poniżej znajduje się opis co znajduje się w 
          poszczególnych podkatalogach tego katalogu:
        </p>
        <ul>
          <li><strong>bin</strong> - większość, jak nie wszystkie
            ogólnodostępne programy w systemie.</li>
          <li><strong>include</strong> - przechowuje pliki nagłówkowe
            wykorzystywane przez kompilator języka C.</li>
          <li><strong>info</strong> - zawierają strony dokumentacji
            <em>GNU</em> info.</li>
          <li><strong>local</strong> - miejsce gdzie administratorzy mogą
            mogą instalować swoje oprogramowanie, katalog ten może zawierać
            podobną identyczną strukturę, jak katalog <em>/usr</em> lub
            katalog główny.</li>
          <li><strong>man</strong> - przechowuje strony podręcznika
            systemowego.</li>
          <li><strong>share</strong> - kiedyś ten katalog był katalogiem
            współdzielonym między komputerami, obecnie stracił na znaczeniu.
            Mimo to dalej przechwouje informacje, przeważnie są to pliki ikon, 
            pliki zawierające znaki
            towarowe dystrybucji oraz inne dane z których może korzystać wiele
            programów. Ten katalog może zawierać podkatalogi takie jak
            <em>man</em> oraz <em>info</em>.</li>
        </ul>
        <h3 id="2.19.3.kernelplace">2.19.3. Umiejscowanie jądra w systemie</h3>
        <p>
          Wspomniałem już że plik jądra znajduje się w katalogu <em>/boot</em>,
          plik ten rozpoczyna się od nazwy <strong>vmlinuz</strong>, po tych
          znakach
          mogą wystąpić inne inforamcje oznaczające jego wersje. Po załadowaniu
          jądra przez program rozruchowy, sam plik przestaje być
          potrzebny. W trakcie pracy systemu operacyjnego jądro wykorzystuje
          najróżniejsze ładowane i usuwane dodatkowo modułu. <strong>Ładowane
          moduły jądra</strong> umieszczane są w katalogu <em>/lib/modules</em>.
        </p>
        <h2 id="2.20runitasroot">2.20. Uruchamianie poleceń przez superużytkownika</h2>
        <p>
          Korzystając z linuksa na naszym osobistym komputerze, przyjdzie taki
          moment że będziemy musieli skorzystać z konta użytkownika 
          <em>root</em>. Aby to zrobić możemy przelogować się na jego konto
          wykonać potrzebne czynności a następnie się wylogować. Ta czyność
          przyniosła by zamierzony efekt ale nie jest bez wad. Dlatego też
          możemy skorzystać z polecenia <strong>sudo</strong>, które
          pozwoli, na uruchomienie polecenia podanego jako arugment 
          z uprawnieniami
          superużytkownika. Jeśli polecenie nie występuje w systemie, to jest
          dobry czas aby przelogować się na użytkownika <em>root</em>, i je
          zainstalować. Polecenie po zainstalowaniu nie zadziała samo w sobie
          potrzebne jest jeszcze określenie, którzy użytkownicy mogą używać
          tego polecenia i co za jego pomocą mogą zrobić. Za to odpowiada
          pliki <strong>/etc/sudoers</strong>.
        </p>
        <h3 id="2.20.1.sudoersfile">2.20.1. Plik /etc/sudoers</h3>
        <p>
          Samo polecenie sudo ma bardzo duża ilość opcji, jednak na tym
          etapie nie skorzystamy z większości z nich. Najprostszym sposobem
          na konfiguracje pliku <em>/etc/sudoers</em> jest odnalezienie w pliku
          linii rozpoczynającej się pod słowa <em>root</em> a następnie
          pod tą linią wpisać linię rozpoczynjącą się nazwy użytkownika oraz
          dopisaniu kilku opcji, tak jak na poniższym przykładzie.
        </p>
<pre class="code-block">
user ALL=(ALL) ALL
</pre>
        <p>
          Pierwsze <code class="code-inline">ALL</code>, oznaczna dowolny
          komputer. Drugie
          <code class="code-inline">(ALL)</code> w nawiasach oznacza, że możemy
          wydać polecenie jako dowolny użytkownik, być może spotkamy się
          z takim zapisem w nawiasie (<em>ALL:ALL</em>), oznacza ono dowolnego
          użytkownika i dowolną grupę. Trzecie <code class="code-inline">ALL</code>
          oznacza dowolne polecenie.
        </p>
        <p>
          Jeśli drażnić nas będzie ciągłe wpisywanie haseł, to możemy przed
          trzecim <em>ALL</em> w konfiguracji umieścić opcję 
          <strong>NOPASSWD</strong>, pamiętając aby pomiędzy te opcje wstawić
          dwukropek (<strong>:</strong>) bo tak naprawdę określamy jakie
          polecenia mają być uruchamiane bez podawania hasła.
        </p>
        <h2 id="2.21.summary">2.21. Podsumowanie</h2>
        <p>
          Po przeczytaniu tego rodziały wydaje mi się, że każdy ma solidne
          podstawy obsługi systemu Linux z poziomu powłoki. Powłoka jest
          jednym ze stałych komponentów dystrybucji, a wiele z nich dalej
          obstaje przy BASH-u, jako domyślnej powłoce.
        </p>
        <h1 id="3.devices">3. Urządzenia</h1>
        <p>
          Odkąd powstał system Linux, w sposobach prezentowania urządzeń
          użytkownikowi zachodziło wiele zmian. Na początku tego rozdziału
          omówimy sobie tradycjny system <strong>sysfs</strong>. Aby potem
          zająć się omówieniem systemu <strong>udev</strong>, pozwalającego 
          programom przestrzeni użytkownika automatycznie konfigurować oraz
          używać nowych urządzeń. Podczas normalnego użytkowania systemu
          rzadko będziemy mieć okazję do zarządzania urządzeniami. Nasza
          interakcja z urządzeniami będzie ograniczać się do obsługi pamięci
          masowych i korzystania najstarszego i naprostszego interfejsu jakim
          jest katalog <em>/dev</em>. Mimo to, warto jednak wiedzieć w systemie
          co jest od czego. 
        </p>
        <h2 id="3.1.devicefiles">3.1. Pliki urządzeń</h2>
        <p>
          Jądro udostępnia wiele urządzeń pod postacią plików, co daje nam
          możliwość prostej manipulacji nimi. Te pliki są często nazywane
          <strong>węzłami urządzeń</strong>. Korzystać z urządzeń możemy
          za pomocą zwykłych operacji na plikach. Tego typu rozwiązanie nie
          jest bez wad dlatego też nie wszystkie urządzenia lub ich funkcje
          są udostępnianie w ten sposób.
        </p>
        <p>
          Pliki urządzeń są przechowywane w katalogu <strong>/dev</strong>.
          A najprostszym sposobem interakcji z urządziem jest przekierowanie
          wyniku jakiegoś polecenia do urządzenia <strong>/dev/null</strong>.
          Urządzenie to jest miejscem na nie potrzebne nam dane ze strumieni,
          ponieważ cokolwiek trafi do tego urządzenia, jest przez jądro
          poprostu ignorowane.
        </p>
        <p>
          Wyświetlając sobie zawartość katalogu w bardziej szczegółowej liście
          może zauważyć dziwne oznaczenia w trybie pliku. Litery te określają
          rodzaje urządzeń a wśród nich możemy wyszczególnić:
        </p>
        <ul>
          <li><strong>Urządzenia blokowe - b</strong> - Procesy mogą odczytywać
            dane z urządzeń blokowych przy użyciu bloków o stałej wielkości.
            Pamięci masowe są przykładem urządzeń blokowych. Łatwo dzieli się 
            je na bloki, a ogólna wielkość
            takiego urządzenia jest stała i można ją zindeskować, co daje
            możliwość jądru na dostępu do dowolnego bloku danych.</li>
          <li><strong>Urządzenia znakowe - c</strong> - Urządzenia znakowe
            działają w oparciu o strumienie danych. Do takich urządzeń można
            zapisywać i odczytywać pojedyńcze znaki. Jądro zazwyczaj wykonuje
            operacje odczytu i zapisu na fizycznym urządzeniu. Drukarki są 
            przykładami urządzeń znakowych. Warto wspomnieć, że jądro nie
            jest w stanie ponownie odczytać danych ze strumienia po przekazaniu
            ich dalej do procesu.</li>
          <li><strong>Urządzenia potokowe - p </strong> - tzw.
            <strong>nazwane potoki</strong> są to urządzenia podobne do
            urządzeń znakowych z tą jednak różnicą, że na drugim końcu
            strumienia wejścia-wyjścia nie znajduje się fizyczne urządzenia ale
            inny proces.</li>
          <li><strong>Urządzenia gniazdkowe - s</strong> - tzw. <strong>gniazda</strong>
            są interfejsami specjalnego przeznaczenia i służa komunikacji
            międzyprocesowej. Mogą występować poza katalogiem <em>/dev</em>.</li>
        </ul>
        <p>
          Inną dość rzucającą się w oczy informacją na listingu katalogu, są
          dwie liczy odzielone przecinkiem zamiast rozmiaru pliku, jest
          <strong>numer główny</strong> i <strong>numer poboczny</strong>.
          Te numer ułatwiają jądru identyfikacje urządzeń. Dla przykładu
          partycje tego samego dysku mają ten sam <em>numer główny</em> ale
          inny <em>numer poboczny</em>.  
        </p>
        <p>
          Nie wszystkie urządzenia mają swoje pliki, takim przykładem są
          interfejsy sieciowe. Jądro wykorzystuje dla nich inny interfejs
          wejścia-wyjścia.
        </p>
        <h2 id="3.2.sysfsdevicepath">3.2. Ścieżka urządzeń sysfs</h2>
        <p>
          Ze względu na uproszczoną interakcje z urządzeniami poprzez 
          odwołowywanie się do pliku w katalogu <em>/dev</em> oraz fakt, że
          jądro systemu nadaje plikom z tego katalogu nazwy na podstawie
          koleności wykrywania urządzeń podczas uruchamiania systemu,
          wewnątrz jądra zaimplementowano interfejs <strong>sysfs</strong>.
          <em>Sysfs</em> jest ujednoliconym sposobem prezentacji urządzeń 
          bazującym
          na atrybutach sprzętowych, mający formę struktury katalogów i plików.
          Główny katalogiem tego systemu jest katalog <strong>/sys/devices</strong>.
          Przykładowa ścieżka dla pierwszego dysku SATA mającego swój plik
          <em>/dev/sda</em> może wyglądać następująco:
        </p>
<pre class="code-block">
/sys/devices/pci0000:00/0000:00:1f:2/host0/target0:0:0/0:0:0:0/block/sda
</pre>
        <p>
          Warto tutaj zaznaczyć iż, scieżki systemu <em>sysfs</em> nie służą 
          uzyskaniu dostępu do urządzeń, umożliwają przeglądanie informacji
          oraz zarządzanie urządzeniami. Dane zawarte na plikach na ścieżkach
          <em>sysfs</em> powinny być odczytywane przez programy nie przez
          ludzi.
        </p>
        <p>
          Chcąc sprawdzić scieżkę <em>sysfs</em> dla dowolnego urządzenia z
          katalogu <em>/dev</em> należało by uzyć programu systemu <em>udev</em>
          <strong>udevadm</strong>.
        </p>
<pre class="code-block">
$ udevadm info --query=all --name=/dev/sda
</pre>
        <p>
          Wykonując to polecenie dowiemy się przy okazji ile danych można 
          uzyskać informacji z systemu <em>udev</em>.
        </p> 
        <h2 id="3.3.ddcommand">3.3. Polecenie dd</h2>
        <p>
          Polecenie <strong>dd</strong> jest dość prostym, aczkolwiek 
          przydatnym narzędziem jeśli
          choodzi o prace z urządzeniami znakowymi czy blokowymi. Jedyną
          rzeczą, którą robi to polecenie jest odczyt danych z pliku 
          wejściowego lub ze strumienia i zapisanie go do wyjściowego pliku
          lub strumienia, przy okazji dokonując pewnych konwersji. Najczęsciej
          używane przeze mnie polecenie znajduje się poniżej. 
        </p>
<pre class="code-block">
$ sudo dd if=/dev/zero bs=1M of=/dev/sdX count=1
</pre>
        <p>
          Polecenie wykorzystuje uprawnienia superużytkownika, aby uzyskać
          dostęp do urządzenia blokowego. Samo polecenie zapisuje jeden
          blok o wielkości 1M za pomocą zer z pliku <em>/dev/zero</em> 
          (nieskończony strumień zer), co powoduje usunięcie tablicy partycji
          (o której będzie w następnym rodziale).
        </p>
        <p>
          Poniżej zostaną opisane najważniejsze opcje programu <em>dd</em>,
          ich format różni się od innych programów uniksowych. Do przypisania
          wartości opcją używa się tutaj znaku równości (<strong>=</strong>).
        </p>
        <ul>
          <li><strong>if=plik</strong> - plik wejściowy. Domyślnie stosowane
            jest standardowe wejście.</li>
          <li><strong>of=plik</strong> - plik wyjściowy. Domyślnie stosowane
            jest standardowe wyjście.</li>
          <li><strong>bs=rozmiar</strong> - rozmiar bloku danych. Polecenie
            przesyła wiele bloków naraz, więc możemy użyć wielokrotności 
            takich jak: bajt - <em>B</em>, kilobajt - <em>K</em>, megabajt -
            <em>M</em>, gigabajt - <em>G</em> i tak dalej.</li>
          <li><strong>ibs=rozmiar</strong>, <strong>obs=rozmiar</strong> - 
            rozmiar blok wejściowego oraz bloku wyjściowego, jeśli nie możliwe
            jest stosowanie dla plików wejściowych oraz wyjściowych tego
            samego rozmiaru bloku.</li>
          <li><strong>count=liczba</strong> - liczba kopiowanych bloków.</li>
          <li><strong>skip=liczba</strong> - powoduje pominięcie pierwszych
            <em>liczba</em> bloków danych. Nie są one kopiowane do pliku
            wyjściowego.</li>
        </ul>
        <p>
          Przy korzystaniu z <em>dd</em>, należy uważać gdyż literówka w 
          poleceniu wystarczy, aby uszkodzić system lub spowodować utratę
          ważnych dla nas danych.
        </p>
        <h2 id="3.4.namingsummary">3.4. Podsumowanie nazewnictwa urządzeń</h2>
        <p>
          Do pracy z urządzeniami potrzebujemy jego nazwy. W systemie istnieje
          kilka metod pozwalających na ustalenia nazwy urządzenia.
        </p>
        <ul>
          <li>Odpytanie systemu <em>udev</em>, za pomocą polecenia <em>udevadm</em>.</li>
          <li>Przeszukanie katalogu <em>/sys</em>.</li>
          <li>Wyświetlenie plików dziennika jądra za pomcą polecenia <em>dmesg</em>,
              w plikach dziennika znajdują się jego ostatnie komunikaty w tym
              informacje o znalezionych urządzenia i nadanych im nazwach.</li> 
          <li>Jeśli to dysk i jest on widoczny w systemie to możemy skorzystać
              z polecenia <em>mount</em>, chyba że nasz system nie montuje
              samodzielnie partycji, to w tym przypadku możemy skorzystać z
              polecenia <strong>fdisk</strong> z opcją <strong>-l</strong>.</li>
          <li>Ostatni sposób działa tylko dla urządzeń blokowych oraz znakowych.
              W katalogu <em>/proc/devices</em> znajduje się zestawienie 
              urządzeń reprezentowanych przez <em>numer główny</em> oraz przez
              przypisany im sterownik. Wystarczy użyć <em>numeru głównego</em>
              jako wyrażenia regulanego i zastosować go na listingu katalogu
              <em>/dev</em>.</li>
        </ul>
        <p>
          Dzisiaj praca z urządzeniami na Linuksie sprowadza się głównie do
          partycjonowania dysku, więc aby znależć właściwe urządzenie wystarczy
          użyć polecenia <em>fdisk -l</em>.
        </p>
        <p>
          Na poniższej liście znajdują się najczęściej wykorzystywane na
          Linkusie konwencje nazwenicze.
        </p>
        <ul>
          <li><strong>Dyski twarde SATA - /dev/sd*</strong> - Nazewnictwo
            dysków pochodzi od protokołu SCSI, mimo iż same urządzenia SCSI
            wyszły z użycia. To protokół mający świetne zdolności adaptacyjne
            cały czas działa we współczesnych systemach. Nazwa np. <em>/dev/sda</em>
            odnosi się do całego dysku. Partycje oznaczne są dodatkowo liczbą
            np. <em>/dev/sda1</em>. Pamięci masowe ze złączem USB również 
            wykorzysują podsystem SCSI do komunikacji z komputerem dla tego też
            dyski tego typu również mogą występować jak <em>/dev/sd*</em>.</li>
          <li><strong>Napędy CD i DVD - /dev/sr*</strong> - Napędy optyczne
            tak samo jak dyski korzystają z SCSI. Jednak te urządzenia są tylko
            do odczytu. Jeśli chcielibyśmy skasować zawartość płyty, lub na
            niej coś nagrać, to należało by się odwołać do ogólnego urządzenia
            którego nazwa może byc na przykład taka: <em>/dev/sg0</em>. Raczej
            jednak do nagrywania płyt będziemy wykorzystywać specjalne 
            oprogramowanie.</li>
          <li><strong>Dyski twarde PATA - /dev/hd*</strong> - w starszych
            wersjach jądra, dyski były przedstawione za pomocą innych nazw.
            Obecnie dyski PATA również wykorzystują SCSI, więc ich nazwy nie
            będą się różnić od dysków SATA.</li>
          <li><strong>Terminale - /dev/tty1, /dev/pts/*, /dev/tty</strong> -
            Terminale są urządzeniami przeznaczonymi do przesyłania znaków
            pomiędzy system a urządzeniem wejscia-wyjścia, co najczęściej
            ma celu wyświetlanie tekstu na ekranie terminala. Pseudoterminale
            posiadają wyszystkie funkcję fizycznych terminali, jednak jądro
            nie komunikuje się z fizycznym urządzniem, a z programowym 
            interfejsem wejscia-wyjścia takim jak okno powłoki. Urządzenie
            <em>/dev/tty1</em> to pierwsza wirtualna konsola, a
            <em>/dev/pts/0</em> to pierwsze okno powłoki. Linux do działania
            nie potrzebuje klasycznego interfejsu użytkownika, jaki znamy
            z innych systemów operacyjnych. Nie potrzebuje okien, paska zadań,
            menu "Start" i innych elementów graficznych. Równie dobrze może
            działać jak system 'DOS' w tzw. <strong>trybie tekstowym</strong>.
            Praca w tym trybie pozwala na wykorzystanie komputera znacznym
            stopniu.
            Jedyne czego nie będziemy w stanie zrobić to skorzystać z czego
            kolwiek co wymaga wyświetlania graficznego wymagającego pokazania
            na ekranie czegoś więcej niż teskt i 8 podstawowych kolorów. 
            <strong>Tryb graficzny</strong>
            zawiera wszystkie te rzeczy znane z innych systemów operacyjnych a
            wymienione zostały one powyżej, choć to wszystko zależy od
            uruchomionego menadżera okien. Pierwsza wirtualna
            konsola jest pierwszym ekranem powłoki w trybie tesktowym, okna
            powłoki mogą wystąpić w środowisku graficznym po uruchomieniu
            odpowiedniego programu <em>Terminal</em> lub w przypadku trybu 
            tesktowego multipleksera terminala. Multipleksery są powielaczami, 
            pozwalającymi
            podzielić konsolę na kilka mniejszych "okien", w których możemy
            uruchomić kolejną powłokę. Zaś urządzenie <em>/dev/tty</em>, jest
            odniesienie procesu do właściwego terminala, jeżeli program
            odczytuje i zapisuje dane do terminala.</li>
          <li><strong>Porty szeregowe - /dev/ttyS*</strong> - są specjalnymi
            urządzeniami terminalowymi pozwalającymi na komunikację z różnej
            maści sprzętem wykorzystując do tego oprogramowanie, które pozwoli
            skonfigurowanie komunikacji. Porty szeregowe otrzymują w systemie
            nazwy kolejno: <em>/dev/ttyS0</em> itd. w zależności od tego ile
            mamy portów zainstalowanych w komputerze. Do połączenia za pomocą
            portu szeregowego można wykorzystać adaptery USB, te urządzenia 
            mogą posiadać następujące nazwy: /dev/ttyUSB* lub /dev/ttyAMC*.
            Modemy sieci komórkowych mogą występować w systemie pod postacią
            adapterów USB portów szeregowych.</li>
          <li><strong>Porty równoległe - /dev/lp0, /dev/lp1</strong> - służyły
            do podłączenia drukarek wykorzystujących port LPT. Obecenie
            zostały zastąpione przez porty USB. Drukarki mogą wymagać
            dodatkowych znaków sterujących, dlatego też do drukowania lepiej
            wykorzystać serwer druku CUPS, niż pisanie bezpośrednio do tego
            portu.</li>
          <li><strong>Urządzenia audio - /dev/dsp, /dev/audio, /dev/snd/*</strong> -
            Na Linuksie dostępne są dwa zestawy urządzeń odpowiadająych za
            dźwiek. Starszy, rzadziej spotykany system <em>OSS</em>
            korzystający z urządzeń <em>/dev/dsp</em> oraz <em>/dev/audio</em> 
            i nowszysz spotykany w większości dystrybucji <em>ALSA</em>
            używający urządzeń w katalogu <em>/dev/snd</em>. System dzwięku
            na Linuksie może być dwuwartstwowy, ponieważ do dyspozycji mamy
            serwer pośredniczący <em>PulseAudio</em>, główną jego zaletą jest
            łatwa możliwość przełącznia wyjść dzwięku oraz proste zarządzanie
            całym podsystem dźwięku z poziomu jednego panelu. Wykorzystanie
            samego systemu <em>ALSA</em> jest wystarczające, jednak
            nie zbyt wygodne, ale oczywiście co kto lubi.</li>
        </ul>
        <h3 id="3.4.1.makedev">3.4.1. Tworzenie plików urządzeń</h3>
        <p>
          We współczesnych systemach nie ma potrzeby samodzielnego tworzenia
          urządzeń, jednak czasami w specyficznych konfiguracjach może dość
          do potrzeby utworzenia urządzenia. Osobiście spotkałem się z takim
          przypadkiem konfigurując VPN na dystrybucji Alpine Linux, należało
          osobiście utworzyć urządzęnie znakowe TUN. 
        </p>
        <p>
          Urządzenie tworzymy za pomocą polecenia <strong>mknod</strong>,
          podając nazwę urządzenia, jego rodzaj i w zależności od rodzaju
          <em>numer główny</em> oraz <em>numer poboczny</em> (w przypadku
          nazwanych potoków, nie trzeba podawać <em>numery głównego</em> i
          <em>numeru pobocznego</em>.
        </p>
        <h2 id="3.5.udev">3.5 System udev</h2>
        <p>  
          Zarządzanie plikami urządzeń jest jedną z cech jądra, która
          mogła działać w przestrzeni użytkownika. Jądro tylko gdyby wykryło
          nowe urządzenie wysłało by powiadomienie do procesu
          <em>udevd</em>. Proces ten zbadał by charakterystykę urządzenia,
          utworzył dla niego odpowiedni plik, a na koniec przewprowadził 
          jego inicjację. Niestety to tylko teoria. 
        </p>
        <p>
          Rozwiązanie tego typu nie uwzględnia kilku problemów. Pliki urządzeń
          są potrzebne już na wszczesnych etapach uruchamiania, zatem proces
          <em>udev</em> musiał by zostać uruchomiony bardzo wcześnie, nie może
          mieć żadnych zależności wobec plików urządzeń i uruchomić się
          błyskawicznie, aby nie spowalniać procedury rozruchu systemu.
        </p>
        <h3 id="3.5.1.devtmpfs">3.5.1. System plików devtmpfs</h3>
        <p>
          System plików (będzie o tym w dalszej części materiału)
          <strong>devtmpfs</strong>, został opracowany w celu rozwiąznia
          problemów z dostęp do urządzeń w czasie uruchamiania systemu. W razie
          gdy jądro będzie potrzebować pliku urządzenia to utworzy je oraz
          powiadamia o tym fakcie system <em>udev</em>, który zamiast zajmować
          się tworzeniem pliku przystępuje do inicjacji urządzenia i informuje
          o tym pozostałe procesy. Po za tym proces <em>udev</em> tworzy kilka
          dowiązań symbolicznych w katalogu <em>/dev</em>, które bardziej
          szczegółowo identyfikują urządzenie, wyniki tego działania możemy
          obejrzeć w katalogu <em>/dev/disk/by-id</em>.
        </p>
        <p>
          System <em>udev</em>, tworzy nazwy dowiązań bazdując na typie
          interfejsu, nazwie producenta, informacji o modelu, numerze seryjnym
          oraz partycji. Proces pobiera te informacji na podstawie reguł
          systemu <em>udev</em>, jednak nie będziemy się tym tutaj zajmować.
        </p>
        <h1 id="4.disksandfs">4. Dyski i systemy plików</h1>
        <p>
          Dyski w systemach Linux przedstawiane są jako urządzenia blokowe z
          nazwami pochodzącymi od podsystemu SCSI - <em>/dev/sdX</em>. Z punktu
          widzenia systemu na dysku znajduje się wiele warstw oraz 
          komponentów. Wybrane częsci dysku możemu zaalokować na partycje,
          które system prezentuje w taki sam sposób jak dyski, dodają liczbę
          na końcu nazwy dysku. Wystąpienia partycji na dysku przechowywane
          są w <strong>tablicy partycji</strong>.
        </p>
        <p>
          Jądro systemu umożliwia dostęp do całego urządzenia (dysku) oraz do
          partycji dzięki osobnym plikom urządzeń.
        </p>
        <p>
          Każdy dysk musi posiadać chociażby jedną partycję, aby był użyteczny
          w systemie, z kolei taka partycja musi zostać sformatowana pod
          wybrany system plików, aby mogła przez chowywać jakie kolwiek dane.
          <strong>System plików</strong> możemy określić mianem bazy danych
          przechowywującej informacje na temat plików i katalogów.
        </p>
        <h2 id="4.1.partitioning">4.1. Partycjonowanie dysków</h2>
        <p>
          Partycjonowanie dysku, odbywa się w oparciu o schematy. <strong>
          Schematy partycjonowania</strong> okreslają ilość możliwych do
          utworzenia na dysku partycji oraz ewentualne dodatkowe informacje
          przechowywane w tablicy partycji. Wśród obecnie stosowanych możemy
          wyróżnić takie schematy jak <strong>MBR</strong> oraz <strong>GPT</strong>.      
        </p>
        <p>
          Na Linuksie dostępnych jest wiele narzędzi partycjonujących dysk,
          jedne są obsługiwane jak z poziomu środowiska graficznego inne
          zaś z poziomu terminala. Osobiście używam programu <strong>fdisk</strong>
          i to na nim skupię się jeśli chodzi o partycjonowanie. Program ten
          ma dwie istotne zalety. Po pierwsze nic nie zostanie zapisane do
          momentu gdy nie wydamy polecenia (Tak, w <em>fdisk</em> wydaje się
          polecenia, ale są one ograniczone do wpisania jednej litery i
          naciśnięcia klawisza <em>enter</em>); po drugie w pakiecie <em>fdisk</em>
          zawarty jest również program <strong>sfdisk</strong> (co prawda z
          nieco dziwną składnią), ktory umożliwia manipulowanie dyski z poziomu
          pojedynczych polecenie (w przypadku <em>fdisk</em> wykorzystywany 
          jest tryb interaktywny), przez co możemy użyć <em>sfdisk</em> w 
          skrypcie.
        </p>
        <h3 id="4.1.1.listingpartitiontable">4.1.1. Przeglądanie tablicy partycji</h3>
        <p>
          Przy użyciu polecenia:
        </p>
<pre class="code-block">
$ sudo fdisk -l
</pre>
        <p>
          możemy wyświetlić zawartość tablicy partycji wszystkich dysków w
          systemie, Jeśli zaś interesuje nas wybrane urządzenie możemy wpisać
          jego nazwę po opcji <code class="code-inline">-l</code>. Informacja
          zwracana przez polecenie zawiera informacje o schemacie
          partycjonowania w polu <em>Disklabel type:</em> oraz tabele
          przedstawiającą nazwę urządzenia, informacje o ustwionej fladze
          rozruchu, początku, końcu i rozmiarze podanym w sektorach (informacja
          ile wynosi sektor znajduje się w linii <em>Sector size</em>) oraz 
          identyfikatorze i nazwie typu partycji. Identyfikatory można wypisać
          podczas nadawania typu. 
        </p>
        <p>
          Schemat partycjonowania MBR nazwany jest <em>fdisk</em> <strong>dos</strong>.
          Identyfikator dysk jest krótszy. W przypadku tablicy partycji
          <em>GPT</em> identyfikator dysku zawiera ciągu znaków odzielone
          spacjami, nie występują w tabeli identyfikatory typów partycji
          ponieważ są tak duże jak identyfikator dysku (podczas ustalania
          wybierane są z wyświetlonej listy) oraz może wystąpić dodatkowa
          kolumna przechowywująca etykietę partycji. Jednak główną różnicą
          wśród tych schematów jest zarządzanie miejscem na dysku. Dyski z
          tablicami MBR mogą mieć maksymalną pojemność do 2TB, jeśli użyjemy
          wiekszego, to stosując tego typu partycję pozbędziemy się pozostałej
          części dysku, kolejny minus dla tego rodzaju to możlwość tworzenie
          maksymalnie czterech <strong>partycji podstawowych</strong>
          (zwykłych partycji na dane), jeśli 
          chcielibyśmy
          więcej owszem możemy jednak, musimy użyć jedno miejsce na 
          <strong>partycję rozszerzoną</strong>
          bedącą kontenerem dla dysków logicznych. W przypadku
          GPT raczej maksymalna wielkość dysku nie jest póki co osiąglna 
          (9,4 mld TB) a partycji podstawowych możemy utworzyć, aż 128. To są
          tak naprawę za i przeciw, które decydują o użytym schemacie.
        </p>
        <h3 id="4.1.2.modifypartition">4.1.2. Modyfikowanie tablicy partycji</h3>
        <p>
          Modyfikowanie tablicy partycji należy rozpocząć, od zastanowienia się
          na temat przydatności danych, które znajduja się obecnie na dysku.
          Ponieważ modyfikowanie tablicy partycji, często będzie wiązać się z
          potrzebą reformatowania modyfikowanej partycji. W stopniu podstawowym
          skupimy się tworzeniu oraz usuwaniu partycji. Modyfikowanie tablicy
          za pomocą <em>fdisk</em>, jest dość łatwe, polega na interaktywnym
          wydawaniu poleceń oraz odpowiadniu na pytania programu, dlatego też
          dla urozmaicenia użyjemy <strong>sfdisk</strong> zamiast wymienionego
          wcześniej programu. Dla przykładu stworzymy dysk do klasycznej
          instalacji systemu Linux z tablicą partycji typu MBR. Za dysk testowy
          może posłużyć nam pendrive, karta pamięci lub plik na dysku. Ja
          skorzystam z pliku. 
        </p>
        <p>
          Plik przygotowuje za pomocą polecenia <em>dd</em> poznanego w
          poprzednim rozdziale.
        </p>
<pre class="code-block">
$ sudo dd if=/dev/zero bs=1M of=vhd.img count=8192
</pre>
        <p>
          Zapisanie 8GB zer może chwilę potrwać. Po utworzeniu pliku przechodzę
          do jego inicjalizacji.
        </p>
<pre class="code-block">
$ echo "label:dos" | sudo sfdisk vhd.img
</pre>
        <p>
          Polecenia <em>sfdisk</em> muszą pochodzić ze strumienia lub z
          wcześniej przygotowanego skryptu. Polecenie tworzy na dysku
          tablice partycji typu MBR. Kolejne polcenie będą już poleceniami
          właściwymi tworzącymi partycje na naszym dysku.
        </p>
        <p>
          Polecenia <em>sfdisk</em> składają się z czterech pól:
        </p>
        <ul>
          <li><strong>początkowy sektor</strong> - w pierwszym polu wskazujemy
            od którego sektora na dysku ma zaczynia się partycja. Pierwsza
            partycja zawsze zaczyna się od drugiego megabajtu dysku. Wartość
            ta jest najczęściej pomijana i pozostawiana do decyzji programowi.</li>
          <li><strong>wielkość partycji</strong> - wielkość partycji podajemy
            zapisując na początku znak plusa (<strong>+</strong>) następnie
            podając jej wielkość w wygodnej dla nas wielkrotności bajtu,
            pamiętając że zapisując jednostkę, używamy tylko pierwszej litery
            (dla GB nie jest GB tylko G).</li>
          <li><strong>typ partycji</strong> - typ partycji określany jest za 
            pomocą pojedyńczej litery dla zywkłej partycji na dane Linuksa
            jest to <strong>L</strong>, dla przestrzeni wymiany (będzie o niej
            za chwilę) jest <strong>S</strong>, a dla partycji rozszerzonej
            jest to <strong>E</strong>.</li>
          <li><strong>flaga rozruchowa</strong> - flaga rozruchowa była
            stosowana dawniej, obecnie straciła na znaczeniu. I jej obecność
            może służyć zaznaczeniu partycji przechowywującej podkatalog
            <em>/boot</em> katalogu głównego.</li> 
        </ul>
        <p>
          Po utworzeniu pierwszej partycji, każda kolejna będzie wymagać 
          podania podania opcji <strong>-a</strong>,  która spowoduje
          wykorzystanie wcześniej utworzonej tablicy partycji oraz jej numeru 
          po opcji <strong>-N</strong> przed wskazaniem
          poleceniu urządzenia. Zatem pierwszą partycję tworzymy za pomocą
          poniższego polecenia:
        </p>
<pre class="code-block">
$ echo ",+7G,L,*" | sudo sfdisk vhd.img
</pre>
        <p>
          Pierwszej partycji przydzielono większość miejsca na dysku, będzie
          ona przechowywać katalog główny. Resztę miejsca wykorzystamy na
          partycję rozszerzoną, a wewnątrz niej utworzymy dysk logiczny będący
          partycją wymiany.
        </p>
<pre class="code-block">
$ echo ",,E," | sudo sfdisk -a -N 2 vhd.img
$ echo ",,S," | sudo sfdisk -a -N 5 vhd.img
</pre>
        <p>
         Teraz możemy wyświetlić sobie tablice dysku, który partycjonowaliśmy.
         Zwróćmy uwagę na to, że wystarczy odpowiedni numer partycji aby
         utworzyć dysk logiczny. Pominięcie rozmiaru spowoduje zaalokowanie
         pozostałego wolnego miejsca. Tak przygotowane partycje są gotowe do
         sformatowania pod wybrany system plików. 
        </p>
        <h4>Usuwanie partycji</h4>
        <p>
          Eksperymentując poraz pierwszy z <em>sfdisk</em> może nam coś nie
          wyjść dlatego też zamiast rozpoczynać partycjonowanie od nowa możemy
          źle przygotowaną partycję usunąć. Wydając polecenie <em>sfdisk</em>
          opcję <strong>--delete</strong> następnie nazwę urządzenia oraz
          numer partycji, którą chcemy usunąć.
        </p>
        <p>
          Korzystając z <em>sfdisk</em> pozbawiamy się bufora, ponieważ 
          program ten zmienia tablicę partycji z każdą modyfikacją. Jeśli
          chcemy tylko sprawdzić jak będą wyglądać pewne zmiany to lepiej
          użyć polecenia <em>fdisk</em>. Pomoc uruchamiana jest
          za pomocą polecenia <strong>m</strong> po uruchomieniu programu.
        </p>
        <h2 id="4.2.filesystems">4.2. Systemy plików</h2>
        <p>
          Systemy plików umożliwiają zamianę prostego urządzenia blokowego
          w sktrukturę plików i katalogów zarozumiałą dla końcowego użytkownika.
          Dawniej służyły głównie przchowywaniu plików jednak obecne ich
          funkcje umożliwiają wykorzystanie ich jako interfejsów systemowych
          w takich katalogach jak <em>/proc</em> czy <em>/sys</em>.
        </p>
        <p>
          Normalnie systemy plików są implementowane w jądrze systemu, jednak
          rozwiązana zastosowane w następcach Uniksa, takich jak <em>Plan 9</em>.
          umożliwiły stworzenie systemów plików działających w przestrzeni
          użytkownika, tzw. <strong>FUSE</strong>. Dzięki tej funkcji możemy
          zapisywać dane na nośnikach z takim system plików jak NTFS.
        </p>
        <p>
          Istotną funkcję jeśli chodzi o sposób działania systemów plików, jest
          wykorzystanie <strong>VFS</strong>, który standaryzuje dostęp do
          plików i katalogów dla aplikacji użytkownika, dlatego też Linux 
          obsługuje tak wiele systemów plików.
        </p>
        <h3 id="4.2.1.fstypes">4.2.1. Typy systemów plików</h3>
        <p>
          Mimo iż Linux, może obsługiwać chyba wszystkie możliwe systemy plików,
          to większość z nich wymaga dodatkowego oprogramowania. Natywnie 
          obsługiwane systemy plików Linuksa znajduje się na liście poniżej.
        </p>
        <ul>
          <li><strong>EXT4</strong> (<em>Czwarty rozszerzony system plików</em>)
              - domyślny i najpopularniejszy system plików dla linuksa, 
              wyposarzony w pliki dziennika, znane z <em>ext3</em> oraz
              zwiększone limity związane z wielkością plików oraz ilością
              podkatalogów w katalogu względem wersji trzeciej. W przyszłości
              może zostać zastąpiony przez <em>btrfs</em> lub <em>xfs</em>.</li>
          <li><strong>iso9660</strong> - standardowy system plików stosowany na
              płytach CD-ROM.</li>
          <li><strong>FAT</strong> - rodzina systemów plików znan z wczesnych
              wersji systemu MS Windows, obecnie wykorzystywana przez pamięci
              flash, jak pendrive oraz karty pamięci.</li>
          <li><strong>HFS+</strong> - system plików stosowany w starszych
              wersjach systemu Apple macOS. Zastąpiony prze APFS. Wykorzystanie
              partycji system HFS+, jest jedyną możliwością przenaszalności
              plików pomiędzy współczesnymi Macami a Linuksem.</li> 
        </ul>
        <h3 id="4.2.2.createfs">4.2.2. Tworzenie systemu plików</h3>
        <p>
          Tworząc partycje w poprzednim punkcie pozostało jeszcze sformatować
          pod konkretny system plików, aby można było przechowywać na nich
          informacje. System plików tworzony jest za pomocą polecenia
          <strong>mkfs</strong>. Polecenie ma inną nieco inna składnię,
          ponieważ żądany system plików podaje się po kropce w nazwie polecenia
          np. <strong>mkfs.ext4</strong>. Jako argument podajemy nazwę
          urządzenia partycji.
        </p>
<pre class="code-block">
$ sudo mkfs.ext4 /dev/sda1
</pre>
        <p>
          Podczas formatowania partycji program wyświetla komunikaty
          diagnostyczne. Wśród nich znajdują się liczby oddzielone do siebie
          przecinkami. Te liczby to kopie zapasowe <em>superbloku</em>.
          <strong>Superblok</strong> to najwyższy poziom bazy danych systemu
          plików, jest on na tyle ważny że program tworzy kilka jego kopii.
          Numery bloków zawierających kopie <em>superbloku</em> należy zachować
          ponieważ może być ona potrzebna do ewentualnego odzyskiwania danych.
        </p>
        <p>
          Przyglądając się samemu programowi <em>mkfs</em> dojedziemy do 
          wniosku, że jest to swojego rodzaju interfejs do całego zbioru 
          programów tworzących systemy plików. Nie które wystąpienia tego
          interfejsu są dowiązaniami sybolicznymi do innych programów.
          np <code class="code-inline">mkfs.ext4</code> wskazuje na 
          program <strong>mke2fs</strong>, będący głównym programem do służącym
          do tworzenia systemów plików z rodziny EXT, warto o tym pamiętać
          ponieważ możemy natknąć się na systemy bez polecenia <em>mkfs</em>.
        </p>
        <h3 id="4.2.3.mountfs">4.2.3. Montowanie systemów plików</h3>
        <p>
          Proces dołączania systemu plików w uniksach nazywany jest
          <strong>montowaniem</strong>. Aby zamontować w systemie jakiś system
          plików należy użyć polecenia <strong>mount</strong>, użyć tego
          polecnia bez żadnej opcji spowoduje wyświetlenie podmonotowanych
          systemów plików. Montowanie jak i późniejsze odmontowywanie wymagają
          uprawnień superużytkownika.
        </p>
        <p>
          Każdy wpis to jedno montowanie systemu plików, wpisy zwierają kolejno
          nazwę urządzenia, docelowe miejsce montowania, typ systemu
          oraz opcje specyficzne dla systemu.
        </p>
        <p> 
          Montowanie systemu plików odbywa się za pomocą tego samego polecenia,
          jednak wymaga podania kilku argumentów, kolejno: 
        </p>
        <ul>
          <li><strong>nazwy urządzenia</strong></li>
          <li><strong>typ systemu plików</strong></li>
          <li><strong>punktu montowania</strong> - katalogu docelowego dla
            montowanego systemu plików.</li>
          <li><strong>opcje specyficzne dla systemu plików</strong> - opcje
            są podawane jak wartość opcji <strong>-o</strong> polecenia. Nie
            zawsze trzeba podawać opcje systemu plików.</li>
        </ul>
        <p>
          Montując systemy takie jak EXT, czy któryś z FAT możemy pominąć 
          rodzaj podczas montowania, program sam to ustali. Jednak montowanie
          udziałów sieciowych <strong>CIFS</strong>, wymaga podania typu aby
          program <em>mount</em> mógł rozpoznać wartości zapisane w
          argumentach.
        </p>
        <p>
          Po skończeniu prac z system plików, możemy go odmontować za pomocą
          polecenia <strong>umount</strong>. Polecenie wymaga podania albo
          urządzenia albo punktu montowania jako argumentu.
        </p>
        <h3 id="4.2.4.uuid">4.2.4. Identyfikator UUID systemu plików</h3>
        <p>
          Montowanie systemu plików wymaga podania nazyw urządzenia. Pliki
          konfiguracyjne odpowiedzialne za automatyczne montowanie systemów
          plików w systemie podczas jego startu, nie mogą polegać na tych 
          samych nazwach urządzeń co użytkownicy, ponieważ są one ustalane
          pod czas startu systemu, i ich nazwy zależą od kolejności
          wykrycia ich przez jądro. W takich plikach używa się
          <strong>identyfikatorów UUID</strong> swoistych numerów seryjnych
          systemów plików nadawanych podczas formatowania. Listę urządzeń
          wraz z UUID-ami, możemy wywołać za pomocą polecenia:
        </p>
<pre class="code-block">
$ sudo blkid
</pre>
        <p>
          Identyfikatorów możemy używać nie tylko z plikami konfiguracyjnymi
          jak <em>/etc/fstab</em>, ale równie przy polecniu mount zamiast
          klasycznej nazwy urządzenia. Jednak posługiwanie się tak długim i
          skomplikowanym ciągiem znaków nie jest za wygodne.
        </p>
        <p>
          Polecenie <em>blkid</em> może zwracać w polu <em>UUID</em> numery
          identyfikacyjne innych systemów plików takich jak na przykład FAT,
          gdzie UUID-em jest numer seryjny woluminu FAT. Oczywiście takie
          identyfikatory możemy używać podczas konfiguracji pliku
          <em>/etc/fstab</em>.
        </p>
        <p>
          UUID musi być unikatowy, dlatego też jeśli zasła potrzeba skopiowania
          całego systemu plików, to należy zmienić ten identyfikator aby
          odróżnić kopię od oryginału.
        </p>
        <h3 id="4.2.5.diskcache">4.2.5. Buforowanie dysku i systemu plików</h3>
        <p>
          Uniksy w tym i Linux nie zapisują wszysktkich zmian w systemie
          plików po otrzymaniu takiego żądania. Zmiany przechowywane są w
          pamięci RAM od momentu kiedy jądro będzie mogło swobodnie zapisać
          je na dysku.
        </p>
        <p>
          W momencie odmontowywania systemu plików jądro automatycznie
          synchronizuje zawartość dysku. Jeśli z jakiego powodu nie będziemy
          mogli odmontować systemu plików to wówczas możemy wydać polecenie
          <strong>sync</strong>, które wymusza zapisanie na dysku wszyskich
          zmian w systemie plików. Oczywiście w wiekszej liczbie przypadku
          problemów z odmonotowaniem systemu plików jest proces używający
          któregoś z plików na dysku.
        </p>
        <p>
          Jądro dysponują całą serią mechanizmów wykorzystujących pamięć RAM
          do buforowania danych odczytywanych z dysków, przez co jeśli proces
          wielokrotnie będzie odczytywać dane z tego samego pliku, jądro nie
          będzie musiało odwoływać się do danych na dysku przez każde dane do
          procesu z bufora, oszczędzając tym samym czas i zasoby.
        </p>
        <h3 id="4.2.6.mountoptions">4.2.6. Opcje montowania</h3>
        <p>
          Polecenie <em>mount</em> posiada dużą ilość opcji. Jest ona tak duża
          że wprowadzenie opcji długich wynikało z obowiązku aniżeli wygody,
          ponieważ nazwyczajniej zaczynało tych liter w alfabecie brakować.
          Z posród opcji krótkich - jedno literowych możemy wyróżnić
          najważniejsze:
        </p>
        <ul>
          <li><strong>-r</strong> - powoduje zamontowanie systemu plików w
            trybie tylko do odczytu.</li>
          <li><strong>-n</strong> - powoduje nie modyfikowanie pliku
            <em>/etc/mtab</em> (plik zawiera zamontowane obecnie systemy plików,
            wydanie polecenia <em>mount</em> bez żadnych opcji powoduje
            wyświetlenie zawartości tego pliku). Opcja ta pozwala na 
            zamontowanie systemu plików w momencie gdy system plików zawierjący
            katalog główny, a co za tym idzie plik <em>/etc/mtab</em> jest
            zamknotowany w trybie tylko do odczytu, bowiem nie zapisanie zmian
            w tym pliku spowoduje niepowodzenie montowania.</li>
          <li><strong>-t</strong> - umożliwia podanie systemu plików.</li>
        </ul>
        <p>
          Opcje długie podawane wraz z opcjami specyficznymi dla systemu plików
          po opcji <em>-o</em>. Z opcji długich możemy wyróżnić takie jak:
        </p>
        <ul>
          <li><strong>exec, noexec</strong> - włącza i wyłącza możliwość
            uruchamiania programów w danym systemie plików.</li>
          <li><strong>suid, nosuid</strong> - włącza i wyłącza możliwość
            korzystania z bitu <em>suid</em> przez programy.</li>
          <li><strong>ro</strong> - montuje system plików w trybie tylko do
            odczytu.</li>
          <li><strong>rw</strong> - mountuje system plików w trybie pełnego
            dostępu.</li>
        </ul>
        <h3 id="4.2.7.remount">4.2.7. Pownowne montowanie systemu plików</h3>
        <p>
          W trakcie odzyskiwania danych może zajść potrzeba ponownego
          zamontowania systemu plików w celu zmiany opcji montowania.
          Najczęściej chodzi o przełączenie systemu plików zawierającego
          katalog główny z trybu tylko do odczytu w tryb pełnego dostępu.
          Ponownemu montowaniu służy opcja <strong>remount</strong>.
        </p>
        <h3 id="4.2.8.fstabfile">4.2.8. Tablica systemów plików /etc/fstab</h3>
        <p>
          Plik <strong>/etc/fstab</strong> przechowuje informacje o systemach
          plików oraz ich punktach montowania, dzięki czemu montuje te systemy
          podczas uruchamiania systemu. Każdy wiersz tego pliku przechowuje
          informacje o jednym systemie plików i jest podzielony na sześć pól.
        </p>
        <ul>
          <li><strong>Nazwa urządzenia lub UUID</strong> - dla dysków stosowane
            są identyfikatory UUID, jednak napęd optyczny w
            tym pliku, zapisywany jest nazwą urządzenia. Urządzeniem tylko do 
            odczytu napędu optycznego zazwyczja będzie <em>/dev/sr0</em>.</li>
          <li><strong>Punkt monotowania</strong> - katalog docelowy dla
            montowanego systemu plików.</li>
          <li><strong>Typ systemu plików</strong></li>
          <li><strong>Opcje</strong> - list długich opcji rodzielonych
            przecinkami.</li>
          <li><strong>Informacje o kopiach bezpieczeństwa dla programu 
              <em>dump</em></strong> - w tym polu zawsze należy podawać 0.</li>
          <li><strong>Kolejność sprawdzania spójność systemów plików</strong> -
              systemowi plików zawierającemu katalogów zawsze podajemy wartość
              1. Oznacza to sprawdzenie tego systemu w pierwszej kolejności.
              Pozostałym możemy podać wartość 2 lub 0, gdzie 2 oznacza 
              sprawdzenie tych systemów po systemie oznaczonym wartością 1.
              Każdy kolejny system przychowywujący jakieś dane oznacza się
              2. Po sprawdzeniu systemu z jedynką, program będzie sprawdzać
              po kolei systemy z dwójką. Natomiast 0 oznacza pominięcie 
              sprawdzania systemu przez program <em>fsck</em>.</li> 
        </ul>
        <p>
          Posiadając odpowiednie wpisy w plik <em>/etc/fstab</em>, możemy
          montować system plików podając poleceniu mount tylko punkty
          montowania co może być wygodne podczas montowania systemów plików
          dużą ilością opcji.
        </p>
        <p>
          Istnieje kilka opcji które mają zastosowanie tylko w omawianym przez
          nas pliku.
        </p>
        <ul>
          <li><strong>defaults</strong> - włącza domyślne ustawienie polecenia
            <em>mount</em> dając tym samym największe uprawenienia.</li>
          <li><strong>errors</strong> - ta opcja ma zastosowanie tylko dla
            systemów z rodziny EXT, pozwala na ustalenia zachowania systemu
            w momencie problemów z montowaniem systemu plików. Do wyboru mamy
            takie możliwości jak: <em>continue</em> - wygeneruj kod błędu i 
            kontynuuj pracę; <em>remount-ro</em> - zamontuj ponownie w trybie
            tylko do odczytu; <em>panic</em> - zatrzymaj system.</li>
          <li><strong>noauto</strong> - opcja nakazuje pominąć wpis podczas
            automatycznego montowania systemów plików.</li>
          <li><strong>user</strong> - pozwala na podmontowanie tego systemu
            za pomocą polecenia <em>mount</em> bez potrzeby uprawnień 
            superużytkownika - podmontować ten system plików może każdy
            użytkownik.</li>
        </ul>
        <h3 id="4.2.9.fscapacity">4.2.9 Pojemność systemu plików</h3>
        <p>
          Sprawdzenia zajętości systemu plików możemy dokonać za pomocą
          polecenia <strong>df</strong>. Polecenie to domyślnie zwraca
          wszelkie wartość w postaci kilobajtów, które nie są zbyt czytelne dla
          człowieka. Aby przeskalować jednostki możemy posłużyć się opcją
          <strong>-h</strong>. Polecenie wyświetla wynik swojego działania
          w postaci pięciu kolumn przedstawiających kolejno system plików,
          jego rozmiar, użyte miejsce, dostępne miejsce, stopień użycia w
          procentach oraz punkt montowania. W przypadku użycia programu bez
          podanej opcji rozmiar systemu nosi nazwę <em>1K-bl</em> jest to
          wielkość systemu plikach w jednokilobajtowych blokach.
        </p>
<pre class="code-block">
$ df -h
</pre>
        <p>
          Jeśli przjrzymy się na chwilę wynikom działania tego polecenia,
          możemy dość do wniosku, że albo mamy doczynienia z błędem albo
          tolerancja błędu przybliżenia jest bardzo. Otóż nie. Kilku gigabajtów
          brakuje ze względu na to, że zostały <strong>zarezerwowane</strong>
          i są do dyspozycji superużytkownika w momencie wyczerpania się
          miejsca na danym systemie plików, aby zapewnić systemówi dalsze
          funkcjonowanie oraz umożliwić administratorowi odzyskanie chociaż
          części miejsca na dysku.
        </p>
        <h3 id="4.2.10.fsrescue">4.2.10. Sprawdzanie i naprawnia systemu plików</h3>
        <p>
          Jądro do pracy systemu musi mieć pewność, że zamontowane systemy
          plików są pozbawione błędów. Błędy systemów plików mogą powodować
          utratę danych lub załamanie systemu. Najczęstszym powodem
          występowania błędów w systemie plików, są zaniki zasialania
          komputera spowodowane ludzką niewiedzą lub czynnikami środowiskowymi.
          Najnowszej generacji systemy plików wykorzystują pliki dziennika,
          dzięki, przerwanie działania systemu w wyniku różnych czynników
          nie doprowadza do katastrofy to są przypadki gdzie i one zawodzą.
        </p>
        <p>
          Narzędzie przeznaczone do sprawdzania oraz naprawy systemu plików 
          nazywa się <strong>fsck</strong>. <em>Fsck</em> podobobnie do
          <em>mkfs</em> uruchamia odpowiedni dla użytego na partycji systemu
          plików. Program w trybie interaktywnym uruchamiamy wydając polecenie
          <em>fsck</em> następnie podając nazwę urządzenia.
        </p>
<pre class="code-block">
$ fsck /dev/sdb1
</pre>
        <p>
          Nie wolno uruchamiać programu na zamontowanym systemie plików, gdyż
          grozi to utratą danych oraz załamaniem systemu. Inaczej sprawa ma się
          gdy system plików jest w trybie tylko do odczytu.
        </p>
        <p>
          W trybie interaktywnym program będzie zwracać raport z kolejnych
          etapów, jeśli napotka jakiś problem program zapytanie o usunięcie
          błędu. W wyniku błedów w systemie plików może zdarzyć się, że
          pewne pliki zostaną pozbawione nazwy (nazwy plików są w uniksach
          elementami systemu plików). Program kiedy napotka na taki to zostanie
          on przeniesiony do katalogu <strong>lost+found</strong> z nazwą 
          odpowiadającą numerowi identyfikacyjnemu z systemu plików (węzła
          <em>i-node</em>). Rzeczywistą nazwę musimy ustalić samodzielnie
          na podstawie analizy jego zawartości.
        </p>
        <p>
          Program <strong>e2fsck</strong> - właściwy program <em>fsck</em> dla
          rodziny systemów plików EXT, posiada opcję <strong>-p</strong>
          zajmującą się naprawą drobnych błędów. Program zatrzyma się wówczas
          tylko wtedy gdy napotka poważny błąd. Jeśli mamy podejrzenie, że coś
          się dzieje z system plików, to możemy sprawdzić system plików bez
          dokonywania w nim żadnych modyfikacji, korzystając z opcji
          <strong>-n</strong>. Co w przypadku uszkodzenia <em>superbloku</em>?
          Podstawową bazę danych możemy odbudować za pomocą opcji
          <strong>-b</strong> po opcji należy podać lokalizację kopii 
          superbloku (numer sektora podawany przez <em>mkfs</em> podczas
          tworzenia systemu plików). W przypadku gdy zapomnieliśmy spisać te
          numery, możemy spróbować je odzyskać wydając polecenie <em>mke2fs</em>
          wraz z opcją <strong>-n</strong> dla urządzenia. Należy upewnić się, 
          że na pewno użyliśmy tej opcji jej pominięcie sformatuje partycję. 
        </p>
        <p>
          Istnieją przypadki uszkodzeń, które wykraczają po za sferę programową
          program <em>fsck</em>, nie jednokrotnie pokazał mi, że by się
          wydawało katastrofę, naprawiał pojedyńczym domyślnym uruchomieniem.
          Jeśli nasze systemy dyskowe przechowują ważne informacje, to
          najlepszą ochroną jest <strong>kopia zapasowa</strong> warto je
          robić. Lepiej jest wymieć dysk, zainicjalizować dysk i przegrać dane
          niż liczyć na to, że może coś się uda odzyskać. Może się uda, jakieś
          szanse istnieją. Jeśli posiadamy kopię, to szanse przekraczają 90%
          reszta to ich aktualność.
        </p>
        <h3 id="4.2.11.specialfs">4.2.11. Systemy plików o specjalnym znaczeniu</h3>
        <p>
          Nie wszyskie systemy plików służą zapisywaniu informacji na
          fizycznych nośnikach, nie które z nich mogą służyć jako intefejsy
          systemowe lub przezentować informacje systemowe. Takimi systemami
          są:
        </p>
        <ul>
          <li><strong>proc</strong> - system montowany w katalogu <em>/proc</em>,
            Zawiera katalogi odpowiadające każdemu z procesów w systemie ich
            nazwy pochodzą od <em>PID</em>-u procesu. Pliki opisują różne
            aspekty procesów. Na Linuksach katalog ten przechowuje wiele
            dodatkowych informacji o jądrze systemu i sprzecie.</li>
          <li><strong>sysfs</strong> - system montowany w katalogu <em>/sys</em>.
            Omawiany był w poprzednim rozdziale.</li>
          <li><strong>tmpfs</strong> - montowany w katalogu <em>/run</em> oraz
            innych miejsach. Za pomocą tego systemu możemy przekształcić pamięć
            systemową w coś w rodzaju przestrzeni dyskowej, za pomocą dwóch
            paramerów (<em>size</em> oraz <em>nr_block</em>) możemy określić
            jego wielkość podczas montowania. Nie należy przesadzać z zapisem 
            danych do tego systemu, możemy doprowadzić do braku pamięci i 
            załamania systemu.</li>
        </ul>
        <h2 id="4.3.swapspace">4.3. Przestrzeń wymiany</h2>
        <p>
          Za pomocą przestrzeni na dysku jesteśmy wstanie powiększyć ilość
          użytkowej pamięci operacyjnej. System będzie automatycznie przenosić
          strony pamięci (obszary) na dysk i z dysku, wykorzystująca tzw.
          pamięć wirtualną. Operacja przenoszenia stron pamięci na dysk i
          z powrotem nosi nazwę <strong>wymiany</strong> 
          (ang. <em>swapping</em>), ponieważ polega na wymianie nieaktywnych
          stron w pamięci z aktywowany zanajdującymi się aktualnie na dysku.
          Przestrzeń, w której zapisywane są strony pamięci nazywa się
          przestrzenią wymiany.
        </p>
        <h3 id="4.3.1.swappartition">4.3.1. Wykorzystanie partycji jako 
          przestrzeni wymiany.</h3>
        <p>
          Wykorzystanie partycji jako przestrzeni wymiany jest standardową
          procedurą wykonywaną podczas instalacji systemu. Wiele dystrybucji
          zwraca uwagę na to, gdy brakuje <strong>partycji wymiany</strong>.
          Partycja wymiany może nie być nigdy wykorzystana, jednak chroni
          system przed załamianiem gdy zaczyna brakować pamięci RAM. 
        </p>
        <p>
          Podczas modyfikowania tablicy partycji, utworzyliśmy dysk logiczny,
          który posłuży jako przestrzeń wymiany. Przestrzeń wymiany należy
          sformatować, tak jak każdą partycje, jednak już nie za pomocą
          polecenia <em>mkfs</em>, ale <strong>mkswap</strong> podając 
          nazwę urządzenia jako parametr.
        </p>
<pre class="code-block">
$ sudo mkswap /dev/sda5
</pre>
        <p>
          Partycję wymiany możemy montować automatycznie w systemie za pomocą
          wpisu w pliku <em>/etc/fstab</em>. Poniżej znajduje się wpis, który
          można wykorzystać w instalacji. Zgaduje jednak, ża zainstalowana
          przez nas dystrybucja Linuksa do Mint, Ubuntu lub Kali więc raczej
          taki wpis znajduje się już tym pliku.
        </p>
<pre class="code-block">
UUID="..."  none  swap  sw  0 0
</pre>
        <p>
          Przestrzeń wymiany możemy włączać oraz wyłączać na żądanie za pomocą
          poleceń <strong>swapon</strong> oraz <strong>swapoff</strong> 
          podając urządzenie lub plik jako argument.
        </p>
        <h3 id="4.3.2.swapfile">4.3.2. Wykorzystanie pliku jako przestrzeni
          wymiany</h3>
        <p>
          Jeśli nie mamy dostępnego wolnego miejsca na dysku, możemy wówczas
          stworzyć plik, który będzie służyć nam za przestrzeń wymiany.
          Aktywujemy go, wówczas gdy ilość wolnej pamięci RAM, będzie
          niebezpieczenie niska. Aby utworzyć taki plik, musi on posiadać
          żądaną przez nas wielkość. Najprościej zapisać do niego określoną 
          liczbę zer z strumienia. 
        </p>
<pre class="code-block">
$ sudo dd if=/dev/zero bs=1M of=swap.img count=2048
</pre>
        <p>
          Polecenie to zapisze dwa gigabajty zer do pliku
          <code class="code-inline">swap.img</code>. Taki plik będziemy mogli 
          potraktować jak dysk lub partycję. Chciałbym tutaj również zaznaczyć,
          że w tym momencie spotykamy się w praktyce z jedną z fundamentalnych
          zasad Uniksów otóż <strong>"Wszystko jest plikiem"</strong>.
          Taki plik pozostaje jeszcze sformatować jako partycję wymiany.
        </p>
<pre class="code-block">
$ sudo mkswap swap.img
</pre>
        <p>
          Przygotowaną w ten sposób przestrzeń możemy uruchomić za
          pomocą polecenia <em>swapon</em>.
        </p>
        <h3 id="4.3.3.swapsize">4.3.3. Jak dużej przestrzeni wymiany potrzeuje?</h3>
        <p>
          Odpowiedź na to pytanie nie jest trudna do sformułowania. Otóż
          powszechnie przyjeło się, że przestrzeń wymiany powinna mieć wielkość
          dwukrotności zainstalowanej pamięci RAM. Biorąc pod uwagę to, że
          obecnie jesteśmy w posiadaniu dysków o bardzo dużej pojemności to
          jest to nawet śmieszna wartość, jednakże to przekonanie poważnie
          podważyło upowszechnienie się dysków SSD, które już dużych wartości
          nie muszą mieć. Weźmy sprzęt wbudowany (tzw. <em>embedded</em>) lub
          sprzęt mobilny, nie mówię tu o telefonach, ale np. chrombookach czy
          rozwiązaniach typu HP Stream. To tym przypadku przestrzeni dyskowej
          może być za mało jak na 8GB swapu. Weźmy również pod uwagę fakt iż
          prawdopodbnie nie skorzystamy z przestrzeni wymiany używając
          Linuksa na współczesnym sprzęcie. Więc wydaje mi się, że najbardziej
          optymalną wielkości swapu będzie <strong>1GB</strong>. Na poparcie 
          dodam że wiele
          instalatorów właśnie tyle alokuje podczas automatycznego 
          partycjonowania. 
        </p>
        <h2 id="4.4.fsfuture">4.4. Przyszłość systemów plików</h2>
        <p>
          Jedną z zauważalnych zmian w komputerach jest odejście powoli od
          dysków talerzowych na rzecz dysków SSD, więc możemy spodziewać się
          systemów domyślnie zoptymalizowanych pod kątem ich pełnego, 
          właściwego
          wykorzystania. Zauważymy lub już jesteśmy świadkami odchodzenia od
          rodziny systemu plików EXT, na rzecz takich systemów jak 
          <em>brtfs</em>, który obecnie jest domyślnym systemem dla takich
          dystrybucji jak Fedora. Alternatywą dla tego systemu będzie
          system plików <em>xfs</em>. Ich porównanie możemy znaleźć w
          internecie.
        </p>
        <h1 id="5.startingkernel">5. Uruchamianie jądra Linux</h1>
        <p>
          W tym rodziale rozpoczeniemy przyglądanie się procedurze uruchamiania
          systemu operacyjnego, z czego ten fragment materiału poświęcimy na
          procedurę uruchamiania jądra, programy rozruchowe oraz praktyczną
          konfigurację najpopularniejszego programu rozruchowego jakim nie
          wątpliwie jest GRUB.
        </p>
        <p>
          Procedura uruchamiania systemu wygląda w następujący sposób:
        </p>
        <ol>
          <li>System BIOS lub firmware (w przypadku UEFI) ładuje program
            rozruchowy z dysku i uruchamia go.</li>
          <li>Program rozruchowy szuka na dysku obrazu jądra, następnie ładuje
            go do pamięci i uruchamia.</li>
          <li>Jądro inicjuje wszystkie urządzenia wraz ze sterownikami</li>
          <li>Jądro montuje partycję z katalogiem głównym.</li>
          <li>Jądro uruchamia program o nazwie <em>init</em>, proces tego
            programu zawsze ma <em>PID</em> o wartości 1. Od momentu startu
            procesu typu init, rozpoczyna się uruchamianie przestrzeni
            użytkownika.</li>
          <li>Za pomocą programu <em>init</em> uruchamiane są pozostałe
            elementy systemu (różnego rodzaju usługi).</li>
          <li>Na koniec uruchamiany jest proces pozwalający się zalogować do
            systemu.</li>
        </ol>
        <p>
          W tym rozdziale skupimy się na punktach tej listy od 2 do 4.
          Pozostałe z nich, po za pierwszym (pierwszy wykracza po za ramy
          merytoryczne, tego materiału) omówimy w następnym rozdziale.
        <p>
        <p>
          Niestety możliwość identyfikowania poszczególnych etapów uruchamiania
          systemu jest osiągalna w zależności od dystrybucji. Te przeznaczone
          na desktopy, ukrywają wiele informacji na temat pierwszych etapów
          rozruchu systemu pod graficznymi ekranami, zawierającymi logo
          dystrybucji oraz pasek postępu. Jeśli spotkamy się z takim ekranem,
          to wówczas możemy naciśnać klawisz <em>ESC</em>, aby wyświetlić
          komunikaty wypisywane podczas uruchamiania systemu. Umiejętość
          identyfikacji poszczególnych etapów może pomoć w ewentualnych
          problemach podczas rozruchu.
        </p>
        <h2 id="5.1.dmesg">5.1. Komunikaty rozruchowe</h2>
        <p>
          Większość systemów uniksopodobnych generuje wiele komunikatów
          diagnostycznych. Część z nich pochodzi o samego jądra, pożniej
          pojawiają się komunikaty z poźniejszych etapów uruchamiania.
          Komunikaty te nie są zbyt przyjazne zwykłemu użytkownikowi, a
          dystrybuje dążą do tego aby być jak najbardzie przyjazne dla
          użytkownikowi nietechnicznemu, dlatego też ukrywają je za wyżej
          wspomnianymi ekranami, drugą ważną rzeczą jest ciągły rozwój
          jądra oraz sprzętu przez to systemy uruchamiają się tak szybko, że
          nawet mając te komunikaty przed oczami zdołalibyśmy za nimi
          nadąrzyć.
        </p>
        <p>
          Na szczęście są one zapisywane w plikach dziennika w katalogu
          <em>/var/log</em> oraz nie tylko, poniżej znajduje się lista miejsc,
          w których możemy szukać komunikatów rozruchowych.
        </p>
        <ul>
          <li>Pliki dziennika systemu, takie jak: <strong>/var/log/kern.log</strong>,
            oraz <strong>/var/log/messages</strong> rownież zawierają 
            komunikaty
            diagnostyczne jądra oraz nie których usług systemowych.</li>
          <li>Polecenie <strong>dmesg</strong> przyczym należy pamiętać, że
            trzeba przepuścić jego wyście przez polecenie
            <em>less</em>. Danych na pewno będzie więcej niż może pomieścić
            jeden ekran. Polecenie ty wykorzystuje <em>bufor cykliczny</em>
            jądra mający ograniczoną wielkość, jednak w nowoczesnych jądrach
            jest on na tyle duży, że może przechowywać komunikaty rozruchowe
            przez dłuższy czas.</li>
        </ul>
        <p>
          Nie wszystkie etapy są uwzględnione w wyżej wymienionych miejscach,
          część z nich może być wypisywana jedynie na konsole przez co przepada
          bezpowrotnie. Programy typu init nowszej generacji mogą
          przechwytywać te komunikaty a następnie zapisywać je za pomocą swoich
          rozwiązań protokołowania (prowadzenia plików dziennika).
        </p> 
        <h2 id="5.2.kernelinitandbootoptions">5.2. Inicjowanie jądra i opcje rozruchu</h2>
        <p>
          Podczas rozruchu systemu jądro uruchamiane jest następującej 
          kolejności.
        </p>
        <ul>
          <li>Sprawdzenie procesora</li>
          <li>Sprawdzenie pamięci</li>
          <li>Rozpoznawanie magistrali urządzeń</li>
          <li>Rozpoznawanie urządzeń</li>
          <li>Konfigurowanie uzupełniających podsystemów jądra (sieci itp.)</li>
          <li>Montowanie partycji z katalogiem głównym</li>
          <li>Uruchomienie przestrzeni użytkownika</li>
        </ul>
        <p>
          Jednym z etapów inicjacji jądra jest montowanie katalogu głównego.
          Generalnie to nic w tym nazwyczajnego oczywiście gdy potrzebne do 
          tego komponenty są wbudowane w jądro. Jeśli jednak te modułu
          są w postaci odrębnych modułów, może wówczas zajść potrzeba
          załadowania ich przed zamontowaniem głównego katalogu. Tym właśnie
          zajmuje się <strong>początkowych system plików w pamięci RAM - initramfs</strong>.
        </p>
        <p>
          Zakończenie inicjacji i przekazanie uruchamiania procesu <em>init</em>
          możemy zaobserować w komunikatach diagnstycznych szukając poniższej
          linii.
        </p>
<pre class="code-block">
Freeing unused kernel memory: ... freed
</pre>
        <p>
          W tym momencie jądro zwalnia zaalokowaną nie używaną pamięć.
        </p>
        <h2 id="5.3.kernelparameters">5.3. Parametry jądra</h2>
        <p>
          Parametry jądra pozwajają na określenie jego zachowania, na przykład
          ilość komunikatów diagnostycznych lub podają opcje właściwe dla
          sterowników urządzeń. Parametry jądra użyte przy jego uruchamianiu
          dostępne są pliku  <strong>/proc/cmdline</strong>.
        </p>
<pre class="code-block">
BOOT_IMAGE=/vmlinuz-4.19.0-19-amd64 root=UUID=59382884-accb-4106-9d25-44d1ba914530 ro quiet
</pre>
        <p>
          Na parametry mogą składać się pojedyńcze słowa jak np.
          <code class="code-inline">ro</code> czy <code class="code-inline">quiet</code>
          lub opcje w formacje <em>klucz=wartość</em>. Opcja <strong>root</strong>
          jest najważniejszą opcją, ponieważ bez niej jądro nie będzie mogło
          odnaleźć plików programu typu <em>init</em> i uruchomić go. W
          większości dystrybucji będzie UUID systemu plików zawierającego 
          katalog główny.
        </p>
        <p>
          Warto zwrócić uwagę również na opcję <code class="code-inline">ro</code>,
          która nakazuje jądru zamontować system plików w trybie tylko do
          odczytu. Ta czynność umożliwi bezpieczene sprawdzenie systemu plików
          przez program <em>fsck</em>.
        </p>
        <p>
          Jeśli jądro nie rozumie jakiegoś parametru to zostanie on 
          przezkazany do programu <em>init</em>. Przykładem jest wartość
          <em>-s</em>, który nakaże uruchomić przestrzeń użytkownika w trybie
          pojedyńczego użytkownika.
        </p>
        <h2 id="5.4.bootloaders">5.4. Programy rozruchowe</h2>
        <p>
          Zadaniem <strong>programu rozruchowego</strong> jest załadowanie
          jądra do pamięci i uruchomienie go z odpowiednimi parametrami. Dla 
          linuksa dostępnych jest
          wiele bootloaderów, poniżej znajduje się przedstawiająca je lista.
        </p>
        <ul>
          <li><strong>GRUB</strong> - standardowy program rozruchowy większości
            dystrybucji Linuksa.</li>
          <li><strong>LILO</strong> - jeden z pierwszych programów, obecnie
            został zastąpiony GRUB-em, jednak dalej są dystrybucje takie
            jak <strong>Slackware</strong> (trzecia najstarsza, funkcjonująca
            do tej pory dystrybucja), które go używają.</li>
          <li><strong>SYSLINUX</strong> - można go skonfigurować, tak aby
            współpracował z wieloma różnymi systemami. Można go spotkać w
            systemach wbudowanych, a jego pochodna ISOLINUX występuje na
            obrazach płyt.</li>
          <li><strong>coreboot</strong> - zamiennik systemu BIOS komputera,
            coreboot charkteryzuje się wysoką wydajnością. Stosowany jest
            w odblokowanych chromebookach.</li>
          <li><strong>Linux Kernel EFISTUB</strong> - moduł jądra pozwalający
            na załadowanie jądra bezpośrednio z partycji systemowej EFI/UEFI.</li>
        </ul>
        <p>
          Z racji tego iż, duża liczba dystrybucji, korzysta z GRUB. To jego
          omówimy sobie pod względem praktycznym. <em>Coreboot</em> stosuje
          się jako zamiennik BIOS-u. A SYSLINUX raczej ma zastosowanie
          specjalistyczne wykraczające po za ramy tego materiału.
        </p>
        <p>
          Aby program rozruchowy mógł załadować do pamięci jądro systemu, musi
          uzyskać dostęp do dysku. Nie posiadając żadnych sterowników
          program rozruchowy uzyskuje dostęp do dysku na poziomie BIOS-u, za
          pomocą adresowania <strong>Linear Block Addressing</strong> mimo
          bardzo niskiej wydajności zapewnia ono uniwersalny dostęp do dysku.
        </p>
        <h3 id=5.4.1.linuxandsecureboot">5.4.1. Linux i Secure Boot</h3>
        <p>
          Na nowych komputerach korzystających z UEFI, mogliśmy spotkać się
          przypadkiem, gdy komputer odmówił uruchomienia z płyty czy też z
          pamięci flash. Wiele z nich wyświetlało monit o tym, że włączona
          jest opcja <strong>bezpiecznego rozruchu</strong>. Opcja ta wymaga
          podpisu przez zaufaną organizację programu rozruchowego, aby mógł
          on być uruchomiony. Microsoft w ramach dystrybucji systemu Windows 8
          wymógł na producentach sprzętu domyślne włącznie tej opcji.
          Przyczyny nie są mi znane, chciaż podejrzewam chęć utrudnienia
          instalacji innego systemu nawet Windows 7. Oczywiście tę opcję możemy
          wyłączyć odszukując opcję w panelu sterowania fimwarem (w BIOSie). 
          Jeśli obawiamy się o nasze bezpieczeństwo, to wyłączenie tej opcji
          potrzebne jest wyłącznie na czas instalacji, ponieważ najnowsze
          wersje programów rozruchowych są już podpisane, więc będą zostaną
          zaaprobowane przez tę opcję. 
        </p>
        <h2 id="5.5.practicalusagegrub">5.5. Praktyczne użycie programu rozruchowego GRUB</h2>
        <p>
          GRUB jest obecnie najszerzej wykorzystywanym <em>bootloaderem</em>, 
          dlatego też
          warto poznać podstawy jego obsługi, bez owijania w bawełnę, bez
          wertowania kolejnych kart książek z teorią na temat tego programu
          rozruchowego. 
        </p>
        <h3 id="5.5.1.firstcontactwithgrub">5.5.1. Pierwszy kontakt z GRUBm</h3>
        <p>
          Po przejściu procedur testowych firmware naszego komputera bez
          znaczenia czy jest to BIOS czy UEFI, pokaże nam się tabela z której
          będziemy mogli wybrać jedną z opcji. Podobna do tej na poniższym
          rysunku.
        </p>
        <p>
          <img src="https://i.ibb.co/89wFqZ6/grub-boot-manager.png" alt="grub-boot-manager" border="0">
        </p>
        <p>
          Przedstawiona na rysunku tabela może różnić się wyglądem ale
          funkcjonalność pozostaje taka sama. Na samym dole jest napisane
          <code class="code-inline">Wyróżniony wpis zostanie wykonany
          automatycznie za 5s.</code>. Wyróżniony wpis to ten zaznaczony
          na biało, a po pięciu sekundach zostanie on uruchomiony, ładując
          system przy standardowych ustawieniach. Za pomocą strzałek możemy
          poruszać się pod tabeli dokonując wyboru interesującego nas wpisu.
          Wpis zawierający napis 
          <code class="code-inline">Opcje zaawansowane dla systemu...</code>
          jest podmenu zwierającym (najczęściej) wpisy ładujące system z
          poprzednimi wersjami jądra. Wpis w tabeli możemy edytować
          wybierając go strzałką następnie naciskając klawisz <em>e</em>. GRUB
          daje nam możliwość załadowani systemu z własnego wiersz poleceń. Ta
          opcja przeznaczona jest bardziej zaawansowanych czynności, takich
          jak na przykład diagnostyka konfiguracji GRUB-a. W tym materiale
          nie będziemy się jednak zajmować wierszem polecenia. Jeśli ruszymy 
          się chociaż w menu
          to odliczanie zostanie przerwane, więc aby załadować system trzeba
          wybrać wpis. Naciśnięcie jakiego kolwiek klawisza w menu spowoduje
          przerwanie odliczania. 
        </p>
        <h3 id="5.5.2.grubinstallationinbiosmode">5.5.2. Instalacja GRUB w trybie BIOS</h3>
        <p>
          Instalacja GRUB w tryb BIOS, jest banalnie prosta. Wystarczy użyć
          dwóch poleceń. Zazwyczaj korzystając z mainstreamowych dystrybucji
          przeznaczonych dla użytkowników desktopowowych, nigdy nie będziemy
          musieli tego robić, ponieważ zrobi to za nas instalator. Natomiast
          są dwa scenariusze, kiedy niezbędna będzie ponowna instalacja
          programu GRUB.
        </p>
        <ul>
          <li>Instalacja bardziej zaawansowanych dystrybucji takich jak Gentoo
            czy Arch Linux</li>
          <li>Przenoszenie systemu z jednego komputera na drugi za pomocą
            programów do obrazowania, jak Norton Ghost czy Paragon Backup.</li>
        </ul>
        <p>
          Pierwsze polecenie jest takie same dla każdej dystrybucji. Jako 
          argument podajemy dysk (urządzenie główne - np. sda, sdb itp.).
          Polecenie musi zapisać dane bezpośrednio na urządzeniu, więc
          niezbędne będą uprawnienia administratora.
        <p>
<pre class="code-block">
# grub-install /dev/sdX
</pre>
        <p>
          Drugie polecenie zależy już od dystrybucji. Możemy wówczas
          spotkać takie polecenie jak:
        </p>
<pre class="code-block">
Debian / Ubuntu i pochodne:
# update-grub
Arch Linux i pochodne:
# grub-mkconfig -o /boot/grub/grub.cfg
</pre>
        <p>
          Drugie polecenie jest odpowiedzialne za wygenerowanie pliku
          konfiguracyjnego. W przypadku GRUB jest to normalne, ponieważ
          ze względu na jego skomplikowanie przygotowanie plików składowych
          (będzie o tym później) spoczywa w rękach twórców samego GRUB-a lub
          twórców dystrybucji. Użytkownik końcowy otrzymuje gotowe polecenie,
          które stworzy taki plik konfiguracyjny za niego.
          Polecenie z Arch Linux, jest dłuższe ale pochodzi bezpośrednio z
          pakietu. Natomiast w przypadku Debiana i pochodnych mamy dostępne
          narzędzie przygotowane przez dystrybucję, jest ono bez obsługowe
          i uruchamia program do poszukiwania innych systemów operacyjnych na
          innych dyskach podłączonych do komputera. Na Debianie i pochodnych
          na pewno dostępne jest również to drugie polecenie, jednak lepiej
          skorzystać z polecenia dedykowanego dla naszej dystrybucji. Ponieważ
          to tak naprawdę jej twórcy zajmują się przygotowanie GRUB-a do użycia
          co nie jest takie proste.
        </p>
        <h3 id="5.5.3.grubinstallationinefimode">5.5.3. Instalacja GRUB w trybie UEFI</h3>
        <p>
          Instalacja w trybie UEFI również składa się dwóch poleceń jednak
          samo polecenie instalacyjne jest cieco dłuższe od tego z trybu BIOS.
          Wymaga ona również więcej zachodu niż w trybie BIOS oraz może
          zakończyć się niepowodzeniem. Tak się zdarza to, przy nie których
          specyficznych sprzętach.
        </p>
        <p>
          Polecenie instalacyjne wygląda w następująco:
        <p>
<pre class="code-block">
# grub-install --target=x86_64-efi --efi-directory=/efi --bootloader-id=debian
</pre>
        <p>
          Instalacja GRUB w trybie uefi wymaga, aby podać docelowy system,
          w tym przypadku jest <code class="code-inline">x86_64-efi</code>,
          w trybie BIOS, nie trzeba było podawać docelowego systemu gdyż
          w przypadku BIOS cel <em>i386-pc</em> jest celem domyślnym, kolejny
          argumentem jest podanie punktu montowania partycji <em>efi</em>.
          Taka partycja jest zazwyczaj montowana albo bezpośrednio w głównym
          katalogu - <em>/efi</em> lub wewnątrz katalogu <em>/boot</em> -
          <em>/boot/efi</em>. Ostatnim argumentem jest
          <code class="code-inline">--bootload-id</code> i tutaj panuje pewnego
          rodzaju niewiadoma. Bo jeśli korzystamy instalujemy program 
          rozruchowy
          pod Arch Linuxem, to <em>bootloader-id</em> to <strong>GRUB</strong>.
          z kolei pod Debianem musi być to <strong>debian</strong>. Te nazwy
          wynikają z faktu potrzeby podpisania programu rozruchowego aby
          mógł on być uruchamiany z włączoną opcją bezpiecznego rozruchu. Warto
          dodać, że to co podamy w tej opcji będzie wyświetlane w
          <em>boot menu</em> komputera. Jeśli chcemy użyć jakiejś
          niestandardowej nazwy i nie za bardzo przejmujemy się 
          <em>secure bootem</em>,
          to wówczas możemy użyć opcji <em>--no-uefi-secure-boot</em>.
        </p>
        <p>
          Do w pełni zainstalowanego GRUB-a potrzebujemy tylko pliku
          konfiguracyjnego. Do tego celu możemy wykorzystać polecenia podane
          w punkcie odnośnie instalacji GRUB w trybie BIOS.
        </p>
        <h3 id="5.5.4.changegruborder">5.5.4. Zmiana koleności w menu GRUB</h3>
        <p>
          Aby zamknąć już temat GRUB-a, przjedziemy do ostatniego zagadnienia.
          Rozważmy taki przypadek. Mamy jeden komputer w domu, z którego nie
          korzystamy tylko my. Mamy pozwolenie na wydzielenie pozostałej wolnej
          części dysku (w duży uproszczemiu) i obok Windows 10 chcemy
          zainstalować jakąś dystrybucje Linuksa. Załóżmy, że instalacja się
          powiodła. Niestety mamy problem, gdyż współużytkownicy komputera
          narzekają, że jak uruchamia się komputer to uruchamia się Linux a nie
          Windows. Uruchamiając komputer widzisz, że początkowym i domyślnym
          wyborem w menu GRUB-a jest Linux, a Windows z kolei znajduje się na
          samym końcu listy.
        </p>
        <p>
          Pierwsza myśl jest przychodzi nam do głowy to ręczna edycja pliku
          GRUB-a. Na pewno jest jakieś rozwiązanie. Zatem wyedytowaliśmy plik
          zapisaliśmy zmiany i póki co jest spokój. Wszyscy zadowoleni,
          korzystają z komputera. Któregoś dnia siedząc przy komputerze i
          korzystając z naszej dystrybucji, zostajemy poinformowani o tym, że
          są nowe aktualizacje. Instalujemy je zatem. Aktualizacje się 
          zainstalowały, zauważyliśmy że była również aktualizacja jądra.
          Dobra, wyłączamy komputer. Następnego dnia gdy nasz współużytkownik
          komputera chce skorzystać z niego, znów mu się uruchamia Linux a
          nie Windows. Jaki z tego morał? Instalacja nowego jądra wymaga 
          z aktualizowania pliku konfiguracjnego GRUB-a, aby można było
          korzystać ze świerzo zainstalowanego jądra automatycznie po ponownym
          uruchomieniu komputera, więc nie należy ręcznie zmieniać ręcznie
          pliku konfiguracjnego GRUB-a ponieważ aktualizacja czy to jądra
          czy samego programu rozruchowego nadpisze te zmiany.
        </p>
        <p>
          Sposobów wykonania tej czynności jest kilka, ja znam jedną. Jak wiemy
          plik konfiguracjny jest tworzony z plików składowych. Pliki te 
          znajdują się w katalogu <em>/etc/grub.d</em>, oto listing tych plików
          z mojego komputera:
        </p>
<pre class="code-block">
00_header
05_debian_theme
10_linux
20_linux_xen
30_os-prober
30_uefi-firmware
40_custom
41_custom
README
</pre>
        <p>
          Jeśli obserwowaliśmy generowanie pliku konfiguracjnego GRUB-a, to już
          powinniśmy znaleźć potrzebny nam plik. A jeśli nie to przyjrzyjmy się
          nazwom tych plików. Mamy
          <code class="code-inline">header, debian_theme, linux, linux-xen</code>
          i <code class="code-inline">os-prober</code>. <em>OS</em> to akronim
          od <em>Operating System</em>, z kolei <em>prober</em> oznacza to 
          samo co <em>der Untersucher</em> po niemiecku, czyli kontroler/badacz.
          Czyli chodzi o kontrolera systemów operacyjnych. Jeśli wpiszemy
          <em>os-p</em> w wierszu polecenia i naciśniemy tab, dowiemy się, że
          istnieje nawet takie polecenie, wyszukaniu strony podręcznika dla
          wiem że jest narzędzie odpowiedzialne za poszukiwanie innych systemów
          operacyjnych na wszystkich dyskach komputera. Więc znamy już część
          konfiguracji GRUB-a odpowiedzialną za Windows. Teraz jak zmienić
          kolejność? Otóż przed każdą z tych nazw stoi liczba, wystarczy
          zmienić nazwę, tak aby ten plik znajdował się przed plikiem
          <code class="code-inline">10_linux</code>. 
        </p>
<pre class="code-block">
$ sudo mv /etc/grub.d/30_os-prober /etc/grub.d/09_os-prober
</pre>
        <p>
          Teraz trzeba już tylko wygenerować nowy plik GRUB-a. Rozwiązanie
          powinno być odporne aktualizacje. Nie jest to może najpopularniejsze
          rozwiązanie, ale działa.
        </p>
        <h2 id="5.6.usagerefindasbootmanager">5.6. Wykorzystanie rEFInd jako menedżera rozruchu</h2>
        <p>
          Instalacja GRUB-a w trybie UEFI może się nie powieść, gdyż jednym z
          jego etapów jest zapisanie w pamięci firmware-u informacji o nowym
          programie rozruchowym o nazwie podanej podanej w parametrze
          <em>bootloader-id</em>. Z błedem jak ja się spotkałem by: 
        </p>
<pre class="code-block">
Could not prepare boot variable: No space left on device
</pre>
        <p>
          Nie które firmware mają ograniczoną ilość pamięci przechowywującej
          wskazania programów rozruchowych. Mimo usunięcia jednej ze zmiennych
          problem dalej występował. Usunięcie wszystkich spowodowało tak
          jakby uziemienie komputera, ponieważ nie był on wstanie uruchomić
          się z żadnego podpiętego dysku. Przełączenie trybu na BIOS, na tym
          sprzęcie nie było możliwe. Na sprzęcie tej samej klasy oraz tego
          samego producenta, ale nowszym spotkałem się z problemem z takim
          problemem, iż system zainstalował się poprawnie nawet GRUB w trybi
          UEFI, ale system nie był wstanie wystartować z wbudowanej pamięci,
          ani z system zainstalowanym w trybie UEFI ani w trybie BIOS.
        </p>
        <p>
          Rozwiązanie może i jest proste, niestety może nie za bardzo
          estetyczne oraz wymaga użycia dodatkowego pendrive-a. Pamięć USB nie
          musi być duża, wystarczy 1GB. Polega ono na użyciu odrębnego
          mendżera rozruchu jakim jest <strong>rEFInd</strong>. Program ten
          przeszukuje dyski w poszukiwaniu systemów operacyjnych i
          uruchamia je.
        </p>
        <p>
          Sama dystrybucja przy wykorzystaniu programu <em>rEFInd</em> może
          być zainstalowana trybie BIOS.
          W środowisku LiveCD instalujemy pakiet <strong>refind</strong>. 
          Podczas instalacji zostanie nam wyświetlony monit z pytaniem czy
          zainstalować <em>rEFInd</em> na partycji ESP. Wybieramy opcję
          <strong>No</strong>.
        </p>
<pre class="code-block">
# apt update
# apt install refind
</pre>
        <p>
          Po zainstalowaniu, tworzymy na dysku USB 1 jedną partycję pod system
          plików FAT32, następnie należy ją sformatować.
        </p> 
<pre class="code-block">
# dd if=/dev/zero bs=1M of=/dev/sdX count=1
# echo ',,b,' | sfdisk /dev/sdX
# mkfs.vfat -F32 /dev/sdXY
</pre>
        <p>
          W powyższym przykładzie <code class="code-inline">X</code> to litera
          porządkowa dysku, z kolei <code class="code-inline">Y</code> to 
          liczba partycji. Partycji nie musimy montować. Poniższe polecenie
          zainstaluje na przygotowanym dysku program <em>rEFInd</em>. 
        </p>
<pre class="code-block">
# refind-install --usedefault /dev/sdXY --alldrivers
</pre>
        <p>
          Po zainstalowaniu programu, możemy zrestartować komputer a następnie
          w ustawienia UEFI, ustawić kolejkę rozruchu tak, aby komputer
          startował z pendrive-a, na którym zainstalowaliśmy <em>rEFInd</em>.
          W menu powinien pojawić się wpis z Linuksem zainstalowanym naszym
          dysku. 
        </p>
        <h1 id="6.startinguserspace">6. Uruchamianie przestrzeni użytkownika</h1>
        <p>
          Istotnym momentem podczas startu systemu operacjnego jest
          uruchomienie przez jądro procesu <em>init</em> oznacza to, że pamięć
          oraz procesor są gotowe normalnej pracy. Po za tym uruchomie tego
          programu może przynieść również korzyść dydaktyczną, pozwalając
          obserwować montowanie różnych komponentów w gotowy do pracy system.
          Budowa programów typu <em>init</em> jest bardzie modułowa, więc jeśli
          chcielibyśmy zmienić coś w tym procesie (uruchamiania przestrzeni
          użytkownika) nie potrzebujemy umiejętności niskopoziomowego
          programowania oraz trzymania się ściśle określonej ścieżki, jak ma to
          miejsce w przypadku jądra. Uruchamianie przestrzeni użytkownika 
          zostało przedstawione na poniższej liście kroków: 
        </p>
        <ol>
          <li>Jądro uruchamia program typu <em>init</em>.</li>
          <li>Uruchamiane są usługi niskiego poziomu takie jak <em>udevd</em> 
              czy <em>syslogd</em>.</li>
          <li>Sieć zostaje skonfigurowana.</li>
          <li>Uruchamiane zostają pozostałe usługi jak (<em>cron</em>, 
              <em>cups</em>, itp.)</li>
          <li>Startują aplikacje wyskokiego poziomu, ekrany logowania oraz
              środowiska graficzne.</li>
        </ol>
        <h2 id="6.1.initprocess">6.1. Proces init</h2>
        <p>
          Głównym zadaniem procesu typu <strong>init</strong> jest uruchamianie,
          zatrzymywanie i ponowne uruchamianie procesów istotnych dla pracy 
          całego systemu, chciaż jego najnowsze implementacje mają o wiele
          więcej zadań, to jest to program jak każdy inny. Możemy go znaleźć
          w katalogu /sbin. W dystrybucja Linuksa ma zastosowanie kilka różnych
          implementacji procesu <em>init</em>. Na poniższej liście znajdują się
          te wciąż używane.
        </p>
        <ul> 
          <li><strong>System V init</strong> - tradycyjna wersja tego procesu
            obecnie została wyparta z użycia w dystrybucjach głównego nurtu, co
            przez nie których uznane za zły zabieg. Dalej rozwiajane są
            dystrybucje, które są forkami tych głównych, ale opierają się, nie
            tylko o <em>sysvinit</em> ale dają możliwość wyboru innego procesu
            typu <em>init</em> niż <em>systemd</em>.</li>
          <li><strong>systemd</strong> - najnowsza implementacja tego procesu,
            wykorzystywana w głównych dystrybucjach.</li>
          <li><strong>runit</strong> - alternatywa dla <em>systemd</em>, ma
            zastoswanie nie tylko dla dystrybucji Linuksa ale innych systemów
            zgodnych ze standardem POSIX. Jego działanie opiera się o 3 etapy.
            Wykorzystywany jest w dystrybucjach, takich jak AntiX oraz Void
            Linux.</li>
          <li><strong>OpenRC</strong> - alternatywa dla <em>systemd</em>,
            stosowana przez takie dystrybucje jak Gentoo oraz Alpine Linux. 
            Ma on podobne możliwości do <em>systemd</em>.</li>
        </ul>
        <h2 id="6.2.runlevels">6.2. Poziomy uruchomienia</h2>
        <p>
          <strong>Poziomem uruchomienia</strong> nazywamy stan maszyny, w
          którym na dany moment uruchomione są wybrane komponenty. Są one
          oznaczne liczbą od 0 do 6. Podczas pracy systemu, większość czasu
          spędzamy na tylko na jednym poziomie uruchomienia, z momencie 
          zamykania systemu lub uruchamiania go ponownie przełączamy się na
          inny poziom odpowiedzialny za zatrzymanie pracy jądra oraz poprawne
          zakończenie pracy usług. Na poziomach uruchomienia bazuje tradycjny 
          <em>sysvinit</em>.
        </p>
        <p>
          Za pomocą poniższego polecenia możemy, sprawdzić na jakim poziomie
          uruchomienia się znajdujemy:
        </p>
<pre class="code-block">
$ who -r
</pre>
        <p>
          Polecenie zwraca również moment załączenia wyświetlanego poziomu.
        </p>
        <p>
          Poziomy uruchomienia służą okreslaniu stanu systemu operacyjnego.
          Może on być stanie uruchamiania, zamykania, trybie konsoli
          (serwery, instalacje bez środowiska graficznego), trybie awaryjny
          (tryb pojedyńczego użytkownika, będzie o tym pod koniec rozdziału).
          5 poziom uruchomienia oznacza najczęściej w pełnii uruchomiony system
          wraz z trybem graficznym.
        </p>
        <p>
          Dzisiaj poziomy uruchomienia są domeną programu <em>sysvinit</em>.
          Dystrybucje z <em>systemd</em> wykorzystują je, aby zapewnić
          obsługę z usług, które nadal korzystają ze skryptów <em>sysvinit</em>.
        </p>
        <h2 id="6.3.initidentify">6.3. Rozpoznawanie programu typu init.</h2>
        <p>
          Identyfikacja programu typu init polega, na przeczytaniu
          oprogramowania oferowanego przez dystrybucje. Jeśli program typu
          <em>init</em> nie jest wyszczególniony, możemy przyjąć ze jest to
          <em>systemd</em>. Wiele dystrybucji posiada w swoich cechach 
          wymienioną informacje o tym że używa innego programu typu 
          <em>init</em> niż <em>systemd</em>.
        </p>
        <h2 id="6.4.introductiontochoosedinitprograms">6.4. Wprowadzenie do wybranych programów typu init</h2>
        <p>
          Ze względu na fakt, jak ograniczonych ram tego materiału. Nie będę
          szczegółowo zagłebiał się w tematykę omawianych tutaj programów typu
          <em>init</em>. Opisze ich zalety, na czym opiera się ich
          działanie, jakich plików używają oraz co najważniejsze dla nas na
          tym etapie w jaki sposób możemy zarządzać usługami przy użyciu tych
          programów. Pierwszym jaki procesem typu <em>init</em> jaki poruszę
          z racji popularności jest <em>systemd</em>. 
        </p>
        <h3 id="6.4.1.systemd">6.4.1. Systemd</h3>
        <p>
          <strong>Systemd</strong> wykonując swoje zadania osiąga
          <strong>cel</strong>. Cel jest defiowany przez nas wraz z wszystkimi
          zależnościami (wymaganiami) oraz z góry ustalonym momentem
          realizacji tego celu. Następnie system rozwiązuje wszystkie
          zależności oraz wykonuje postawione przed nim zadanie. Wynika z tego
          jedna z jego cech, możemy opoźnić np. start usługi do momentu gdy
          będzie ona niezbędna. 
        </p>
        <p>
          Poza obsługą usług, której wszyscy oczekują od programu <em>init</em>,
          <em>systemd</em> stara się z integrować ze sobą wiele klasycznych
          usług takich jak <em>cron</em> czy <em>inetd</em>.
        </p>
        <p>
          Podczas uruchamiania usług <em>systemd</em> nie kieruje się żadną
          kolejnością, co więcej większość jego konfiguracji stara unikać
          jakiej kolwiek sekwencyjności, nawet pod czas spełniania zależności. 
          Takie działanie pozwala na zachowanie
          dużej dozy elastyczności w procesie uruchamiania systemu.
        </p>
        <p>
          W zanadrzu swoich możliwości <em>systemd</em> może: montować systemy
          plików, monitorować gniazda sieciowe czy uruchamiać zegary. Takie
          rodzaju funkcje w tej impementacji programu typu <em>init</em>
          nazywane są <strong>jednostkami</strong> (ang. <em>units</em>). A
          operacja uruchomienia takiej jednostki nazywana jest
          <strong>aktywowanie</strong>. Typ jednostek <em>systemd</em> dostępne
          są na stronie podręcznika: <em>systemd(1)</em> (1 w nawiasie to numer
          rozdziału).
        </p>
        <p>
          Każda jednostka może mieć zależności wobec innej jednostki. Może
          wymagać lub chcieć jej działania na potrzeby zadania, które sama
          realizuje. Zależności są definiowane w plikach jednostek dostępnych
          w dwóch miejscach, w konfiguracji globalnej skierowanej do całego
          systemu - <strong>/usr/lib/systemd/system</strong> oraz w definicjach
          lokalnych - <strong>/etc/systemd/system</strong>. Jeśli będziemy
          musieli wprowadzić jakieś zmiany w konfiguracji to zalecanym miejscem
          jest katalog definicji lokalnych. Rozwiązywanie zależności 
          najczęściej polega na uruchomieniu samej jednostki, wobec której
          ważna dla nas jednostka jest zależna. Liczy się czy natomiast czy
          daną jednostkę udało się aktywować lub czy jednostka jest już
          uruchomiona w trakcie uruchamiania naszej jednostki, tego typu
          uwarunkowania definiowane przez typy zależności. Poza zależnościami
          wobec innych jednostek, mogą występować również zależności bazujące
          na stanie (istnieje, nie istnieje, jest niepusty) elementów takich
          jak ścieżka, katalog czy plik.
        </p>
        <p>
          Uruchomienie jednostki nazywane jest aktywowaniem. Dlaczego nie
          włączeniem? Otóż, aby uruchomić należy ją aktywować poniższym
          poleceniem:
        </p>
<pre class="code-block">
$ sudo systemctl start unit.service
</pre>
        <p>
          To czy każdą jednostkę możemy tak sobie uruchomić zależy od jej
          zależności. Zależności można definiować na odwrót, użwając sekcji
          <em>[Install]</em>, a wewnątrz niej typów zależności:
          <strong>RequiredBy</strong> oraz <strong>WantedBy</strong>,
          najczęściej wykorzystywana jest ta druga opcja. Za pomocą tej sekcji
          oraz wymienionych zależności, jednostki instalowane są w celach.
          Większość usług wykorzystywanych w linuksach, posiadają zależność
          <em>WantedBy</em> ustawioną na cel <em>multi-user.target</em>. Jest
          to spowodowane tym, że samo istnienie pliku jednostki może powodować
          jej aktywacje, co w przypadku usług sieciowych nie jest porządane.
          Zatem włączenie jednostki, jest w przypadku <em>systemd</em>
          równoznaczne z włączeniem jej do zależności jednostki zapisanej w
          zależności odwrotnej (cele w <em>systemd</em>, też są jednostkami ale 
          ich rola raczej ogranicza się do grupowanie różnego rodzaju innych
          jednostek). Wydaje mi się, że wszystko rozjaśni się gdy zobaczymy
          polecenie służące do włączania.
        </p>
<pre class="code-block">
$ sudo systemctl enable unit.service
</pre>
        <p>
          Dezaktywacja oraz wyłaczenie jednostki to kolejno:
        </p>
<pre class="code-block">
#Dezaktywacja:
$ sudo systemctl stop unit.service

#Wyłączenie:
$ sudo systemctl disable unit.service
</pre>
        <p>
          Do obsługi <em>systemd</em> używamy pojedyńczego polecenia
          <code class="code-inline">systemctl</code>, ma ono bardzo wiele opcji
          jednak na poziomie podstawowym wystarczym to co napisałem powyżej
          oraz sprawdzenie stanu jednostki poleceniem:
        </p>
<pre class="code-block">
$ sudo systemctl status unit.service
</pre>
        <p>
          Dawniej w czasch powszechnego panowania <em>sysvinit</em> oraz
          obecnie w dystrybucja wykorzystujących ten rodzaj programu
          typu <em>init</em>, gdy usługa definiowała zasób, z którego
          korzystały inne usługi, to musiały one zostać opóźnione do momentu
          uruchomienia usługi macierzytej oraz udostępnienia przez nią
          zasobu. Za pomocą <em>systemd</em> możemy na podstawie dokumentacji
          usługi utworzyć jednostkę zasobu. Taka jednostka zostanie uruchomiona
          w momencie aktywowania jednostki macierzystej usługi. Dzięki temu
          inne usługi korzystające z tego zasobu będą mogły zostać aktywowane
          w tym samym czasie co ta usługa. Usługi nie zrócą żadnego błędu,
          ponieważ zasób jest dostępny. W gdy coś spróbuje uzyskać dostęp do
          tego zasobu, to zostanie zablokowane przez <em>systemd</em> do
          momentu pełnego uruchomienia usługi i przekazania jej kontroli nad
          zasobem. Jeśli podczas próby dostępu do zasobu napłyną jakieś dane
          to zostaną one zbuforowane i przekazne do usługi, gdy przejmie ona
          pieczę na zasobem. Cała ta procedura pozwala na znaczne
          przyspieszenie uruchamiania systemu.
        </p>
        <p>
          <em>Systemd</em> zapewnia pewien stopień zgodności z tradycyjnym
          <em>sysvinit</em>, dla usług nie wspierających plików jednostek.
          Ta funkcjonalność jest na tyle rozwinięta, że pozwala na podobne
          zarządzanie taką usługą, jakoby miała ona plik jednostki.
        </p>
        <p>
          Implementacja procesu typu <em>init</em> jaką jest <em>systemd</em>
          jest na prawdę dość sporym tematem. Więc zostanie on poruszony
          ponownie na tej stronie.
        </p>
        <h3 id="6.4.2.sysvinit">6.4.2. Proces typu init w stylu System V</h3>
        <p>
          Klasyczny proces typu <em>init</em> jakim jest 
          <strong>sysvinit</strong>, opiera się o poziomy uruchomienia oraz
          wykonywane w nich polecenia. Polecenia te opierają się na
          sekwencyjny wykonywaniu skryptów umieszczanych w odpowiednich
          katalogach. Najważniejszym plikem jest w tym przypadku plik
          <em>/etc/inittab</em>, w jego zawrtości znajdują się wspomniane już
          polecenia, rozpisane dla poszczególnych poziomów uruchomienia.
          Polecenie dla 5 poziomu uruchomienia może wyglądać w następujący
          sposób:
        </p>
<pre class="code-block">
l5:5:wait:/etc/rc.d/rc 5
</pre>
        <p>
          To polecenie przy wejściu na 5 poziom uruchomi wszystkie skrypty w
          katologu <em>/etc/rc5.d</em>, o ile będą miały odpowiednią nazwę.
          Słowo <code class="code-inline">wait</code> spowoduje, że proces
          <em>init</em> nie przejdzie na kolejny poziom uruchomieniowy do
          momentu zakończenia pracy tego polecenia. Inne <strong>akcje</strong>
          niż <code class="code-inline">wait</code> mogą
          uruchamiać ponownie polecenie po jego zakończeniu czy definiować
          co należy zrobić po naciśnięciu kombinacji klawiszy
          <em>Ctrl+Alt+Delete</em>, z kolei akcja <strong>initdefault</strong>
          określa domyślny poziom uruchomieniowy dla przestrzeniu użytkownika.
        </p>
        <p>
          Skrypt zawarte w katalogu <em>rc5.d</em>, który jest akronimem od
          polecenia <em>run command</em>. Posiadają dość specyficzne nazwy,
          zaczynają się one od wielkiej litery <em>S</em> lub <em>K</em>.
          Następny jest numer, na końcu zaś znajduje się nazwa własna. Jeśli
          wylistujemy ten katalog bardziej szczegółowo, to zauważymy, że te
          skrypty to tak naprawdę dowiązania symboliczne. Wiele dowiązań w
          jednym katalogu nazywane jest <strong>farmą dowiązań</strong>.
          Te dowiązania zawarte w katalogach <em>rc</em> wskazują 
          na właściwe
          skrypty znajdujące się w katalogu <em>/etc/init.d</em>.
        </p>
        <p>
          Wielkie litery na początku nazw dowiązań oznaczają operację
          podejmowaną na usłudze czy ma ona zostać uruchomiony - <em>S</em>
          (ang. <em>start</em>), czy jej działanie ma zostać zakończone
          - <em>K</em> (ang. <em>kill</em>). Te czynności wykonywane są
          poprzez uruchomienie skryptu z argumentem <em>start</em> lub 
          <em>stop</em>.  Numery w nazwach
          określają miejsce tej czynności w sekwencji uruchomieniowej
          <em>sysvinit</em>. Usługi niskiego poziomu jak np. <em>syslogd</em>
          uruchamiane są bardzo wcześnie (mają niskie numery), demony
          świadczące użytkownikom jakieś usługi zazwyczaj mają numery powyżej
          90. Nazwa wskazuje na uruchamianego daemona.
        </p>
        <p>
          Zatem jeśli nie chcemy, aby jakaś usługa startowała należy wówczas
          zmienić nazwę dowiązania. Warto jednak pozostawić sobie późniejszą
          możliwość jej włączenia. Powiedzmy że chcemy wyłączyć daemona
          <em>httpd</em> jego nazwa to <em>S99httpd</em>, więc najlepiej
          postawić na początku nazwy znak podkreślenia:
        </p>
<pre class="code-block">
$ mv /etc/rc5.d/S99httpd /etc/rc5.d/_S99httpd
</pre>
        <p>
          W ten sposób daemon zostanie wyłączony z sekwencji uruchomieniowej.
          Jeśli chcemy uruchomić/zatrzymać usługę na żądanie, należy 
          uruchomić
          skrypt z katalogu <em>/etc/init.d</em> z argumentem <em>start</em>
          lub <em>stop</em>.
        </p>
<pre class="code-block">
#Uruchomienie:
$ sudo /etc/init.d/httpd start

#Zatrzymanie:
$ sudo /etc/init.d/httpd 
</pre>
        <p>
          Wraz z <em>sysvinit</em> i nie tylko, rozprowadzane jest narzędzie, 
          które działa w systemach nie używających już <em>sysvinit</em>.
          <strong>Run-parts</strong>, jest to bardzo proste na rzędzie, które
          uruchamia wszystkie pliki wykonywalne w danym katalogu 
          według ściśle określonego porządku.
          Implementacja tego narzędzia zależy od dystrybucji. Te bardziej
          złożone pozwalają na użycie wyrażenia regularnego do określenia
          porządku ich uruchamiania. Na potrzeby tego materiału wystarczy
          wiedzieć, że takie narzędzie w ogóle istnieje.
        </p>
        <p>
          Wspomnieniem o <em>run-parts</em> kończymy wprowadzenie do programów
          typu <em>init</em>. Omówiłem tylko te dwa, gdyż są w
          najpowszechniejszym użyciu. Poznając podstawy Linuksa, nie ma co
          zniechęcać się obszernymi szczegółami. Najważniejsze dla nas na ten
          moment jest uruchamienia/zatrzymywanie usług oraz włączanie i
          wyłączanie ich z sekwencji uruchomieniowej. W ramach ćwiczeń możemy
          wydedukować jak należy włączyć usługę, do sekwencji uruchomieniowej
          przy procesie <em>init</em> w stylu <em>System V</em>, chociaż nie
          powinno to zająć więcej niż 30 sekund.
        </p>
        <h2 id="6.5.shutdownthesystem">6.5. Wyłączanie systemu</h2>
        <p>
          Jedynym prawidłowym sposobem na wyłącznie systemu, jest użycie
          polecenia <strong>shutdown</strong>. Wyłączyć system możemy na
          dwa różne sposoby. Pierwszym z nich jest jego 
          <strong>programowe zamknięcie systemu oraz wyłącznie zasilania</strong>
          osiągane przez poniższe polecenie. 
        </p>
<pre class="code-block">
$ sudo shutdown -h now
</pre>
        <p>
          Do wyżej wymienionego celu możemy, użyć polecenia, które może być
          nieco bardziej powszechne:
        </p>
<pre class="code-block">
$ sudo poweroff
</pre>
        <p>
          Ma ono działanie identyczne działanie jak polecenie z przykładu
          powyżej. 
        </p>
        <p>
          Przy poleceniu <code class="code-inline">shutdown</code> należy
          wybrać czy system ma zostać zamknięty, zatrzymany, lub uruchomiony
          ponownie. Kolejnym wymaganym argumentem jest czas. Najczęściej
          używany jest argument <code class="code-inline">now</code> co
          przy przyjmowanym zapisze czasonym jest <em>+0</em> minut.
          Zapis czasowy możemy określić w minutach jak podałem powyżej lub
          lub przy zapisie <em>hh:mm</em> , który pozwala określić konkretną
          godzinę zamknięcia systemu.
        </p>
        <p>
          Innym sposobem na zamknięcie systemu jest ponowne uruchomienie
          komputera. System będzie musiał zostać poprawnie zamknięty, aby
          uruchomić komputer ponownie. W tym celu możemy użyć polecenia, 
        </p>
<pre class="code-block">
$ sudo shutdown -r now

#lub

$ sudo reboot
</pre>
        <p>
          Wyłączenie systemu dla <em>systemd</em> oznacza aktywację jednostek
          zatrzymywania (<em>systemd</em>, posiada wiele typów jednostek), dla
          <em>sysvinit</em> przejście z poziomu 5 na 6 lub 0.
        </p>
        <h2 id="6.6.initramfs">6.6. Początkowy system plików w pamięci RAM</h2>
        <p>
          <strong>initramfs</strong> czy <strong>initrd</strong>, z tych nazw
          korzysta się zamiennie mimo iż oznaczają coś innego, to odnoszą się
          do tego samego komponentu, czyli <strong>początkowego systemu plików
          w pamięci RAM</strong>. Jest to bardzo proste archiwum
          przechowujące mini przestrzeń użytkownika z mini katalogiem głównym.
          Zadaniem <em>initramfs</em> jest stworzenie optymalnego środowiska
          dla narzędzi pozwalających na załadowanie do jądra zewnętrznych
          modułów, wśród których może znajdować się sterownik dysku, co pozwoli
          zamontować już właściwyw katalog główny z dysku i przejść na kolejne
          etapy uruchamiania systemu. 
        </p>
        <p>
          Wykorzystując nasz system w stopniu podstawowym raczej nie będziemy
          mieć styczności z <em>initramfs</em>, chyba że używamy bardziej
          zaawansowanej dystrybucji, która może wymagać załadowania do niego
          dodatkowych modułów. Takie przypadki będą zazwyczaj opisane w na
          stronach dokumentacji dystrybucji. Przykładem takiego działania może 
          być
          szyfrowana partycja z katalogiem głównym, w takich dystrybucjach
          jak Arch Linux. Do obsługi początkowego systemu w pamięci RAM
          służa takie polecenia jak <strong>mkinitramfs</strong> lub
          <strong>update-initramfs</strong>. 
        </p>
        <p>
          System plików pamięci RAM może zostać pominięty w momencie gdy, w
          jądrze znajdują się wszystkie potrzebne mu sterowniki, jednak
          obecnie nie jest to praktykowane.
        </p>
        <p>
          Istnieją dystrybucje, których działanie opiera się na 
          <em>initramfs</em>, pliki dystrybucji znajdują się w tym archiwum, a
          oprogramowanie jest znajduje się wówczas w archiwach <em>squashfs</em>
          montowanych podczas w odpowiednich miejscach w systemie podczas
          jego ładowania. Taką dystrybucją jest na przykład TinyCore, którego
          obraz płyty waży 21 MB.
        </p>
        <h2 id="6.7.oneusermode">6.7. Tryb jednego użytkownika</h2>
        <p>
          Tryb pojedyńczego użytkownika, jest swojego rodzaju trybem
          awaryjnym na Linuksie, a jedynym dostępnym użytkownikiem będzie 
          superużytkownik. W tym trybie zostanie załadowane jądro, za
          montowany katalog główny, a proces typu init zapewni dostęp tylko
          do niezbędnych dla działania systemu usług, wyeliminowywując tym 
          samym potencjalnie wadliwe komponenty. To środowisko ma za zadanie
          umożliwić nam naprawę systemu. 
        </p>
        <p>
          Ze względu na to, iż to środowisko może nie zapewnić potrzebnych
          do takiej naprawy narzędzi, najlepiej jest skorzystać jednak z 
          obrazu <strong>LiveCD</strong>, który pozwala na korzystanie z
          systemu bez konieczności jego instalacji. Jednak na podstawie wiedzy
          zawartej w tym materiale nie sądze, aby można byłoby naprawić system.
          Dlatego też jeśli zdarzy się awaria systemu, to najlepszym
          rozwiązaniem na teraz jest zabezpieczenie osobistych danych i
          przeinstalowanie systemu, chodziaż nie chce nikogo zniechęcić do
          grzebania w systemie, w ten sposób możemy się wiele nauczyć. Z 
          drugiej strony, ciężko jest aby system przestał działać tak sam z
          siebie. Dlatego jesli tak się stało, więcej niż raz to warto zgłość
          problem społeczności za pomocą jednego z kanałów
          udostepnionych na stronie dystrybucji i zmienić dystrybucje na jakiś
          czas. Linux to głównie narzędzie do pracy na naszym komputerze, na
          tym etapie - podstawowym.
        </p>
        <h1 id="7.systemconfigurationandusers">7. Konfiguracje systemowe oraz użytkownicy</h1>
        <p>
          W tym rozdziale zajmiemy się drobnymi konfigracjami, nie których
          komponentów systemowych takich jak <em>syslog</em> czy <em>cron</em>
          zajmiemy się również tematem czasu systemowego na Linuksie. Rozdział
          zakończymy dodatkową wiedzą, (choć nadal w stopniu podstawowym) na
          temat użytkowników.
        </p>
        <p>
          Wszystkie te powyższe zagadnienia łączy jedna rzecz, ich pliki
          konfiguracyjne znajdują się w katalog <strong>/etc</strong> i od
          omówienia tego katalogu zaczniemy.
        </p>
        <h2 id="7.1.etcdirectory">7.1. Katalog /etc</h2>
        <p>
          Jak wiemy z opisu hierarchii systemu plików (katalogu głównego), w 
          katalogu <strong>/etc</strong> przechowywane są różnego rodzaju
          konfiguracje, i to nie zależnie do wielkości czy istotności programu
          w systemie. Kiedyś każdy z programów przechowywał luzem swoją
          konfigurację tym katalogu. Obecnie jak możemy się przekonać większość
          zawartości <em>/etc</em> stanowią podkatalogi. Oczywiście wiele
          plików nadal się w nim znajduje, najczęsciej są to takie pliki
          jak <em>/etc/fstab</em> czy
          <em>/etc/passwd</em> lub <em>/etc/shadow</em> służące do
          przechowywania informacji o użytkownikach. Katalogi w <em>/etc</em>
          mają nazwy przeważnie odpowiadające nazwom programów, które
          konfigurują. Wyjątkiem są katalogi z końcówką <em>.d</em>. Pliki
          konfiguracyjne
          zostały umieszczone w tych katalogach, aby nie zostały one nadpisane
          przez aktualizacje pakietów. Obecnie nie ma to już miejsca, a mimo
          to konfiguracje wielu pakietów są umieszczane w tych katalogach.
        </p>
        <p>
          Pliki konfiguracyjne, nie których pakietów mogą występować w
          dwóch różnych wersjach. Pierwsza
          to jest, ta którą wszyscy znamy czyli katalog <em>/etc</em> taka
          konfiguracja nazywana jest <em>konfiguracją z możliwością dostosowania</em>.
          Druga wersją jest <em>konfiguracja bez możliwości dostosowania</em>
          znajdująca się w katalogu <em>/usr/lib</em>. Oczywiście to jest tylko
          koncepcja, aby administratorzy zajęli się konfiguracją w <em>/etc</em>
          a konfiguracje w <em>/usr/lib</em> zostawili opiekunom pakietów
          (osobom przygotowywującym pakiet oprogramowania dla danej dystrybucji,
          z wybranym programem) oraz twórcom samej dystrybucji. Możemy zmieniać
          oczywiście konfiguracje w tym katalogu, jednak trzeba mieć na uwadze
          dwie rzeczy: 
        </p>
        <ol>
          <li>Trzeba wiedzieć co się robi</li>
          <li>Zmiany w konfiguracji znajdującej w <em>/usr/lib</em> mogą 
            zostać nadpisane przez aktualizacje pakietu.
        </ol>
        <p>
          System Linuks nie jest miejscem, gdzie się cokolwiek komu kolwiek
          zabrania. Zasady i jakieś regułu  wprowadza się po to aby zapewnić 
          względne bezpieczeństwo oraz stabilność dystrybucji czy też ogolnie 
          systemu. 
        </p>
        <h2 id="7.2.syslog">7.2. syslog</h2>
        <p>
          Znaczna część komunikatów dignostycznych z różnych komponentów
          systemowych spływa do protokołowania czy rejestrowania lub
          prowadzenia plików dziennika. W języku polskim istnieje kilka
          określeń na to co konkretnie robi usługa <strong>syslog</strong>, 
          której zadaniem jest nasłuchiwanie na komunikaty diagnostyczne i
          przekazywanie ich do pliku, na ekran poszczególnych użytkowników lub
          całkowite zignorowanie. Wszystko zależy od konfiguracji.
        </p>
        <p>
          Obecnie wykorzystywana jest nowsza wersja <em>syslog</em> -
          <strong>rsyslog</strong>. Funkcje tej wersji nie ograniczają się
          tylko do zapisywania komunikatów diagnostycznych do pliku, program
          może na przykład przesyłać je do bazy danych. Na tym etapie nie
          będziemy się jednak tym zajmować, póki co będziemy musieli się
          zadowolić zwykłymi plikami tekstowymi przechowywanymi w katalogu
          <em>/var/log</em>. Warto mieć jednak na uwadze fakt, iż nie
          wszystkie pliki przechowywane w tym katalogu są zarządzane, przez
          tę usługę. Nie które daemony mogą posiadać swoje sposoby na
          utrzymanie i prezentowanie użytkownikowi własnych komunikaty
          diagnostycznych. Więcej informacji na temat jakie <em>logi</em> są
          przechwytywane przez <em>rsyslog</em> znajduje się w pliku
          konfiguracyjnym - <strong>/etc/rsyslog.conf</strong>.
        </p>
        <p>
          Na konfiguracje składają się tradycyjne reguły oraz dyrektywy
          dostępne w rozszerzonej wersji <em>rsyslog</em>. Dyrektywy możemy
          poznać po tym, że rozpoczynają się od symbolu dolara
          (<strong>$</strong>). Natomiast reguły konfiguracyne klasycznej
          wersji protokołu są nieco bardziej złożone.
        </p>
        <p>
          Reguły protokołu <em>syslog</em> określają sposób przychwytywania
          komunikatów diagostnycznych oraz docelowe miejsce ich zapisu. Zasady
          składają się z selektora i akcji, o to kilka z nich.
        </p>
<pre class="code-block">
*.info;mail.none;authpriv.none;cron.none  /var/log/messages
authpriv.*  /var/log/secure,root
mail.*      -/var/log/maillog
*.emerg     :omusrmsg:*
</pre>
        <p>
          Reguły <em>syslog</em> możemy podzielić na dwie części prawą i lewą.
          Po lewej stronie znajduje się selektor, określający przechwywane
          dane. Natomiast po prawej znajduje się akcja zazwyczaj jest ścieżka
          do pliku docelowego dla przychwconych komunikatów. Przy jednej ze
          ścieżek znajduje się myślnik, który powoduje nie synchronizowanie
          tego pliku jeśli włączono by synchronizacje (jest ona domyślnie
          wyłączona). Synchronizacja powoduje znaczny spadek wydajność i może
          doprowadzić do gubienia komunikatów.
        </p>
        <p>
          Selektor zaś składa się z kolejnych dwóch części: 
          <strong>funkcji</strong> oraz <strong>priorytetu</strong>. Funkcja
          określa źródło komunikatów i są one na stałe zaimplementowane w
          <em>rsyslog</em> a priorytety ich rodzaj wśród, których możemy
          wymienić (ułożenie według od najniższego do najwyższego):
        </p>
<pre class="code-block">
debug, info, notice, warning, error, crit, alert, emerg
</pre>
        <p>
          Tworząc selektor oddziela się funkcję od priorytetu za pomocą kropki.
          Priorytet służy do ograniczania wielkość przechwytywanych komunikatów,
          albowiem <em>rsyslog</em> rozpoczyna przechwytywanie komunikatów od
          tego priorytetu w górę. Jeśli przypatrzmy się pierwszej linii
          konfiguracji, zauważymy, że do pliku 
          <code class="code-inline">/var/log/messages</code> będzie
          spływać masa informacji, ponieważ selektor uwzględnia komunikaty
          ze wszystkich funkcji z minimalnym priorytetem 
          <code class="code-inline">debug</code>. Istnieją jednak pewne
          wykluczenia. Na selektor może składać się więcej niż jedna para
          <em>funkcja.priorytet</em>, co również widać w pierwszej linii
          przykładu. Kolejne pary rozdzielone są średnikami. W omawianym
          przykładzie, pary mają ten sam priorytet, który nie został
          uwzględniony na powyższej liście <strong>none</strong> powoduje
          wyłączenie przechwytywania z użytych w raz z nim funkcji. Tak więc
          w pierwszej linii przechwytywane będą komunikaty ze wszystkich
          funkcji z minmalnym priorytetem <code class="code-inline">info</code>,
          poza takimi funkcjami jak <code class="code-inline">mail</code>,
          <code class="code-inline">authpriv</code> oraz 
          <code class="code-inline">cron</code>. Komunikaty będą zapisywane
          zgodnie z akcją w pliku <code class="code-inline">/var/log/messages</code>.
        </p>
        <p>
          Innymi ciekawymi przypadkami w pokazanymi na przykładzie jest
          podanie w akcji w drugiej linii dwóch miejsc docelowych. Pliku
          <code class="code-inline">/var/log/secure</code> oraz nazwy
          superużytkownika. Podanie jakiej kolwiek nazwy użytkownika w akcji
          spowoduje przesłanie mu (za pomocą polecenia <strong>write</strong>)
          komunikatu diagnostycznego, o ile użytkownik zezwala na wyświetlanie
          tego typu komunikatów (polecenie <strong>mesg</strong>). Chociaż
          komunikaty wysłane przez superużytkownika są wyświetlane mimo tych
          ustawień. Kolejnym przypadkiem związanym z wysyłaniem jest użycie
          specjalnego <strong>modułu wyjściowego</strong> reprezentującego
          konkretną akcje, w tym przypadku jest wysyłanie wiadomości do
          zobrazowane w ostatniej linii przykładu. Jak mogliśmy zauważyć w
          liniach reguł możemy używać symbolu wieloznacznego gwiazdki
          (<strong>*</strong>).
        </p>
        <p>
          Dyrektywy nowszej wersji daemona rejestrującego są dość proste
          do zrozumienia i nie wymgają dodatkowego opisu.
        </p>
<pre class="code-block">
$FileOwner syslog
$FileGroup adm
$FileCreateMode 0640
$DirCreateMode 0775
$Umask 0022
</pre>
        <p>
          Jeśli chodzi o <em>syslog</em>, to w przypadku usługi rejestrowania
          może stać się nie wiele złego, jedynym problemem jaki możemy
          napotkać jest brak przechwytywania komunikatów z powodu 
          nieuwzględnienia jakiejś funkcji lub priorytetu w selektorze.
          Niemniej jednak rejestrator systemowy możemy przetestować za pomocą
          polecenia <strong>logger</strong> podając mu parę 
          <em>funkcja.priorytet</em> po opcji <strong>-p</strong>
          (na stronie podręcznika opcja określona jest jako priorytet) oraz
          komunikat do zapisania. Jeśli priorytet został pominięty, zostanie
          użyty domyślny <em>user.notice</em>. W zależności od konfiguracji
	        <em>rsyslog</em> oraz użytej funkcji nasz komunikat powinien
	        pojawić jednym z plików wyszczególnionych w konfiguracji.
          W przypadku użycia narzędzia <em>logger</em> z domyślnymi wartościami
          komunikat zostanie zapisany do <em>/var/log/messages</em>.
        </p>
        <p>
          Większość rejestratorów istnieje nie tylko w postaci odrębnego 
          programu jakim
          jest <em>rsyslog</em>, ale także w postaci funkcji, nie których 
          <em>daemonów</em>
          jak np. serwer WWW <em>Apache2</em> one również zapisuje swoje 
          komunikaty
          diagnostyczne do <em>/var/log</em>. Bardzo duża ilość danych
          spływająca do jednego katalogu może powodować szybkie
          zapełnienie przestrzeni dyskowej. Jednak się to nie dzieje, dzięki 
          programowi <strong>logrotate</strong>, którego zadaniem jest
          (w zależności od konfiguracji) usuwanie lub kompresja starych plików
          dzienników i utworzenie miejsca na nowe komunikaty.
        </p>
        <p>
          Z racji tego, iż demony działają w trakcje czynności wykonywanych 
          przez <em>logrotate</em>, skrypty obsługujące konkretne pliki 
          dziennika, tworzą puste pliki o takiej samej nazwie jak te utworzone
          przez demon.
        </p>
        <h2 id="7.3.userconfig">7.3. Konfiguracja użytkowników</h2>
        <p>
          Komputery jak i systemy operacyjne mają za zadanie służyć
          użytkownikom. Jak wiemy użytkownicy w systemach istnieją aby
          wyznaczać granicę. Mówiąc kolokwialnie każdy z nas ma swoją
          piaskownice i swoje zabawki. W Linuksach użytkownicy są opisywani za
          pomocą kilku plików w katalogu <em>/etc</em>.
        </p>
        <h3 id="7.3.1.passwdfile">7.3.1. Plik /etc/passwd</h3>
        <p>
          Plik <em>/etc/passwd</em> jest podstawowym źródłem informacji o 
          użytkownikach w systemie. W tym pliku każdy wiersz to jeden wpis
          definiujący użytkownika. Każdy wiersz podzielony jest na 7 pól.
          Poniżej znajduje się kilka przykładowych wpisów:
        </p>
<pre class="code-block">
pulse:x:109:114:PulseAudio daemon,,,:/run/pulse:/usr/sbin/nologin
saned:x:110:117::/var/lib/saned:/usr/sbin/nologin
colord:x:111:118:colord colour management daemon,,,:/var/lib/colord:/usr/sbin/nologin
lightdm:x:112:119:Light Display Manager:/var/lib/lightdm:/bin/false
libvirt-qemu:x:64055:105:Libvirt Qemu,,,:/var/lib/libvirt:/usr/sbin/nologin
geoclue:x:113:124::/var/lib/geoclue:/usr/sbin/nologin
user:x:1000:1000::/home/user:/bin/bash
xf0r3m:x:1001:1001::/home/xf0r3m:/bin/bash
</pre>
        <p>
          Pola te zawierają kolejno:
        </p>
        <ul>
          <li><strong>Nazwa użytkownika</strong> - jednoznaczny identyfikator
            użytkownika, służący do rozpoznawania użytkowników miedzy innymi
            użytkownikami.</li>
          <li><strong>Zaszyfrowane hasło</strong> - w dystrybucjach Linuksa
            hasło nigdy nie było przechowywany w jawnej postaci, nawet w tak
            zamieszchłych czasas kiedy znajdowało się ono w pliku 
            <em>/etc/passwd</em>. Obecnie po haśle został tylko
            <code class="code-inline">x</code>, co oznacza, że hasło jest
            przechowywany w pliku <em>/etc/shadow</em>, który również zostanie
            tu omówiony.</li>
          <li><strong>UID (identyfikator użytkownika)</strong> - numer
            identyfikujący użytkownika, służy głównie odwołaniu się jądra do
            konkretnego użytkownika.</li>
          <li><strong>GID (identyfikator grupy)</strong> - numer
            identyfikujący podstawową grupę użytkownika.</li>
          <li><strong>Pole GECOS</strong> - pole przechowujące rzeczywiste
            informacje o użytkowniku takie jak imie, nazwisko, numer telefonu,
            adres e-mail, numer pokoju. Pole może zostać pominięte, co widzimy
            na kilku wpisach na przykładzie.</li>
          <li><strong>Katalog domowy</strong> - ścieżka wskazująca na katalog
            domowy użytkownika.</li>
          <li><strong>Program uruchamiany po zalogowaniu (powłoka)</strong> -
            ścieżka wskazująca na program jaki ma zostać uruchomiony po 
            zalogowaniu, najczęściej jest to interaktywna powłoka.</li>.
        </ul>
        <p>
          Drugie pole wpisu w <em>/etc/passwd</em> może przyjmować dwie
          dodatkowe wartości. Pole może zawierać gwiazdkę (<strong>*</strong>),
          która uniemożliwia logowanie lub pole może być puste co pozwala na
          zalogowanie się bez podawania hasła. 
        </p>
        <p>
          Jeśli przefiltrujemy za pomocą polecenia <em>grep</em> plik 
          <em>/etc/passwd</em> pod kątem ustawionych programów (powłok), to
          na powiedzmy ok. 50 (zależności od dystrybucji) tylko dwóch, trzech
          użytkowników ma ustawioną powłokę. Pozostali użytkownicy zazwyczaj
          mają ustawiony program, który uniemożliwia im korzystanie z systemu
          nawet gdy się zalogują. Tacy użytkownicy nazwani są 
          <strong>pseudoużytkownikami</strong>. Tego rodzaju użytkownicy
          istnieją w jednym celu, aby uruchamiać z ich uprawnieniami różne
          programy, głównie demony sieciowe. Co w razie włamania spowoduje, że
          atakujący zostanie uwięziony na koncie, na którym nic nie może
          zrobić.
        </p>
        <p>
          Pseudoużytkownicy zaliczają się do użytkowników specjalnych obok nich
          istnieje jeszcze jeden użytkownik - <strong>root</strong>, który ma
          niczym nie ograniczone uprawnienia. Dlatego też nosi nazwę
          <em>superużytkownika</em>. Posiada on UID i GID równy 0 oraz jego
          katalog domowy znajduje się bezpośrednio w głównym katalogu. Innym
          ciekawym użytkownikiem specjalnym jest użytkownik <em>nobody</em>,
          który nie ma możliwości zapisu niczego w systemie.
        </p>
        <p>
          Kombinacja wpisu w pliku <em>/etc/passwd</em> oraz katalogu domowego
          może być określana jako <strong>konto</strong>.
        </p>
        <h3 id="7.3.2.shadowfile">7.3.2. Plik /etc/shadow</h3>
        <p>
          Plik <em>/etc/shadow</em> jest podobnym plikiem <em>/etc/passwd</em>,
          jednak zamiast przechowywać informacje o użytkownika plik ten 
          przechowuje informacje o hasłach. Plik <em>/etc/shadow</em> posiada
          jedno wspólne pole wraz z plikiem <em>/etc/passwd</em> a jest nim
          nazwa użytkownika. Hasło podobnie do pliku <em>/etc/passwd</em> 
          znajduje się na drugim polu we wpisie. Pozostałe pola są
          odpowiedzialne za ważność hasła. Wpisy w pliku <em>/etc/shadow</em>
          biorą również czynny udział w blokowaniu dostępu użytkownikom. 
          Zawartośc pliku wygląda w następujący sposób:
        </p>
<pre class="code-block">
root:$y$j9T$h19rJ2ObBXMdBdXOHB0wF.$.Lqb5iG3.HpsO0FcghqSkXbcA6D5rIp9woC/Ovj40Q7:19251:0:99999:7:::
...
user:$y$j9T$bAf/P4bLm00VJQyS3Lf8I1$dzie3XL5lORpP7jmo4CeanOqhuWMpPzdQArAlQ9AfG0:19327:0:99999:7:::
</pre>
        <p>
          Na tym etapie nauki dalsza analiza tych wpisów nie ma sensu, jeśli
          jednak ktoś jest ciekawy pozostałych pól to może zajrzeć do mojego
          materiału przygotowywującego do RHCSA: <a href="https://morketsmerke.github.io/articles/terminallog/RedHat_-_RHCSA.html#6.1.passwordaging">https://morketsmerke.github.io/articles/terminallog/RedHat_-_RHCSA.html#6.1.passwordaging</a>
        </p>
        <p>
          Plik <em>/etc/shadow</em> jest dość mocno zabezpieczonym plikiem,
          zwykli użytkownicy nie posiadają do niego żadnych praw. Jedyną
          uprawnioną osobą do manipulacji nim jest superużytkownik.
        </p>
        <h3 id="7.3.3.changingusers">7.3.3. Manipulowanie użytkownikami i hasłami</h3>
        <p>
          Omawiane dotychczas pliki są zwykłymi plikami tekstowymi, których 
          zawartością możemy manipulować za pomocą ulubionego edytora
          tekstowego. Nie jest to jednak zalecane działanie. Ze względu na 
          ścisłą budowę (nie możliwe jest aby umieszczać w tych plikach 
          komentarze lub puste wiersze) oraz restrykcyjną składnie wierszy.
          Możemy użyć specjalnego narzędzia jakim jest <strong>vipw</strong>.
          Polecenie to tworzy kopię zmienianych plików i następnie otwiera
          ten plik w terminalowym edytorze. Konfiguruje ono również ten edytor
          aby zaznaczał składnię wpisów w plików, po zapisaniu zmian polecenie
          sprawdzi składnie zmienionych lub dodanych wpisów. Jeśli wszystko
          będzie dobrze, to polecenie zapisze zmiany jeśli coś będzie nie
          tak to polecenie zaproponuje poprawienie błędu. Polecenie wymaga
          oczywiście uprawnień administratora. Wydając polecenie bez żadnej
          opcji otworzy ono plik <em>/etc/passwd</em> do edycji a jesli dodamy
          opcje <strong>-s</strong> to wówczas zostanie otworzony plik 
          <em>/etc/shadow</em>.
        </p>
        <p>
          Inną metodą jest wykorzystanie np. opcji polecnia 
          <strong>passwd</strong> jego domyślną rolą jest zmiana hasła, bądź 
          ustawianie ważności hasła, jednak dodając opcję <strong>-s</strong>
          mozemy zmienić domyślny program startowy (powłokę) lub za pomocą
          opcji <strong>-f</strong> możemy zmienić nazwę użytkownika. Po
          więcej informacji zapraszam do strony podręcznika polecenia 
          <em>passwd</em>. Jeśli na naszym przypadku polecenie <em>passwd</em>
          może nie być zadowalające. Można wówczas skorzystać z polecenia typu
          <strong>usermod</strong>.
        </p>
        <h3 id="7.3.4.groups">7.3.4. Grupy</h3>
        <p>
          Rolą grup w systemach uniksopodobnych jest współdzielenie plików.
          Dzięki nim możemy zwiększyć uprawnienia do pliku, nie którym
          użytkownikom, chroniąc je przed innymi. Wynika to z możliwosci
          nadania uprawnień grupie, natomiast można je zabrać wszystkim 
          pozostałym. Obecnie stacje uniksowe stały się bardziej
          spersonalizowanie to współdzielenie plików przy użyciu grup
          straciło na znaczeniu. Jednak grupy tak jak użytkowników możemy 
          wykorzystać do uzyskiwania dodatkowych uprawnień lub ich
          ograniczania.
        </p>
        <p>
          Wraz z każdym nowym użytkownikiem tworzona jest nowa grupa o tej
          samej nazwie co użytkownik. Grupa ta jest również ustawiana jako
          grupa podstawowa tworzonego użytkownika. Definicje grup znajdują
          się w pliku <em>/etc/group</em>. Poniżej znajduje się fragment:
        </p>
<pre class="code-block">
libvirt:x:123:user,xf0r3m
libvirt-qemu:x:64055:libvirt-qemu,user,xf0r3m
geoclue:x:124:
user:x:1000:
xf0r3m:x:1001:
</pre>
        <p>
          Jak możemy zauważyć wpisy dzielą się na cztery pola, które kolejno
          oznaczają:
        </p>
        <ul>
          <li><strong>Nazwa grupy</strong> - nazwa jednoznacznie identyfikująca
            grupę.</li>
          <li><strong>Hasło grupy</strong> - hasło grupy. Obecnie aby podłączyć
            użytkownika do grupy potrzebna jest interwencja administratora lub
            kogoś z jego uprawnieniami. Jeśli jednak grupa posiada hasło to 
            użytkownik może podłączyć się do grupy za pomocą polecenia
            <strong>newgrp</strong> (dalej jest taka możliwość). Obecnie
            jednak nie stosuje się haseł dla grup. Hasła grup są przechowywane
            w pliku <em>/etc/gshadow</em>.</li>
          <li><strong>GID (identyfikator grupy)</strong> - numeryczny
            identyfikator grupy, służy do odniesienia jądra do konkretnej
            grupy.</li>
          <li><strong>List członków grupy</strong> - lista uzytkowników
            należących do grupy.</li>
        </ul>
        <p>
          Grupy odpowiadające istniejącym użytkownikom nie posiadają żadnych
          członków w tym pliku, jednak odpowiadający tym grupom użytkownicy są
          ich domyślnymi członkami.
        </p>
        <p>
          Jądro Linux, nie posługuje się nazwami użytkowników czy grup 
          odwołując się do jednego lub drugiego bytu. W tym celu używa wartości
          UID oraz GID, aby ich używanie miało sens muszą być one unikatowe
          w skali całego systemu. Oczywiście może zdażyć się przypadek, że
          dwóch użytkowników będzie miało ten sam UID, ale są to bardzo rzadkie
          i specyficzne przypadki.
        </p>
        <h2 id="7.4.gettyandlogin">7.4. Getty oraz login</h2>
        <p>
          Te dwa programy nie są zbyt skomplikowane w swoim działaniu.
          Działanie programu <em>getty</em> polega na podłaczeniu się pod
          terminal (nie ważne czy wirtualny czy fizyczny podłączony przez 
          port COM) i wyświetlenie znaku zachęty logowania (napisu "login: ")
          i oczekiwania na podanie nazwy użytkownika. Kiedy nazwa zostanie
          podana
          polecenie to zastępuje same siebie wywołując program <em>login</em>.
          Ten program odpowiedzialny jest za wyświetlenie znaku zachęty hasła
          (napisu "hasło:") po podaniu przez użytkownika hasła program
          spróbuje go uwierzytelnić. Jeśli to się powiedzie wówczas program
          <em>login</em> zastąpi sam siebie po przez wywołanie systemowe
          <em>exec()</em> programem startowym ustawionym w ostatnim polu 
          wpisu w pliku <em>/etc/passwd</em>.
        </p>
        <p>
          Prawdopodbnie nigdy nie będzie potrzeby konfiguracji tych programów,
          nie mniej jednak jest taka możliwość.
        </p>
        <h2 id="7.5.time">7.5. Ustawienia czasu.</h2>
        <p>
          Działanie wielu operacji w systemach uniksopodobnych opiera się o
          czas. Za zegar w tych systemach odpowiedzialne jest jądro. Jednak
          nie jest ono wstanie wziąć precyzyjnych ustawień czasowych samo z
          siebie. Większość komputerów klasy PC posiada potrzmywany bateryjnie
          zegar czasu rzeczywistego, jądro synchronizuje swój zegar z tym 
          zegarem jednak z racji tego, iż maszyny uniksowe nie są uruchamiane
          ponownie przez miesiące a nawet lata. W czasie systemowym pojawia 
          się odchylenie. 
        </p>
        <p>
          Zegar systemowy jądra również jest korygowany na podstawie ustawień
          strefy czasowej w jakiej się znajdujemy, dlatego też 
          RTC (ang. <em>Real Time Clock</em>) w BIOS lub UEFI powinien być 
          ustawiony zgodnie ze strefą czasową UTC. Za pomocą poniższego
          polecenia możemy ustawić czas UTC jądra względem RTC.
        </p>
<pre class="code-block">
$ sudo hwclock --hctosys --utc
</pre>
        <h3 id="7.5.1.timezonesandtimerepresentation">7.5.1. Strefy czasowe i reprezentacja czasu</h3>
        <p>
          Jądro przechowuje swój czas w formacie uniksowym, czyli ilości 
          sekund od północy 1 stycznia 1970 roku. Na podstawie tych informacji
          takie polecenia jak <strong>date</strong> dokonuja wszelkich 
          konwersji i wyświetlają nam zrozumiałą dla nas datę i czas. Czas
          uniksowy możemy wyświetlić sobie za pomocą polecenia <em>date</em>
          z opcją <strong>+%s</strong> (niestety polecenie <em>date</em> ma
          nieco inny format opcji).
        </p>
<pre class="code-block">
xf0r3m@immudex:~$ date
śro, 28 gru 2022, 13:11:53 CET
xf0r3m@immudex:~$ date +%s
1672229517
</pre>
        <p>
          Domyślnie polecenie <code class="code-inline">date</code> wyświetla
          datę i czas skorygowany o ustawioną w naszym systemie, na podstawie
          przybliżonej lokalizacji strefę czasową. Ustawiona strefa czasowa
          znajduje się katalogu <em>/etc</em> jako dowiązanie symboliczne do
          jednego z plików stref dostępnych w systemie w katalogu 
          <em>/usr/share/zoneinfo</em>.
        </p>
<pre class="code-block">
xf0r3m@immudex:~$ ls -al /etc/localtime 
lrwxrwxrwx 1 root root 33 11-04 17:46 /etc/localtime -&gt; /usr/share/zoneinfo/Europe/Warsaw
</pre>
        <p>
          Strefę czasową możemy zmienić za pomocą polecenia interaktywnego 
          polecenia <strong>tzselect</strong>. Polecenie to spróbuje określić
          twoją przybliżoną lokalizacje na podstawie stolicy kraju w jakim się
          znajdujesz. Następnie utworzy nowe dowiązanie symboliczne
          <em>/etc/localtime</em> do odpowiedniego pliku strefy.
        </p>
        <p>
          Jeśli z jakiś przyczyn potrzebujemy sprawdzić jaki bedzie czas w
          wybranej przez nas strefie czasowej, możemy zmienić zmienną
          środowiskową TZ, która przechowuje informacje o ustawionej strefie
          czasowej na czas wykonania polecenia. Tę czynność możemy wykonać na 
          czas wykonania pojedyńczego
          polecenia, ustawiając wartość zmiennej w tej samej linii co polecenie
          <em>date</em>.
        </p>
<pre class="code-block">
xf0r3m@immudex:~$ TZ=Asia/Tokyo date
śro, 28 gru 2022, 21:29:01 JST
</pre>
        <h3 id="7.5.2.settingntptime">7.5.2. Czas sieciowy</h3>
        <p>
          Jeśli nasza maszyna sieciowa jest na przykład serwerem ze stałym 
          dostępem do sieci. To aby zniwelować to odchylenie czasowe, którym
          wspomniałem na początku tego podrozdziału możemy uruchomić na nim 
          specjalną usługę sieciową, która pobierze czas z serwerów
          podłączonych do bardzo precyzyjnych zegarów atomowych.
        </p>
        <p>
          Pierwszą rzeczą jak należy zrobić to pobrać pakiet odpowiedzialny
          za demon NTP w naszym systemie. Następnie skonfigurować go zgodnie
          jego dokumentacją. Najprostsza konfigurację możemy zapisać w
          poniższych krokach.
        </p>
        <ol>
          <li>Znalezienie najbliższego dla siebie serwera NTP, najlepiej
            na poziomie STRATUM nie większym niż 3.</li>
          <li>Zapisanie adresów serwera (serwerów, może być pula) w pliku
            konfiguracyjnym demona NTP, najczęściej jest to 
            <em>/etc/ntp.conf</em>.</li>
          <li>Uruchomienie polecenia <em>ntpdate</em>.</li>
          <li>Włącznienie demona NTP do uruchomienia w trakcie autostartu.</li>
        </ol>
        <p>
          Jeśli nasz komputery nie posiada stałego łącza internetowego możemy
          wówczas uruchomić takiego demona jak <em>chronyd</em>. Ostatecznie
          mozemy zsynchonizowany czas systemowy załadować do zegara RTC za 
          pomocą poniższego polecenia.
        </p>
<pre class="code-block">
$ sudo hwclock --systohc --utc
</pre>
        <p>
          W tym podrozdziale umieściłem polecenie, którego nie wyjaśniłem.
          Jest nim <strong>poziom STRATUM</strong>. Wyjasnienie tego pojecia
          wymaga zagłebienia się w protokół NTP, co zrobiłem w materiale
          przygotowawczym do RHCSA znajdującym się tutaj: <a href="https://morketsmerke.github.io/articles/terminallog/RedHat_-_RHCSA.html#18.1.ntp">https://morketsmerke.github.io/articles/terminallog/RedHat_-_RHCSA.html#18.1.ntp</a>.
        </p>
        <h2 id="7.6.cron">7.6. Tworzenie powtarzalnych zadań za pomocą cron</h2>
        <p>
          Wróćmy na chwile do drugiego podrozdziału. Tam pod koniec omówiliśmy
          sobie gdzie znajdują się pliki dziennika i w jaki sposób system 
          radzi sobie z problem szybko przyrastających plików zawierających
          komunikaty diagnostyczne z przeróżnych demonów. Wspomnialiśmy tam 
          o <em>logrotate</em>. Ten program aby zapobiec zużyciu całego miejsca
          na dysku musi uruchamiać się co jakiś czas.
        </p>
        <p>
          W uniksach aby wykonywać jakieś czynności co określoną ilość czasu,
          musimy skorzystać z programu o nazwie <strong>cron</strong>. Ten 
          program to swojego rodzaju harmonogram zadań, w którym to może
          zdefiniować co uruchomić, kiedy lub co ile czasu i przez kogo.
          Definicje zadań znajdując się w specjalnych plikach zwanych
          <em>crontab</em>. Każdy użytkownik ma swój plik. Ponieważ pliki te
          znajdując się w miejscu, do którego zwykli użytkownicy nie mają 
          dostępu muszą używać
          dostarczonym wraz z <em>cron</em> narzędziem.
        </p>
        <p>
          Aby móc zdefiniować zadania należy wydać następujące polecenie:
        </p>
<pre class="code-block">
$ crontab -e
</pre>
        <p>
          Wówczas otworzy nam się wybrany przez nas wcześniej edytor
          terminalowy. Wewnątrz pliku znajdziemy obszerny komentarz, w którym
          to rozpisano dokładnie całą składnie definicji zadania <em>cron</em>.
        </p>
        <p>
          Otóż zadania <em>cron</em> to jednowierszowe wpisy definiujące na 
          początku czas (kiedy, co ile czasu) w którym należy uruchomić zadanie
          Następnie polecenie, które należy uruchomić.
        </p>
<pre class="code-block">
21 0 * * * /usr/local/bin/backup.sh &gt; /var/log/backup_sh.log 2&gt;&amp;1
</pre>
        <p>
          To zadanie zostanie uruchomione codziennie 21 minut po północy. Skąd
          to wiem, otóż już śpieszę z wyjaśnieniami. Najpierw objaśnie
          poszczególne pola.
        </p>
        <ul>
          <li><code class="code-inline">21</code> - pole minut, podanie tutaj
            takie zwykłej wartości jak na przykładzie, spowoduje uruchomienie
            zadania o podanej minucie godziny. Zakres wartości od 0 - 59.</li>
          <li><code class="code-inline">0</code> - pole godziny, podanie
            wartości w tym polu spowoduje, że zadanie zostanie uruchomione
            o tej samej pełnej godzinie każdego dnia, chyba że podano konkretną
            minutę. Zakres wartości od 0 - 23.</li>
          <li><strong><span style="color: lightgreen">*</span></strong> - pole
            dnia miesiąca, wartość w tym polu spowoduje, że zadanie zostanie
            uruchomione o północy podanego dnia miesiąca, chyba że zdefiniowano
            wcześniejsze pola. Zakres wartości od 1 - 31.</li>
          <li><strong><span color="color: fuchsia">*</span></strong> - pole
            miesiąca, wartość w tym polu spowoduje uruchomienie zadania o
            północy 1 dnia miesiąca, chyba że zdefiniowano wcześniejsze pola.
            Zakres wartości od 1 - 12.</li>
          <li><strong><span color="color: cornfloweblue">*</span></strong> -
            pole dnia tygodnia, wartość w tym polu spowoduje uruchomienie
            zadania co tydzeń o północy podanego dnia tygodnia. Chyba że 
            zdefiniowano wcześniejsze pola. Zakres wartości od 0 - 7, przy czym
            0 i 7 to niedziela.</li>
        </ul>
        <p>
          Ustawienia czasu wykonania zadania jest w miarę proste o ile nie
          wymagamy bardzo złożonego warunku czasowego lub nie próbujemy go 
          zrozumieć (zadając sobie pytanie: kiedy to dokładnie się wykona?).
          Załóżmy że chcemy aby zadanie wykonało się w każdy weekend wakacji
          w Polsce. Warunek czasowy może przyjmować: wartości krokowe
          (<strong>/2</strong>) co dwie minuty, godziny, dni, miesiące; 
          zakresy (<strong>5-10</strong>) od 5-10 minuty, godziny, dnia itd lub
          listy (<strong>11,12</strong>) zadanie wykoania się np. 11 i 12
          każdego miesiąca. Zakresy oraz listy można ze sobą łączyć, jak i
          dodać pojedyńczą wartość do zakresu, np. 5-10,12. Przy tworzeniu 
          warunku czasowego możemy posłużyć się stronami takimi jak:
        </p>
        <ul>
          <li><a href="https://crontab.guru">https://crontab.guru</a></li>
        </ul>
        <h3 id="7.6.1.instalationofcrontab">7.6.1. Instalacja tablicy cron.</h3>
        <p>
          Po zapisaniu zmian tablica z zadaniami crona (<em>crontab</em>)
          zostanie automatycznie zainstalowana w katalogu
          <em>/var/spool/cron/crontab</em>. Polecenie 
          <code class="code-inline">crontab</code> daje możliwość instalacji
          tablicy zadań z zwykłego pliku tekstowego, dokonujemy tego za pomocą
          polecenia <code class="code-inline">crontab</code> wraz z opcją 
          <strong>-l</strong>. Jednak
          korzystanie z opcji <code class="code-inline">-e</code> jest bardziej
          zalecane. Wówczas podczas zapisywania zmian polecenie sprawdzi 
          zadania pod kątem poprawności składni i przypadku błedu, zapyta czy
          nie chcemy go poprawić.
        </p>
        <p>
          Tablice z zdaniami cron możemy usunąć za pomocą opcji 
          <strong>-r</strong> polecania <code class="code-inline">crontab</code>.
        </p>
        <h3 id="7.6.2.systemwidecrontab">7.6.2. Systemowa tablica zadań crontab.</h3>
        <p>
          Prócz tablic użytkowników, istnieje jescze systemowa tablica
          z zadaniami <em>cron</em>. Ją edytujemy już pomocą edytora tekstowego
          ponieważ jej wpisy mają nieco inną składnie niż tablice użytkowników.
          W jej wpisach znajduje się dodatkowe pole między dniem tygodnia a
          poleceniem. W nim definiuje się użytkownika, z którego uprawnienami
          realizowane jest zapisane zadanie. Dlatego też polecenie 
          <em>crontab</em> z opcją <em>-e</em> nie ma tutaj zastosowania. Jako
          systemowej tablicy cron, nie wykorzystuje się również tablicy
          superużytkownika. Za tablicę systemową odpowiedzialny jest plik 
          <em>/etc/crontab</em>. Plik ten edytujemy za pomocą zwykłego edytora,
          kiedy zakończymy edycję, należy uruchomić demon <em>cron</em>
          ponownie.
        </p>
<pre class="code-block">
xf0r3m@immudex:~$ sudo vim /etc/crontab 
xf0r3m@immudex:~$ sudo systemctl restart cron
</pre>
        <p>
          Inną metodą na powtarzalne wykonywanie czynności jest skorzystania
          z jednego katalogów: <em>/etc/cron.daily</em>, 
          <em>/etc/cron.hourly</em>, <em>/etc/cron.monthly</em> lub 
          <em>/etc/cron.weekly</em>. Wykorzystanie tych katalogów polega na 
          umieszczeniu skryptu (powłoki, nawet jednej linii z konkretnym
          poleceniem) w jednym z nich. W systemowej tablicy <em>cron</em> jest
          napisane o której wykonywane są zadania zapisane w tych katalogach.
          Skrypty uruchamiane są przez znane nam z poprzedniego rozdziału
          narzędzie jakim jest <em>run-parts</em>. W nowszych dystrybucjach
          obsługą tych katalogów może zajmować się demon <em>anacron</em>.
        </p>
        <h3 id="7.6.3.futureofcron">7.6.3. Przysłość narzędzia cron.</h3>
        <p>
          Narzędzie <em>cron</em> jest starsze od samego Linuksa. Jeśli coś
          jest, aż tak stare to kwalifikuje się do wymiany. Obecnie są czynione
          postępy w temacie zastąpienia <em>cron</em>-a jakimś innym
          rozwiązaniem. Kandydatem mogą być elementy licznika czasu
          <em>systemd</em>. Jednak utworzenie ulepszonej funkcjonalności to
          jedno, a zapewnienie wstecznej zgodność z systemami oraz narzedziami
          dalej wykorzystującymi cron to drugie, bez zapewnienia wstecznej
          zgodności zmian nie będzie, więc póki co <em>cron</em> jeszcze z
          nami pozostanie.
        </p>
        <h2 id="7.7.at">7.7. Planowanie jednorazowych zadań.</h2>
        <p>
          Jedno narzędzie do planowania zadań w przyszłości już poznaliśmy. 
          Narzędzie <strong>at</strong> na pewno nie ma tak szerokiego użycia
          jak <em>cron</em>, to pomaga wykonać pewne zadania po za czasem 
          czynnego użytkowania komputera. Jeśli musimy poczekać do powiedzmy
          północy, aby móc wykonać jakąś czynność, możemy ją zaplanować
          za pomocą polecenia <em>at</em>, pozostawić komputer włączony i
          iść spać.
        </p>
        <p>
          Za pomocą polecenia <em>at</em>, możemy nie tylko zaplanować
          wykonanie zadania na kilka godzin do przodu ale i nawet na kilka
          miesięcy. Aby jednak to zrealizować należy poznać polecenie
          <em>at</em>, które może nie być domyślnie dostępne w każdej
          dystrybucji i trzeba je będzie zainstalować.
        </p>
        <p>
          Aby rozpocząć planowanie zadania należy wydać polecenie <em>at</em>
          i jako argument podać czas ewentualnie datę jeśli zadanie ma zostać
          wykonane w dalszej przyszłości. Po wydaniu tego polecenia zostanie
          nam wyświetlony prompt <em>at&gt;</em>. Po wyświetleniu prompta
          podajemy polecenie do wykonania w zadaniu. Polecenia możemy podawać
          do momentu kiedy naciśniemy kombinację klawiszy <em>Ctrl+d</em>,
          przed zatwiedzeniem polecenia należy upewnić się, że zostało 
          poprawnie zapisane ponieważ nie będzie możliwości jego edycji.
          Po naciśnięciu wspomnianiej kombinacji zadanie zostanie zatwierdzone
          Na poniższym przykładzie utworzyłem jedno zadanie z jednym 
          poleceniem:
        </p>
<pre class="code-block">
xf0r3m@immudex:~$ at 00:00 01.01.2023
warning: commands will be executed using /bin/sh
at&gt; echo "Happy New Year" &gt; /dev/pts/1
at&gt; &lt;EOT&gt;
job 1 at Sun Jan  1 00:00:00 2023
</pre>
        <p>
          Za pomocą opcji <strong>-l</strong> polecenia <em>at</em> lub
          polecenia <em>atq</em> możemy wyświetlić znajdujące się w pamieci
          demona <em>atd</em> zadania.
        </p>
<pre class="code-block">
xf0r3m@immudex:~$ at -l
1	Sun Jan  1 00:00:00 2023 a xf0r3m
xf0r3m@immudex:~$ atq
1	Sun Jan  1 00:00:00 2023 a xf0r3m
</pre>
        <p>
          Natomiast za pomocą opcji <strong>-r</strong> polecenia <em>at</em>
          lub za pomocą polecenia <em>atrm</em>, możemy usunąć zdanie, przyczym
          należy podać numer zadnia widniejący w pierwszej kolumnie danych 
          wyjściowych zwracanych przez polecenie <em>at</em> w raz z opcją
          <em>-l</em> lub polecenie <em>atq</em>.
        </p>
<pre class="code-block">
xf0r3m@immudex:~$ atq
1	Sun Jan  1 00:00:00 2023 a xf0r3m
xf0r3m@immudex:~$ at -r 1
xf0r3m@immudex:~$ atq
</pre>
        <h2 id="7.8.switchinguids">7.8. Identyfikatory użytkowników oraz ich przełączanie.</h2>
        <p>
          Jak pamiętamy, lub może nie bit <em>setuid</em> powodował fakt iż 
          program uruchomiony z tym bitem dział (jego proces) z uprawnieniami
          właściciela pliku. Tutaj poznamy inne możliwości przełączania
          użytkowników wraz regułami oraz jaki udział ma w tym wszystkim jądro.
        </p>
        <p>
          Na Linuksie istnieją dwie metody na przełączanie użytkowników.
          Pierwszym z nich jest ustawienie wspomnianego wcześniej bitu dla
          pliku wykonywalnego. A drugim sposobem jest wykorzystanie wywołania
          systemowego <strong>setuid()</strong>, a żeby sprawę jeszcze bardziej
          skomplikować to wersji tego wywołania systemowego jest kilka, w 
          zależności o tego na jaki identyfikator użytkownika chcemy się
          przełączyć. Zanim poznamy możliwe identyfikator (a przynajmniej ich
          część) warto poznać reguły dotyczące możliwości procesów w zakresie
          przełączania identyfikatorów. Otóż:
        </p>
        <ul>
          <li>Procesy działające z uprawnieniami superużytkownika mogą używać
            wywołania systemowego <em>setuid()</em> do uzyskania uprawnień 
            dowolnego innego użytkownika.</li>
          <li>Proces, który nie działa z uprawnieniami superużytkownika ma 
            poważne ograniczenia odnośnie korzystania z wywołania systemowego
            <em>setuid()</em>. Przeważnie takie procesy nie mogą z niego 
            korzystać.</li>
          <li>Dowolny proces może wykonać program z ustawionym bitem 
            <em>setuid</em>, o ile dysponuje odpowiednimi uprawnieniami do
            tego pliku (każdy proces działa z uprawnieniami jakiegoś
            jakiegoś użytkownika i dziedziczy po nim uprawnienia).</li>
        </ul>
        <p>
          Dla ścisłości w tym przełączaniu użytkowników nie chodzi o
          przełączanie między kontami. A raczej o to, że na podstawie
          dostępnych mechanizmów w systemie proces może zmieniać uprawnienia
          wrazie potrzeby oraz możliwości z jakim został uruchomiony.
        </p>
        <h3 id="7.8.1.processowneranduids">7.8.1. Właściciel procesu oraz identyfikatory użytkownikow</h3>
        <p>
          Dotych czas można było sądzić, że procesy, które uruchamiamy w
          Linuksie posiadły jeden identyfikator użytkownika. Użytkownika, który
          ten proces zainicjował. Rzeczywistość jest niestety zgoła inna. 
          Każdy proces posiada co najmniej dwa identyfikatory użytkowników.
          Pierwszym z nich jest <strong>euid</strong> 
          (ang. <em>Effective User IDentifier</em>) - efektywy identyfikator
          użytkownika. Ten identyfikator wskazuje na użytkownika, z ktorego 
          uprawnienia działa ten proces. Drugim jest <strong>ruid</strong>
          (ang. <em>Real User IDentifier</em>) - rzeczywisty identyfikator
          użytkownika. Ten wskazuje natomiast użytkownika, który zainicjował
          ten proces. 
        </p>
        <p>
          Ze względu na niejasność związane z rozgraniczeniem miedzy 
          <em>euid</em> a <em>ruid</em>. Rzeczywistemu identyfikatorowi
          użytkownika przypisje się rolę właściciela procesu. Może on 
          prowadzić interakcje z procesem wysyłać do niego sygnały w tym 
          kończyć jego działanie. W przypadku większości procesów 
          działających w systemie <em>ruid</em> oraz <em>euid</em> będą równe.
          Jednak w przypadku gdy uruchomimy proces z ustawionym bitem
          <em>setuid</em>, efektywny identyfikator zostanie ustawiony na
          właściciela pliku, zaś rzeczywisty identyfikator będzie 
          przechowywać nasz UID. Najprostszym przykładem uruchomienia programu 
          z bitem <em>setuid</em> a za razem doświadczenia przełączenia 
          identyfikatorów jest użycie polecenia <strong>sudo</strong>.
        </p>
        <p>
          Żeby całość jeszcze bardziej skomplikować, do tych dwóch
          identyfikatorów należy dodać jescze większego poziomu skomplikowania
          to istnieje trzeci identyfikator <strong>suid</strong>
          (ang. <em>Saved User IDentifier</em>) - zapisany identyfikator
          użytkownika. Podczas działania, proces może przełączać się między
          zapisanym a rzeczywistym identyfikatorem. 
        </p>
        <p>
          Jeśli uruchomimy jakiś proces przy użyciu polecenia <em>sudo</em>
          i ten proces będzie trwać, i spróbujemy go zabić to wówczas 
          dostaniemy informacje o braku dostępu. Polecenie <em>sudo</em>
          z ustawionym bitem <em>setuid</em> (jak i inne) zamienia 
          <strong>jawnie</strong>
          identyfikatory użytkowników za pomocą wywołania systemowego
          <em>setuid()</em>. Wynika to z kilku problemów jakie wynikają z
          braku zgodności między identyfikatorami, przez co nie musimy
          się zbytnio przejmować nimi oraz ich przełączaniem.
        </p>
        <p>
          Ze względu na duże uprawnienia (czynny udział jądra w przełączaniu
          użytkowników oraz obsłudzie uprawnień dostępu do pliku) programów z 
          ustawionym bitem 
          <em>setuid</em> i działającym wraz z nim wywowałań systemowych.
          Należy uważać jakim programom nadaje się ten bit. Pozostawienie
          kopii powłoki z ustawionym takim bitem, daje możliwość zwykłym 
          użytkownikom przejęcia kontroli nad całym systemem. Wydając jedno
          polecenie.
        </p>
        <h2 id="7.9.identifyandauthtenticate">7.9. Identyfikacja i uwierzytelnianie</h2>
        <p>
          Każdy wieloużytkowy system musi zapewnić mechanizmy czuwające nad
          kontrolą użytkowników. Użytkownicy powinni przedstawić się systemowi
          przekazać tajną informację (hasło), wówczas mechanizmy w systemie 
          będą wiedzieć, że
          ten użytkownik jest tym za kogo się podaje. Jeśli użytkownik został
          uwierzytelniony ma on dostęp do swojego konta, które jest
          autoryzowane (posiada pewne prawa w systemie) i w ten sposób systemy
          identyfikują użytkowników. To tak wygląda tylko w teorii. Z racji
          tego, iż jądro zna tylko UID, ustalenie nazwy użytkownika wymaga 
          kilku czynności. Można przedstawić tutaj krokowy algorytm, który
          byłby w stanie ustalić taką nazwę, jednak stosuje sie funkcję
          biblioteki standardowej, które pomagają w ustaleniu takich
          informacji. Problem stanowią natomiast hasła, ponieważ funkcje 
          biblioteki standardowej posiadają w sobie pewne założenia, które
          niestety nie sprawdzają się przy obecnym sposobie przechowywania
          haseł w systemie. Więc zatem w jaki sposób obecne dystrybucje
          dokonuja uwierzytelniania? Wykorzystują on do tego 
          <strong>podsystem PAM</strong>.
        </p>
        <h2 id="7.10.pamsystem">7.10. System PAM</h2>
        <p>
          System PAM (ang. <em>Pluggable Authentication Modules</em>) jest to
          zbiór bibliotek współdzielonych, których zadaniem jest udostępnienie
          uwierzytelniania użytkownika, w taki sposób aby aplikacja nie
          musiała się tym zajmować. System PAM może również kontrolować
          autoryzację użytkownika np. blokując mu dostęp do pewnych usług. Jak
          sama nazwa wskazuje system ten wykorzystuje dynamicznie ładowane
          moduły, które realizują poszczególne zadania w zależności od użytej
          funkcji (o tym za chwilę). Jeśli system ma sprawdzić hasło
          użytkownika użyje modułu <em>pam_unix.so</em>. Ze względu te 
          informacje dość łatwym zdaniem jest stworzenie dodatkowych modułów
          obsługujących uwierzytelniania dwuskładnikowe lub klucze fizyczne,
          mimo to system PAM dalej pozostaje spuścizną Uniksa przez co,
          niektóre zagadnienia bywają skomplikowane a intefejs programowania
          nie jest zbyt prosty. To z tego systemu korzysta większość aplikacji
          wymagających uwierzytelniania na dystrybucjach Linuksa, ponieważ 
          połączenie aplikacji z PAM wymaga niewiele pracy lub wcale.
        </p>
        <h3 id="7.10.1.pamconfig">7.10.1. Konfiguracja PAM</h3>
        <p>
          Ze względu na to, iż konfiguracja różni się w zależności od
          dystrybucji, cieżko jest się odnaleźć i wyjaśnić to w ogólny sposób.
          pliki konfiguracyjne systemu powinny znajdować się w katalogu 
          <em>/etc/pam.d/</em>. Ich nazwy często zawierają nazwy komponentów
          systemu, które wykorzystują system PAM. Najprostszym z nich jest
          plik <em>/etc/pam.c/chsh</em>. Polecenie <em>chsh</em> służy do
          zmiany powłowki. Pierwszy wiersz pliku wygląda następująco:
        </p>
<pre class="code-block">
auth  requisite pam_shell.so
</pre>
        <p>
          Nakłada on wymóg, aby podana podczas zmiany powłoka była wymieniona
          w pliku <em>/etc/shells</em>, w przeciwym wypadku uwierzytelnienie
          użytkownika kończy się nie powodzeniem.
        </p>
        <p>
          Każda linia konfiguracji PAM składa się z co najmniej trzech części.
          Między innymi z:
        </p>
        <ul>
          <li><strong>Typu funkcji</strong>, które aplikacja żąda od systemu PAM
            w tym przypadku jest to <code class="code-inline">auth</code>
            powodujący uwierzytelnienie użytkownika.</li>
          <li><strong>Argumentu kontrolnego</strong>, decydującego o tym jak
            system zareaguje na powodzenie lub niepowodzenie działania
            wykonywanego przez typ funkcji.</li>
          <li><strong>Modułu</strong>, określającego jaka czynność zostanie tak
            naprawdę wykonana. W tym przypadku jest sprawdzenie czy funkcja 
            występuje w pliku <em>/etc/shells</em>.</li>
        </ul>
        <h4>Typy funkcji</h4>
        <p>
          System PAM oferuje aplikacji wykonanie czynności określonej jedną z 
          z poniższych funkcji:
        </p>
        <ul>
          <li><strong>auth</strong> - uwierzytelnienie użytkownika.</li>
          <li><strong>account</strong> - sprawdzenie status (czy użytkownik
            jest autoryzowany do wykonania pewnej czynności).</li>
          <li><strong>session</strong> - wykonanie jakieś czynność na bierzącej
            sesji użytkownika.</li>
          <li><strong>password</strong> - zmiana danych uwierzytelniania.</li> 
        </ul>
        <p>
          Warto wspomnieć, że moduły mogą zachować się inaczej (wykonywać inną
          czynność, gdy zestawimy je z innymi funkcjami. Dla przykładu moduł
          <em>pan_unix.so</em> dla modułu <em>auth</em> sprawdzi poprawność
          podanego hasła, natomiast dla funkcji <em>password</em> ustawi je
          użytkownikowi. Dlatego też funkcję i moduł podczas konfiguracji
          PAM należy traktować jako parę.
        </p>
        <h4>Argumenty kontrolne</h4>
        <p>
          Inną częścią, wartą omówienie są argumenty kontrolne. Są one 
          stosowane ze względu na to, iż wiersz zapisane w konfiguracji są 
          zestawiane, co oznacza, że nie zawsze status (powodzenie,
          niepowodzenie) jednego 
          wiersza może oznaczać zwrócenie do aplikacji informacji o
          powodzeniu lub niepowodzeniu funkcji przez nią żądanej. Inną kwestią 
          jest rozszerzona składnia
          argumentów kontolnych dopuszająca inne wartości niż tylko prawda
          czy fałsz. Więcej na ten temat znajduje się na stronie podręcznika
          pliku <em>pam.conf</em>. Poniżej znajdują się arguementy kontrolne
          o prostej składni.
        </p>
        <ul>
          <li><strong>sufficient</strong>. Jeśli reguła opatrzona tym 
            argumentem powiedzie się, zbędne staje się sprawdzanie pozostałych
            reguł, system PAM nie musi tego robić. Jeśli się niepowiedzie to
            system przechodzi do kolejnej reguły.</li>
          <li><strong>requisite</strong>. Jeśli reguła z tym argumentem
            niepowiedzie się to wówczas całe uwierzytelnianie kończy się
            niepowodzeniem. Jeśli reguła powiedzie się, to system przechodzi do
            sprawdzenia pozostałych reguł, oczywiście jeśli zostały 
            zdefiniowane.
          </li>
          <li><strong>required</strong>. Jeśli reguła powiedzie się to system
            przechodzi do kolejnych reguł. Jeśli nie to system i tak sprawdzi
            pozostałe dostępne reguły jednak jedyną zwracaną infomacją bedzie
            niepowodzienie bez znaczenia czy następujące po <em>required</em>
            reguły sie powiodły lub nie.</li>
        </ul>
        <p>
          Znając składnię reguł systemu PAM, możemy spóbować samodzielnie
          przeanalizować drugą linię znajdującą się w pliku <em>chsh</em> w
          katalogu <em>/etc/pam.d</em>.
        </p>
<pre class="code-block">
auth  sufficient  pam_rootok.so
</pre>
        <p>
          Pamiętając o tym, że typ funkcji oraz moduł należy taktować jako
          parę. Skupimy się na początku na argumencie kontrolonym. Otóż jeśli
          ta reguła zakończy się powodzeniem system PAM nie będzie dalej
          sprawdzać reguł. Natomiast funkcja (wraz z modułem) mają za zadanie
          ustalenie czy to superużytkownik próbuje się uwierzytelnić.
        </p>
        <p>
          Zwrócićmy uwagę na to, iż mimo tego co poznaliśmy konfigrację PAM
          oraz przeanalizowaliśmy skonstruowany plik konfiguracyjny dla 
          <em>chsh</em>, to 
          <em>root</em> nadal może ustawić dowolną powłokę. Wynika to z
          konstrukcji samego narzędzia. W tym przypadku PAM ma działać nad
          uwierzytelnianiem zwykłego użytkownika i jego działań.
        </p>
        <p>
          Moduły w regułach PAM mogą posiadać argumenty i są one umieszczane
          po nazwie modułu, na przykład:
        </p>
<pre class="code-block">
auth  sufficient  pam_unix.so nullok
</pre>
        <p>
          Argument ten pozwala na stosowanie pustego hasła podczas
          uwierzytelnienia.
        </p>
        <h3 id="7.10.2.pamnotices">7.10.2. Uwagi dotyczące PAM</h3>
        <p>
          Ze względu na to, iż wiekszość mechanizmów opisanych w tym materiale
          zostało przedstawionych pobierznie, przecież to podstawy. To poniżej
          znajduje się kilka wskazówek odnośnie systemu PAM.
        </p>
        <ul>
          <li>Lista dostępnych w systemie modułów możemy wyświetlić za pomocą
            polecenia 
<pre class="code-block">
$ man -k pam_
</pre>
            Jeśli potrzebujemy znać lokalizację modułów PAM, wówczas możemy
            spróbowac użyć polecenia <em>locate</em> podając nazwę modułu
            jako argument polecenia.</li>
          <li>Strony podręcznika zawierają opis funkcji i argumentów dla
            każdego modułu.</li>
          <li>W wielu dystrybucjach pliki konfiguracji systemu PAM są
            generowane automatycznie, wiec ich modyfikacja może nie być
            najlepszym pomysłem. Przed wprowadzeniem zmian warto zapoznać
            się z umieszczonymi w tych plikach komentarzami.</li>
          <li>Plik <em>/etc/pam.d/other</em> definiuje konfigurację dla
            aplikacji, które nie posiadają własnego pliku. Zazwyczaj
            wszystko tam jest blokowane.</li>
          <li>Istnieje możliwość dołączenia dodatkowych plików konfiguracjnych.
            Za pomocą dyrektywy <em>@include</em> możemy załadować cały
            dodatkowy plik, ale za pomocą specjalnego argumentu kontrolnego
            możemy załadować plik konfiguracjny dla określonej funkcji. Te
            sposoby są określne przez dystrybucje.</li>
          <li>Definicja reguł systemu PAM nie kończy się na argumentach 
            modułów. Moduły mogą uzyskiwać dostęp do plików w katalogu
            <em>/etc/security</em>, które głownie mają na celu ograniczanie
            uprawnień użytkownikom.</li>
        </ul>
        <h3 id="7.10.3.pamandpasswords">7.10.3. System PAM i hasła</h3>
        <p>
          System PAM możemy wykorzystać do uzyskiwania informacji na temat
          haseł w systemie. Wykorzystanie modułu <em>pam_unix.so</em> wraz
          z funkcją <em>auth</em> powoduje sprawdzenie hasła. Natomiast
          jeśli użyjemy tego modułu wraz z funkcją <em>password</em> moduł
          ustawi podane przez uzytkownika hasło. Wyszukując odpowiednią 
          regułę możemy dowiedzieć się na przykład jakiego algorytmu użyto
          do tworzenia skrótu hasła. Do odnalezienia tej linii posłużymy się
          poniższym poleceniem. 
        </p>
<pre class="code-block">
xf0r3m@immudex:/ic0$ grep password.*unix /etc/pam.d/*
/etc/pam.d/common-password:# used to change user passwords.  The default is pam_unix.
/etc/pam.d/common-password:password	[success=1 default=ignore]	pam_unix.so obscure yescrypt
</pre>
        <p>
          W drugiej linii znajduje się poszukiwana przez nas 
          reguła. Skupmy się tylko na argumentach modułu. Otóż argument
          <code class="code-inline">obscure</code>, najprościej rzecz ujmując
          powoduje on sprawdzenie czy podane hasło jest wystarczająco 
          "przesłonięte" (nie jest zbliżone do obecnie używanego). Kolejny
          argument to algorytm szyfrowania w tym przypadku jest to
          nowy algorytm <code class="code-inline">yescrypt</code>, do Debiana
          został on wdrożony wraz z wypuszeniem wersji 11 "Bullseye".
        </p>
        <p>
          No dobrze, w przypadku ustawiania hasła mamy jawnie podany algorytm.
          A co w przypadku gdy moduł PAM musi sprawdzić czy podane hasło jest
          poprawne. Niestety w tym przypadku PAM próbuje odgadnąć algorytm
          wykorzystując do tego bibliotekę libcrypt, ktora wypróbowuje
          wszystkie dostępne możliwości do momentu aż coś zadziała lub
          nie pozostanie nic sprawdzenia.
        </p>
        <h1 id="8.processandresourcemonitoring">8. Procesy oraz monitorowania zasobów</h1>
        <p>
          Jeśli pamiętamy definicję procesu, to wiemy, że proces to nic innego
          jak wystąpienie uruchomionego programu. Każdy proces aby mógł
          wykonać swoje zadanie potrzebuje zasobów sprzetowych naszych 
          komputerów oferowanych przez system operacyjny. Jądro odpowiada
          za sprawiedliwy przydział zasobów systemowych. Samo jądro również
          może być zasobem - programowym wykorzystywanym przez
          procesy do uzyskiwania dostępu do plików czy do urządzeń
          wejścia-wyjścia.  
        </p>
        <p>
          W tym rozdziale objaśnimy sobie nieco bardziej procesy oraz zajmiemy
          się monitorowaniem zasobów. Jednak nie po to aby optymalizować
          system, ponieważ ten na domyślnych ustawieniach dystrybucji działa 
          całkiem dobrze i nie potrzeba nic zmieniać. Zajmiemy się 
          natomiast monitorowaniem zasobów by lepiej zrozumieć co jest 
          dokładnie mierzone, dzięki czemu przybliżymy sobie, niektóre
          działania jądra.
        </p>
        <h2 id="8.1.processtracking">8.1. Śledzenie procesów</h2>
        <p>
          Procesy możemy śledzić za pomocą polecenia <strong>ps</strong> i
          w zależności od użytych przełączników możemy uzyskać różne 
          rezultaty działania tego polecenia. Osobiście polecam
          kombinację trzech przełączników <strong>-aux</strong>. Poza tym
          to polecenie posiada trzy rózne możliwości wprowadzania do niego
          opcji. Ja skupie się na jednym myślniku i łączeniu razem opcji. 
          Inną godną polecenia kombinacją opcji jest <strong>-elf</strong>
          te opcje zwracają najważniesze dla nas informacje, na przykład
          jak wartość priorytetu oraz wartość <em>nice</em>, które biorą
          udział w szeregowaniu procesów do wykonania. Dlaczego polecam tę
          pierwszą kombinacją, ponieważ najczęściej do zarządzania jakimś
          procesami będzie nam potrzebny PID, właściciel procesu, z jakiego
          polecenia proces pochodzi lub procentowe wartości zużycia pamięci
          czy procesora.
        </p>
        <p>
          Innym przydatnym narzędziem dla śledzenia procesów jest polecenie
          <strong>top</strong>. Ponieważ informacje wyświetlane przez to
          polecenie są odświeżane co sekundę dając aktualny obraz tego co
          się aktualnie dzieje w systemie. Po uruchomieniu tego programu na
          samej górze listy procesów znajdują się najbardziej aktywne z nich.
          Podczas działania programu, można przekazywać do niego opcje za
          pomocą naciśniecia odpowiedniego klawisza. Poniżej znajduje się
          kilka opisanych klawiszy.
        </p>
        <ul>
          <li><strong>Spacja</strong> - natychmiastowe odświerzanie ekranu.</li>
          <li><strong>Shift + m</strong> - sortuje procesy pod względem
            zajętości pamięci.</li>
          <li><strong>Shift + t</strong> - sortuje procesy pod względem
            całkowitego zużycia czasu procesora.</li>
          <li><strong>Shift + p</strong> - sortuje procesy pod względem
            aktualnego zużycia czasu procesora. Użycie tego polecenia
            przywraca domyślne ustawienia.</li>
          <li><strong>u</strong> - wyświetla tylko dane procesów 
            użytkownika.<li>
          <li><strong>f</strong> - umożliwia wybranie różnych statystyk do
            wyświetlenia.</li>
          <li><strong>?</strong> - wyświetla informacje o opcjach programu
            <em>top</em>.</li>
        </ul>
        <p>
          W dystrybucjach Linuksa dostępne są różne odmiany polecenia
          <em>top</em>, takie jak <strong>htop</strong> lub <em>atop</em>.
          Polecenie <em>htop</em> jest znacznie bardziej rozbudowane, a
          jego interaktywna konfiguracja pozwala nie tylko na zmianę
          wyświetlanych danych, ale również zmianę tematu wyświetlania
          (kolorów). Za pomocą <em>htop</em> możemy monitorować stan baterii.
          Po za tym polecenie to posiada, niektóre możliwości innego
          przydatnego polecenia jakim jest <em>lsof</em>.
        </p>
        <h2 id="8.2.lsof">8.2. Wyszukiwanie otwartych plików z pomocą polecenia lsof</h2>
        <p>
          Polecenie <strong>lsof</strong> może być bardzo przydatne ponieważ
          pozwala wyświetlić
          listę plików otwartych przez różnego rodzaju procesy. Co może okazać
          się przydatne przypadku gdy chcemy odmontować jakiś system plików,
          ale otrzymujemy informacje o tym, że <em>target is busy</em>. Ten 
          komunikat
          może być spowowany tym, że w systemie istnieją jeszcze procesy 
          działające na plikach znajdujących się na odmontowywanym systemie
          plików. Poza tym polecenie to generuje masę danych ze względu na
          to, że w systemach uniksopodobnych wszystko jest plikiem, a więc 
          nie otrzymamy informacji tylko i wyłącznie o konwencjonalnych
          plikach, ale również o gniazdkach czy nazwanych potokach. Poniżej
          znajduje się linia z otwartym plikiem podczas pisania tego tekstu. 
        </p>
<pre class="code-block">
COMMAND    PID   USER   FD      TYPE             DEVICE SIZE/OFF       NODE NAME
vim.gtk3  3645 xf0r3m    7u      REG              254,0    20480    8391246 /media/xf0r3m/immudex_crypt0/
Repos/morketsmerke-dev/articles/terminallog/.Linux.Podstawy.html.swp
</pre>
        <p>
          Linia przedstawia otwarty plik z materiałem w trakcie redagowania.
          Zwróćmy uwagę na nazwę pliku. Wygląda na to, że edytor <em>Vim</em>
          ładuję zawartość pożądanego przez nas pliku do pliku bufora
          (rozszenienie .swp). W momencie zapisu otwiera właściwy plik,
          zapisuje dane poczym go zamyka. Edytor ten jest znany z tej metody
          obsługi plików. Dzięki temu w przypadku nagłego wyłącznia komputera,
          dane wciąż pozostają w pliku bufora. Nawet w przypadku, kiedy
          będziemy otwierać ten plik to edytor zauważy pozostawiony plik
          bufora, który o opuszczeniu programu powinien zostać usunięty. Jeśli
          dla otwieranego przez ten edytor istnieje już plik wymiany, wówczas
          edytor zapyta co zrobić z jego zawartością. 
        </p>
        <p>
          Wracając, linie zwracane przez to polecenie podzielone są na 9 kolumn
          Każda z nich zawiera:
        </p>
        <ul>
          <li><strong>COMMAND</strong> - polecenie / nazwa procesu.</li>
          <li><strong>PID</strong> - identyfikator procesu.</li>
          <li><strong>USER</strong> - użytkownik, który zainicjował proces.</li>
          <li><strong>FD</strong> - deskryptor pliku lub jego przeznaczenie.
            Deskryptor otwartego pliku jest wykorzystywany przez proces przy
            użyciu bibliotek wspódzielonych oraz jądra do identyfikowania
            i manipulowania plikiem. Na przedstawionej linii mamy doczynienia
            z deskryptorem.</li>
          <li><strong>TYPE</strong> - rodzaj otwartego pliku (zwykły plik,
            katalog).</li>
          <li><strong>DEVICE</strong> - główny i poboczny numer urządzenia
            przechowywującego plik.</li>
          <li><strong>SIZE/OFF</strong> - rozmiar pliku.</li>
          <li><strong>NODE</strong> - numer węzła inode.</li>
          <li><strong>NAME</strong> - nazwa pliku / ścieżka do pliku.</li>
        </ul>
        <p>
          Ze względu na przytłaczającą ilość danych zwracanych przez to
          polecenie, możemy uruchomić je na dwa sposóby. Pierwszym z nich
          jest przepuszcznie danych zwracanych przez to polecenie przez jakiś
          filtr, najprostszym jest chyba polecenie <em>less</em> jednak lepiej
          wyszukać informacji z użyciem wyrażeń regularnych (polecenia
          <em>grep</em>). Drugą metodą jest zawężenie informacji zwracanych
          poprzez wykorzystanie dostępnych opcji narzędzia. Najłatwiejszym w
          użyciu jest podanie jako argumentu po prostu ścieżki do katalogu, z
          którego chcemy widzieć otwarte pliki. Na przykład:
        </p>
<pre class="code-block">
xf0r3m@immudex:~$ lsof /home/xf0r3m
COMMAND    PID   USER   FD   TYPE DEVICE SIZE/OFF NODE NAME
pipewire   978 xf0r3m  cwd    DIR   0,27      400  638 /home/xf0r3m
dbus-daem  983 xf0r3m  cwd    DIR   0,27      400  638 /home/xf0r3m
pipewire-  988 xf0r3m  cwd    DIR   0,27      400  638 /home/xf0r3m
xfce4-ses  989 xf0r3m  cwd    DIR   0,27      400  638 /home/xf0r3m
at-spi-bu 1042 xf0r3m  cwd    DIR   0,27      400  638 /home/xf0r3m
dbus-daem 1047 xf0r3m  cwd    DIR   0,27      400  638 /home/xf0r3m
xfconfd   1051 xf0r3m  cwd    DIR   0,27      400  638 /home/xf0r3m
...
mpv       2923 xf0r3m  cwd    DIR   0,27      400  638 /home/xf0r3m
atrild    3227 xf0r3m  cwd    DIR   0,27      400  638 /home/xf0r3m
</pre>
        <p>
          A jeśli chcelibyśmy się dowiedzieć jakie otawrte pliki posiada
          proces <em>mpv</em>, to możemy na przykład skorzystać z opcji
          <strong>-p</strong> a jako jej argument podać PID procesu
          <em>mpv</em> tak jak przedstawiłem to na przykładzie.
        </p>
<pre class="code-block">
xf0r3m@immudex:~$ lsof -p 2923
COMMAND  PID   USER   FD      TYPE             DEVICE SIZE/OFF   NODE NAME
mpv     2923 xf0r3m  cwd       DIR               0,27      400    638 /home/xf0r3m
mpv     2923 xf0r3m  rtd       DIR               0,27      200      2 /
mpv     2923 xf0r3m  txt       REG               0,29  2158056   4302 /usr/bin/mpv
mpv     2923 xf0r3m  mem       REG                7,0            4302 /usr/bin/mpv (path dev=0,29)
...
mpv     2923 xf0r3m    5u     IPv4              26738      0t0    TCP 192.168.168.29:34108-&gt;
prg03s12-in-f14.1e100.net:https (CLOSE_WAIT)
mpv     2923 xf0r3m    6u     IPv4              26743      0t0    TCP 192.168.168.29:34122-&gt;
prg03s12-in-f14.1e100.net:https (CLOSE_WAIT)
mpv     2923 xf0r3m    7u     IPv4              88390      0t0    TCP 192.168.168.29:38584-&gt;
prg03s13-in-f14.1e100.net:https (ESTABLISHED)
mpv     2923 xf0r3m    8u     IPv4              86801      0t0    TCP 192.168.168.29:48618-&gt;
85.162.162.204:https (ESTABLISHED)
mpv     2923 xf0r3m    9u     unix 0x000000006b6ad31e      0t0  26745 type=STREAM
mpv     2923 xf0r3m   10r     FIFO               0,12      0t0  26746 pipe
mpv     2923 xf0r3m   11w     FIFO               0,12      0t0  26746 pipe
mpv     2923 xf0r3m   12u      CHR              226,0      0t0    237 /dev/dri/card0
mpv     2923 xf0r3m   13u      CHR              226,0      0t0    237 /dev/dri/card0
mpv     2923 xf0r3m   14u      CHR              226,0      0t0    237 /dev/dri/card0
mpv     2923 xf0r3m   15u      CHR              226,0      0t0    237 /dev/dri/card0
mpv     2923 xf0r3m   16r     FIFO               0,12      0t0  26079 pipe
mpv     2923 xf0r3m   17w     FIFO               0,12      0t0  26079 pipe
mpv     2923 xf0r3m   18u  a_inode               0,13        0   7971 [eventfd]
mpv     2923 xf0r3m   19u     unix 0x0000000075d44df6      0t0  26081 type=STREAM
mpv     2923 xf0r3m   20u  a_inode               0,13        0   7971 [eventfd]
mpv     2923 xf0r3m   21r     FIFO               0,12      0t0  26082 pipe
mpv     2923 xf0r3m   22w     FIFO               0,12      0t0  26082 pipe
</pre>
        <p>
          Zastanawiające może być, dlaczego <em>mpv</em> korzysta z połączeń
          sieciowych, otóż za pomocą mpv oraz pakietu <em>youtube-dl</em>,
          można korzystać z serwisu YouTube bez nadmiernego obciążenia
          komputera przez nieoptymalną aplikację internetową.
        </p>
        <p>
          Jeśli często aktualizujemy jądro, poza aktualizacją całej dystrybucji
          to należy pamiętać o aktualizacji programu <em>lsof</em>.
          Po aktualizacji jądra oraz programu <em>lsof</em>, może ono nie
          nie działać prawidłowo, dopóki nie uruchomimy nowego jądra.
        </p>
        <h2 id="8.3.tracingprogramexecutionandsystemcalls">8.3. Śledzenie wykonania programów oraz wywołań systemowych</h2>
        <p>
          Zazwyczaj program jeśli się uruchamia i napotka podczas wykonywania
          swoich czynności błąd to zwróci jakąś informację o tym co się
          stało (większość programów uruchomianych na uniksach). Możemy jednak
          napotkać taki przypadek, że uruchomimy program i on odrazu się
          zamknie. Wówczas pojawia się problem w jaki sposób mamy dowiedzieć
          się co jest nie tak z programem czy naszym środowiskiem (czy wszyskie
          wymagane pakiety zostały zainstalowane, na przykład). Rozwiązania,
          które przedstawię w tym podrozdziale na pewno nie są idealne i nie
          sprawdzą się w przypadku każdego "migającego" programu.
          Nie mniej jednak warto uruchomić dla niego chodziaż jedno z
          zaprezentowanych tutaj poleceń.
        </p>
        <h3 id="8.3.1.stracecommand">8.3.1. Polecenie strace</h3>
        <p>
          Polecenie <em>strace</em> pozwala na uruchomienie programu wraz ze
          śledzeniem wywołań systemowych (interfejsu jądra, pozwalającego na
          wykonanie wielu czynności systemowych, na przykład otwarcia pliku
          zapisanego gdzieś w systemie plików). Najprostszą poleceniem jakie
          możemy wykonać dla przykładu jest wyświetlenie zawartości jakiegoś
          pliku. Polecenie <em>strace</em> może nie występować we wszystkich
          dystrybucjach, więc będzie trzeba je zainstalować. Z racji tego, iż
          informacji zwracanych przez to polecenie jest na prawdę dużo to 
          poniżej przedstawiłem wywołanie prostego wyświetlenia zawartości
          pliku przy użyciu polecenia <em>cat</em>:
        </p>
<pre class="code-block">
xf0r3m@immudex:~$ strace cat yt-links
execve("/usr/bin/cat", ["cat", "yt-links"], 0x7ffc8ee949b8 /* 39 vars */) = 0
brk(NULL)                               = 0x564490232000
access("/etc/ld.so.preload", R_OK)      = -1 ENOENT (Nie ma takiego pliku ani katalogu)
openat(AT_FDCWD, "/etc/ld.so.cache", O_RDONLY|O_CLOEXEC) = 3
fstat(3, {st_mode=S_IFREG|0644, st_size=105669, ...}) = 0
mmap(NULL, 105669, PROT_READ, MAP_PRIVATE, 3, 0) = 0x7f2f770de000
close(3)                                = 0
openat(AT_FDCWD, "/lib/x86_64-linux-gnu/libc.so.6", O_RDONLY|O_CLOEXEC) = 3
read(3, "\177ELF\2\1\1\3\0\0\0\0\0\0\0\0\3\0&gt;\0\1\0\0\0@&gt;\2\0\0\0\0\0"..., 832) = 832
fstat(3, {st_mode=S_IFREG|0755, st_size=1905632, ...}) = 0
mmap(NULL, 8192, PROT_READ|PROT_WRITE, MAP_PRIVATE|MAP_ANONYMOUS, -1, 0) = 0x7f2f770dc000
mmap(NULL, 1918592, PROT_READ, MAP_PRIVATE|MAP_DENYWRITE, 3, 0) = 0x7f2f76f07000
mmap(0x7f2f76f29000, 1417216, PROT_READ|PROT_EXEC, MAP_PRIVATE|MAP_FIXED|MAP_DENYWRITE, 3, 0x22000) = 0x7f2f76f29000
mmap(0x7f2f77083000, 323584, PROT_READ, MAP_PRIVATE|MAP_FIXED|MAP_DENYWRITE, 3, 0x17c000) = 0x7f2f77083000
mmap(0x7f2f770d2000, 24576, PROT_READ|PROT_WRITE, MAP_PRIVATE|MAP_FIXED|MAP_DENYWRITE, 3, 0x1ca000) = 0x7f2f770d2000
mmap(0x7f2f770d8000, 13952, PROT_READ|PROT_WRITE, MAP_PRIVATE|MAP_FIXED|MAP_ANONYMOUS, -1, 0) = 0x7f2f770d8000
close(3)                                = 0
arch_prctl(ARCH_SET_FS, 0x7f2f770dd580) = 0
mprotect(0x7f2f770d2000, 16384, PROT_READ) = 0
mprotect(0x56448ed5a000, 4096, PROT_READ) = 0
mprotect(0x7f2f77122000, 4096, PROT_READ) = 0
munmap(0x7f2f770de000, 105669)          = 0
brk(NULL)                               = 0x564490232000
brk(0x564490253000)                     = 0x564490253000
openat(AT_FDCWD, "/usr/lib/locale/locale-archive", O_RDONLY|O_CLOEXEC) = 3
fstat(3, {st_mode=S_IFREG|0644, st_size=3041312, ...}) = 0
mmap(NULL, 3041312, PROT_READ, MAP_PRIVATE, 3, 0) = 0x7f2f76c20000
close(3)                                = 0
fstat(1, {st_mode=S_IFCHR|0620, st_rdev=makedev(0x88, 0), ...}) = 0
openat(AT_FDCWD, "yt-links", O_RDONLY)  = 3
fstat(3, {st_mode=S_IFREG|0644, st_size=512, ...}) = 0
fadvise64(3, 0, 0, POSIX_FADV_SEQUENTIAL) = 0
mmap(NULL, 139264, PROT_READ|PROT_WRITE, MAP_PRIVATE|MAP_ANONYMOUS, -1, 0) = 0x7f2f76bfe000
read(3, "lofi girl stream: www.youtube.co"..., 131072) = 512
write(1, "lofi girl stream: www.youtube.co"..., 512lofi girl stream: www.youtube.com/watch?v=jfKfPfyJRdk
Stalker czyste niebo: www.youtube.com/playlist?list=PLMnTK-S7An4KqvvXn6AMkE00s_aDNZ29o
Stalker zew prypeci: www.youtube.com/playlist?list=PLMnTK-S7An4K8BMXzFCVA0Y8KLSSHRfwV
MysteryTV CP S03: www.youtube.com/playlist?list=PLjkTsi__dtwWJm4gUqaFLBva0k1TljXcn
MysteryTC CP S04: www.youtube.com/playlist?list=PLjkTsi__dtwWR247M06TZ_2FxccG91f1u
Tu skończyłem: https://www.youtube.com/watch?v=wnY3cTAujMc

Iceberg o stalkerze: www.youtube.com/watch?v=uMHvO7LXVz8
) = 512
read(3, "", 131072)                     = 0
munmap(0x7f2f76bfe000, 139264)          = 0
close(3)                                = 0
close(1)                                = 0
close(2)                                = 0
exit_group(0)                           = ?
+++ exited with 0 +++
</pre>
        <p>
          Polecenie <code class="code-inline">strace</code> wykorzystuje
          wyołanie systemowe <em>fork()</em> aby utworzyć kopię swojego procesu
          następnie ta kopia jest zastępowana przez wywołanie systemowe
          <code class="code-inline">execve()</code>, które uruchamia
          podany przez nas proces, w tym przypadku jest wyświetlenie
          zawartości pliku <code class="code-inline">yt-links</code>, po
          zinicjowaniu pamięci oraz odpytaniu się bibliotek
          proces <em>cat</em> chcę otworzyć
          plik za pomocą wywołania systemowego
          <code class="code-inline">openat</code>, jeśli otwarcie pliku
          się powiedzie, otwartemu plikowi zostanie nadany pierwszy wolny
          deskryptor, najczęsiej będzie to <code class="code-inline">3</code>,
          co zostało przedstawione na przykładzie. Jeśli samodzielnie będziemy
          uruchamiać podobne polecenie (nie każdy w swoim systemie posiada,
          pliki <em>yt-links</em>), to zauważym że ten deskrytor jest
          przypisywany i zwalniany kilkukrotnie podczas wykonywania czynności
          Przed pobraniem zawartości pliku, pobierane są jego atrybuty za
          pomocą wywołania <code class="code-inline">fstat()</code> oraz 
          alokowana jest pamięci operacyjna 
          (<code class="code-inline">mmap</code>) i wówczas następuje wywołanie
          systemowe <code class="code-inline">read()</code>, które pobiera
          zawartości pliku. Następne wywołanie systemowe odpowiedzialne jest
          za wypisanie zawartości, do deskryptora o numerze
          <code class="code-inline">1</code>. Jak pamiętamy polecenie 
          <em>cat</em> wyświetla zawartość pliku podanego jako ścieżka
          albo wyświetla podane dane z standardowego wejścia na standardowe 
          wyjście. A
          więc numer standardowego wyjścia, którym jest <strong>1</strong> jest
          deskryptorem otwartego pliku. Dlatego też wywołanie systemowe
          <code class="code-inline">write()</code> odwołuje się do
          deskryptora o numerze <code class="code-inline">1</code>. Następnie
          pamięć oraz wykorzystywane deskrytory zostają zwolnione i w ten
          sposób kończy się wykonanie procesu polecenia <em>cat</em>.
        </p>
        <p>
          Czytając ten obszerny opis możemy przyjrzeć się jak działają programy
          na uniksach. Nie mniej jednak polecenie <em>strace</em> może pomóc
          nam przy, nie których problemach z programami. Często sytuacją,
          w której program może nam "mignąć" jest brak jakiegoś pliku lub
          problem z jego dostępnością. Kiedy analizujemy wykonanie programu
          za pomocą polecenia <em>strace</em> to należy szczególną uwagę
          zwrócić na wywołania systemowe <em>openat()</em>. Poniżej znajdują się
          dwa przykładowe komunikaty:
        </p>
<pre class="code-block">
openat(AT_FDCWD, "test.txt", O_RDONLY)  = -1 ENOENT (Nie ma takiego pliku ani katalogu)
openat(AT_FDCWD, "/etc/shadow", O_RDONLY) = -1 EACCES (Brak dostępu)
</pre>
        <p>
          W przypadku błędu, zazwyczaj otrzymujemy deskryptor o numerze
          <em>-1</em>, jednak zwróćmy uwagę na komunikaty błedów różnia się od
          siebie (<code class="code-inline">ENOENT</code> a 
          <code class="code-inline">EACCES</code>).
        </p>
        <h3 id="8.3.2.ltracecommand">8.3.2. Polecenie ltrace</h3>
        <p>
          Podobnym do <em>strace</em> narzędziem jest <strong>ltrace</strong>.
          Jednak zamiast wywołań systemowych śledzi on wywołania bibliotek
          wspóldzielonych, dane wyjściowe tego programu są zbliżone do 
          <em>strace</em>. Program <em>ltrace</em> nie śledzi niczego na
          poziomie jądra, to jednak warto mieć na uwadzę fakt, iż programy
          o wiele częściej korzystają z bibliotek wspódzielonych niż z 
          wywołań systemowych. Polecenie <em>ltrace</em> nie zadziała w
          przypadku bibliotek dołączonych statycznie. A jego dane wyjściowe
          możemy odfiltrować za pomocą opcji polecenia, których opis dostępny
          jest na stronie podręcznika.
        </p>
        <h2 id="8.4.threads">8.4. Wątki</h2>
        <p>
          Procesy mogą dzielić się na podobne byty zwane 
          <strong>wątkami</strong>. Wątki w pewnym sensie są podobne do
          procesów, również zawierają identyfikator zwany <strong>TID</strong>
          (ang. <em>Thread IDentifier</em>). Podobnie jak program może mieć
          kilka procesów, odpowiadających wykonywanym przez niego czynnością,
          to wątki mogą być efektem podziału czynności procesu na jeszcze
          mniejsze części. W przypadku komputerów metoda rozwiązywania 
          problemów "dziel i rządź", będzie miała zastosowanie jeszcze
          nie jednokrotnie.
        </p>
        <h3 id="8.4.1.oneormultithreadprocess">8.4.1. Procesy jedno oraz wielowątkowe</h3>
        <p>
          Część procesów uruchamianych w systemie zawiera tylko jeden wątek.
          Wówczas taki proces jest procesem jednowątkowym. Na początku, każdy
          proces posiada jeden wątek, zwany <strong>wątkiem głównym</strong>.
          Wątek główny może tworzyć kolejne wątki, zmieniając ten proces tym
          samym w proces wielowątkowy.
        </p>
        <p>
          Podstawową zaletą procesów wielowątkowych jest fakt wykonania 
          zaplanowanych w procesie czynności o wiele szybciej, gdyż każdy
          wątek może być wykonywany przez jeden procesor (wątek procesora,
          tak rdzenie procesorów też mogą zawierać w sobie wątki, przeważnie
          na jeden rdzeń przypadają dwa wątki). Innym cechą wątków jest to
          iż wykorzystują one wspólne obszary pamięci, (nie tak jak w
          przypadku procesów, gdzie procesy nie mają dostępu do obszaru
          pamięci innych procesów) usprawniając tym samy komunikację miedzy
          wątkami. Wątki najczęsciej wykorzystywane są do obsługi operacji
          wejscia-wyjścia. Użycie w tym przypadku wątków zamiast procesów 
          pozwala nam zaoszczędzić trochę czasu procesora.
        </p>
        <h3 id="8.4.2.displaingthreads">8.4.2. Wyświetlanie wątków.</h3>
        <p>
          Pozanane do tej pory narzędzia służące do obserowania procesów
          również sprawdzą się gdy będziemy chcieli wyświetlić informacje
          na temat wątków. W przypadku polecenia <em>ps</em> wystarczy dodać
          do polecenia opcję <strong>m</strong>, warto jednak zaznaczyć by 
          nie mieszać opcji <em>m</em> wraz z opcją <em>u</em>. Na poniższym
          przykładzie wyświetliłem moje procesy uruchomione w terminalach.
        </p>
<pre class="code-block">
xf0r3m@immudex:/media/xf0r3m/immudex_crypt0$ ps -am -opid,tid,time,cmd
    PID     TID     TIME CMD
   1799       - 00:00:02 /usr/bin/python3 -O /usr/bin/ranger
      -    1799 00:00:02 -
   7507       - 00:00:00 /bin/sh -c set -- '/ic0/Repos/morketsmerke-dev/articles/terminallog/Linux.P
      -    7507 00:00:00 -
   7508       - 00:00:00 /bin/sh /usr/bin/sensible-editor -- /ic0/Repos/morketsmerke-dev/articles/te
      -    7508 00:00:00 -
   7512       - 00:00:05 /usr/bin/vim.gtk3 -- /ic0/Repos/morketsmerke-dev/articles/terminallog/Linux
      -    7512 00:00:05 -
  12070       - 00:00:00 ps -am -opid,tid,time,cmd
      -   12070 00:00:00 -
</pre>
        <p>
          Zwróćmy uwagę na to numery PID oraz TID są takie same. W przypadku
          poleceń jednowątkowych, wątek główny posiada taki sam TID jak
          proces macierzysty. Jeśli pojawiłby się procesy, wkorzystujące 
          wątki, to wówczas TIDy wynośiły by kolejne numery rozpoczynając od
          PID-u lub TID-u wątku głównego.
        </p>
        <p>
          Jeśli preferujemy narzędzie <em>top</em> to wówczas użycie kombinacji
          klawiszy <em>Śhift + h</em> pozwoli nam na wyświetlenie wątków.
          Możemy je rozpoznać po tym, że wyświetlone tam "procesy" są
          uruchomione z tego samego polecenia i posiadają następujące po sobie
          identyfikatory.
        </p>
        <p>
          Wątki w tym materiale zostały przedstawione, aby zaprezetować ich
          istnienie i na tym temat się kończy.
        </p>
        <h2 id="8.5.resourcemonitoring">8.5. Monitorowanie zasobów</h2>
        <p>
          Monitorowanie zasobów komputerów przeprowadza się głównie, aby 
          dowiedzieć się, które z komponentów systemów lub komputerów należy
          z optymalizować, aby nasza praca była jescze bardziej wydajna, abyśmy
          mogli zrobić coś lepiej, szybciej oraz niższym nakładem pracy. Jak
          już wspomniałem jądro Linuksa jest bardzo wydajne przy domyślnych
          ustawieniach i nie trzeba się tym przejmować. Dlatego też
          wykorzystamy monitorowanie zasobów czasu procesora, pamięci
          operacyjnej oraz operacji wejścia-wyjścia do sprawdzenia w jaki
          sposób dzieli je między procesami.
        </p>
        <h2 id="8.6.measuringprocessorusage">8.6. Pomiar czasu procesora</h2>
        <p>
          Do monitorowania w czasie rzeczywistym pojedynczych procesów możemy
          wykorzystać polecenie <em>top</em> wraz z opcją <strong>-p</strong>.
          Jako argumenty opcji podajemy listę identyfikatorów procesów.
        </p>
<pre class="code-block">
$ top -p 3329,1230
</pre>
        <p>
          Wówczas polecenie <em>top</em> pokaże na swojej liście tylko te dwa
          procesy.
        </p>
        <p>
          Aby dowiedzieć się ile czasu procesora w trakcie swojego działania
          wykorzystało konkretne polecenie, to należy je uruchomić za pomocą
          polecenia <strong>time</strong>, jednak tu musimy się na chwilę
          zatrzymać gdyż przeważnie w większości dystrybucji istnieją dwa
          polecenia <em>time</em>. Jedno jest polecenie wbudowanym w powłokę
          i nie ma z niego za bardzo pożytku. Dla przykładu poniżej umieszczam
          pomiar czasu procesora wbudowanym w powłokę polecenie <em>time</em>:
        </p>
<pre class="code-block">
xf0r3m@immudex:~$ time ls
...
real	0m0,007s
user	0m0,001s
sys	  0m0,007s
</pre>
        <p>
          Z kolei dostęp do właściwego polecenie uzyskamy uruchamiając
          konkretny plik: <strong>/usr/bin/time</strong>, jednak twórcy
          wiodących dystrybucji uznają, że polecenie wbudowane w powłokę
          wystarczy, dlatego też prawdopodbne jest, że omawiany przez nas
          program nie będzie domyślnie zainstalowany w naszym systemie. 
          Poniżej znajduje się to samo polecenie wykonane za pomocą właściwego
          programu.
        </p>
<pre class="code-block">
xf0r3m@immudex:~$ /usr/bin/time ls
...
0.00user 0.00system 0:00.00elapsed 100%CPU (0avgtext+0avgdata 2516maxresident)k
0inputs+0outputs (0major+123minor)pagefaults 0swaps
</pre>
        <p>
          To polecenie zwraca znacznie więcej informacji na temat wykonanego
          polecenia. Na tym etapie będą interesować trzy pierwsze wartości:
          <code class="code-inline">0.00user 0.00system 0:00.00elapsed</code>.
          Wskazują one kolejno: 
        </p>
        <ul>
          <li><strong>Czas użytkownika</strong>
            (<code class="code-inline">0.00user</code>) - liczba sekund
            poświęcona przez procesor na wykonanie właściwego kodu programu.
            Przy obecnej mocy obliczeniowej komputerów czas wykonania prostej
            czynności jest natyle krótki, że program zaokrągla go do zera.</li>
          <li><strong>Czas systemowy</strong>
            (<code class="code-inline">0.00system</code>) - czas poświęcony
            przez jądro na obsługę procesu (na przykład, odczyt zawartości
            plików lub katalogów).</li>
          <li><strong>Czas trwania</strong>
            (<code class="code-inline">0.00elapsed</code>) - całkowity czas
            działania procesu od początku do końca jego życia, wraz ze
            wszystkimi dodatkowymi czynnościami. Czas ten nie jest szczególnie
            brany pod uwagę podczas pomiarów wydajności, ale odjęcie sumy
            czasu użytkownika oraz czasu systemowego od tej wartości przedstawi
            czas oczekiwania na zasoby.</li>
        </ul>
        <p>
          Pozostałe wartości zwracane przez to polecenie dotyczą pamięci,
          operacji wejścia-wyjścia oraz stronicowania (do stronicowania jeszcze
          wrócimy w tym rozdziale).
        </p>
        <h2 id="8.7.processprioritization">8.7. Priorytetyzacja procesów</h2>
        <p>
          W pierwszym rodziale poruszyliśmy temat zarządzania procesami przez
          jądro, dowiedzielśmy się, że każdy proces otrzymuje dostęp do
          procesora na ułamek sekundy. Modułem odpowiedzialnym za to, który
          z procesów uzyska w chwili obecnej dostęp do procesora jest
          <strong>program szeregujący</strong>, który na podstawie
          <strong>priorytetu</strong> procesu może przydzielć mu więcej lub
          mniej czasu. W dystrybucja Linuksa priorytety funkcji przedstawiane
          są dwojako. Polecenie <em>top</em> przestawia domyślny priorytet
          wartością <strong>20</strong> (kolumna PR), jeśli jednak wywołamy 
          polecenie
          <em>ps</em> z opcjami <em>-elf</em> (ta sama kolumna), to domyślnym 
          priorytetem będzie
          <strong>80</strong>. My na tym etapie będziemy trzymać się raczej
          wartosci przedstawianych przez polecenie <em>top</em>, ponieważ
          łatwiej będzie nam je zrozumieć. Więc domyślnym priorytem jest
          <em>20</em>, poniżej przedstawiam kilka procesów wyświetlonych przez
          narzędzie <em>top</em>:
        </p>
<pre class="code-block">
xf0r3m@immudex:~$ top

top - 09:32:04 up  1:55,  1 user,  load average: 0,73, 0,65, 0,61
...
PID UŻYTK.    PR  NI    WIRT    REZ    WSP S  %CPU  %PAM     CZAS+ KOMENDA
2364 xf0r3m    20   0 2504764 158992  90048 S   0,3   2,0   0:37.66 Isolated Web Co
2418 xf0r3m    20   0  474048  94468  66272 S   0,3   1,2   1:39.81 xfce4-terminal
4395 root      20   0       0      0      0 I   0,3   0,0   0:01.40 kworker/3:0-events
33705 xf0r3m    20   0   10404   4212   3452 R   0,3   0,1   0:00.36 top 
</pre>
        <p>
          Najwyższym priortem w tym przypadku jest działanie w czasie
          rzeczywistym, ale na tym etapie nie będziemy się tym zajmować. Tak
          więc na chwilę obecną najwyższym priortetem jest <strong>1</strong>,
          a najniższym <strong>39</strong>.
        </p>
        <p>
          Do manipulacji priorytetami wartość <strong>nice</strong>
          (kolumna NI), przechowuje ona wartość wpływającą na priorytet
          zwiększając go lub zmieniajszając. Do ustawienia wartości
          <em>nice</em> służy polecenie <strong>renice</strong>. To polecenie
          możemy wykonać bez uprawnień administrator o ile zmniejszamy
          priorytet (podając wysoką wartość <em>nice</em>, która dodawana jest
          do domyślnej wartości priortetu), zmniejszenie priorytetu
          (podanie ujemnej wartości <em>nice</em>) wymaga już uprawnień
          superużytkownika. Polecenie to poza nową wartością <em>nice</em>
          wymaga podania PID-u procesu.
        </p>
<pre style="code-block">
xf0r3m@immudex:/media/xf0r3m/immudex_crypt0$ pidof top
37426
xf0r3m@immudex:/media/xf0r3m/immudex_crypt0$ renice 20 37426
37426 (process ID) old priority 0, new priority 19

#lub krócej:

xf0r3m@immudex:/media/xf0r3m/immudex_crypt0$ renice 20 $(pidof top) 
37426 (process ID) old priority 0, new priority 19
</pre>
        <p>
          Polecenie <code class="code-inline">pidof</code> pozwala uzyskać
          PID procesu na podstawie polecenia, jeśli uruchomionych jest więcej
          niż jedna instancja danego programu polecenie zwróci listę PID-ów.
          Podczas zmiany priorytetu mimo, iż podaliśmy wartość 20 to
          największą wartością <em>nice</em> jest 19 tak samo jest w drugą
          stronę. Najmniejszą wartością <em>nice</em> (a zatem proces będzie
          mieć największy priortet) jest <em>-19</em>.
        </p>
        <p>
          Priortety i manipulacja nimi miała dużo większe znaczenie w czasch
          gdy z jednego systemu korzystało wielużytkowników. Obecnie maja one
          mniejsze znaczenie. Warto też dodać, aby nie wymuszać wysokich
          priortetów, gdyż mogą one zablokować istotne dla funkcjonowania
          systemu procesy i go zdestabilizować.
        </p>
        <h2 id="8.8.loadaverages">8.8. Średnie obciążenia</h2>
        <p>
          <strong>Średnie obciążenia</strong> jest to o szaczowana liczba
          procesów do uruchomienia. Ten parametr określa ilość procesów
          gotowych w każdej chwili użyć procesora. Jak pamiętamy nie wszystkie
          procesy są gotowe do działania, część z nich czeka na dane. Średnie
          obciążenia są wyświetlane przez polecenie <strong>uptime</strong>. 
        </p>
<pre class="code-block">
xf0r3m@immudex:~$ uptime
 10:40:15 up  3:03,  1 user,  load average: 1,14, 0,99, 1,17
</pre>
        <p>
          Wartości przedstawione obok etykiety
          <code class="code-inline">load average</code> przedstawiaja średnie
          obciążenia z minuty, 5 i 15 minut. Na powszszym przykładzie widzimy
          że ciągu ostatniej minuty z użyto na wykonanie procesów użytkownika
          114% procent procesora. Jeśli obiążenia tak jak na przykładzie stale
          utrzymują się powyżej 1, to oznacza to, że jeden proces cały czas
          wykorzystuje jeden rdzeń procesora. Pełne obiążenie komputera w
          przypadku tego wskaźnika będzie oscylować w granicach ilości
          rdzeni/wątków procesora zamontowanego w naszym komputerze.
        </p>
        <p>
          Wysokie średnie obciążenia mogą wynikać nie tylko z działania w
          systemie procesów ale również ze względu na pozostałą nie wielką
          ilość pamięci dostępnej w systemie. Wówczas jądro może zarządzić
          <strong>proces przeładowania</strong> (ang. <em>trashing</em>), 
          powoduje to szybkie
          przenoszenie stron pamięci na dysk oraz z dysku. Gdy ma to miejsce
          ilość procesów gotowych do uruchomienia zwiększa sią powodując
          znacznie zwiększenie średniej obiążenia. Ze względu na małą ilość
          wolnej pamięci system może działać znacznie wolniej i niż zwykle.
        </p>
        <h2 id="8.9.operating memory">8.9. Pamięc</h2>
        <p>
          Pamięć operacyjna jest bardzo ważnym komponentem komputera, jeśli
          chodzi o maszyny uniksowe. W pamięci rezydują obszary, w których
          procesy przechowują swoje dane, a jej ilość jest ograniczona. Do
          monitorowania pamięci możemy posłużyć się takimi narzędziami jak
          polecenie <strong>free</strong> (w przypadku tego polecenia, warto
          przeskalować sobie wartości zwracane za pomocą opcji 
          <strong>-h</strong>) lub skorzystać z interfejsu systemowego
          wyświetlając zawartość pliku <em>/proc/meminfo</em> (tutaj jednak
          jestśmy skazani na wartość wyrażone w kilobajtach). Jeśli pamięć
          podręczna/bufora nie zajmuje dużego obszaru pamięci fizycznej, a
          mimo to nie mamy w zanadrzu wiekszej ilości wolnej pamięci to 
          niezbędne może być dołożenie pamięci do naszego komputera, aby
          poprawić jego wydajność.
        </p>
        <h3 id="8.9.1.memorymanagement">8.9.1. Zarządzenie pamięcią</h3>
        <p>
          Jądro w tym zadaniu opera się na jednosce <strong>MMU</strong>
          (ang. Memory Management Unit), której zadaniem jest zamiana adresów
          pamięci wirtualnej na adresu pamięci fizycznej. Pamięć wirtualna
          jest wykorzystywana przez procesy. Jądro współpracuje
          z MMU dzieląc obszary procesów na mniejsze strony, trzymając tym
          samym dane służące MMU do odzworowania adresów w strukturze danych
          zwanej <strong>tabelą stron</strong>. W momencie uzyskania przez
          proces dostępu do pamięci jednostka MMU dzięki tej strukturze może
          dokonywać translacji adresów.
        </p>
        <p>
          Procesy zazwyczaj nie wymagają dostępu do pełnego obszaru w pamięci
          od razu. Jądro ładuje wówczas tylko te strony, których proces
          wymaga. Taki rodzaj przydzielania pamięci nazywany jest
          <strong>stronicowaniem na żądanie</strong>.
        </p>
        <p>
          Przydzielenie pamięci nowemu procesowi, możemy zapisać w czterech
          krokach. 
        </p>
        <ol>
          <li>Jądro ładuje do stron pamięci początek kodu programu</li>
          <li>Jeśli zajdzie taka potrzeba jądro może przypisać procesowi kilka
            stron pamięci.</li>
          <li>W trakcie działania procesu, może zajść potrzeba załadowania
            większej ilości kodu, ponieważ następna instrukcja do wykonania
            nie znajduje się na załadowanych początkowo stronach. W takiej
            sytuacji jądro przejmuje kontrolę, ładuje wymagane strony i
            pozwala programowi wznowic działanie.</li>
          <li>Jeśli zajdzie potrzeba przydzielenia więcej pamięci niż
            zakładano na początku, jądro znajduje nieużywane strony, zwalnia
            je i przydziela procesowi.</li>
        </ol>
        <h3 id="8.9.2.pageserrors">8.9.2. Błędy stron</h3>
        <p>
          Nie zawsze wyżej wymienione czynności da się spiąć w czasie. Jeśli
          żądana przez proces strona w pamięci nie jest jeszcze gotowa to
          generują on <strong>błąd strony</strong>. Gdy taki błąd zostanie
          wygenerowany, to kontrolę nad procesorem przejmuje jądro aby
          załadować żądaną stronę. Błędy dzielą się na podstawowe oraz
          drugorzędne.
        </p>
        <h4>Drugorzędne błedy stron</h4>
        <p>
          Błędy tego typu nię są poważnym błedami, i zdarzają się dość często.
          Ich najczęstszym powodem występowania jest fakt iż MMU nie zna 
          położenia strony z instrukcjami programu. Samo MMU może nie mieć
          odpowiednio dużo miejsca aby przechować adresy wszystkich obszarów.
          W przypadku występowania takiego błędu jądro przekazuje do MMU
          informacje o położeniu strony i pozwala na wznowienie działania
          procesu.
        </p>
        <h4>Podstawowe błędy stron</h4>
        <p>
          Podstawowe błędy występują wówczas gdy strony nie ma w ogóle w
          pamięci. Jądro musi ją załadować z jakiegoś nośnika najczęsciej jest
          to dysk. Duża ilość tego typu błędów może przeciążyć system ponieważ
          procesor jest zajęty przez jądro ładujące kod z niekoniecznie
          szybkich nośników, blokując go tym samym dla innych procesów. 
          Niestety pewna ilość tego typu błedów jest
          nie unikniona, a mają one miejsce kiedy po raz pierwszy uruchamiamy
          jakiś program, wówczas należy załadować kod z dysku. 
        </p>
        <h4>Obserowowanie błędów stron</h4>
        <p>
          Do obserwowania błędów stron przydatne staje się polecenie 
          <strong>time</strong>, o którym wspomniałem przy okazji pomiaru
          czasu procesora. Jednak w tym przypadku będzie interesować nas
          wartość w nawiasie obok napisu 
          <code class="code-inline">pagefaults</code>.
        </p>
<pre class="code-block">
xf0r3m@immudex:~$ /usr/bin/time timedatectl
               Local time: nie 2023-01-08 17:59:08 CET
           Universal time: nie 2023-01-08 16:59:08 UTC
                 RTC time: nie 2023-01-08 16:59:08
                Time zone: Europe/Warsaw (CET, +0100)
System clock synchronized: no
              NTP service: n/a
          RTC in local TZ: no
0.00user 0.01system 0:00.10elapsed 24%CPU (0avgtext+0avgdata 7416maxresident)k
522inputs+0outputs (8major+359minor)pagefaults 0swaps
</pre>
        <p>
          W przypadku uruchomienia w moim systemie polecenia
          <code class="code-inline">timedatectl</code> wystąpiły 8 błędów
          podstawowych (<code class="code-inline">8major</code>) oraz 359
          błedów drugorzędnych.
        </p>
        <p>
          Inne narzędzia takie <em>top</em> oraz <em>ps</em> również mogą 
          wyświetlać informacje o błędach stron pamięć, w przypadku polecenia
          <em>top</em> należy włączyć wyświetlanie <em>nMaj</em> oraz
          <em>nMin</em>, aby przejść do konfiguracji należy nacisnąć literę
          <em>f</em>, a następnie postępować zgodnie z instrukcją. Program
          <em>ps</em> pozwala na wyświetlenie błędów strony poprzez podanie
          niestandardowego wyświetlania kolumn (opcja <em>-o</em>) kolumny
          noszą kolejno nazwy <em>maj_ftl</em> i <em>min_ftl</em>.
        </p>
        <h2 id="8.10.vmstat">8.10. Monitorowanie wydajności za pomocą polecenia vmstat</h2>
        <p>
          Polecenie <em>vmstat</em> pozwala na monitorowanie wielu aspektów
          wydajności systemu, a jest jednym z najstarszych narzędzi tego typu.
          Dane wyświetlane również pozostawiają wiele do życzenia i osoba
          nie mająca styczności z tym narzędziem, może uznać je za mało
          czytelne.
        </p>
<pre class="code-block">
xf0r3m@immudex:~$ vmstat 2
proc. -----------pamięć---------- ---swap-- ---we/wy--- -system-- ------cpu-----
dz bl   swap  wolna  bufor  cache   si   so    bi    bo   in   cs uż sy be io sk
 0  0      0 861264  13196 5331448    0    0    56     3  189  210 13  4 83  0  0
 0  0      0 861112  13196 5330624    0    0     0     0 2071 4073  8  4 88  0  0
 0  0      0 861712  13196 5330664    0    0     0     0 1944 3661  7  4 88  0  0
 0  0      0 862012  13196 5330608    0    0     0     0 2007 3866  7  4 89  0  0
</pre>
        <p>
          Polecenie to przyjmuje jako argument interwał czasowym co ile sekund
          ma wyświetlać nowe statystki. Każda linia to w tym przypadku
          statystyki pobrane co dwie sekundy. Wyjście polecenia zawiera
          tematyczne kolumny. Pierwszą z nich są procesy, ta kolumna zawiera
          jeszcze dwie inne kolumny wskazujące procesy gotowe do uruchomienia
          (<code class="code-inline">dz</code>) oraz te
          zablokowane (<code class="code-inline">bl</code>). W następnej 
          kolumnie znajdują się informacje na temat
          pamięci, a w niej informacje o wykorzystaniu przestrzeni wymiany
          (<code class="code-inline">swap</code>), ilości wolnej
          pamięci, pamięci przeznaczonej na bufor oraz pamięci przeznaczonej
          na pamięć podręczną. W trzeciej kolumnie znajdują się informacje o
          przestrzeni wymiany, ile stron zostało przeniesionych na dysk
          (<code class="code-inline">si</code>) oraz ile stron zostało
          załadowanych z dysku do pamięci 
          (<code class="code-inline">so</code>). Czwarta kolumna zawiera 
          informacje o użyciu urządzeń wejścia-wyjścia, dane odczytane z dysku
          (<code class="code-inline">bi</code>) oraz dane zapisane na dysku
          (<code class="code-inline">bo</code>). Piąta kolumna zwiera
          informacje systemowe, w niej znajdują się liczniki wywołań
          systemowych (<code class="code-inline">in</code>) oraz przełączeń
          kontekstu (<code class="code-inline">cs</code>). Ostatnia kolumna
          zawiera procentowe zużycie czasu procesora dla kolejno: aplikacji
          użytkownika (<code class="code-inline">uż</code>), jądra oraz obsługi
          procesów (<code class="code-inline">sy</code>), stanu bezczynności
          (<code class="code-inline">be</code>), czasu przeznaczonego na
          obsługę operacji wejścia-wyjścia 
          (<code class="code-inline">io</code>), czasu skradziony wirtualnej
          maszynie (<code class="code-inline">sk</code>).
        </p>
        <p>
          Polecenie to zawiera wiele przydanych opcji, które są zawarte na
          stronie podręcznika programu. Jak na przykład opcję
          <strong>-d</strong>, która pozwala na monitorowanie dysków.
        </p>
        <h2 id="8.11.iomonitoring">8.11. Monitorowanie operacji wejścia-wyjścia</h2>
        <p>
          Na dystrybucje Linuksa dostępnych jest kilka narzędzi służących do
          monitorowania operacji wejścia-wyjścia, które w dużej mierze są
          operacjami dyskowymi.
        </p>
        <h3 id="8.11.1.iostat">8.11.1. Polecenie iostat</h3>
        <p>
          Jedno znich przypomina omawiany w wcześniejszym
          podrozdziale program <em>vmstat</em>, a jest nim polecenie
          <strong>iostat</strong>, to polecenie może nie być domyślnie
          zainstalowane i jeśli chcemy z niego skorzystać to należy je
          zainstalować. Pakiet zawierający ten program zajduje się w
          repozytoriach <em>Debiana</em> po nazwą <em>sysstat</em>. Poniżej
          znajduje się przykład:
        </p>
<code class="code-block">
xf0r3m@immudex:/media/xf0r3m/immudex_crypt0$ iostat 
Linux 5.10.0-20-amd64 (immudex) 	10.01.2023 	_x86_64_	(4 CPU)

avg-cpu:  %user   %nice %system %iowait  %steal   %idle
          17,27    0,00    4,22    0,01    0,00   78,50

Device             tps    kB_read/s    kB_wrtn/s    kB_dscd/s    kB_read    kB_wrtn    kB_dscd
dm-0              0,35         3,52         0,61         0,00      25273       4396          0
loop0             6,27        73,04         0,00         0,00     524237          0          0
sda               1,55        66,41         0,56         0,00     476690       4048          0
</code>
        <p>
          Oryginalny wydruk jest kolorowy. Ciemno niebieskie pola, mogą być
          trochę nieczytelne, ale oznaczają one wartość
          <code class="code-inline">0,00</code>. Pierwsza linia zawiera nazwę
          jądra, nazwę hosta w nawiasie, aktualną datę, architekturę procesora
          oraz liczbę logicznych procesorów (rdzenie/wątków). Druga oraz
          trzecia linia zawierają średnie zużycie czasu procesora oraz 
          objaśnienia tych wartości. Poniżej znajduje się tabelka
          przedstawiająca urządzenia (<code class="code-inline">Device</code>),
          liczba transferów na sekundę (liczba operacji wejścia-wyjścia na
          sekundę wystosowana wobec urządzenia, 
          <code class="code-inline">tps</code>); liczba danych odczytanych na
          sekundę (<code class="code-inline">kB_read/s</code>); liczba danych
          zapisanych na sekundę (<code class="code-inline">kB_write/s</code>);
          liczba danych odrzuconych na sekundę dla urządznia
          (<code class="code-inline">kB_dscd</code>), ostatnie trzy kolmny
          wrażają podobne wartości tylko zamiast prędkości jest przedstawiona
          tam łączna ilość.
        </p>
        <p>
          Domyślnie dane wyrażane są w kilobajtach, jak prawie wszystko w
          systemie co dotyczy pamięci masowych, jednostki możemy przeskalować
          do megabajtów za pomocą opcji <strong>-m</strong>, natomiast za
          pomocą opcji <strong>-p</strong> wraz z argumentem <em>ALL</em>
          możemy wyświetlić statystki dla wszystkich urządzeń blokowych
          dostępnych w systemie. Podobnie do <em>vmstat</em> podanie gołej
          liczby jako argumentu spowoduje włączenie interwału czasowego o 
          podanej wartości. Więcej opcji oraz bardziej szczegółowe wyjaśnienia
          znajdują się na stronie podręcznika programu.
        </p>
        <h3 id="8.11.2.iotop">8.11.2. Polecenie iotop</h3>
        <p>
          Innym poleceniem służącym do monitorowania operacji wejścia-wyjścia
          jest program <strong>iotop</strong>, zasada działania tego programu
          jest podobna do znanego nam już narzędzia <em>top</em> tylko tym
          razem zamiast skupiać się na procesach, położono nacisk na operacje
          wejścia wyjścia.
        </p>
<pre class="code-block">
xf0r3m@immudex:~$ sudo iotop
Total DISK READ:         0.00 B/s | Total DISK WRITE:         0.00 B/s
Current DISK READ:       0.00 B/s | Current DISK WRITE:       0.00 B/s
    TID  PRIO  USER     DISK READ  DISK WRITE  SWAPIN     IO&gt;    COMMAND                            
      1 be/4 root        0.00 B/s    0.00 B/s  0.00 %  0.00 % init
      2 be/4 root        0.00 B/s    0.00 B/s  0.00 %  0.00 % [kthreadd]
      3 be/0 root        0.00 B/s    0.00 B/s  0.00 %  0.00 % [rcu_gp]
      4 be/0 root        0.00 B/s    0.00 B/s  0.00 %  0.00 % [rcu_par_gp]
      6 be/0 root        0.00 B/s    0.00 B/s  0.00 %  0.00 % [kworker/0:0H-events_highpri]
      8 be/0 root        0.00 B/s    0.00 B/s  0.00 %  0.00 % [mm_percpu_wq]
      9 be/4 root        0.00 B/s    0.00 B/s  0.00 %  0.00 % [rcu_tasks_rude_]
     10 be/4 root        0.00 B/s    0.00 B/s  0.00 %  0.00 % [rcu_tasks_trace]
     11 be/4 root        0.00 B/s    0.00 B/s  0.00 %  0.00 % [ksoftirqd/0]
     12 be/4 root        0.00 B/s    0.00 B/s  0.00 %  0.00 % [rcu_sched]
     13 rt/4 root        0.00 B/s    0.00 B/s  0.00 %  0.00 % [migration/0]
     15 be/4 root        0.00 B/s    0.00 B/s  0.00 %  0.00 % [cpuhp/0]
     16 be/4 root        0.00 B/s    0.00 B/s  0.00 %  0.00 % [cpuhp/1]
     17 rt/4 root        0.00 B/s    0.00 B/s  0.00 %  0.00 % [migration/1]
     18 be/4 root        0.00 B/s    0.00 B/s  0.00 %  0.00 % [ksoftirqd/1]
</pre>
        <p>
          Jak możemy zauważyć to polecenie wyświetla nam identyfikatory wątków.
          Jest to jedno z nielicznych narzędzi wyświetlających wyświetlających
          wątki, ponieważ często procesy dzielą się na nie aby własnie
          zająć się obsługą wejścia-wyjścia. Inna kolumną wartą opisania jest
          <code class="code-inline">PRIO</code>, podobnie jak procesy jądro
          stara się szergować operacje wejścia-wyjścia. Przyczym priorytet
          tutaj dzieli się na dwie wartości, klasę oraz poziom samego
          priorytetu. Wątki o priorytecie
          <code class="code-inline">be/0</code> otrzymają więcej czasu 
          procesora na realizacje operacji niż wątki z priorytetem
          <code class="code-inline">be/4</code>. Samych klas priorytetów
          mogą wystąpić trzy rodzaje takie jak:
        </p>
        <ul>
          <li><strong>be</strong>(<strong>best-effort</strong>) - w przypadku
            tego priorytetu jądro stara się jak najbardziej sprawiedliwie
            uszeregować operacje wejścia-wyjścia. Tę klasę posiada większość
            operacji.</li>
          <li><strong>rt</strong>(<strong>real-time</strong>) - Jądro
            bezwarunkowo szereguje operacje opatrzone tą klasą ponad każdą
            inną.</li>
          <li><strong>idle</strong>, klasa bezczynności. Jądro będzie wykonywać
            operacje z tą klasą, tylko wtedy gdy nie jest wykonywana żadna 
            inna operacja. Ta klasa nie posiada żadnych poziomów, będąc
            zarazem najniższym priorytetem.</li>
        </ul>
        <p>
          Do manipulacji priortetami operacji wejścia-wyjścia służy polecenie
          <strong>ionice</strong>, więcej na jego temat znajdziemy na stronie
          podręcznika.
        </p>
        <h2 id="8.12.pidstat">8.12. Monitorowanie procesów za pomocą narzędzia pidstat</h2>
        <p>
          Za pomocą polecenia <em>top</em> możemy śledzić wykorzystanie
          zasobów przez wybrany proces. Problem w przypadku tego rozwiązania
          jest brak poprzednich wartości, ponieważ dane odświerzane są co
          interwał czasowy (w przypadku <em>top</em> jest to jedna sekunda).
          Rozwiązaniem tej niedogodności może być zastosowanie narzędzia
          <strong>pidstat</strong>, ponieważ zachowuje on się tak jak 
          <em>vmstat</em>, ale dla procesów. Jeśli nie podamy konkretnego
          PID-u, polecenie wyświetli wszystkie procesy, które zostały
          uruchomione w systemie. Polecenie to nie jest domyślnie dostępne w
          dystrybucjach opartych na Debianie, jest ono częścią pakietu
          <em>sysstat</em>, ten pakiet zawiera również polecenie <em>iostat</em>.
        </p>
<pre class="code-block">
xf0r3m@immudex:/media/xf0r3m/immudex_crypt0$ pidstat 
Linux 5.10.0-20-amd64 (immudex) 	11.01.2023 	_x86_64_	(4 CPU)

17:02:56      UID       PID    %usr %system  %guest   %wait    %CPU   CPU  Command
...
17:02:56     1001      2820    4,84    0,99    0,00    0,08    5,83     1  mpv
17:02:56     1001      2886    0,04    0,01    0,00    0,00    0,05     1  ranger
17:02:56     1001      3366    0,18    0,04    0,00    0,00    0,21     1  atril
17:02:56     1001      3398    0,00    0,00    0,00    0,00    0,00     0  WebKitNetworkPr
17:02:56     1001      3805    0,03    0,01    0,00    0,00    0,04     1  vim.gtk3
17:02:56     1001      3829    0,00    0,00    0,00    0,00    0,00     2  bash
17:02:56        0      4176    0,00    0,01    0,00    0,00    0,01     0  kworker/u8:2-kcryptd/254:0
17:02:56        0      5013    0,00    0,00    0,00    0,00    0,00     0  kworker/u8:3-i915
17:02:56     1001      5610    0,00    0,00    0,00    0,00    0,00     0  Web Content
17:02:56     1001     28551    0,00    0,00    0,00    0,00    0,00     2  pidstat
</pre>
        <p>
          Polecenie to w pierwszej linii zwraca nam podsumowanie odnośnie
          systemu (wersję jądra, nazwę hosta, architekturę procesora oraz
          ilość rdzeni/wątków) i datę. Następnie wyświetlana jest tabela z
          procesami, w kolumnach kolejno od lewej znajduje się czas wywołania
          polecenia; UID użytkownika, który ten proces zainicjował; PID
	        procesu. Następne pięć kolumn pokazuje informacje o zużyciu czasu
          procesora. Kolumna <code class="code-inline">%wait</code> jest
          procentowym żużyciem czasu procesora poświęconym na operacje
          wejścia-wyjścia. Ciekawą wartością, nie zwracaną przez inne polecenia
          jest kolumna <code class="code-inline">%guest</code>, która
          przedstawia zużycie procesora na potrzeby zadań wykonywanych przez
          maszynę wirtualną. Kolejnymi kolumnami są sumaryczne procentowe
          zużycie czasu procesora; wskazanie, z którego z rdzeni/wątków
          procesora korzysta ten proces oraz nazwa polecenia.
        </p>
        <p>
          Uruchomienie tego polecenia dla pojedyńczego procesu wymaga podania
          opcji <strong>-p</strong> wraz z wartością, którą jest PID procesu
          oraz najlepiej podanie interwału czasowego w postaci suchej liczby
          po PID-zie.
        </p>
<pre class="code-block">
xf0r3m@immudex:/media/xf0r3m/immudex_crypt0$ pidstat -p 2820 2
Linux 5.10.0-20-amd64 (immudex) 	11.01.2023 	_x86_64_	(4 CPU)

17:32:37      UID       PID    %usr %system  %guest   %wait    %CPU   CPU  Command
17:32:39     1001      2820   13,50    5,00    0,00    0,50   18,50     1  mpv
17:32:41     1001      2820   13,00    3,00    0,00    0,00   16,00     0  mpv
17:32:43     1001      2820   14,00    4,50    0,00    0,50   18,50     0  mpv
17:32:45     1001      2820   12,50    4,00    0,00    0,00   16,50     1  mpv
17:32:47     1001      2820   14,00    4,00    0,00    0,00   18,00     1  mpv
17:32:49     1001      2820   15,00    2,50    0,00    0,00   17,50     3  mpv
17:32:51     1001      2820   14,00    2,50    0,00    0,50   16,50     2  mpv
17:32:53     1001      2820   15,00    3,50    0,00    0,00   18,50     1  mpv
17:32:55     1001      2820   11,50    5,50    0,00    0,00   17,00     3  mpv
^C
Średnia:    1001      2820   13,61    3,83    0,00    0,17   17,44     -  mpv
</pre>
        <p>
          Przerywając działanie polecenia przed jego zakończeniem wyświetli
          nam o ono jedną dodatkową linię zawierającą średnią poszczególnych
          wartości uzyskanych podczas działania polecenia.
        </p>
        <p>
          Więcej przydanych opcji dla tego polecenie znajduje się na stronie
          podręcznika.
        </p>
        <h2 id="8.13.extrainfo">8.13. Informacje dodatkowe</h2>
        <p>
          Powodem istnienia tak szerokiej gamy różnych narzedzi do 
          monitowania wydajności jest możliwość użycia, nie których komponentów
          na różne sposoby. Najprostszym przykładem jaki przychodzi mi teraz
          na myśl jest wykorzystanie pamięci operacyjnej jako dysku. Inną
          rzeczą jest, iż te zasobo są ograniczone, a takie systemy jak serwery
          sieciowe wymagają stałego i intesywnego monitoringu. Dlatego jeśli
          chcemy lub musimy monitorować systemy, którymi zarządzamy lub
          będziemy zarządzać warto zapoznać się z poniższymi zagadnieniami.
        </p>
        <ul>
          <li><strong>sar</strong> (raportowanie dotyczące aktywności systemu).
            Pakiet <em>sar</em> oferuje możliwości monitorowania systemu
            podobne do programu <em>vmstat</em>, ale również rejestruje on
            wykorzystanie zasobów w czasie. Przez co możemy sprawdzić jak
            wyglądało zużycie zasobów podczas wykonywania wcześniejszych zadań.
          </li>
          <li><strong>acct</strong> (ewidencja procesów). Ten pakie z kolei
            zajmuje się ewidencjonowanie procesów, a nie monitorowaniem
            wydajności, nie mniej jednak funkcja sprawdzenia jakie procesy
            działały powiedzmy kilka dni temu może być przydatna.</li>
          <li><strong>Przydziały</strong> przy użyciu przydziałów możemy
            nałożyć limity wykorzystania podstawowych zasobów (czas procesora,
            pamięć operacyjna, czy przestrzeń dyskowa). Niestety jest to funkcja
            systemu <em>PAM</em> więc podlegją im procesy uruchomione w
            obrębie czegoś co z niego korzysta, na przykład powłoka logowania.
          </li>
        </ul>
        <h1 id="9.network">9. Sieć</h1>
        <p>
          Komputery służą do przetwarzania informacji. Informacje 
          wykorzystywane do obliczeń mogą pochodzić z różnych źródeł a jednym
          z nich może być inny system komputerowy. Jednak, aby to miało miejsce
          komputery muszą się w jakiś sposób komunikować ze sobą. W celach
          w miarę swobodnej komunikacji między systemami, komputery łączy się
          w sieci. Połączenie ze sobą dwóch komputerów za pomocą jednego kabla
          również możemy nazwać się siecią, ponieważ mechanizmy oraz
          komponenty związane z komunikacją pozozstają takie same jak dla
          większej ilości komputerów. Zagadnienia łączności sieciowej zostały
          w taki sposób zdefiniowane, aby były niezależne od systemu
          operacyjnego, ale to systemy definiują narzędzia do ich konfiguracji.
          W tym rodziale zapoznamy się z konfiguracją sieci w Linuksie.
        </p>
        <h2 id="9.1.networkbasics">9.1. Podstawy sieci</h2>
        <p>
          Dla łatwiejszego zrozumienia sieci, zaczniemy od zapoznania się z
          nazewnictwem, niektórych jej elementów. Nasz komputer podłączony do
          sieci nazywany jest <strong>hostem</strong>. <em>Hosty</em> często są
          podłączone do sieci lokalnej określanej jako <strong>LAN</strong>.
          Sieci tego typu są wszechobecne. Tego typu sieci posiadamy w naszych
          domach, nie przekraczają one swoim obszarem działania
          jednego budynku lub grupy pomiesczeń. Składają się one z routera
          łączącego sieć internet z siecią <em>LAN</em> oraz (zazwyczaj) z 
          podłączonych do niego hostów. Definicja <em>LAN</em>-u nie ogranicza
          się tylko do hostów podłączonych za pomocą przewodów, łączność może
          zostać zapewniona tutaj bezprzewodowo nie ma na tym polu żadnych
          ograniczeń.
        </p>
        <p>
          Poza możliwością podłączenia sieci <em>LAN</em> do internetu routery
          klasy <strong>SOHO</strong> (<em>Small Office/Home Office</em>)
          posiadają wiele usług przez co konfiguracja i obsługa <em>hosta</em>
          w sieci staje się bezobsługowa. Kilka z tych usług omówimy sobie
          w kontekscie Linuksa w tym rozdziale.
        </p>
        <h3 id="9.1.1.packages">9.1.1. Pakiety</h3>
        <p>
          Jeśli żądana strona internetowa ma zostać przekazana do chcącego ją
          obejrzeć użytkownika, musi zostać specjalnie przygotowana do
          transmisji sieciowej. Takim przygotowaniem zajmują się poszczególne
          <strong>warstwy stosu TCP/IP</strong>. Dane strony
          (powiedzmy kod) przechodzi z jednej warstwy do drugiej będąc
          zamienianym w <strong>pakiety</strong> zrozumiałe dla tych samych 
          warstw po drugiej
          stronie transmisji. Dane są przetwarzane przez poszczególne warstwy
          stosu aż staną się możliwe do przesłania przez
          fizyczny nośnik w postaci kabla miedzianego, światłowodu lub 
          fal radiowych. Pakiety składają się najczęsciej z danych z poprzednej
          warstwy (zwanych <strong>ładunkiem</strong>) oraz dedykowanego tej
          warstwie nagłówka. Przetwarzanie danych przez stos <em>TCP/IP</em>
          nazwywane jest <strong>enkapsulacją</strong> Dwie warstwy stosu 
          zostaną opisane w tym rodziale.
          Warstwą najwyższą zajmiemy się następnym rodziale. Natomiast warstwę
          najniższą omówimy sobie w dużym uogólnieniu.
        </p>
        <h3 id="9.1.2.tcpstack">9.1.2. Stos TCP/IP</h3>
        <p>
          W stosie <em>TCP/IP</em> możemy wyróżnić cztery różne warstwy:
        </p>
        <ol reversed>
          <li><strong>Warstwa aplikacji</strong> - określa sposób komunikacji
            między aplikacjami. Wewnątrz tej warstwy rezydują protokoły
            aplikacji wykorzystywane przez użytkowników takiej np. HTTP.</li>
          <li><strong>Warstwa transportowa</strong> - określa sposób transmisji
            danych z warstwy aplikacji. W tej warstwie znajdują się protokoły
            takie jak TCP oraz UDP. Tutaj także rezyduje pojęcie 
            <strong>portu</strong>. Warstwa transportowa będzie jeszcze
            omawiana w tym materiale.</li>
          <li><strong>Warstwa internetowa</strong> - określa sposób
            dostarczania pakietów z hostów źródłowych do docelowych i
            odwrotnie. W tej warstwie rezyduje protokół IP oraz protokoły
            odpowiedzialne za trasowanie (znalezienie jak najlepszej drogi z
            jednego do drugiego hosta). W tej warstwie znajduje się również
            protokół ICMP odpowiedzialny z diagnozowanie problemów z protokołem
            IP.</li>
          <li><strong>Warstwa łącza</strong> - ta warstwa definuje topologię
            logiczną sieci. Okresla ona metody transmisji danych przez użyty
            w sieci nośnik fizyczny. W tej warstwie znajdują się takie
            protokoły jak Ethernet oraz standard 802.11, definiujący
            transmisję bezprzewodową.</li>
        </ol>
        <p>
          Warto wspomnieć o tym, że w dystrybucjach Linuksa trzy z czterch 
          warstw znajdują się w jądrze systemu.  Mogą jednak pojawić się
          wyjątki, wówczas pakiet może trafic do przetworzenia w przestrzeni
          użytkownika.
        </p>
        <h2 id="9.2.networklayer">9.2. Warstwa sieciowa</h2>
        <p>
          Jak wiemy warstwa sieciowa definiuje sposoby dostarczenia pakietów
          z jednego do drugiego hosta. Ze względu na to, iż będziemy zajmować
          się sieciami internetowymi, skupimy się na jednym protokole tej
          warstwy na - protokole <strong>IP</strong>. Ten protokół posiada
          kilka funkcji, jednak dla nas na tym etapie najważniejsza będzie 
          jedna z nich - <strong>adresacja</strong>. Każdy host aby mógł
          komunikować się w sieci musi mieć przypisany taki adres. Adres ten
          składa się (a przynajmniej w wersji 4 protokołu IP) z czterech grup 
          liczb z
          zakresu od 0 do 255 rozdzielonych kropkami. Na przykład adres IP
          mojego komputera to:
        </p>
<pre class="code-block">
192.168.8.101
</pre>
        <p>
          Uzyskałem te informacje za pomocą poniższych poleceń. Te polecenia
          są tożsame:
        </p>
<pre class="code-block">
xf0r3m@immudex:~$ ip address show
#lub
xf0r3m@immudex:~$ ip a
</pre>
        <p>
          Drugi zapis jest skrótem pierwszego polecenia. Analizując wynik
          działania tego polecenia musimy zwrócić uwagę na dwie rzeczy.
          Pierwszą z nich są "dziwne" nazwy intefejsów sieciowych. Jeśli nikt
          nie korzystał z dystrybucji Linuksa przed 2016 rokiem to wówczas
          nie mógł spotkać się z klasycznymi nazwami interfejsów sieciowych. 
          To jest pierwszy interfejs przewodowy = <em>eth0</em> i tak dalej
          do <em>ethX</em>. Miało to jedną podstawową wadę znaną już z
          dysków. Otóż po którymś uruchomieniu ponownym system mógł wykryć
          karty sieciowe w innej kolejności niż poprzednio co powodowało
          problemy ze <strong>statyczną</strong> (zapisana na stałe w systemie)
          konfiguracją sieciową, ponieważ adresy niezgadzały się z adresacją
          podpiętej sieci. Obecnie ich nazwy są zaczerpnięte z modułów jądra,
          które są wykorzystywane do ich obsługi. Nie wszystkie dystrybucje 
          stosują
          nową nomenklaturę dla interfejsów sieciowych. W dużej mierze są to
          systemy korzystające z innych programów typu <em>init</em> niż
          <em>systemd</em>, choć co prawda nie jest to regułą.
        </p>
        <h3 id="9.2.1.ipaddresses">9.2.1. Adresacja IP</h3>
        <p>
          Inną rzeczą jest sposób prezentowania adresów IP. W linii
          rozpoczynającej się od słowa <code class="code-inline">inet</code>
          znajduje się adres IP przedstawioy w ten sposób 
          <code class="code-inline">192.168.8.101/24</code>. Jest to zapis w
          notacji <strong>CIDR</strong>. Na zapis ten składa się adres IP
          oraz <strong>maska podsieci</strong> w postacji ilości bitów. 
        </p>
        <p>
          Maska podsieci jest rodzajem adresu IP, który określa gdzie i jakie
          liczby z zakresu możemy wpisać do adresów IP hostów. Wyzanczając tym
          samym pierwszy oraz ostatni adres w sieci (początek i koniec sieci),
          na podstawie maski możemy określić ilość hostów w sieci.
          W jaki sposób się to dzieje? Otóż adres IP jak i maskę możemy
          przedstawić w postaci binarnej. W na poprzedni przykładzie maska 
          wynosiła 24 bity. Co to oznacza? Aby sobie to wyjaśnić przedstawimy
          adres IP w postaci binarnej.
        </p>
<pre class="code-block">
192.168.8.101 = 11000000.10101000.00001000.01100101
</pre>
        <p>
          Z adresem poszło w miarę łatwo, ponieważ znaliśmy konkretne liczby.
          Jeśli policzymy wszystkie cyferki w postaci binarnej otrzymam wynik
          32 cyfr, z racji tego że są to wartości binarne bardziej mówimy o
          bitach - podstawowej jednostce informacji, klasycznemu 0 oraz 1.
          Adresy IP w wersji 4 (można zapisać to skrótowo IPv4) mają długość
          32-bitów. Powyżej omawiając maskę podsieci zostało wspomniane, że
          maska wyznacza początek oraz koniec sieci. Adres IP możemy przyrównać
          do adresów pocztowych, kolejne jego części mogą wskazywać na miasto,
          ulicę, budynek oraz na mieszkanie. Adresy pocztowe zawierają
          zazwyczaj stałe elementy jak nazwy miast, ulic czy numerację budynków.
          Tak samo jest w przypadku adresów IP. Te stałe elementy wydzielane są
          maskę podsieci. Mając maskę w postaci ilości bitów z notacji CIDR,
          możemy zapisać ją w ten sposób.
        </p>
<pre class="code-block">
/24 = 11111111.11111111.11111111.00000000
/24 = 255.255.255.0
</pre>
        <p>
          Więc zapis maski w notacji CIDR, to nic innego jak ilość bitów o
          wartości <strong>jeden</strong> (1) zapisanych od lewej w 
          reprezentacji binarnej adresu
          IP. No dobrze, ale 32 - 24 = 8. Co zrobić z tymi 8 bitami? Otóż te
          bity pozostają do dyspozycji administratora i stanowią przestrzeń
          adresową. Maskę podsieci można podzieli na dwie częsci. Jedną częścią
          jest część sieciowa, która wyznacza stałą część adresu IP w adresacji
          hostów w sieci i ta część adresu IP jest niezmienna podczas adresacji.
          Drugą częścią jest część hosta, wskazująca, która część adresu IP
          będzie zawierać konkretną wartość wskazującą na hosta w sieci. Teraz
          złożymy ze sobą adres IP oraz maskę zapisaną w postaci dziesiętnej
          (<code class="code-inline">255.255.255.0</code>).
        </p> 
<pre class="code-block">
Adres IP: 192.168.8.101
Maska:    255.255.255.0
</pre>
        <p>
          Poszczególne części adresu IP odzielone kropkami noszą nazwe
          <strong>oktetów</strong>, ponieważ w reprezentacji binarnej każda
          z częsci posiada 8 bitów. Zatem przyglądając się powyższemu
          przykładowi możemy dojść do wniosku, że czwarty ostatni oktet będzie
          przeznaczony na częśc hostów, i tylko on będzie się zmieniać
          podczas adresacji kolejnych hostów w tej sieci.
        </p>
        <p>
          Warto zaznaczyć że przy prostych sieciach, maski mogą pozostać
          typowe tj. 24, 12 oraz 8 bit. Gdzie niegdzie spotykałem się
          również z maską 16 bitową. Dającą dwa oktety na część przeznaczną
          dla hostów. W przypadku 12-bitowej maski, nie ma już takiego
          eleganckiego podziału. Część bitów z drugiego oktetu pozostanie w
          części sieciowej, a druga część przejdzie do części hosta. Rozpiszmy
          sobie ten przykład. Załóżmy że nasz komputer jest podłączony do
          sieci 172.16.X.Y/12 i chcielibyśmy dowiedzieć się jak duża jest 
          ta podsieć. Za stałą możemy przyjąć, że jeśli na konkretnym oktecie
          maski występuje 0, to ten sam oktet adresu IP może przyjąć wartości
          od 0 do 255.
        </p>
<pre class="code-block">
172.16.0.0/12
10101100.00010000.00000000.00000000 = 172.16.0.0
11111111.11110000.00000000.00000000 = /12 = 255.240.0.0
#Część bazowa adresu IP po usunięciu wszystkich bitów z zermi na masce:
10101100.0001

10101100.00010000.00000000.00000000 = 172.16.0.0
1.           0000                   = 172.16
2.           0001                   = 172.17
3.           0010                   = 172.18
4.           0011                   = 172.19
5.           0100                   = 172.20
6.           0101                   = 172.21
7.           0110                   = 172.22
8.           0111                   = 172.23
9.           1000                   = 172.24
10.          1001                   = 172.25
11.          1010                   = 172.26
12.          1011                   = 172.27
13.          1100                   = 172.28
14.          1101                   = 172.29
15.          1110                   = 172.30
16.          1111                   = 172.31
10101100.00011111.00000000.00000000 = 172.31.0.0
(16 x 256 ^ 2) - 2 = 1048574
</pre>
        <p>
          Myślę że powyższy przykład jasno przedstawia jak wygląda podział
          klasowych sieci. A co jeśli będziemy chcieli
          rozszerzyć sieci 192.168.8.0/24? Jeśli założym, że potrzebowalibyśmy
          kolejne 255 adresów to wówczas wystarczy zabrać z maski 1 bit. Da to
          maskę 23-bitową a my swojej sieci będziemy mogli zaadresować hosty od
          192.168.8.1 - 192.168.9.254.
        </p>
        <p>
          Każdy komputer posiadający skonfigurowaną w ten sposób warstwę
          internetową/sieciową może komunikować się z hostami w sieci.
          Konfigurowanie warsty sieciowej, jest chyba jedyną czynnością, w
          w której użytkownik będzie mieć styczność z stosem TCP/IP. Jednak
          aby móc skomunikować się za pośrednictwem routera z internetem
          potrzebujemy jeszcze kilku informacji.
        </p>
        <h3 id="9.2.2.routingtable">9.2.2. Routowanie oraz tabela routingu</h3>
        <p>
          Każdy funkcjonujący w sieci system musi posiadać źródło informacji na
          temat gdzie należy przesłać pakiety lub jakiego interfejsu do tego
          celu należy użyć. Czynność ustalenia optymalnej trasy dla pakietu
          nazywa się <strong>routowaniem</strong>, natomiast informacje na
          temat jakie sieci są osiągalne i przez jakie interfejsy znajduje się
          w <strong>tabeli routingu</strong>. W systemie, który nie jest
          jakmiś routerem, tabela routingu będzie zawierać prawdopodobnie
          tylko dwa wpisy. Na poniższym przykładzie widnieje zrzut tabeli
          routingu z mojego komputera.
        </p>
<pre class="code-block">
default via 192.168.8.1 dev enp0s31f6 onlink
192.168.8.0/24 dev enp0s31f6 proto kernel scope link src 192.168.8.154
</pre>
        <p>
          Pierwsza linia zawiera definicję <strong>bramy domyślnej</strong>,
          którą zajmiemy się za chwilę. Natomiast druga linia wskazuje jaka
          sieć jest osiągalna przez jaki interfejs w tym przypadku sieć
          <code class="code-inline">192.168.8.0/24</code> jest dostępną przez
          interfejs <code class="code-inline">enp0s31f6</code>. 
        </p>
        <p>
          W systemach, które łączą ze sobą sieci (routerach) wpisów
          w tabeli <em>routingu</em> takich jak druga linia może być znacznie
          więcej. Możemym sobie wówczas zadać pytanie na jakiej podstawie
          jądro wybiera właściwy port. Otóż jądro przy wyborze będzie bazować
          na dwóch czynnikach. Pierwszy z nich jest oczywisty i chodzi tu
          adres częsci sieciowej adresu IP, musi on pasować do adresu sieci
          inaczej ma się rzecz jeśli jedna z sieci jest na tyle duża, że
          obejmuje swoim zakresem także adresacje innej sieci. Tutaj wówczas
          pojawia się drugi czynnik, którym jest długość maski/części sieciowe.
          Czasami nazywanej także <strong>prefiksem</strong>. Jeśli przy
          którymś z wpisów adresy sieci zachodzą na siebie, to wówczas dłuższy
          prefiks (a co za tym idzie, mniejsza sieć) jest wybierana jako
          trasa dla pakietu.
        </p>
        <h3 id="9.2.3.defaultgateway">9.2.3. Brama domyślna</h3>
        <p>
          Omawiając tablę <em>routingu</em> wspomnieliśmy o bramie domyślnej.
          Brama domyślna jest rodzajem wpisu we wspomnianej tabeli a jej
          zadaniem jest przechowywanie domyślniej trasy, która wybierana jest
          jeśli żadna inna nie jest odpowiednia. Wynika to z faktu jak jądro
          wybiera właściwe dla pakietów trasy oraz adresu jaki kryje się za 
          słowem <code class="code-inline">default</code>  a jest nim
          <strong>0.0.0.0/0</strong>. Oznacza on wszystkie hosty w adresacji
          IPv4. Co daje najmniejszy możliwy prefiks, dlatego też jeśli komputer
          nie posiada właściwej dla pakietu trasy to jest ona przekzywana
          do adresu przez który taka sieć jest osiągalna.
        </p>
        <p>
          Tym adresem jest przeważnie adres <em>routera</em>, który łączy 
          sieć LAN z inną siecią np. siecią usługodawcy internetowego.
          Zwyczajowo takie urządzenia zwykło się nazywać <em>routerami</em>,
          mimo ich możliwość to najczęściej wykorzystywaną funkcjonalnością
          jest automatyczna konfiguracja hostów (protokół DHCP, będzie o nim
          w tym rozdziale), pamięć podręczna i przekazywanie zapytań systemu
          DNS (o systemie DNS, też będzie tutaj) oraz translacja adresów
          (o adresach prywatnych oraz translacji adresów też sobie wspomnimy)
          oraz przekazywanie pakietów dalej do jednego z routerów usługodawcy,
          więc równie dobrze urządzenia tego typu można nazwać bramkami.
        </p>
        <h2 id="9.3.ipv6">9.3. Adres IPv6</h2>
        <p>
          Adres IPv4 posiada długość 32 bitów, co daje nam możliwość
          zaadresowania 4,3 miliarda hostów w Internecie. Co jest o wiele
          mniejszym wynikem niż ilość ludzi na świecie, biorąc pod uwagę
          rozwój przedsiębiorstw oraz samego internetu wymaga od organizacji
          czuwających nad jego standaryzacją rozwiązań, które są w stanie
          sprostać wymaganiom czasów obecnych oraz przyszłości. Jedym z takich
          rozwiązań są prace na rozwojem oraz wdrożeniem nowego standardu
          jakim <strong>protokół IP w wersji 6</strong>.
        </p>
        <p>
          Adres IP w wersji 6, ma długość 128-bitów, co czyni go 4 razy
          dłuższym od adresu IPv4. Adres ten nie przypomina adresu z
          poprzedniej wersji. Zamiast cyfr dziesiętnych użytko cyfr systemu 
          heksadecymalnego, a kropki zastąponio dwukropkami. Poniżej znajduje
          się adres IPv6 komputera na którym pisze ten tekst.
        </p>
<pre class="code-block">
fe80::921b:eff:fe6a:717d/64
</pre>
        <p>
          Cyfry heksadecymalne są reprezentowane przez znaki: 0-9 oraz a-f.
          Każda grupa cyfr jest odzielona dwukropkiem, a każda z nich posiada
          po 4 znaki. Jeśli zero jest napoczątku grupy, to można je pominąć,
          jeszcze inną zależność jak możemy zauważyć jest to, jeśli grupa
          składa się z samych zero to można ją pominąć, wówczas w zapisie
          adresu widnieją dwa dwukropki obok siebie. Nie tyczy się to tylko
          jednej grupy, ale jeśli grupy zer następują po sobie to rownież
          można je pomniąć. Zapis natomiast nie ulegnie zmianie, jesli będzie
          więcej niż jedna grupa zer do pominięcia.
        </p>
        <p>
          Jak możemy zauważyć adresy IPv6 również możemy zapisać w notacji
          CIDR. Tutaj maska wynosi 64-bit, co oznacza ze połowa adresu zajmuje
          prefiks. Natomiast druga połowa jest już częścią hosta.
        </p>
        <p>
          Adresy IPv6 możemym podzielić na globalne, która mogą być osiągalne
          z internetu lub lokalne, które są przypisywane automatycznie przez
          systemy z obsługą IPv6. Każdy z tych typów posiada swój prefix i dla
          adresów globalnych (znanych także jako globalny adres hosta) prefix 
          wynosi <em>2000::/3</em>, przez co globalny adres hosta zaczyna się
          od 2 lub od 3 (ze zwględu na prefix, 3 pierwsze bity pierwszej cyfry
          są stałe (001), a zatem do dyspozycji mamym tylko jeden bit, którego
          zmiana nie dam nam innych wartości jak 2 lub 3). Pozostałe zera służa
          jako dopełnienie do zapisu. Z kolei prefiksem dla adresów lokalnych
          jest <em>fe80::/10</em>. W przypadku adresu łącza lokalnego resztę
          częsci sieciowej adresu wypełniają 54-bity zer. Na podstawie
          przedstawionych tutaj prefiksów możemy ustalić z jakiego rodzaju
          adresem mamy doczynienia.
        </p>
        <h3 id="9.3.1.showipv6">9.3.1. Wyświetletnie adresów IPv6</h3>
        <p>
          Do wyświetlenia adresów IPv6 może posłużyć nam to samo polecenie,
          z którego korzystaliśmy do wyświetlenia adres IP w wersji 4.
          Mianowicie polecenie <code class="code-inline">ip</code>, po za
          samymi podpoleceniami tego polecenia dla adresów IPv6 podaje się
          także opcję <strong>-6</strong>.
        </p>
<pre class="code-block">
$ ip -6 addr show
</pre>
        <p>
          Podobnie rzecz ma się adresami IP tras, tutaj wykorzystuje się
          tę samą opcją natomiast inne podpolecenia.
        </p>
<pre class="code-block">
$ ip -6 route show
</pre>
        <h2 id="9.4.basictoolkiticmpanddns">9.4. Podstawowe narzędzia ICMP oraz DNS</h2>
        <p>
          W tym podrozdziale omówimy sobie podstawowe narzędzia wykorzystywane
          przy połączeniach sieciowych. Służą one do ustalania
          adresów IP oraz sprawdzania dostępności hosta.
        </p>
        <h3 id="9.4.1.ping">9.4.1. Narzędzie ping</h3>
        <p>
          Protokół ICMP jest protokołem diagostycznym dla protokołu IP. Do jego
          podstawowych zadań należy sprawdzenie dostępności hosta w sieci. Do
          tego celu wykorzystujemy narzędzie <strong>ping</strong>. To
          niepozorne narzędzie wysyła specjalny pakiet z żądaniem odesłania
          pakietu z odpowiedzią. W przypadku tego narzędzia istotna jest
          sama odpowiedź ale poza nią zwracanych jest kilka statystyk, które
          pozwolają na przykład na określenie jakość połączenia oraz czasem
          stanu samej sieci (gdy odpowiedzi z bramy domyślnej przychodzą po
          ok. 1 sekundzie).
        </p>
<pre class="code-block">
xf0r3m@immudex:~$ ping wp.pl
PING wp.pl (212.77.98.9) 56(84) bytes of data.
64 bytes from www.wp.pl (212.77.98.9): icmp_seq=1 ttl=54 time=11.2 ms
64 bytes from www.wp.pl (212.77.98.9): icmp_seq=2 ttl=54 time=11.0 ms
64 bytes from www.wp.pl (212.77.98.9): icmp_seq=3 ttl=54 time=14.1 ms
^C
--- wp.pl ping statistics ---
3 packets transmitted, 3 received, 0% packet loss, time 2001ms
rtt min/avg/max/mdev = 11.049/12.096/14.062/1.391 ms
</pre>
        <p>
          Na 56-bajtowe żądanie <em>echa</em> wysłane z naszego komputera
          host docelowy odpowiada 64-bajtowym pakietem. Jego zawartość nie
          jest istotna. Dla nas ważne są pola 
          <code class="code-inline">icmp_seq</code> oraz
          <code class="code-inline">time</code>, gdyż swiadczą on one jakości
          połączenia pomiędzy naszym komputerem, a hostem docelowym. 
          <code class="code-inline">icmp_seq</code> wskazuje kolejności
          otrzymywanych odpowiedzi. Jeśli jakiegoś pakietu brakuje, oznacza to
          że został on zgubiony podczas transmisji. Zagubione pakiety
          zdarzają się gdy korzystamy z połączenia bezprzewodowego przy słabym
          zasięgu. Drugim ważnym polem jest czas wyrażony w kolumnie
          <code class="code-inline">time</code>. Czas poniżej 30 ms oznacza
          że mamy bardzo dobre połącznie z hostem. Czas w sieci lokalnej
          oscyluje poniżej 1 ms. Natomiast jeśli jest powyżej jednej sekundy
          (1000 ms) lub w jej granicach oznacza, że gdzieś w sieci może
          znajdować się problem. Polecenie <em>ping</em> w dystrybucjach
          Linuksa ale i ogólnie w implementacji Uniksowej działa do momentu,
          aż nie przerwiemy mu działania. Na sam koniec zostanie wyświetlona
          statystyka zawierająca informacje o tym ile pakietów zostało
          wysłanych ile zostało odebranych, jaki procent pakietów został
          utracony. W drugiej linii podsumowania znajduje się podstawowe
          statystki związane z odpowiedzia na żądania.
        </p>
        <p>
          Ze względów bezpieczeństwa nie wszystkie hosty (z właszcza w
          internecie są w stanie odpowiedzieć na żądania narzędzia 
          <em>ping</em>. Pakiety mogą zostać do nich wysłane, ale jest wielce
          prawdopodobne, że zostaną zablokowane po drodze. Takie zachowanie
          jest przecidziałaniem przeciwko atakowi odmowy usługi, który opiera
          się na przesłaniu wielu żądań (<em>echo request</em>, typ pakietu
          nazywa się właśnie w ten sposób), tak aby host nie był w stanie
          obsłużyć żadnego innego połączenia sieciowego.
        </p>
        <p>
          Istnieje możliwość wykorzystania pakietów <em>echo request</em> 
          zarówno z protokołu <em>IPv4</em> oraz <em>IPv6</em>. Wówczas należy
          wskazać to za pomocą opcji <em>-4</em> lub <em>-6</em> w poleceniu
          <em>ping</em>.
        </p>
        <h3 id="9.4.2.host">9.4.2. Narzędzie host</h3>
        <p>
          Narzędzie <strong>host</strong> jest najprostszym sposobem na
          skorzystanie z systemu DNS. 
        </p>
        <p>
          System DNS pozwala on zapamiętać ludziom typowy adres strony, bez
          potrzeby znajomości jej adresu IP, aby zrealizować to połączenie.
          Jeśli wpiszemy adres strony do przeglądarki, zapyta ona system DNS o
          jej adres IP i ten udzieli jej takiej odpowiedzi. Oczywiście w
          skrócie rzecz ujmując. Czasami możemy znaleźć się w odwrotnej
          sytuacji, kiedy będziemy znać adres IP, a chcielibyśmy się
          dowiedzieć do jakiej organizacji jest on przypisany. Jednak ta
          funkcjonalność nie jest kluczowa i rzadko bywa dobrze skonfigurowana,
          nie mniej jednak warto spróbować. 
        </p>
        <p>
          Aby skorzystać z narzędzia <em>host</em>, podajemy nazwę lub adres
          IP jako argument polecenia.
        </p>
<pre class="code-block">
xf0r3m@immudex:~$ host morketsmerke.org
morketsmerke.org has address 213.186.33.5
morketsmerke.org mail is handled by 10 mx3.mail.ovh.net.
morketsmerke.org mail is handled by 1 mx4.mail.ovh.net.

xf0r3m@immudex:~$ host 93.184.216.34
Host 34.216.184.93.in-addr.arpa. not found: 3(NXDOMAIN)

xf0r3m@immudex:~$ host 213.186.33.5
5.33.186.213.in-addr.arpa domain name pointer redirect.ovh.net.
</pre>
        <p>
          Na powyższym przykładzie widzimy trzy wywołania polecenia
          <code class="code-inline">host</code> jedno z nich klasyczne
          pytające o adres IP i dwa pytające o nazwę domenową, zwróćmy uwagę
          na to w jaki sposób zostały zapisane adresy IP. Nie będę tutaj
          przytaczać więcej informacji o sposobie działania systemu DNS, gdyż
          wykraczają one poza ramy tego materiału. Do systemu DNS wrócimy 
          podczas konfiguracji interfejsu hosta.
        </p>
        <h2 id="9.5.ethernet">9.5. Warstwa fizyczna</h2>
        <p>
          Wiemy, że sieć internetowa oparta jest o oprogramowanie. Nie miej
          jednak gdzieś zagadnienia sieciowe muszą stykać się ze swiatem
          realnym, z tym że komputery koniec, końców są ze sobą połączone
          za pomocą specjalnych przewodów oraz z lub bez pośrednictwa
          dodatkowych urządzeń. Tymi elementami zajmuje się warstwa
          fizyczna. Standardów implementacji warstwy fizycznej (tego w jaki
          sposób informacje przesyłane są przez media (przewody lub fale
          radiowe)) jest wiele, jednak wykorzystywaną po dzień dzisiejszy oraz
          najpowszechniejszą z nich jest <strong>Ethernet</strong>. Sprzęt
          sieciowy, mimo tej samej implementacji będzie różnić się od siebie
          ze względu na użyte medium transmisji, ale mają one wiele cech
          wspólnych. Oto kilka z nich:
        </p>
        <ul>
          <li>Element identyfikującym w sieciach <em>Ethernet</em> jest 
            adres sprzetowy znany także jako adres <strong>MAC</strong>. Adresy
            MAC są niezależne od adresów progrmowych i aby transmisja w sieci
            <em>Ethernet</em> doszła do skutku to musi on być unikatowy w
            obrębie sieci lokalnej (i zazwyczaj tak jest, w sieci lokalnej,
            jednak w sieciach rozległych, już może tak nie być. Obecnie
            <em>losowy</em> MAC adres interfejsu sieciowego może być stosowany
            aby podnieść poziom prywatności w sieciah publicznych
	          (ogólnodostępne sieci bezprzewodowe)). Adres sprzętowy składa się
            z 6 grup po 2 cyfry systemu heksadecymalnego oddzielonego
            dwukropkami. Całość ma łącznie 48-bitów.</li>
          <li>W sieciach Ethernet dane wysłane są w ramkach. Ramki są 
            opatrzone adresami MAC hostów biorących udział w wymianie
            danych</li>
        </ul>
        <p>
          Host mając nawet dwa interfejsy sieciowe podłączone do różnych
          sieci <em>Ethernet</em> nie może przekazać pakietu z jednej do
          drugiej sieci, chyba skonfigurowano na nim most. Więc jeśli dane
          mają zostać wysłane do internetu, potrzebny jest udział warstw
          wyższych, albowiem każda sieć fizyczna jest podsiecią sieci
          warstwy wyższej, zatem router może odebrać ramkę, wyodrębnić jej
          dane a następnie przepakować do nowej ramki i wysłać dalej
          w świat.
        </p>
        <h2 id="9.6.kernelnetworkinterfaces">9.6. Sieciowe interfejsy jądra</h2>
        <p>
          Jądro samodzielnie odróżnia warstwę fizyczną od sieciowej, przez co
          musi zapewniać im standard w komunikacji. Czymś takim właśnie jest
          <strong>interfejs sieciowy</strong>. W trakcie jego konfiguracji
          przypisane parametry warstwy internetowej są łączone z parametrami
          urządzenia. Nazwy interfejsów opierają się o rodzaj sprzętu na którym
          bazują. Np. <em>enp0s4</em>, oznacza zazwyczaj kartę sieciową
          podłączoną do magistrali PCI. Nazwy tego typu są określane
          nazwami przewidywalnymi i nie zmieniają się one ponownym uruchomieniu
          systemu. Jest to jednak prowadzone głównie program typu <em>init</em>
          - <em>systemd</em>. Aby wyświetlić interfejsy wydajemy polecenie:
        </p>
<pre class="code-block">
xf0r3m@immudex:~$ ip a
1: lo: &lt;LOOPBACK,UP,LOWER_UP&gt; mtu 65536 qdisc noqueue state UNKNOWN group default qlen 1000
    link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00
    inet 127.0.0.1/8 scope host lo
       valid_lft forever preferred_lft forever
    inet6 ::1/128 scope host
       valid_lft forever preferred_lft forever
2: enp4s0: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1500 qdisc mq state UP group default qlen 1000
    link/ether 90:1b:0e:6a:71:7d brd ff:ff:ff:ff:ff:ff
    inet 172.16.1.2/16 brd 172.16.255.255 scope global enp4s0
       valid_lft forever preferred_lft forever
    inet6 fe80::921b:eff:fe6a:717d/64 scope link
       valid_lft forever preferred_lft forever
3: enp0s25: &lt;BROADCAST,MULTICAST&gt; mtu 1500 qdisc noop state DOWN group default qlen 1000
    link/ether 90:1b:0e:87:3c:43 brd ff:ff:ff:ff:ff:ff
</pre>
      <p>
        Polecenie <code class="code-inline">ip a</code>, jest poleceniem
        skrótowym dla polecenia <em>ip address show</em>.
        Interfejsy sieciowe są numerowane kolejno do numeru 2, numer 1
        zarezerowany jest dla specjalnego interfejsu systemowego - zwanego
        pętlą zwrotną. Każdy działający interfejs w linii z numerem oraz
        nazwą posiada flagę <code class="code-inline">UP</code>. Poza
        informacjami warstwy sieciowej możmy również zauważyć informacje z
        warstwy fizycznej takie jak adres MAC. Polecenie
        <code class="code-inline">ip a</code>, głównie skupia się na warstwie
        sieciowej. Jeśli chcielibyś poznać więcej szczegółów związanych z
        warstwą fizyczną, wówczas należało by użyć polecenia takiego jak
        <strong>ethtool</strong>.
      </p>
      <h2 id="9.7.interfaceconfig">9.7. Konfiguracja interfejsu sieciowego</h2>
      <p>
        Do tej pory omawialiśmy kwestie sieciowe wyłącznie teoretycznie, a to
        przeanalizowaliśmy sobie wynik jednego czy drugiego polecenia, ale
        teraz zajmiemy konfiguracją interfejsu sieciowego. Aby użytkownik
        dowolnej dystrybucji mógł połączyć się z internetem musimy wykonać
        cztery poniższe czynności:
      </p>
      <ol>
        <li>Zapewnienie obecności sterownika karty sieciowej w jądrze. Jeśli
          sterownika będzie brakować, to nawet nieskonfigurowany interfejs
          nie zostanie wyświetlony po wydaniu polecenia <em>ip a</em>.</li>
        <li>Dodatkowa konfiguracja warstwy fizycznej, na przykład poprzez
          podanie nazwy sieci oraz hasła (głównie sieci bezprzewodowe).</li>
        <li>Ustawienie dla interfejsu adresu IP oraz maski podsieci (dzięki
          temu warstwy będą mogły się ze sobą komunikować).</li>
        <li>Ustawienie wszystkich wymaganych tras w tym trasy domyślnej.</li>
      </ol>
      <p>
        Wiedząc teraz co musimy zrobić. Przejdziemy do wykonania tych
        czynności w systemie.
      </p>
      <h3 id="9.7.1.manualifconf">9.7.1. Ręczna konfiguracja interfejsu</h3>
      <p>
        Reczna konfiguracja interfejsów sieciowych rzadko jest wymagana, chyba
        eksperymentujemy z systemem lub próbujemy skonfigurować urządzenie,
        które samo nam interfejsu nie skonfiguruje. Nie mniej jednak, a
        własnego doświadczenia wiem, że warto posiadać taką wiedzę. Więc tak
        załóżmy, że posiadamy sterowniki do karty sieciowej (interfejsu), którą
        chcemy skonfigurować oraz łączymy się z siecią <em>Ethernet</em> za 
        pomocą kabla miedzianego, dlatego też punkt nr. 2 też możemy pominąć.
        Jeśli tak rzeczywiście jest to wówczas konfiguracja interfejsu 
        sprowadza się do dwóch poleceń.
      </p>
      <p>
        Aby skonfigurować ręcznie interfejs musimy musimy użyć polecenia
        <strong>ip</strong> wraz z podpoleceniem <strong>address</strong> lub
        <em>addr</em>, następnie podać komendę <em>add</em> po niej adres IP
        wraz z maską w notacji CIDR do tego opcję <em>dev</em> po której
        należy wskazać nazwę interfejsu jaki chcemy skonfigurować.
      </p>
<pre class="code-block">
xf0r3m@immudex:~$ sudo ip address add 172.16.1.1/16 dev enp4s0
</pre>
      <p>
        Wykorzystując powyższe polecenie mamy pierwszą część za sobą.
        Pamiętajmy jednak aby zmienić dane.
      </p>
      <p>
        Drugą czynnością jest dodanie tras. Do połączenia z internetem
        potrzebna będzie na pewno brama domyślna. Jeśli będziemy potrzebować
        dodatkowych tras wystarczy zmodyfikować poniższe polecenie: 
      </p>
<pre class="code-block">
xf0r3m@immudex:~$ sudo ip route add default via 172.16.0.1 dev enp4s0
</pre>
      <p>
        Za trasy odpowiada podpolecenie <code class="code-inline">route</code>,
        komenda <code class="code-inline">add</code> odpowiada za dodawanie
        tras. Następnie podawana jest sieć jaka ma być osiągalna. Po opcji
        <code class="code-inline">via</code> podawny jest adres IP na jaki
        mają być kierowane pakiety do docelowej sieci, tym adresem może być
        adres routera sieci lokalnej lub nawet jeden z interfejsów
        zainstalowanych na tym samym komputerze, na koniec po opcji
        <code class="code-inline">dev</code> podajemy interfejs, przez który
        adres IP podany po opcji <code class="code-inline">via</code> jest
        osiągalny.
      </p>
      <p>
        Jeśli trasa jest nam nie potrzebna lub pomyliliśmy się podczas jej
        dodawnia, to taką trasę bez obaw można usunać, przy użyciu komendy
        <em>del</em> podpolecenia <em>route</em>. Komenda przyjmuje adres
        sieci jako argument.
      </p>
<pre class="code-block">
xf0r3m@immudex:~$ sudo ip route del 192.168.60.0/24
</pre>
      <h3 id="9.8.networkifacebootconfig">9.8. Konfiguracja interfejsów sieciowych podczas rozruchu</h3>
      <p>
        Próba konfiguracji interfejsu podczas rozruchu mogła by wyglądać w 
        taki sposób, że gdzieś podczas sekwencji rozruchowej program typu
        <em>init</em> (lub jeden z jego skryptów) mógłby wydać polecenia
        <em>ip</em> (takie jak te, które wkorzystywaliśmy do ręcznej 
        konfiguracji) lub
        innego narzędzia. Pytanie tylko jakiego? A odpowiedzi tyle co
        wiodących dystrybucji.
      </p>
      <p>
        Do tej pory próbowano ustandaryzować ten proces za pomocą poleceń
        <em>ifup</em> oraz <em>ifdown</em>. Z niezbyt zadawalającym skutkiem
        ze względu na różne implementacje tych narzędzi przez osoby
        zajmujące się rozwojem dystrybucji, czego następstwem są różnice w
        plikach konfiguracyjnych. Kolejną problematyczną rzeczą jest fakt
        iż wiele elementów sieciowych wykorzystywanych do konfiguracji
        znajduje się różnych miescach w systemie i odpowiadają za nie inne
        komponenty. W Linuksie panuje również zasada aby nie rozpowszechniać
        plików konfiguracyjnych w przypadku wielu osobnych narzędzi czy
        bibliotek, ponieważ zmiany wprowadzone w jednym narzędziu mogą
        spowodować, że inne przestaną działać.
      </p>
      <p>
        Więc tak chcąc skonfigurować interfejsy sieciowe podczas rozruchu
        musimy skorzystać z jednego z dostępnych managerów lub dostępnego w
        systemie kompnentu. W Debianie, interfejsy sieciowe są zarządzane
        przez dodatek <strong>ifupdown</strong>, którego składową jest plik
        <em>/etc/network/interfaces</em>. Na Ubuntu system <em>Netplan</em>,
        od najnowszysch wersji dystrybucji opartych o Red Hat, korzysta się
        głównie z managerów. Natomiast managerem godnym uwagi jest
        <strong>NetworkManager</strong> i to na nim się skupimy podczas ich
        omawiania. Aby ten podrozdział wniósł coś pożytecznego poza kilkoma
        teoretycznymi dywagacjami omówimy sobie konfigurację interfejsów na
        przykładzie dystrybucji Debian.
      </p>
<pre class="code-block">
source /etc/network/interfaces.d/*

# The loopback network interface
auto lo
iface lo inet loopback

# The primary network interface
auto enp4s0
iface enp4s0 inet static
        address 172.16.1.2
        netmask 255.255.0.0
        gateway 172.16.0.1
        dns-nameservers 172.16.0.1
</pre>
      <p>
        Na powyższym przykładzie mamy dwie deklaracje interfejsów sieciowych.
        Pierwszym z nich jest interfejs pętli zwrotnej. Jego rola w systemie
        jeszcze zostanie omówiona. Nie miej jednak jego deklaracja zawiera
        słowo <code class="code-inline">auto</code>, która powoduje załączenie
        interfejsu podczas startu systemu. Po linii ze słowem auto następuje
        definicja interfejsu (linia ze słowem
        <code class="code-inline">iface</code>) w niej podawana jest nazwa
        interfejsu (<code class="code-inline">enp4s0</code>), stos protokółów
        (<code class="code-inline">inet</code>, co oznacza IPv4. Mogą być też
        inne). Następnie podawana jest metoda konfiguracji interfejsu.
        Najczęściej wykorzystywanymi są <code class="code-inline">static</code>
        oraz <em>dhcp</em>, w przypadku pętli zwrotnej w tym miejscu
        używane jest słowo <code class="code-inline">loopback</code>. W
        przypadku drugiego (właściwego) interfejsu adres przypisywany będzie
        statycznie. To tak samo jakbyśmy przypisywali go ręcznie, jest to
        czynność automatyczna wykonywana podczas rozruchu. Po uruchomieniu
        ponownym komputera interfejs powinien zostać automatycznie podniesiony
        (załączony) i skonfigurowany przy użyciu podanych w pliku parametrów. 
      </p>
      <p>
        Obecnie systemy służą użytkownikom końcowym, którzy zapewne mają
        uprawnienia administratora, ale nie posiadają odpowiedniej wiedzy aby
        móc konfigurować odpowiednie warstwy. Proste rozwiązania, takie jak
        to opisane powyżej daje oczywiście taką mozliwośc, jednak nie jest
        ono zbyt przystępne dla użytkownika, dlatego też w dystrybucjach takich
        Red Hat, stosowane są managery, których zadaniem jest ułatwienie
        konfiguracji.
      </p>
      <h2 id="9.9.networkconfigmanagers">9.9. Menedżery konfiguracji sieciowe</h2>
      <p>
        Dla dystrybucji Linuksa dostępnych jest wiele programów będących
        menedżerami konfiguracji sieciowe. Część z nich przeznaczona jest  na
        systemy wbudowane. Dlatego godnymi uwagi pozostają tylko dwa. Jeden
        będący częścią programu typu <em>init</em> <strong>systemd-networkd</strong>
        nadaje się on wykonania podstawowej konfiguracji sieciowej. Jest
        wystarczający dla serwerów, ale nie dla użytkonika końcowego. Wówczas
        pozostaje jeden - <strong>NetworkManager</strong> i to na nim się
        skupimy. 
      </p>
      <p>
        <strong>NetworkManager</strong> jest demonem takim samym jak pozostałe
        więc jego zadaniem jest nasłuchiwanie zdarzeń generowanych zarówno
        przez system jak i przez samych użytkowników, dodatkowo 
        <em>NetworkManager</em> zajmuje się konfiguracją sieciową zgodnie z
        założonymi regułami. Program ten operuje na informacjach
        o dostępnych urządzenia uzyskanch od jądra oraz na 
        <strong>połączeniach</strong>, które są wskazaniem konkretnych urządzeń
        wraz z parametrami warstw sieciowych. Konfigurując sieć w danej
        dystrybucji, <em>NetworkManager</em> korzysta z określonego dodatku
        aby dostosować konfigurację do standardu używanego przez dystrybucję,
        nie narzucacjąc przy tym swoich rozwiązań.
      </p>
      <p>
        W momencie uruchomienia <em>NetworkManager</em>, zbiera informacje o
        dostępnych urządzeniach sieciowych, sprawdza listę połączeń i
        podejmuje decyzję o próbie połączenia. Proces decyzyjny na podstawie,
        którego menedżer decyduje, z którą z sieci chce się połączyć można
        rozpisać w trzech krokach.
      </p>
      <ol>
        <li>Jeśli dostępne jest połaczenie kablowe. To ono jest preferowane
          jako pierwsze.</li>
        <li>Jeśli połączenie kablowe nie jest dostępne, wówczas jeśli w
          systemie dostępny jest interfejs bezprzewodowy to skanowane jest
          otoczenie podzwględem występowania sieci bezprzewodowych. Jesli
          dostępne są sieci, z którymi system już kiedyś nawiązał połączenia.
          To jest ono nawiązywane ponownie. Jeśli nie to dostępna jest lista
          sieci bezprzewodowych osiągalnych na danym terenie.</li>
        <li>Jeśli dostępne są więcej niż dwie sieci, z którymi już wcześniej
          nawiązywano połączenie to wówczas wybierana jest,
          z którą łączono się jako z <em>ostatnią</em>.</li>
      </ol>
      <p>
        Połączenie sieciowe zwłaszacza wśród sieci bezprzewodowych utrzymywane
        jest do momentu uzyskanie połączenia o lepszych parametrach. Na
        przykład, po przez wpięcie kabla.
      </p>
      <h3 id="9.9.1.interactionwithnm">9.9.1. Interakcja z Network Manager</h3>
      <p>
        Kontrolować <em>NetworkManager</em> możemy za pomocą apletu,
        przygotowanego dla środowiska graficznego. Jednak w tym materiale
        skupiamy się wyłącznie na rozwiązaniach opartych o wiersz polecenia.
        Więc przejdziemy od razu do tego typu interakcji z tym narzędziem.
        Do kontrolowania <em>NetworkManager</em> z poziomu powłoki, służy
        narzędzie <em>nmcli</em>. Za pomocą podpoleceń tego narzędzia możemy
        kontrolować połączenia sieciowe zarządzane przez omawiany menedżer.
      </p>
      <p>
        Innym narzędziem związanym z <em>NetworkManager</em>-em, jest polecenie
        <strong>nm-online</strong>, które zwraca jedynie infomacje w zależności
        od tego czy posiadamy aktywne połączenie czy też nie.
      </p>
      <p>
        Poniżej znajduje się przykładowe uruchomienie, <em>nmcli</em> bez
        żadnych podpoleceń. 
      </p>
<pre class="code-block">
</pre>
      <p>
        Polecenie to agreguje informacje zwracane przez wiele poznanych do
        tej pory poleceń, takich jak <em>ip addr</em> lub <em>ip route show</em>.
        Dodatkowo wyświetlane są informacje o konfiguracji systemu DNS. 
      </p>
      <p>
        Dla przykładu możemy utworzyć ręczną konfigurację dla interfejsu tym
        razem wykorzystując do tego <em>NetworkManager</em>.
      <p>
<pre class="code-block">
xf0r3m@immudex:~$ sudo nmcli con add con-name my-connection ifname enp4s0 \
type ethernet ipv4 192.168.8.150/24 gw4 192.168.8.1
</pre>
      <p>
        Efekt działania tego polecenia możemy sprawdzić za pomocą polecenia
        <em>ip a</em> lub za pomocą <em>nmcli</em> 
      </p>
<pre class="code-block">
xf0r3m@immudex:~$ ip a

xf0r3m@immudex:~$ nmcli -p con show my-connection
</pre>
      <p>
        Opcja <code class="code-inline">-p</code> formatuje wynik polecenia,
        aby był on bardziej czytelny dla człowieka. Więcej przykładowych
        poleceń wraz z opisami znajduje się na stronie podręcznika:
        <em>man 7 nmcli-examples</em>. <em>NetworkManager</em> to naprawdę
        rozbudowane narzędzie więc warto mieć z tyłu głowy to polecenie,
        chociażby dlatego, że znajduje się tam opis sposobu łączność z siecią
        bezprzewodową z poziomu wiersza poleceń. Sposób dużo bardziej
        przystępny niż samodzielne skanowanie i obcowanie z pakietem
        <em>wpa_supplicant</em>, gdzie często demon tego narzędzia może być
        już użwany przez jeden z komponentów systemu.
      </p>
      <h3 id="9.9.2.nmconfiguration">9.9.2. Konfiguracja NetworkManager</h3>
      <p>
        Konfiguracja <em>NetworkManagera</em> wymaga edycji pliku
        <em>/etc/NetworkManager/NetworkManager.conf</em>. Plik jest formatu
        <em>XDG</em> lub wśród osób zaznajomionych z systemami od Microsoftu
        formatu <em>.ini</em>. Rzadko będzie potrzeba zmiany czego kolwiek w
        tym pliku. Nie mniej jednak jest jedna funkcją warta omówienia związana
        z konfiguracją tego menedżera - <strong>wyłączenie zarządania interfejsu</strong>
        przez <em>NetworkManager</em>. Interfejs pętli zwrotnej jest izolowany
        od tego narzędzia i jeśli uznamy, że inny/inne interfejsy w systemie
        też powinny to możemy zadeklarować w tym pliku. W sekcji
        <em>[keyfile]</em> (jeśli nie ma takowej, to należy dopisać). Plik
        ma format <em>XDG</em>, więc opcje zapisywane są w postaci 
        <em>klucz=wartość</em>. Tak więc do klucza <em>unmanaged-devices</em>
        przypisujemy adres MAC interfejsów, które mają być wyłączone z spod 
        zarządzania przez <em>NetworkManager</em> w taki sposób jak przedstawio
        to poniżej.
<pre class="code-block">
...
[keyfile]
unmanaged-devices=mac:08:00:27:3d:1b:9c
</pre>
      </p>
      <p>
        Inną kwestią związaną z konfiguracją omawianego w tym rodziale
        menedżera jest propagacja informacji o zmianie status interfejsu
        sieciowego. Niektóre demony do swojego poprawnego działania muszą
        otrzymać takową informację o tego typu sytuacji, aby zakończyć lub
        rozpocząć nasłuchiwanie na danym interfejsie. <em>NetworkManager</em>
        realizuje to za pomoca <strong>sieciowych skrytów sterujących</strong>
        znajdujących się w katalogu <em>/etc/NetworkManager/dispatcher.d</em>.
        Jeśli status interfejsu sieciowego ulegnie zmianie menedżer uruchomi
        wszystko co zostało umieszczone w powyższym katalogu z odpowiednim
        dla stanu interfejsu (<em>up</em> lub <em>down</em>). Na przykład
        w dystrybucjach opartych na Debianie (w tym i Ubuntu) istnieje plik
        <em>01-ifupdown</em>, który na podstawie otrzymanego komunikatu
        zdrzenia (jeśli przyjrzeć się plikowi, to dowiemy się że to nie tylko
        <em>up</em> oraz <em>down</em>) uruchomi wszystko znajduje się w
        odpowiednich podkatalogach w katalogu <em>/etc/network</em>.
      <p>
      <p>
        Dla nas zarówno konfiguracja <em>NetworkManager</em> może być mało
        istotna, podobnie jest ze skryptami rozsyłającymi. Nie mniej jednak
        może się kiedyś zdarzyć, że będzię potrzeba zmiany czegoś w skrypcie
        tego typu lub wyłączenie interfejsu z menedżera.
      </p>
      <h2 id="9.10.nameresolution">9.10. Rozwiazywanie nazw hostów.</h2>
      <p>
        Jeśli chcemy nawiązać jakie kolwiek połączenie sieciowe musimy podać
        adres komputera, z którym chcemy to połączenie nawiązać. Ludzie
        rzadko posługują się adresami IP, chyba że są to specjaliści lub 
        entuzajści nauk komputerowych i pracują oni w lokalnych środowiskach.
        Takie adresy trudno zapamiętąć, więc niezbędne jest zapewnienie
        systemu/usługi, która zmieni adresu domenowe 
        (np. <em>morketsmerke.org</em>) na adres IP. Z systemem DNS mieliśmy
        już
        styczność, w momencie gdy omawialiśmy protokół ICMP. Konfiguracja
        adresów systemu DNS jest tak naprawdę czwartą ostatnią wartością
        konfigurowaną na interfejsie sieciowym, aby mógł on nawiązać
        połączenie z internetem. Jest to o tyle ciekawe, że system DNS należy
        do warstwy aplikacji. Większość aplikacji sieciowych w Linuksie ma
        możliwość odpytania systemu DNS o adres IP, dlatego możemy zarówno
        użyć adresów IP lub nazw domenowych (chyba, że wyszczególniono inaczej). 
        Uzyskiwania takiego adresu od DNS zwykle przebiega w następujący sposób:
      </p>
       <ol>
          <li>Przy uzyciu systemowej biblioteki współużytkowanej aplikacja
            wywołuje funkcję wyszukiwania adresu IP.</li>
          <li>Określa się kolejność odpytywania źródeł na podstawie danych 
            zapisanych w pliku <em>/etc/nsswitch.conf</em>. Jedną z takowych
            reguł może być wymuszenie kolejności odpytania na początku pliku
            <em>/etc/hosts</em> jeszcze przed odpytaniem systemu DNS.</li>
          <li>Jeśli funkcja jednak zdecyduje o skorzystaniu z systemu DNS, musi
            użyć zawartości pliku konfiguracyjnego, w którym zawarte są adres
            serwerów systemu DNS.</li>
          <li>Funkcja wysyła zapytanie z adresem domenowym serwera, prosząc o
            jego adres IP.</li>
          <li>Serwer DNS odsyła do funkcji adres IP serwera, który zwracany
            jest do aplikacji.</li>
       </ol>
        <p>
          Często występującym scenariuszem jest to, że serwer systemu DNS nie
          zna adresu IP serwera, o który prosimy, wówczas serwer, do którego
          skierowaliśmy to zapytanie musi zapytać się innych serwerów.
          DNS ma budowę hierarchiczną, a cała hierarchia jest zapisana w 
          adresie domenowym. Szerszy opis systemu DNS wykracza poza ramy
          meryteoryczne tego materiału. 
        </p>
        <h3 id="9.10.1.dnsfiles">9.10.1. Pliki biorące udział w działaniu systemu DNS</h3>
        <p>
          Jak możemy wywnioskować z wyżej wymienionych czynności system DNS
          nawet w roli klienta potrzebuje korzysta z dużej ilości plików.
          Pierwszym z nich jest <strong>/etc/nssswitch.conf</strong>. Ten plik
          nie jest związany <em>stricte</em> z systemem DNS, ale ze wszystkim
          co jest związane z nazwami w systemie. Jest to klasyczny interfejs
          określający pierwszeństwo w źródłach rozwiązywania nazw. Jeśli
          przeanalizujemy sobie zawartość tego pliku, możemy zauważyć
          skąd i na jakiej podstawie, niektóre z narzędzi czerpią wiedzę
          taką jak 
          informacje o użytkownikach, usługach czy innych rodzajach sieci niż
          IP. Jednak na tym etapie interesuje nas wyłącznie linia
          rozpoczynająca się od <em>hosts</em>. Wskazuje ona pierwszeństwo
          pliku /etc/hosts nad system DNS, przez co korzystając z dystrybucji
          możemy dowolnie manipulować rozwiązywaniem nazw. Jest to szczególnie
          przydane podczas administracji i testowania usług, które później
          będziemy chcieli użyć.
        </p>
        <p>
          Kolejnym plikiem jest wspomaniany już wcześniej <em>/etc/hosts</em>.
          Plik ten zawiera zestawienie adresów IP wraz z nazwami domenowymi.
          Kiedyś kiedy hosty w internecie można było policzyć na palcach obu
          rąk służył za centralną bazę danych odnosnie odwzrowania nazw. Był
          on swojego czasu protoplastą systemu DNS. Jednak ze względu na
          <em>bum</em> rozwoju internetu, zaprzestano korzystania z tej
          praktyki. Jednak obecnie wciąż można spotkać go w roli lokalnej bazy
          rekordów DNS w sieciach, gdzie centralnym urządzeniem (router/bramka
          core'owy) jest urządzenie oparte na jakimś uniksie.
        </p>
        <p>
          Ostatnim plikiem jest <em>/etc/resolv.conf</em>. Zawartość tego 
          pliku, ma
          wpływ na to z jakiego źródła systemu DNS korzysta nasz system. Otóż
          w tym pliku przechowywane są zazwyczaj dwie wartości pierwszą z nich
          są adresy serwerów systemu DNS, a drugim sufiks nazwy domenowej
          wykorzystywany wtedy gdy podamy samą nazwę hosta bez nazwy domeny,
          to znaczy jeśli na przykład podamy samo <em>www</em> zamiast
          <em>www.morketsmerke.org</em>, wówczas funkcja na podstawie sufiksu
          z tego pliku sama go doda i przekaże żądanie dalej na 
          jeden z adresów widniejących po opcji <em>nameserver</em>.
        </p>
        <h3 id="9.10.2.configlessdnsandcache">9.10.2. Buforowanie oraz bezkonfiguracyjne systemy DNS</h3>
        <p>
          Buforowanie to czyność, którą głównie się kocha a czasem nienawidzi.
          Buforowanie odpowiedzi systemu DNS jest odpowiedzią na fakt, że
          komputery odpytujące system DNS nie przechowywały nigdzie uzyskanych
          od
          serwera odpowiedzi, zbyt często powtarazna tego typu czynność mogła
          przytkać sieć. Obecnie bardzo często adres serwera DNS jest również
          adres bramy. Ma to głównie na celu właśnie buforowanie, na naszym
          domowym routerze za pewne uruchomiony jest demon 
          buforująco-przekazujący. Niestety w
          przypadku wielu urządzeń nie będzie my się wstanie tego dowiedzieć.
          Ale jeśli nasz sprzęt jest zmodyfikowany, lub naszym routerem jest
          jest oprogramowanie zainstalowane na komputerze z wieloma kartami
          sieciowymi, to raczej na 100% tak będzie. Innym sposóbem na
          <em>wykrycie</em> systemu buforującego, jest sprawdzenie zawartości
          pliku <em>/etc/resolv.conf</em>. Jeśli widnieje tam tylko jeden
          wpis <em>nameserver</em> to za pewne z adresem <em>127.0.0.53</em>.
          Jest to adres z klasy <em>pętli zwrotnej</em> (o której będzie za
          chwilę), czyli wiemy, że to usługa uruchomiona lokalnie na tej
          maszynie. Jest to jeden z demonów programu typu <em>init</em>
          (<em>systemd</em>) - <strong>systemd-resolved</strong>. Często w tym
          wypadku sam plik jest dowiązaniem symboliczym. Użycie tego rodzaju
          systemu rozwiązuje inny problem związany z brakiem elastyczności
          statycznych konfiguracji, wówczas nie ma potrzeby wprowdzania zmian
          w komponentach systemu.
        </p>
        <p>
          Wspomniany wcześniej demon posiada jedną ważną cechę. Potrafi łączyć
          wiele sposobów wyszukiwania nazw w sieci, co przekłada się na
          możliwość użycia bezkonfiguracyjnych systemów DNS. W przypadku takiej
          konfiguracji jeśli podłączymy nowe urządzenie do sieci będziemy
          mogli wywołać je za pomocą nazwy. Jeśli host istnieje udzieli
          odpowiedzi ze swoim adresem IP. Rozwiązaniami tego typu są 
          <strong>mDNS</strong> (<em>multicastDNS</em>) oraz 
          <strong>LLMNP</strong> (<em>Link-Local Multicast Name Protocol</em>).
          Rozwiązania te poza zwykłym odwzorowaniem nazw, mogą przedstawiać
          dostępność usług. Ich dostępność w systemie możemy sprawdzić za
          pomocą polecenia <em>resolvectl status</em>, warto jednak pamiętać,
          że jego działanie jest uzależnione od działania wcześniej 
          wspomnianego demona.
        </p>
        <h2 id="9.11.localhost">9.11. Host lokalny</h2>
        <p>
          W wielu systemach operacyjnych, poznając ich możliwości sieciowe
          możemy natknąć się na dośc specyficzny interfejs, który w uniksach
          określany jako <strong>lo</strong>. Jest to jedyny interfejs, który
          będzie posiadać w plikach konfiguracyjnych statyczną konfigurację.
          Interfejs <strong>pętli zwrotnej</strong> bo tak jest określany
          przez swój sposób działnia służy głównie interakcji z programami
          sieciowymi bez potrzeby angażowania innych interfejsów. Na przykład
          jeśli aplikacja jest w fazie testów i póki co nikt po za naszym
          komputerem nie powinien się z nią łączyć. To wtedy taką aplikację
          ustawia się tak aby oczekiwała na połączenia na interfejsie pętli
          zwrotnej. Wówczas pakiety będą przesyłane przez ten interfejs w obu
          kierunkach i opuszczając tym samym jednej fizycznej maszyny. Można
          powiedzieć również że adres pętli zwrotnej to połączenie z
          <em>samym sobą</em>.
        </p>
        <p>
          Jeśli wyświetlimy sobie konfigurację interfejsu pętli zwrotnej to 
          zwrócimy uwagę na to, jaki adres został mu przypisany:
        </p>
<pre class="code-block">
xf0r3m@immudex:~$ ip addr show lo
1: lo: &lt;LOOPBACK,UP&gt; mtu 1500 group default qlen 1
    link/loopback 00:00:00:00:00:00
    inet 127.0.0.1/8 brd 127.255.255.255 scope global dynamic
       valid_lft forever preferred_lft forever
    inet6 ::1/128 scope host dynamic
       valid_lft forever preferred_lft forever
</pre>
        <p>
          Jest to bardzo duża klasa adresowa. Jeśli przypisany do usługi adres
          będzie rozpoczynął się od 127 i posiadał 8 bitową maskę, będzie
          wówczas przypisany do pętli zwrotnej.
        </p>
        <h2 id="9.12.transportlayer">9.12. Warstwa transportowa oraz usługi</h2>
        <p>
          Przedostatnią warstwą modelu TCP/IP jest warstwa transportowa.
          Jak sobie wcześniej omówilismy definiuje ona sposób transmisji w
          sieciach IP. Wewnątrz niej możemy znajdują się takie protokoły
          jak <strong>TCP</strong> oraz <strong>UDP</strong>, ona także
          definiuje pojęcie <strong>portu</strong>.
        </p>
        <h3 id="9.12.1.tcp">9.12.1. TCP - Transmission Control Protocol</h3>
        <p>
          TCP jest protokołem przepływu danych w sieciach IP. Jest to protokół,
          który przed właściwą transmisją danych zestawia coś w rodzaju
          <em>połączenia</em>. Za pomocą specjalnych pakietów kontrolnych 
          strona odległa
          informowana jest o nadchodzącej transmisji, i jeśli faktycznie jest
          ona w stanie odebrać dane (port na który, strona lokalna chce wysłać
          informacje jest otwarty) odsyła informacje zwrotną o tym, że może
          wysyłać. Wówczas po wymianie pakietów kontrolnych, dochodzi do
          wysłania danych z komputera lokalnego do komputera zdalnego. Protokół
          TCP czuwa nad przebiegiem transmisji, każdy pakiet ma swój numer i
          strona
          zdalna po jego otrzymaniu wysyła pakiet kontrolny z potwierdzeniem
          jeśli odpowiedź nie przychodzi w określonym czasie wówczas dochodzi
          do retransmisji zagubionych pakietów. TCP jest protokołem
          wolniejszym od innego protokołu z tej samej warstwy, zapewnia jednak
          niezawdność transmisji, przez co strona odległa może mieć pewność, że
          uzyska poprawne dane. Ten protokół wykorzystywany jest w wiekszości
          usług w internecie, w których przenoszone przez jego łącza dane mają
          znaczenie użytkowników końcowych. Dane są po prostu istotne.
        </p>
        <h3 id="9.12.2.udp">9.12.2. UDP - User Datagram Protocol</h3>
        <p>
          UDP jest trochę innym protokołem niż TCP, ale jego główna rola jest
          bardzo podobna, z tą różnicą, że nie zawiera on żadnych mechanizmów
          kontroli. Ma to swoje plusy i minusy. Protokół jest na tyle szybki,
          że wykorzystywany jest przez różnego rodzaju aplikacji służące do
          przesyłania strumieniowego. W tym wypadku możemy osobiście
          doświadczyć błędów w transmisji objawiających się spadkiem jakość
          <em>streamowanych</em> materiałów. Inną ważnym wykorzystaniem tego,
          protokołu, właśnie ze względu na <em>zalety</em> protokołu TCP jest
          użycie UDP do budowania sieci prywatnych VPN. Faktem, dla którego
          nie korzysta się protokołu TCP jest <em>piekło</em> retransmisji.
          Załóżmy, że dochodzi do błedów w zewnętrznej
          transmisji, czyli między serwerami VPN i jeśli byłaby to transmisja
          TCP doszło by do retransmisji, system VPN będzie musiał zatrzymać się
          wówczas host docelowy transmisji wewnętrznej zauważy zagubienie 
          pakietu i rozpocznie swoją retransmisję
          co doprowadzi do zapchania łącza i wstrzymania trasnsmisji
          w ogóle. Dlatego też stosuje się protokół UDP dla transmisji
          zewnętrznej, wówczas nad poprawnością danych przenoszonych przez
          tunel VPN czuwać będą hosty transmisji wewnętrznej. Jak możemy 
          zauważyć wszystko co może być zaletą w konkretnym przypadku może 
          okazać się wadą w innym.
        </p>
        <h3 id="9.12.3.ports">9.12.3. Porty</h3>
        <p>
          Z wyżej wymienionych metod
          transmisji przy uzyciu portów korzystają różne aplikacje. 
          <strong>Port</strong> to
          nic innego jak numer wystąpienia aplikacji w obszarze warstwy
          transportowej. Na ten numer kierowane są pakiety i w ten sposób 
          aplikacja otrzymuje dane z sieci. Aplikacje sieciowe posidaja
          przypisane te numery przez swoich twórców, ich lista wstępuje
          w każdym uniksie, który ma możliwośc podłaczenia do sieci. Lista
          znajduje się w pliku, <em>/etc/services</em>. Większość zebranych
          tam aplikacja powstawa wraz z internetem, więc lista może być długa
          i już nie zbyt aktualna, ale jednak jest pewnym zbiorem informacji.
          Poniżej znajduje się kilka protokołów wraz z informacją z której
          pochodzi źródło.
        </p>
<pre class="code-block">
# Updated from https://www.iana.org/assignments/service-names-port-numbers/service-names-port-numbers.xhtml .
http            80/tcp          www             # WorldWideWeb HTTP
https           443/tcp                         # http protocol over TLS/SSL
https           443/udp                         # HTTP/3
http-alt        8080/tcp        webcache        # WWW caching service
</pre>
        <p>
          Obok portu wyświetlony jest również rodzaj transmisji. Ciekawostką
          jest fakt, że trzecia generacja protokołu HTTPS będzie oparta na
          protokole UDP, a nie TCP.
        </p>
        <h3 id="9.12.4.printconnections">9.12.4. Wyświetlanie połączeń sieciowych w systemie</h3>
        <p>
          Omawiając warstwę transportową to nie sposób jest nie wspomnieć o 
          wyświetlaniu połączeń. Obecnie w dystrybucjach Linuksa używa się
          nowego polecenia jakim jest <strong>ss</strong>, aby wyświetlić
          połączenia TCP w systemie należy wydać poniższe polecenie. Polecenie
          to dla przykładu zostało wydane na jednym z moich serwerów VPS
        </p>
<pre class="code-block">
root@searx:~# ss -tr
State       Recv-Q  Send-Q          Local Address:Port                                     Peer Address:Port   Process
CLOSE-WAIT  32      0        ip109.ip-51-178-2.eu:57026                                   146.75.74.208:https
CLOSE-WAIT  64      0        ip109.ip-51-178-2.eu:32808                     text-lb.drmrs.wikimedia.org:https
CLOSE-WAIT  64      0        ip109.ip-51-178-2.eu:43164                     text-lb.drmrs.wikimedia.org:https
CLOSE-WAIT  40      0        ip109.ip-51-178-2.eu:57466                                    52.84.150.51:https
CLOSE-WAIT  40      0        ip109.ip-51-178-2.eu:35092     server-143-204-68-27.lhr61.r.cloudfront.net:https
CLOSE-WAIT  25      0        ip109.ip-51-178-2.eu:45492                   upload-lb.drmrs.wikimedia.org:https
CLOSE-WAIT  40      0        ip109.ip-51-178-2.eu:41928     server-143-204-68-21.lhr61.r.cloudfront.net:https
CLOSE-WAIT  32      0        ip109.ip-51-178-2.eu:36336              qwantbot-115-168-187-194.qwant.com:https
ESTAB       0       52       ip109.ip-51-178-2.eu:2022                                     213.25.29.68:63950
CLOSE-WAIT  130     0        ip109.ip-51-178-2.eu:60580                        waw02s07-in-f4.1e100.net:https
CLOSE-WAIT  47      0        ip109.ip-51-178-2.eu:33310                                    104.16.55.16:https
CLOSE-WAIT  130     0        ip109.ip-51-178-2.eu:43572                        waw02s07-in-f4.1e100.net:https
CLOSE-WAIT  32      0        ip109.ip-51-178-2.eu:36666                                   140.177.50.13:https
CLOSE-WAIT  1       0        ip109.ip-51-178-2.eu:33408                       par21s17-in-f14.1e100.net:https
CLOSE-WAIT  40      0        ip109.ip-51-178-2.eu:53446                                    172.67.22.17:https
CLOSE-WAIT  40      0        ip109.ip-51-178-2.eu:57454                                    52.84.150.51:https
ESTAB       0       0        ip109.ip-51-178-2.eu:2022                                     213.25.29.68:61628
CLOSE-WAIT  32      0        ip109.ip-51-178-2.eu:53654                            www.wolframalpha.com:https
CLOSE-WAIT  32      0        ip109.ip-51-178-2.eu:58752              qwantbot-109-168-187-194.qwant.com:https
CLOSE-WAIT  130     0        ip109.ip-51-178-2.eu:58880                        waw02s07-in-f4.1e100.net:https
CLOSE-WAIT  40      0        ip109.ip-51-178-2.eu:37804              qwantbot-106-168-187-194.qwant.com:https
CLOSE-WAIT  25      0        ip109.ip-51-178-2.eu:50924     server-18-244-117-84.lhr50.r.cloudfront.net:https
CLOSE-WAIT  64      0        ip109.ip-51-178-2.eu:43148                     text-lb.drmrs.wikimedia.org:https
CLOSE-WAIT  90      0        ip109.ip-51-178-2.eu:41176                                  151.101.65.181:https
CLOSE-WAIT  40      0        ip109.ip-51-178-2.eu:58504    server-18-244-153-127.lhr50.r.cloudfront.net:https
CLOSE-WAIT  40      0        ip109.ip-51-178-2.eu:58216      server-13-224-132-41.lhr3.r.cloudfront.net:https
</pre>
        <p>
          W pierwszej kolumnie znajduje się stan połaczenia, jak już wcześniej
          wspominałem protokół TCP ustanawia połączenia i ta kolumna
          przedstawia ich stan. <code class="code-inline">Estab</code> skrót od
          ang. <em>established</em> oznacza że połączenie zostało nawiązane i
          dalej trwa. Dalej przesyłane są jakieś pakiety. Reszta połączeń
          pozostaje w stanie <code class="code-inline">CLOSE-WAIT</code> jest
          to stan oczekiwania na zamknięcie połączenia przez użytkownika.
          Przeważnie nie musimy się przejmować tego rodzaju połączeniami, one
          zostaną zakończone z czasem. Druga i trzecia kolumna przechowują
          informacje odnośnie pamięci podręcznej wysyłania i odbioru. Najlepiej
          aby te wartości były jak najbliżej zera. Wysokie wartości w kolumnie
          <code class="code-inline">Recv-Q</code> mogą świadczyć o tym, że
          pakiety osiągneły komputer docelowy, ale nie ma kto ich odebrać, na
          natomiast w wysokie wartości w kolumnie
          <code class="code-inline">Send-Q</code> mogą najczęściej oznaczać, że
          pakiety zostały wysłane ale do hosta, który na nie oczekuje i nie
          potwierdza ich odebrania lub pakiety nie zostały wysłane w ogóle.
          Czwarta oraz piąta kolumna zawierają <strong>gniazda</strong> lokalne
          oraz zadalne. Za pomocą <strong>gniazd</strong> określamy połączenie
          adresu IP lub nazwy domenowej (tak, jak w tym przypadku) z portem.
          O gniazadach w kontekście Uniksów więcej informacji przedstawię w
          następnym rozdziale.
        </p>
        <p>
          Wydając powyższe polecenie użyłem opcji <code class="code-inline">-t</code>
          określającej rodzaj transmisji 
          (<code class="code-inline">-t</code> - TCP) oraz opcji
          <code class="code-inline">-r</code>, która zamienia adres IP oraz
          numery portów na nazwy domenowe i nazwy usług. Warto zapoznać się
          zawartością strony podręcznika narzędzia <em>ss</em>. Można odnależć
          opcje pozwalającą na zamykanie dowolnych połączeń. Połączenia
          (może, raczej rejestr transmisji) dla protokołu UDP możemy
          wyświetlić za pomocą opcji <em>-u</em>.
        </p>
        <h2 id="9.13.dhcp">9.13. Protokół dynamicznej konfiguracji hosta - DHCP</h2>
        <p>
          Ciężko sobie wyobrazić współczesną sieć bez tak ważnego składnika
          jakim jest protokół <strong>DHCP</strong>. Jest on odpowiedzialny
          za konfigurację interfejsów sieciowych oraz za utrzymywanie 
          informacji o przekazanych parameterach, aby nie dochodziło do
          absurdalnych zdarzeń, np. żeby dwa komputery w sieci nie dostały tego
          samego adresu. Poza adresami IP serwer DHCP, konfigurje interfejsy
          w taki sposób, aby komputer był podłączony do internetu. W sieciach
          korporacyjnych mogą być konfigurowane dodatkowe paramety lub
          domyślna pula może nie istnieć, a nowe urządzenia trzeba dodawać do
          listy
          rezerwacji, w tym wypadku komputery uzyskują statyczny adres IP ale
          nie jest on przypisywany przez administratora, tylko przez DHCP
          właśnie.
        </p>
        <p>
          Metoda uzyskiwania adresu jest dość niezwykła. Otóż jak komputer,
          który nie posiada adresu IP ma skomunikować z innym komputerem i
          jakimi. Otóż z każdym. Klient DHCP rozsyła na pakiet z poszukiwaniem
          serwera DHCP, na adres rozgłoszeniowy sieci (<em>255.255.255.255</em>)
          w tym pakiecie może być zawarty adres, jaki klient kiedyś posiadał.
          W odpowiedzi od serwera, klient dostanie ofertę, z którą może się
          zgodzić lub żądać innych, bądź dodatkowych parametrów, wówczas
          zostaje wysłane żądanie. Po uznaniu żądania, serwer wysyła
          potwierdzenie. Kiedy klient otrzyma potwierdzenie rozpoczyna
          konfigurację interfejsu sieciowego i na tym etapie rola DHCP kończy
          się. Jednak należy pamiętać, że adresy są dzierżawione od serwera,
          czyli czas konfiguracji jest określony i od czasu do czasu 
          trzeba się z tym serwerem skomunikować, aby utrzymać obecną
          kofigurację lub prosić o nową. Jednak to pozostaje już w gestii
          klienta. 
        </p>
        <p>
          Obsługa protokołu DHCP na uniksach występuje w oryginalnej 
          implementacji. Do dyspozycji mamy pakiet klienta
          <strong>dhclient</strong>, wśród serwerów możemy wyróżnić co najmniej
          dwie godne polecenie implementacje. Jedną z nich wykorzystamy
          tworząc z komputera z dystrybucją Linuksa domową bramkę. Aby
          pobrać konfigurację z serwera DHCP (nie które dystrybucje, nie
          posiadają domyślnie żadnej konfiguracji sieciowej) należy wydać
          poniższe polecenie. 
        </p>
<pre class="code-block">
xf0r3m@immudex:~$ dhclient enp4s0
</pre>
        <p>
          Podanie interfejsu jako argument spowoduje skonfigurowanie
          tylko tego konkretnego interfejsu, jeśli go pominiemy skonfigurowane
          zostaną wszystkie aktywe (w których warstwy poniżej internetowej już
          działają).
        </p>
        <p>
          Jeśli chcelibyśmy poznać np. czas dzierżawy to informacje uzyskane
          od serwera znajdują sie w pliku dzierżawy
          <em>/var/lib/dhcp/dhclient.leases</em>
        </p>
        <p>
          Do tej pory omawiając DHCP, skupialiśmy się głównie na protokole
          IPv4. W przypadku protokołu IPv6 również istnieje możliwość
          zastosowania DHCP, nawet został przygotowany ku temu standard
          protokołu DHCPv6 to proponowane jest innego rodzaju rozwiązanie.
          Ze względu na długość adresów IPv6, organizacja zarządzająca
          wykorzystała częśc adresów na potrzeby nowej metody konfiguracji.
          <strong>Konfiguracja bezstanowa</strong> nie wymaga punktów
          centralnych w postaci serwerów do konfiguracji interfejsów dla IPv6.
        </p>
        <p>
          Metoda działania tej konfiguracji opiera się o adresy sieci lokalnej
          łącza, ze względu długość adresu host może wygenerować sobie adres,
          który może z mały prawdopodobnieństwem powtórzyć się w sieci.
          Z resztą mając ustalony prefiks (<em>fe80::/64</em>) można wysłać
          zapytania do innych hostów w sieci czy adres, który host wygenerował
          jest wykorzystywany przez inne hosty w sieci. Jest to mało
          prawdopodobne gdyż do wygenerowania tego adresu bierze udział
          adres MAC. Po uzyskaniu łącza lokalnego, host może określić adres
          globalny z pomocą komunikatów RA (<em>Router Advertisement</em>)
          wysłanego co jakiś czas przez router w naszej sieci lokalnej.
          Komunikat zawiera prefiks sieci globalnej, adres routera oraz adresy
          serwerów DNS. Po otrzymaniu tych informacji może podjąć próbę
          wygenerowania części adresów odpowiadającej za identyfikator
          interfejsu. W ten sposób interfejs otrzymuje dostęp do internetu
          za pośrednictwem protokołu IP w wersji 6.
        </p>
        <h2 id="9.14.linuxasrouter">9.14. Konfiguracja systemu Linux jako router</h2>
        <p>
          Ten podrozdział będzie dość obszerny, ponieważ postanowiłem zebrać
          w nim część zagadnień sieciowych dotyczących konfiguracji dystrybucji
          Linuksa w celu wykorzystania jako router.
        </p>
        <p>
          Chcąc wykorzystać komputer z dystrybucją Linuksa jako bramę czy
          router (w zależności ile sieci będzie łączyć) musimy zaopatrzyć nasz
          komputer w odpowiednią ilość interfejsów. Jak możemy się domyślić
          interfejsy to nic innego jak karty sieciowe. Jeśli jest to zwykły
          PC to dołożenie kart nie powino być problemem (zakładając, że
          nasza sieć jest oparta na miedzianej skrętce) a najzwyklejsze
          karty (gigabitowe) mogą kosztować w okolicach 50 zł  jeśli nie mamy
          możliwości rozbudowania komputera o więcej niż jedną kartę to możemy
          użyć kart serwerowych, one zazwyczaj posiadają od 2 do 4 portów a
          zajmują jeden port PCI-E x16 (rzadko, kto będzie mieć w komputerze
          przeznaczonym na router, złącza PCI-E x8 lub x4, bo takie złącze
          będą mieć karty tego typu). 
        </p>
        <h3 id="9.14.1.linuxdistroforrouters">9.14.1. Oprogramownie główne</h3>
        <p>
          Wiele urządzeń dostępnych na rynku jako router posiada przyjazny,
          z którym możemy połączyć się za pośrednictwem przeglądarki
          internetowej, a obecnie cześć producentów posiada również aplikacje
          mobline do ich kontrolowania. Tego typu rozwiązania zapewniają nam
          łatwość konfiguracji, która często sprowadza sie to wpisania kilku
          rzeczy i klikania <em>Dalej, dalej, dalej...</em> i na koniec
          zrestartowania urządzenia. Na tym zadanie się, kończy za
          pośrednictwem tego urządzenia komputery w naszej sieci lokalnej będą
          posiadać połączenie z internetem. Mimo to na tych sprzętach w dużej
          mierze przeważa Linux. Ten system w warunkach wbudowanych jest
          wstanie uruchomić się z każdego urządzenia. Czytając te słowa,
          zabrneliśmy tak daleko w głąb tego materiału, że możemy z pewnością
          stwierdzić, że domyślnie na Linuksie próżno szukać takich udogodnień.
        </p>
        <p>
          Każda dystrybucja posiada wiele cech specyficznych, z racji tego iż
          nie narzucałem żadnej konkretej (chociaż, Debian tutaj przoduje). To
          warto wybrać tę której używaliśmy do tej pory jeśli jest to wiodąca
          dystrybucja to możemy zainstalować takie oprogramowanie jako
          <strong>cockpit</strong>, jest to środowisko do zarządania serwerem
          z poziomu WWW, przez przeglądarkę. Dostępne jest ono w wiekszości
          dystrybucji. Niestety nie daje ono zbyt rozbudowanych możliwości.
          Cechą dominującą przy wyborze powinna być stabliność
          dystrybucji, dlatego takie dystrybucje jak Debian lub dystrybucje
          klasy <em>Enterprise</em> (pomijając te płatne) jak Rocky czy Alma
          Linux sprawdzą się tutaj znakomicie. Problemem z tymi dystrybucjami
          jest trochę inna konfiguracją zapory sieciowej, ale ona opisana jest
          w innym moim materiale odnośnie RHCSA. Zatem wybierając taką
          dystrybucję mamy nieco więcej pracy, ale możemy mieć pewność, że
          nie spotkamy się z różnymi, nie zawsze przemyślanymi rozwiązaniami
          dostawców różnych nakładek czy dystrybucji skierowanych na routery.
          Sam osobiście wole takie rozwiązanie.
        </p>
        <p>
          Innym, dużo prostszym podejściem do tego typu zadania, może być użycie
          dystrybucji przeznaczonej do zamieniania PC-tów z kilkoma kartami
          sieciowymi w router, takimi jak np. dystrybucja IPFire. Takich
          dystrybucji nie tylko opartych o Linux jest wiele więcej. Część z
          nich jest już niewspierana lub wątpliwej jakość (<em>zeroshell</em>,
          może dlatego upadła). Cała lista dostępna jest pod 
          <a href="https://en.wikipedia.org/wiki/List_of_router_and_firewall_distributions">tym</a>
          adresem.
        </p>
        <p>
          Możemy również zmienić całkowicie podejście do tematu. Jeśli nie mamy
          wolnego
          komputera, którego możemy użyć w roli routera. To możemy użyć
          domowego routera, jako mikroserwer z Linux. Za pomocą dystrybucji
          takiej jak DD-WRT, a szczególnie <strong>OpenWRT</strong> możemy
          uzyskać dostęp dystrybucji Linuksowej na tym nie pozornym urządzeniu.
          Lista kompatybilnego sprzętu, na którym możemy zainstalować
          OpenWRT jest dość obszerna. Więc może znajdziemy system pasujący do
          naszego sprzętu. Dodam również, że obsługa tego typu dystrybucji
          może może opierać na konkretnym narzędziu i żadne z przedstawionych
          poniżej rozwiązań, skierowanych raczej do dystrybucji ogólnych, takich
          jak Debian, może nie działać. Wówczas zachęcam do zapoznania się z
          dokumentacją.
        </p>
        <p>
          Poniższe rozwiązania bedą dotyczyć głównie wiodących dystrybucji.
          Więc jeśli zdecydujemy się inne rozwiązania wykonanie zadania możemy
          oprzeć o dostępną dokumnetację.
        </p>
        <h3 id="9.14.2.additionalsoftware">9.14.2. Oprogramowanie dodatkowe</h3>
        <p>
          Poza system operacyjnym i jego wewnętrznymi komponentami sieciowymi
          do zbudowania pełno prawnego routera lub bramy potrzebujemy kilku
          pakietów: 
        </p>
        <ul>
          <li>Pakietu zapory sieciowej - <strong>iptables</strong></li>
          <li>Pakietu DHCP wraz z DNS - <strong>dnsmasq</strong></li>
          <li>Pakietu rozgłaszania sieci bezprzewodowej (opcjonalnie) - <strong>hostapd</strong></li>
        </ul>
        <p>
          Jeśli jesteśmy w posiadaniu odpowiedniego sprzętu nasz router może
          rozgłaszać sieć bezprzewodwą. Jeśli chcielibyśmy coś takiego
          zrealizować to warto zapoznać się z tematem tworzenia mostów.
          Jeśli taki most miedzy <em>LAN-em</em> a <em>WLAN</em>-em zostanie
          zestawiony to oba interfejsy zostaną połączone jednym wirtualnym,
          który będzie obsługiwał połączenia z zupełnie różnych dwóch
          warstw fizycznych.
        </p>
        <p>
          Dostępność oraz sposób instalacji tych pakietów dla wybranych przez
          nas dystrybucji (ze względu na ich róznorodność) należy ustalić we
          własnym zakresie. Poniżej znajduje się polecenie dla dystrybucji
          Debian oraz pokrewnych.
        </p>
<pre class="code-block">
xf0r3m@immudex:~$ sudo apt install dnsmasq
</pre>
        <p>
          To polecenie zainstaluje tylko jeden pakiet. Debian 11 jest
          już rozprowadzany zainstalowanym pakietem zapory.
        </p>
        <h3 id="9.14.3.linuxrouterconfig">9.14.3. Konfiguracja dystrybucji jako router</h3>
        <p>
          Po złożeniu sprzętu oraz zainstalowaniu oprogramowania. Przyszedł
          czas na jego konfigrację. Najlepiej rozpocząć ją (a wręcz trzeba) od
          konfiguracji interfejsów. Musimy ustalić wykorzystywany przez nas
          sposób łączenia z Internetem, czy posiadamy statyczny adres IP lub
          interfejs jest konfigurowany dynamicznie przez naszego usługodawcę.
          Te informacje musimy zapisać w charkterystyczny dla naszej
          dystrybucji sposób konfiguracji interfejsów. Jeśli chcemy możemy
          wykorzystać do tego celu <em>NetworkManager</em>. Pamietając, że
          w przypadku Debiana interfejs wykorzystywany podczas instalacji
          będzie kontrolowany przez system <em>ifupdown</em>, trzeba go 
          stamtąd usunąć. Po skonfigurowaniu interfejsu łączącego z internetem
          musimy skonfigurować interfejsy sieci LAN. Tutaj wystarczy sam adres
          oraz maska podsieci. Adres ten musi być jednym z adresów
          <strong>sieci prywatnych IPv4</strong>.
        </p>
        <h4>Sieci prywatne IPv4</h4>
        <p>
          Sieci prywatne to nic innego jak wycięte klasy adresowe
          sieci IP w wersji 4. Te adresy mają zastosowanie jedynie w sieciach
          lokalnych, ale i usługodawcy również mogą się nimi posługiwać,
          ponieważ to co wpinamy w port WAN routera jest umowne i tak naprawdę
          naszym WAN-em, może być sieć osiedlowa, która jest nieco wiekszym
          LAN-em lub będąc bardziej szczegółowym siecią kampusową. Adresy sieci
          prywatnych powstały ze względu na wyczerpywanie się adresów
          publicznych. Można by się zastanowić nad tym w jaki sposób zabranie
          prawie 18 milionów adresów, przyczniło się do tego, że sieci IPv4
          jest na wyczerpaniu to nadal są przydzielane konkretne adresy. Otóż
          adresy klas prywatnych nie mogą funkcjonowac w internecie, są tylko
          do użytku wewnetrznego. Największa klasa A (posidająca grubo ponad
          16 miliownów adresów) może być widoczna w internecie jako jeden adres.
          Dzięki technologii translacji adresów (bardziej szczegółów informacje
          na ten temat znajdują się poniżej).
          Stąd taka optymalizacja. Dostępne mamy trzy klasy adresowe: 
        </p>
        <ul>
          <li><strong>Klasa A</strong> - o masce 255.0.0.0, dającą 256^3 - 2
            adresów w zakresie od 10.0.0.0 do 10.255.255.255.</li>
          <li><strong>Klasa B</strong> - o masce 255.240.0.0, dająca
            16*256^2 -2 adresów w zakresie od 172.16.0.0 do 172.31.255.255.</li>
          <li><strong>Klasa C</strong> - o masce 255.255.0.0, dająca 256^2 - 2
            adresów w zakresie od 192.168.0.0 do 192.168.255.255.</li>
        </ul>
        <p>
          Gdzieś wśród młodych adeptów informatyki, wzięło się przeswiadczenie,
          że klasy B oraz C są dużo mniejsze. Klasie B przypisywało się wówczas
          maskę 16-bitową, odcinając wszystkie adresy powyżej 172.16.255.255.
          A klasie C przypisywano maskę 24-bitową, przez co zmniejszano ją
          do 254 adresów. Ten sposób adresacji wziął się z nie wiedzy osób
          konfigurjących sprzęt oraz z narzucenia przez producentów domyślnie
          takich wartości. Nie jest to błędem, ponieważ możemy alokować te
          adresy odpowiednio do swoich potrzeb. Dlatego jeśli nie potrzebujemy
          tak dużej sieci, to możemy ją zmniejszyć dzieląc te sieci na
          podsieci i wykorzystując tylko jedną z nich.
        </p>
        <p>
          Po konfiguracji interfejsów możemy przjeść do konfiguracji serwera
          DHCP, który jest również serwerem buforująco-przekazujący systemu
          DNS. Przyczym konfiguracja DNS-u nie wymaga od nas żadnej uwagi
          <strong>dnsmasq</strong> zaraz po uruchomieniu zaczyna nasłuchiwać
          na porcie 53/UDP. Naszym zadaniem będzie jedynie ograniczenie tego
          nasłuchiwania do portów LAN. Dla przykładu żałożymy, że naszym
          interfejsem LAN-u jest klasyczny port eth0. 
        </p>
<pre class="code-block">
interface=eth0
dhcp-range=192.168.4.2,192.168.4.20,255.255.255.0,12h
dhcp-option=3,192.168.4.1
dhcp-option=6,192.168.4.1
</pre>
        <p>
          Pierwsza opcja <code class="code-inline">interface=eth0</code>
          ogranicza działanie demona tylko i wyłącznie do interfejsu
          <code class="code-inline">eth0</code>. Dzięki tej opcji nasłuchiwanie
          na porcie 53/udp (DNS) zostanie ograniczone do wskazane interfejsu.
          Pozostałe opcje konfigurją nam już serwer DHCP. Pierwsza opcja
          <code class="code-inline">dhcp-range</code> definiuje nam zakres
          przydzielanych adresów, maskę podsieci oraz czas dzierżawy. Następnie
          zaczynają się typowe opcje protokołu DHCP, są one opisane w
          standardzie, ale dla zachowania kontekstu przytocze je również tutaj
          opcja <code class="code-inline">3</code> odpowiada za przypisanie
          adresu domyślnej bramy, natomiast opcja
          <code class="code-inline">6</code> odpowiada za przypisanie adresów
          serwerów DNS. Adres bramy oraz adres serwera DNS wskazują na adres
          portu LAN. Te cztery linie wystarczą aby skonfigurować serwer DNS i
          DHCP dla naszej sieci. Teraz po podłączeniu komputera do routera
          powinniśmy uzyskać adres IP wraz z pozostałymi paramerami 
          pozwalającymi na połączenie z internet za pośrednictwem naszego
          systemu.
        </p>
        <p>
          Aby zrealizować połączenie z internetem hostów podłączanych do sieci
          LAN musimy wykonać jescze dwie czynności. Umożliwić w systemie
          przsyłanie pakietów między interfejsami, domyślnie jest ono 
          wyłączone oraz włączyć funckję NAT-u.
        </p>
        <h4>NAT - Translacja adresów sieciowych</h4>
        <p>
          Translacja adresów potocznie zwana NAT-em, jest funkcja zapór
          sieciowych, której zadaniem jest najczęściej zamiana adresów sieci
          LAN, na adres sieci publicznej. Tak aby komputery mogły wysyłać oraz
          odbierać dane z sieci rozległej nie będąc do niej bezpośrednio
          podłączone. Istnieje kilka rodzajów translacji adresów nas będą
          interesować tylko dwa. Przeznaczone dla ruchu wychodzącego (danych
          generowanych przez komputery z sieci LAN). Do wybory wówczas mamy
          <strong>SNAT</strong> - ang. <em>Source Network Address Translation</em>
          lub <strong>MASQUERADE</strong>. Użycie SNAT-u będzie wymagać
          podania adresu IP portu WAN, teoretycznie nic w tym złego, ale jeśli
          nasz usługodawca automatycznie przypisuje swoim klientom adresy IP,
          za każdą zmianą adresu na tym interfejsie połączenie z internetem
          zostało by zerwane. Zatem SNAT jest szybszą metodą NAT-u, ale wymaga
          stałego adresu IP. Jeśli takim nie władamy, pozostało nam tylko
          użycie MASQUERADE, który pozwala na podanie interfejsu. Działanie
          NAT-u opiera się na podstawieniu w miejscu adresu źródłowego pakietu
          albo adresu podanego w regule (SNAT) albo adres interfejsu 
          (MASQUERADE).
        </p>
        <p>
          Za przekazywanie pakietów między interfejsami odpowiada jądro. Aby
          je włączyć musimy skorzystać z interfejsu ukrytego za poleceniem
          <strong>sysctl</strong>. Do konkretnych wartości prowadzi ścieżka,
          której elementy są odzielone od siebie kropkami. Poniżej znajduje
          sie polecenie, które odpowiada za przekazywanie pakietów miedzy
          interfejsami.
        </p>
<pre class="code-block">
xf0r3m@immudex:~$ sudo sysctl net.ipv4.ip_forward=1
</pre>
        <p>
          Teraz pakiety będą swobodnie przekazywane między interfejsami. Tak
          jak wspomniałem NAT jest funkcją zapory sieciowej. Tak więc
          konfiguracja dystrybucji Linuksa jako router będzie wymagać jej
          konfiguracji. Co prawda będzie to jedno polecenie, ale żeby nie
          pozostawiać użytkownika w niewiedzy trzeba trochę przybliżyć temat
          działania zapory jaką jest <strong>iptables</strong>.
        </p>
        <h4>Zapora sieciowa w systemie Linux</h4>
        <p>
          Zapora sieciowa w dystrybucjach Linux realizowana jest przez pakiet
          <em>iptables</em>, jego zasada
          działania opiera się o <strong>łańcuchy</strong> zasad pod kątem
	        których sprawdzany może być pakiet przychodzący, wychodzący a nawet
          dodatkowo przekazywany dalej. Łańcuchy łączą się w tablice, które
          mogą modyfikować moment konfrontacji pakiety z łańcuchem, ale ogólna
          zasada pozostaje bez zmian. Każdy łańcuch posiada domyślną politykę,
          która jest stosowana dla pakietów niepasujących do żadnej z reguł.
          Domyślnie jest to polityka <em>przepuszczaj</em>, oznacza to swobodną
          transmisję. Wśród najważniejszych tablic oraz łańcuchów możemy 
          wyróżnić:
        </p>
        <ul>
          <li><strong>filter</strong> - tablica zwierająca łańcuchy
            sprawdzające pakiety, które są związane jakoś z docelowym 
            komputerem, Ta tablica jest również domyślna i nie ma
            potrzeby definiowania jest nazwy wśród niej możemy wyróżnić takie 
            łańcuchy jak:
          <ul>
            <li><strong>INPUT</strong> - zawiera reguły filtrujące pakiety
            przeznaczone dla lokalne hosta (tego komputera).</li>
            <li><strong>OUTPUT</strong> - zawiera reguły filtrujące pakiety
            wysyłane (jego połączenia) z tego komputera.</li>
            <li><strong>FORWARD</strong> - zawiera reguły filtrujące pakiety
            przesyłane przez ten komputer.</li>
          </ul>
          </li>
          <li><strong>nat</strong> - tablica zawierająca łańcuchy, których
            zadaniem jest modyfikacja przechodzących przez nią pakietów.
            Np. łańcucha <em>PREROUTING</em> korzysta się do
            <strong>port-forwardingu</strong>, czyli udostępniania połączeń
            z internetu dla wybranych usług. Kluczowe łańcuchy tej tablicy
            przetwarzają pakiety zaraz po pojawieniu się na interfejsie (tj.
            bardzo wcześnie) lub zaraz przed jego opuszczeniem (tj. bardzo
            późno). Będą przy tym pierwszymi oraz ostatnimi zestawiami reguł
            przetwarzającymi pakiet. Wśród tej tablicy możemy wyróżnić takie
            łańcuchy jak:
          <ul>
            <li><strong>PREROUTING</strong> - zawiera reguły filtrujące, które
            najwcześniej przetwarzają pakiety. Ten łańcuchy wykorzystywany jest
            w <em>port-forwarding</em>.</li>
            <li><strong>OUTPUT</strong> - zawiera reguły filtrujące pakiety dla
            wygenerowanych lokalnie pakietów, które poźniej będą wymagały
            trasowania.</li>
            <li><strong>POSTROUTING</strong> - zawiera reguły filtrujące, które
            najpóźniej przetwarzają pakiety. Tutaj stosowany jest SNAT oraz
            <em>maskarada</em>.</li>
          </ul>
          </li>
        </ul>
        <p>
          <em>Iptables</em> konfrontując pakiet z łańcuchem zastosuję akcję
          dla pierwszej reguły do której będzie pasować przetwarzany pakiet.
          Natomiast możemy wyróżnić trzy rodzaje akcji podstawowych takich
          jak:
        </p>
        <ul>
          <li><strong>ACCEPT</strong> - przepuść pakiet do dalszego
            przetwarzania</li>
          <li><strong>DROP</strong> - odrzuć pakiet</li>
          <li><strong>REJECT</strong> - odrzuć pakiet, ale poinformuj nadawcę
            o takiej sytuacji</li>
        </ul>
        <p>
          Istnieją także dodatkowe akcje specyficzne dla tablicy. Przeważnie
          po podaniu akcji w tablicy <em>filter</em> reguła się kończy. W
          przypadku akcji <em>SNAT</em> oraz <em>DNAT</em> tablicy <em>nat</em>
          wymagane jest podanie docelowego adresu IP. Akcją bez argumentów dla
          tej tablicy jest <em>MASQUERADE</em> uruchamiające maskaradę.
        </p>
        <p>
          Z powyższego wywodu możemy wywnioskować, że aby uruchomić NAT na
          naszym routerze musimy zapisać regułę tablicy <em>nat</em> w łańcuchu
          <em>POSTROUTING</em>. Więc tak, tablicę wskazujemy z pomoca opcji
          <em>-t</em>, teraz w zależności od tego czy chcemy wstawić w
          konkretną linią naszą regułę czy ją dopisać musimy użyć innych opcji.
          Opcja <em>-I</em> odpowiedzialną za wstawianie (<em>INSERT</em>)
          wymaga po podaniu nazwy łańcucha numeru linii, w którą ma wstawić
          daną regułem, natomiast opcja <em>-A</em> odpowiedzialna za
          dopisanie (<em>APPEND</em>). Ze względu na to, że jest to łańcuch 
          <em>POSTROUTING</em>, to raczej będzie on pusty, więc nie będzie
          to miało znaczenia czy użyjemy dopisania czy wstawienia. Drugą rzeczą
          jest wskazanie interfejsu, na którym interfejsy będą wymagały NAT-u,
          aby transmisja miała sens. W przypadku wyjściowych łańcuchów takich
          jak <em>POSTROUTING</em> czy <em>OUTPUT</em> interfejs podwany jest
          po opcji <em>-o</em> (nazywane jest kierunkien od 
          <em>in</em>/<em>out</em>, jednak łańcuchy mają już zdefiniowane
          możliwe kierunki transmisji) następnie po opcji <em>-j</em> podawana
          akcja, zawsze wieliki literami. Więc nasza reguła uruchamiająca NAT
          prezentuje się następująco. W przypadku tego oraz poniższych
          przykładów dotyczących zapory sieciowej interfejsem przeznaczonym do
          połączenia z siecią WAN będzie <em>eth1</em>.
        </p>
<pre class="code-block">
xf0r3m@immudex:~$ sudo iptables -t nat -A POSTROUTING -o eth1 -j MASQUERADE
</pre>
        <p>
          Teraz o ile komputery podłaczone do interfejsu <em>LAN</em> posiadają
          prawidłowe adresy IP, powinny mieć już połączenie z Internetem.
          Mimo, że wszystko funkcjonuje prawidłowo to pozostawienie tak
          podłączonego routera do Internetu pozostawia wiele do życzenia.
          Pierwszym rażącym zaniedbanie jest fakt iż router będzie przyjmował
          połączenia z internetu, z każdym dowolnym portem, w ramach lepszego
          poznania pakietu <em>firewall</em>-a na Linuksie możemy nieco
          bardziej zabezpieczyć naszą transmisję.
        </p>
        <p>
          Jak zapewne pamiętamy, każdy łańcuch posiada swoją politykę, która
          jest stosowana dla każdego pakietu, które nie zostanie przypasowana
          żadna reguła. Moglibyśmy ustawić ją na odrzucanie i dopuścić tylko
          potrzebny ruch. To dobry pomysł szczególnie jeśli myślimy o
          interfejsie WAN, ale zły jeśli pomyślimy interfejsie LAN. Ponieważ
          możemy zdefiniować polityki <em>per</em> interfejs, ten pomysł
          odpada, ponieważ dla interfejsu LAN musiała by powstać długa lista
          reguł dopuszczająca ruch do wszystkie bardziej oraz mniej znanych 
          usług. Dlatego też pozostawimy politykę bez zmian i dopuścimy tylko
          niezbędny ruch. Na pewno z internetu musimy przyjąć dane od serwera
          DNS, aby rozwiązywać dotąd nieznane nazwy oraz w zależności
          konfiguracji interfejsu WAN dane z serwera DHCP usługodawcy. Łańcuch
          INPUT będziemy konfigurować dodają na początku reguły zezwalające na
          ruch, żeby następnie zablokować pozostały nieokreślony regułami.
        </p>
<pre class="code-block">
xf0r3m@immudex:~$ sudo iptables -A INPUT -i eth1 -p udp --sport 53 -j ACCEPT
#Opcjonalnie:
xf0r3m@immudex:~$ sudo iptables -A INPUT -i eth1 -p udp --sport 67 -j ACCEPT
#Zablokowanie pozostałego ruchu
xf0r3m@immudex:~$ sudo iptables -A INPUT -i eth1 -p udp -j DROP;
xf0r3m@immudex:~$ sudo iptables -A INPUT -i eth1 -p tcp --syn -j DROP;
</pre>
        <p>
          Dwie pierwsze reguły dopusczają ruch z sieci WAN (interfejs eth1) na
          porcie 53/udp (serwer systemu DNS) oraz 67/udp (serwer DHCP).
          Pozostały ruch protokołu UDP został zablokowany. Podobnie jest z
          całym ruchem na protokole TCP, tutaj dodano także modyfikator
          <code class="code-inline">--syn</code>. Jak wspominałem omawiając
          protokół TCP, musi on zestawić połączenie, aby rozpocząć transmisje
          co wymaga wysłania kilku pakietów sterujących. Pakiet wysyłany aby
          zainicjować zestawienie połączenia TCP posiada własnie ustawioną
          flagę SYN (pakiety TCP posiadają specjalne miejsce na flagi).
          I tego typu pakiety są właśnie blokowane. To rozwiązanie skutecznie
          zablokuje próbę połączenia, ale prawdopodbnie nie uchroni przed
          metodą rozpoznawczą jaką jest skanowanie portów. Należało by tutaj
          zamiast flagi, stanów połączenia.
        </p>
        <p>
          Ze względu na to, iż zapora na Linuksie to temat rzeka. 
          Małe ćwiczenie. Usprawnienie tej ostatniej reguły, takby aby 
          opierała się na stanach TCP. (Podpowiedź: Zablokowanie ma służyć
          nawiązywaniu nowych połączeń z naszym routerem. Transmisja
          przez hosty w sieci, ktore łączy nasz routera powina przebiegać bez
          zarzutu).
        </p>
        <p>
          <em>Iptables</em> nie jest bez wad jedną z nich jest utrzymanie
          reguł w łańuchach do momentu wyłączenia systemu. Dlatego
          systemy, w których instalowany jest ten pakiet dostępny jest też
          pakiet odpowiadający za zapisanie reguł w pliku i przywrócenie ich
          w momencie startu systemu. Pakiet nazywa się 
          <em>iptables-persistent</em> dostępny jest w repozytoriach Debiana.
        </p>
<pre class="code-block">
xf0r3m@immudex:~$ sudo apt install iptables-persistent
</pre>
        <p>
          Zapisanie reguł odbywać się będzie za wydaniem poniższego polecenia.
        </p>
<pre class="code-block">
xf0r3m@immudex:~$ sudo iptables-persistent save
</pre>
        <p>
          Teraz router jest skonfigurowany i gotowy do działania. Routery
          programowe mają to do siebie, że ich funkcjonalność można
          rozszerzyć np. o serwer plików. Konfiguracje takiego serwera plików
          będziemy jeszcze omawiać w tym materiale. Także będziemy jeszcze
          wracać do naszego routera.
        </p>
        <p>
          Kolejną kwestią jest komunikacja między sieciami. Jeśli nasz router
          łączy ze sobą więcej niż jedną sieć lokalną i ich komputery mają się
          ze sobą komunikowac to należy utworzyć statyczne trasy, wskazujące
          przez, który interfejs należy komunikować się z daną siecią.
        </p>
<pre class="code-block">
xf0r3m@immudex:~$ sudo ip route add 192.168.1.0/24 via 192.168.1.1 dev eth2
xf0r3m@immudex:~$ sudo ip route add 192.168.4.0/24 via 192.168.4.1 dev eth0
</pre>
        <p>
          Trasy te mogą zostać utworzone automatycznie jeśli np. interfejs
          sieci WAN zostanie podniesiony podczas automatycznej konfiguracji.
          Jeśli takie zachowanie nie jest przez nas porządane to w najlepszym
          wypadku jest zablokować transmisję między sieciami na 
          <em>firewall</em>-u. Ninejszym temat konfigruacji routera uważam
          za zakończony. Nie mniej jednak to nie koniec rodziału. Zostały
          jeszcze dwa tematy do omówienia.
        </p>
        <h2 id="9.15.ipoverethernet">9.15. Sieci IP oparte na Ethernet. Protokół ARP i NDP</h2>
        <p>
          Mając na uwadzę to, że chcąc wysłać jakieś dane musimy podać adres
          hosta docelowego. Zazwyczaj takim adresem jest albo adres IP albo 
          nazwa domenowa. Te piewsze wykorzystywane są głównie w sieciach
          lokalnych przez specjalistów. Zatem podając nazwę domenową aplikacja
          musi rozwiązać ją na adres IP i dokonuje tego za pomoca systemu DNS.
          To dzieje się w warstwie aplikacji. Warstwa transportowa definiuje
          port oraz rodzaj transmisji dla wysłanych danych. Najczęściej są
          to znane protokoły jak HTTPS, protokoły przesyłania strumieniowego
          oraz protokoły poczty. Warstwa sieciowa posiada już adres IP hosta
          docelowego i bez względu na to czy host docelowy znajduje się w tej 
          samej sieci czy nie, pakiet przekazywany jest dalej i tutaj pozostaje
          nam pewna nie wiadoma, skąd host źródłowy wie jakim adresem MAC 
          ma zaadresować ramkę <em>ethernet</em>? 
        </p>
        <p>
          Tutaj pojawia się protokoły <strong>ARP</strong> oraz RARP. Ten 
          drugi jest może mniej wykorzystywany. Ich zadaniem jest zamiana
          adresów IP na MAC i odwrotnie. Głownie chodzi tu o protokół ARP i
          to nanim się się skupimy. Informacje na temat adresów MAC hostów
          w sieci przechowywane są w tablicy lub w buforze ARP. Jednak co jeśli
          tablica jest pusta? Wówczas protokół ARP dla docelowego adresu IP
          tworzy ramkę z żądaniem ARP. Taka ramka rozsyłana jest w całej sieci.
          Jeśli jeden ze znajdujących się w niej hostów posiada adres MAC dla
          adresu IP z żądania wówczas odsyłana jest odpowiedź. Nasz host na
          podstawie odpowiedzi uzpełnia swoją tablicę o ten wpis wówczas może
          on rozpocząć transmisję.  Dostęp do tablicy w dystrybucjach Linuksa
          odbywa się z pomocą: 
        </p>
<pre class="code-block">
xf0r3m@immudex:~$  sudo ip -4 neigh
172.16.2.20 dev enp4s0 lladdr 74:27:ea:e9:cc:14 STALE
172.16.7.6 dev enp4s0 lladdr 70:85:c2:a4:bf:b9 STALE
172.16.8.2 dev enp4s0 lladdr 6c:4b:90:be:91:74 STALE
172.16.6.1 dev enp4s0 lladdr 78:45:c4:12:6a:5d STALE
172.16.2.100 dev enp4s0 lladdr 3c:84:6a:44:d7:a4 STALE
172.16.2.46 dev enp4s0 lladdr 74:27:ea:ea:98:8a STALE
172.16.17.15 dev enp4s0 lladdr 78:45:c4:09:23:4c STALE
172.16.2.146 dev enp4s0 lladdr 1c:69:7a:cd:f4:cb STALE
172.16.2.119 dev enp4s0 lladdr 74:27:ea:ea:63:56 STALE
172.16.8.13 dev enp4s0 lladdr 6c:4b:90:be:88:16 STALE
172.16.0.1 dev enp4s0 lladdr 90:e2:ba:45:4f:8c REACHABLE
...
</pre>
        <p>
          Wpisy w tablicy same ulegją usunięciu jeśli nie nastąpiła aktywność
          przez pewien czas. Nie mniej jednak istnieje możliwość ręcznego
          usunięcia wpisów za pomocą polecenia:
        </p> 
<pre class="code-block">
xf0r3m@immudex:~$ sudo ip neigh del 172.16.8.13 dev enp4s0
</pre>
        <p>
          Efektem działania tego polecenia będzie usunięcie wpisu dotyczączego
          host <code class="code-inline">172.16.8.13</code>.
        </p> 
        <p>
          Protokołem o działaniu udwrotnym jest <strong>RARP</strong>, jego
          zadaniem była zamiana adresów MAC na adresy IP, przez co
          wykrzystywany był do automatycznej konfiguracji hosta, przed
          upowszechnieniem się protokołu DHCP. Obecnie jest już rzadko
          spotykany.
        </p>
        <p>
          Za pomocą podpolecenia <em>neigh</em> polecenia <em>ip</em> mogliśmy
          sprawdzić tablicę ARP w systemie. Kiedyś używano do tego polecenia
          <em>arp</em>. Obecnie doszło do unifikacji przez narzędzie 
          <em>ip</em> obsługi protokołu ARP dla IPv4 oraz protokołu NDP dla
          IPv6. NDP jest podobny rozwiązaniem dla IPv6. Jego działanie opiera
          na dwóch rodzajach komunikatów:
        </p>
        <ul>
          <li><strong>Poszukiwanie adresu</strong> - pakiet tego rodzaju służy
            do uzyskania informacji o sieci lokalnej hosta wraz z adresem MAC.</li>
          <li><strong>Ogłaszenie adresu</strong> - pakiet z odpowiedzią wraz
            z żądanymi informacjami.</li>
        </ul>
        <h2 id="9.16.wirelesslan">9.16. Sieć bezprzewodowa</h2>
        <p>
          Logiczna konstrukcja sieci bezprzewodowej, nieco rózni się
          od połączeń kablowych kilkoma charakterystycznymi elementami w 
          warstwie fizycznej. Sieci bezprzewodowe definiowane są przy użyciu
          standardu <strong>802.11</strong> i jego poszczególnych odmian
          (np. 802.11a lub 802.11n)
          Poniżej opiszemy sobie cechy charakterystyczne, z którymi będziemy
          mieć styczność podczas konfiguracji sieci bezprzewodowej.
        </p>
        <ul>
          <li><strong>Identyfikator/Nazwa sieci/ESSID</strong> jest ciąg
            znaków jednoznacznie określający sieć. Każda sieć bezprzewodowa
            go posiada. Jest on niezbedny do połączenia.</li>
          <li><strong>Dane autoryzacyjne</strong> sieci bezprzewodowe, mogą
            zostać zabezpieczone za pomocą funkcji kryptograficznych 
            (zaszyfrowane), aby osoby nie będące jej częścią nie mogły
            się podłączyć lub 
            przechwycić przesyłanych przez nie danych. Najczęsciej jest hasło,
            chociaż, czasami też stoswane są PIN-y (w przypadku funkcji WPS)
            lub dane logowania (w przypadku sieci korporacyjnych).</li>
          <li><strong>Częstotliwość</strong> - fragment pasma częstotliwości
            radiowej, na której możliwa jest wymiana informacji w obrębie danej
            sieci bezprzewodowej. Bezprzewodowe sieci komputerowe operują
            najczęściej na częstotliwości 2,4GHz lub 5GHz. Każda sieć ma
            do dyspozycji tylko fragment pasma powyższych częstotliwości.</li>
          <li><strong>Kanał</strong> - kanał jest powiązany z częstotliwością
            Kanał określa konkretną częstotliwość dla pasma np. 2,4GHz.
            Jeśli nasza sieć ma nadawać na pierwszym kanale (Kanał/CH 1,
            oznaczenia są różne) to znaczy że będzie nadawać na częstotliwości
            2412MHz.</li>
        </ul>
        <p>
          Oczywiście cech charakterystycznych jest jescze więcej. Nie 
          opisywałem tutaj siły sygnału. To chyba każdy rozumie. My tutaj
          skupimy się głownie na podłączaniu się do sieci i to najlepiej za
          pomocą terminala. Opcji jest kilka.
        </p>
        <ul>
          <li><strong>NetworkManager</strong>. Do przyłączenia się do sieci
            bezprzewodowej możemy wykorzystać dobrze znany nam już menedżer.
            Za pomocą komend polecenia <em>nmcli</em> możemy wyświetlić sobie
            listę dostępnych sieci i następnie się do niej podłączyć. Poniżej
            znajdują się polecenia, dzięki którym możemym wykorzystać ten
            menedżer do podłączenia do sieci.
<pre class="code-block">
xf0r3m@immudex:~$ nmcli device wifi list
*  SSID               MODE    CHAN  RATE       SIGNAL  BARS  SECURITY
   netdatacomm_local  Infra   6     54 Mbit/s  37      ▂▄__  WEP
*  F1                 Infra   11    54 Mbit/s  98      ▂▄▆█  WPA1
   LoremCorp          Infra   1     54 Mbit/s  62      ▂▄▆_  WPA2 802.1X
   Internet           Infra   6     54 Mbit/s  29      ▂___  WPA1
xf0r3m@immudex:~$ nmcli device wifi connect "F1" password "p4ssw0rd"
#lub
xf0r3m@immudex:~$ nmcli --ask device wifi connect "F1"
xf0r3m@immudex:~$ nmcli -p -f general,wifi-properties device show wlan0
</pre>
            Można użyć modyfikatora <code class="code-inline">--ask</code>
            zamiast wpisywać hasło w poleceniu. Ostatnie polecenie zwraca
            podstawowe informacje na temat interejsu oraz samej sieci. 
        </li>
          <li><strong>iwd</strong>, jest menedżer sieci bezprzewodywych stworzony
            przez firmę Intel. Jego obsługa jest interaktywna i opiera sie na
            wydaniu kilku poleceń. W przeciwieństwie do <em>NetworkManagera</em>
            (który może być już zainstalowany w wielu dystrybucjach) trzeba go
            zainstalować. Pomoc dostępna jest wewnąrz narzędzia po jego
            uruchomieniu. Uruchomienie odbywa się poprzez wydanie polecenia:
<pre class="code-block">
xf0r3m@immudex:~$ iwctl
[iwd]# help
[iwd]# device list
[iwd]# station wlp1s0 scan
[iwd]# station wlp1s0 get-networks
[iwd]# station wlp1s0 connect SSID
</pre>
            Ten program wymaga nieco więcej poleceń. Ostanie poleceń, jeśli
            połączenie tego będzie wymagać zapyta o hasło. (Więcej informacji
            na <a href="https://wiki.archlinux.org/title/iwd">https://wiki.archlinux.org/title/iwd</a>)
          </li>
          <li><strong>wireless-tools</strong> - Pakiet. Konfiguracja ręczna.
            Ten sposób jest najdłuższy, ale zadziała na każdej dystrybucji.
            Składa się on z klasycznego interfejsu <em>iwconfig</em> oraz
            programu <strong>wpa_supplicant</strong> służącego do łączenia się
            sieciami wykorzystującymi mechanizm bezpieczeństwa WPA. Chcąc
            znaleźć sieć, do której chcemy się podłaczyć musimy skorzystać z
            polecenia <em>iwlist</em>, który wyświetli nam raport ze skanowania
            z znalezionymi sieciami oraz ich parametrami. Te informacje są
            trochę nieczytelne, ale nam potrzebny jest jedynie ESSID
            (nazwa sieci) oraz sam fakt jej obecnosci. Po uzyskaniu tych
            informacji musimy utworzyć plik zawierający <em>profil</em> sieci
            posiłkując się poleceniem <em>wpa_passphrase</em>. Czasami może
            być wymagane dodanie kilku opcji, ale przedstawie to na liście
            poleceń. Następnie należy uruchomić polecenie 
            <em>wpa_supplicant</em> z odpowiednimi przełącznikami oraz opcjami
            a na sam koniec należy pobrać adresy IP. Jeśli zestawienie
            połączenie niedochodzi do skuktu to może oznaczać, że uruchomiony
            jest już demon, którego to my mieliśmy uruchamiać. Można wówczas
            wyłączyć jednostkę i zabić wszystkie pozostałe procesy związane
            z <em>wpa_supplicant</em>, a następnie spróbować ponownie. Jednak
            tutaj mała wskazówka. W raz z obecnością działającego demona
            wpa_supplicant w systemie dostępne jest polecenie 
            <strong>wpa_cli</strong>, które umożliwia nam podłączenie za
            pomocą interaktywnego interfejsu. Nie mniej jednak próba reczenego
            podłączenia się do sieci bezprzewodowej wygląda następująco.
<pre class="code-block">
xf0r3m@immudex:~$ sudo iwlist wlp1s0 scan
xf0r3m@immudex:~$ wpa_passphrase "F1" 'p4ssw0rd' &gt;&gt; f1_wlan.conf
#lub
xf0r3m@immudex:~$ echo "ctrl_interface=DIR=/var/run/wpa_supplicant GROUP=netdev" | tee f1_wlan.conf
xf0r3m@immudex:~$ echo "update_config=1" | tee -a f1_wlan.conf
xf0r3m@immudex:~$ echo "country=PL" | tee -a f1_wlan.conf
xf0r3m@immudex:~$ wpa_passphrase "F1" 'p4ssw0rd' | tee -a f1_wlan.conf
xf0r3m@immudex:~$ sudo systemctl stop wpa_supplicant.service
xf0r3m@immudex:~$ sudo kill -9 $(ps -aux | grep '^root.*wpa_supplicant' | awk '{printf %2" "}')
xf0r3m@immudex:~$ sudo wpa_supplicant -B -Dwext -iwlp1s0 -cf1_wlan.conf
xf0r3m@immudex:~$ sudo dhclient
</pre>
            Jak możemy zauważyć proces jest nieco bardziej złożony, ale jest
            to ręczna metoda. Z racji tego iż opisałem główny proces powyżej
            tutaj skupię się na kilku szczegółach. Program
            <code class="code-inline">wpa_passphrase</code> tworzy tak zwany
            <em>blok sieci</em> w nim zawarta jest nazwa sieci oraz klucz PSK
            (hasło do sieci). Mimo tego my podajemy ten plik jako plik
            konfiguracyjny <em>wpa_supplicant</em> i w niektórych przypadkach
            nie jest wystarczająca konfiguracja. Dlatego też podaje się
            takie informacje jak lokalizacja interfejsu sterowania 
            wpa_supplicant 
            (<code class="code-inline">ctrl_interface=DIR=/var/run/wpa_supplicant</code>),
            grupa użytkowników, którzy mogą sterować <em>wpa_supplicant</em>
            (<code class="code-inline">GROUP=netdev</code>), zezwolenie na
            możliwość modyfikacji konfiguracji
            (<code class="code-inline">update_config=1</code>) oraz kod ISO
            kraju w którym działa odbiornik
            (<code class="code-inline">country=PL</code>). Kod kraju jest o
            o tyle istotny, że każdy kraj posiada swoje regulacje prawne
            odnośnie wykorzystania częstotliwości radiowych, które są
            wykorzystywane przez sieci bezprzewodowe. Na przykład w Polsce
            dostępnych jest 13 kanałów a w USA tylko 11. A to są tylko kanały
            większość krajów reguluje również moc nadawczą. Więc manipulacja
            kodem kraju może wpłynąć na siłę sygnału i poprawić jakość
            połączenia. Kolejną rzeczą jest działanie już <em>wpa_supplicant</em>
            w systemie. Ten program może działać jako usługa. Dzięki czemu
            możemy zapisać <em>bloki sieci</em> w ogólnym pliku konfiguracjnym.
            Wówczas powoduje to, że jeśli komputer z włączony demon znajdzie
            się w zasięgu sieci, zostanie z nią połączony. W przypadku kiedy
            łaczność ma być wykonywana na żadanie użytkownika działanie demona
            nie jest pożądane. Dlatego demona należy wyłączyć, ale mimo jego
            wyłączenia nadal może pozostawać proces, który bedzie blokował
            próbę podłączenia się. Dlatego też ważne jest aby pozbyć się
            tego procesu i za to odpowiada polecenie
            (<code class="code-inline">kill</code>) w podstawieniu polecenia
            uzyskujemy PID tego procesu. Uruchomienie polecenia
            <em>wpa_supplicant</em> wymaga kilku opcji. Opcja
            <code class="code-inline">-B</code> uruchamia narzędzie w tle,
            opcja <code class="code-inline">-D</code> wraz z wartością
            <code class="code-inline">wext</code> jest to wskazanie sterownika
            odpowiedzialnego za obsługę sieci bezprzewodowej, dostępnych jest
            ich kilka, <code class="code-inline">wext</code> jest rozwiązaniem
            przestarzałym niemniej jednak cechuje się obsługa przez bardzo
            wiele układów kart bezprzewodowych na rynku. Następnie po opcji
            <code class="code-inline">-i</code> podaje się interfejs sieciowy,
            ostatnią opcją jest <code class="code-inline">-c</code>, która
            wskazuje na plik konfiguracyjny. Zwróćmy uwagę na to, iż opcję
            wraz z wartościami zapisujemy łącznie.
            Inną opcją skorzystania z tego
            pakietu jest wykorzytanie narzędzia <strong>wpa_cli</strong>.
            Poniżej znajduje się lista polecenie, jakich należy użyć. Użycie
            <em>wpa_cli</em> wymaga działania demona <em>wpa_supplicant</em>.
<pre class="code-block">
xf0r3m@immudex:~$ sudo wpa_cli
&gt; scan
&gt; scan_results
#tu_wyswietli_sie_lista_znalezionych_sieci
&gt; add_network
#tu_wyswietli_sie_id_sieci_wazne_bo_sluzy_do_odlowania_sie_do_sieci
&gt; set_network 0 ssid "nazwa_sieci/ESSID"
&gt; set_network 0 psk "haslo/PSK"
&gt; enable_network 0
#tu_wyswietli_sie_informacja_o_podlaczaeniu_do_sieci
&gt; save_config
&gt; quit
</pre> 
           Jeśli nie chcemy aby połączenie zostało zapisane dołączenia
           do łączenia automatycznego to należy pominąć przedostatnią opcję.
          </li>
        </ul>
        <p>
          Na konfiguracji narzędzia <em>wpa_suplicant</em> zakończymy temat
          konfiguracji sieci w Linuks. Jednak to nie koniec tematów 
          sieciowych ponieważ następne dwa rozdziały będą na niej bazować.
        </p>
        <h1 id="10.applicationlayer">10. Warstwa aplikacji - usługi sieciowe</h1>
        <p>
          W poprzednim rozdziale dowiedzieliśmy się czym są sieci komputerowe
          i jak wygląda ich konfiguracja w dystrybucjach Linuksa. Sieci służą
          do przesyłania danych, a te musimy dostarczyć za pomocą uzupełnienia
          formularza na stronie internetowej lub w postaci zwykłego pliku
          tekstowego. Za obie te formy odpowiadają różne ustandaryzowane zbiory
          programów składające się na jeden konkrent <strong>protokół</strong>.
          Protokołów nie należy stawiać obok programów, które możemy kojarzyć
          z daną formą sposóbu przesyłania informacji przez sieć. Te programy
          najczęściej zajmują się ich obsługą, zawierają tym samym ich
          implementacje oraz dostosowanie aby korzystanie z protokołu było
          najcześciej niezauważalne a końcowy użytkownik utrzymał tylko
          i wyłącznie żądaną stronę internetową lub dostęp do zasobu dyskowego
          udostępnionego gdzieś na serwerze.
        </p>
        <p>
          Aby pomiędzy dwoma <em>stronami</em> mogła zajść komunikacja
          potrzebny jest nadawca i odbiorca. Z punktu widzenia sieci
          komputerowej, każdy host jest jednocześnie jednym i drugim. Jednak
          patrząc na to ze strony obecnie omiawianego tematu, różnica między
          stronami jest już dużo bardziej podkreślona. Mamy sztywny podział
          między aplikacji klienckimi danego protokołu, które żądają dostępu
          do konkretnego zasobu a serwera, które te dane udostępniają.
          Wiele serwerów określa się mianem <strong>usług sieciowych</strong>.
          Często mówiąc o jakiś serwerze do słowa <em>serwer</em> dodaje się
          protokół, który obsługuje. Jak możemy pamiętać np. z rozdziału 7,
          niektóre serwery domyślnie nie są usługami sieciowymi (chociaż mogą,
          wystarczy odpowienio je skonfigurować).
        </p>
        <p>
          Usługi sieciowe mają za zadanie udostępniać dane poprzez wybrane
          protokoły. Na przykład coś co nazywamy przeglądarką internetową
          opiera swoje działanie na protokole HTTP bądź jego bezpieczeniejszej
          wersji w postacji protokołu HTTPS. Programy pocztowe wykorzystują
          protokoły SMTPS oraz POP3S lub IMAPS. Wiele różnych aplikacji
          sieciowych może wykorzystywać różne protokoły lub samodzielnie
          implementować format danych przesyłanych przez sieć. Nie mniej jednak
          wszystkie te protokoły rezydują w <strong>warstwie aplikacji</strong>,
          czwartej warstwie modelu TCP/IP.
        </p>
        <p>
          W tym rozdziale nadal pozostaniemy w sieciach. Przeanalizujemy
          działanie protokołu HTTP. Omówimy sobie usługę sieciową na podstawie
          SSH. Dowiemy się jak uruchamiane były, niektóre specyficzne usługi
          i jak są uruchamiane teraz. Sprawdzimy sobie narzędzia diagnostyczne,
          które pozwolą nam na sprawdzenie dostępności usługi ale również
          monitorowanie przesłanych przez nia i do niej danych. Na koniec
          zajmiemy się zdalnym wywołaniem procedur (RPC) oraz omówimy sobie
          podstawowe zagadnienia związane z bezpieczeństwem.
          Tematem zaawansowamym będą gniazda. 
        </p>
        <h2 id="10.1.httpanalysis">10.1. Analiza HTTP</h2>
        <p>
          Na wstępie omówilśmy sobie co tak naprawdę znajduje się w warstwie
          aplikacji. Aby była możliwość zapewnienia bezbłędnego działania
          wielu znanych protokołów, które są podstawą komunikacji
          w internecie, zespoły odpowiedzialne za implementacje tych standardów
          często umieszczają w swoich programach klienckich możliwość analizy
          przesyłanych danych. W tym podrozdziale skupimy się głównie na jednym
          protokole i jednym narzędziu umożliwiającym śledzenie danych
          przesyłanych za pomocą protokołu. Jednak w podrozdziale poświęconym
          narzędziom dianostycznym dowiemy się, że możemy sprawdzić większość
          usług, za pomocą kilku narzędzi.
        </p>
        <p>
          W większości dystrybucji dostępne jest narzędzie 
          <strong>curl</strong> jest ono nagminnie wykorzystywane do pobierania
          plików za pomocą protokołu HTTP w terminalu. Program ten jako, że
          wykorzystuje protokół HTTP/S posiada również możliwość prześledzenia
          transmisji. Jako przykład wykorzystamy serwis pogodowy, który
          przesyła obecną sytuację pogodową (lub dwu-dniową prognozę) za ASCII.
          Dla przykładu:
        </p>
<pre class="code-block">
xf0r3m@immudex:~$ curl wttr.in/Warszawa?0\&amp;lang=pl
Pogoda w: Warszawa

      \   /     Słonecznie
       .-.      21 °C
    ― (   ) ―   → 9 km/h
       `-’      10 km
      /   \     0.0 mm
</pre>
        <p>
          Na podstawie wyścia tego polecenia, ciężko jest na prierwszy rzzut
          oka dostrzec, że jest to strona internetowa, ale tak właśnie jest.
          Chcąc przeanalizować jak wygląda komunikacja za pomocą protokołu
          HTTP należy wydać następujące polecenie:
        </p>
<pre class="code-block">
xf0r3m@immudex:~$ curl --trace-ascii curl.log wttr.in/Warszawa?0\&amp;lang=pl
</pre>
        <p>
          Opcja <code class="code-inline">--trace-ascii</code> mówi programowi
          <em>curl</em> aby zapisywał on komunikaty diagnostyczne. Dodatkowo
          ta opcja wymaga podania pliku przeznaczonego na dane wyjściowe. W
          moim przypadku jest <em>curl.log</em>. Poniżej znajduje się jego
          zawartość, pominąłem na poniższym przykładzie dane zwracane przez
          polecenie (są one normalnie dostępne w terminalu po wydaniu 
          polecenia).
        </p>
<pre class="code-block">
== Info:   Trying 5.9.243.187:80...
== Info: Connected to wttr.in (5.9.243.187) port 80 (#0)
=&gt; Send header, 89 bytes (0x59)
0000: GET /Warszawa?0&amp;lang=pl HTTP/1.1
0022: Host: wttr.in
0031: User-Agent: curl/7.74.0
004a: Accept: */*
0057:
== Info: Mark bundle as not supporting multiuse
&lt;= Recv header, 17 bytes (0x11)
0000: HTTP/1.1 200 OK
&lt;= Recv header, 32 bytes (0x20)
0000: Access-Control-Allow-Origin: *
&lt;= Recv header, 21 bytes (0x15)
0000: Content-Length: 314
&lt;= Recv header, 41 bytes (0x29)
0000: Content-Type: text/plain; charset=utf-8
&lt;= Recv header, 37 bytes (0x25)
0000: Date: Wed, 23 Aug 2023 08:23:51 GMT
&lt;= Recv header, 2 bytes (0x2)
0000:
&lt;= Recv data, 314 bytes (0x13a)
0080:  .  .[38;5;226m  ... (   ) ...  .[0m .[1m....[0m .[38;5;154m9.[0
00c0: m km/h.[0m       .  .[38;5;226m     `-...     .[0m 10 km.[0m
0100:       .  .[38;5;226m    /   \    .[0m 0.0 mm.[0m         .
== Info: Connection #0 to host wttr.in left intact
</pre>
        <p>
          Pierwsze dwie linie, są to linie informujące nas o uzyskanym adresie
          IP oraz o tym czy połącznie powiodło się. Jeśli tak jest, to wówczas
          wysyłany jest <strong>nagłówek</strong> - w nagłówkach HTTP
          przeważnie znajdują się informacje kontrolne dla programów, które
          będą zajmować się interpretowaniem treści przesłanej przez serwer.
          No właśnie. Logiczne było by to, że przeglądarka powinna
          pobrać żądaną stronę WWW. W rzeczywistości to klient przesyła
          jedynie nagłówek z żądaniem. Przyglądając się pierwszej linii 
          nagłówka
          rozpoczynajcego się liczbą: <code class="code-inline">0000</code>
          (Ta liczba to bajt rozpoczęcią tych danych w ładunku/bloku danych
          przesyłanych w pakietach sieciowych). Zawiera ona słowo kluczowe
          <code class="code-inline">GET</code> Następnie występuje wartość
          żądania (czego sobie życzysz), na podstawie tych informacji skrypt
          jest wstanie zwrócić odpowiedni stan pogodowy, w przypadku kiedy
          poprostu odwiedzamy jakąś witrynę to najczęściej po słowie 
          <em>GET</em> występuje ukośnik (<strong>/</strong>). Serwery wówczas
          interpretują to, że żądanie dotyczy głównie pliku <em>index.html</em>
          zapisanego w katalogu przypisanym na serwerze do danej witryny.
        </p>
        <p>
          Uwaga! Jeden serwer WWW, może utrzymać kilka jak nie kilkanaście lub
          kilkadziesiąt różnych stron internetowych. Wszystko zależy od jego
          ustawień oraz konfiguracji sprzętowej, która go utrzymuje. Dlatego też
          wiele stron może kierowanych pod jeden adres IP. Taka funkcjonalność
          nazywa się <strong>hostingiem</strong>.
        </p>
        <p>
          W naszym przypadku również żądamy głównego pliku tego hostingu. W
          nagłówku natomiast przekazujemy dane, które pomogą w uzyskaniu
          żądanych przez nas danych. Jest to jedna z cech protokołu HTTP. Dane
          (głównie do aplikacji, ponieważ statyczne strony rzadko interpretują
          jakieś dane) mogą być przekazywane jako rozwinięcie adresów jest to
          tak zwana <em>metoda GET</em> lub w postaci odrębnego pakietu danych
          poza widocznością dla zwykłego użytkownika - <em>metoda POST</em>.
          Przy użyciu <em>metody POST</em> najczęściej przesyłane są dane
          uzupełnionych formularzy na stronach WWW. Po danych przekazywanych
          aplikacji (w tym przypadku) wstepują już informacje kontrolne dla
          samego protokołu HTTP w linii <em>0022</em> (będę używał takich
          oznaczeń) występuje pole nagłówka 
          <code class="code-inline">Host:</code> zawiera ono nazwę hosta do,
          którego kierujemy nasze żądanie. Następne pole nagłówka to 
          <code class="code-inline">User Agent:</code>, to pole zawiera
          informacje jakiego programu klienckiego WWW używamy. Ta informacja
          jest zapisywana w plikach dziennika serwera wraz z adresem IP.
          Narzędzia takie jak <em>curl</em> lub podobny mu i bardziej
          powszechny <em>wget</em> pozwalają na zmianę tej wartości, za pomocą
          jednej opcji możemy podać się za np. program indeksujący jednej z
          wyszukiwarek. Trzecim polem jest rodzaje danych jakie może 
          zinterpretować, polecenie <em>curl</em> to służy głównie pobieraniu
          treści więc
          rzadko kiedy je interpretuje. Wyjątkiem może być omawiany przez nas
          przykład. Ostatnim pole jest znak nowego wiersza, który kończy
          nagłówek żądania. Teraz następuje jego przesłanie i oczekiwnaie na
          odpowiedź serwera.  
        </p>
        <p>
          W przypadku odpowiedzi jak możemy zauważyć przesyłanych jest wiele
          nagłówków przedstawiających pojedyncze pola. Nie będe ich tutaj
          wszystkich opisywał, jednak na uwagę zasługuję jedna informacja,
          która została wcześniej pominięta. Otóż, w polu metody żądania lub
          w pierwszym naglówku odpowiedzi znajduje się wykorzystywana w
          transmisji wersja protokołu HTTP. Wersja 1.1 jest obecnie
          standardem, jednak obecnie w stanie proponowanych standardów są
          wersje 2 i 3. Seria nagłówków odpowiedzi kończy się w taki sam 
          sposób jak w przypadku nagłówka żądania, znakiem nowego wiersza.
          Następnie odebrany zostaje pakiet danych a dane w nim zawarte
          trafiają do użytkownika.
        </p>
        <p>
          Tak moglibyś to wywnioskować na podstawie danych diagnostycznych
          zwróconych przez program <em>curl</em>. Wygląda to nieco inaczej, ale
          różnice występują tylko w przedstawieniu danych. Otóż otrzymując
          pakiet protokołu HTTP, nie ma w nim podziału na sekcje nagłówka i
          danych. Nie ma także dwóch odrębnych pakietów. Wszystko spakowane
          jest w jednej paczce, a <em>curl</em> na podstawie znaku nowego
          wiersza jest jedynie oddzielić te dane.
        </p>
        <p>
          Innym sposobem na wejście interakcje np. z protokołem HTTP jest
          wykorzystanie zapomnianego już programu <strong>Telnet</strong>.
          <em>Telnet</em> kiedyś służył do tego do czego służy teraz 
          protokół SSH. Do zdalnego połączenia się z powłoką.
          Telnet sam w sobie również jest protokołem, obecnie  rzadko
          jest spotykany w swojej pierwotnej formie, chyba że w postaci
          lokalnej konsoli w systemach wbudowanych.
        </p>
<pre class="code-block">
xf0r3m@immudex:~$ telnet example.org 80 &gt; telnet.log
Trying 93.184.216.34...
Connected to example.org.
Escape character is '^]'
GET / HTTP/1.1
Host: example.org

HTTP/1.1 200 OK
Age: 126394
Cache-Control: max-age=604800
Content-Type: text/html; charset=UTF-8
Date: Wed, 23 Aug 2023 11:28:50 GMT
Etag: "3147526947+ident"
Expires: Wed, 30 Aug 2023 11:28:50 GMT
Last-Modified: Thu, 17 Oct 2019 07:18:26 GMT
Server: ECS (dcb/7F7F)
Vary: Accept-Encoding
X-Cache: HIT
Content-Length: 1256
...
</pre>
        <p>
          Po wielokropku występuje już tylko kod HTML strony. Polecenie
          <code class="code-inline">telnet</code> wymaga portu, pod który
          należy się podłączyć. Aby otrzymać odpowiedź musimy metodę
          (<code class="code-inline">GET</code>), ewentualne dane/żądany plik
          (<code class="code-inline">/</code>), wersje protokołu
          (<code class="code-inline">HTTP/1.1</code>) w drugiej lini nagłówka
          należy podać nazwę hosta
          (<code class="code-inline">Host: example.org</code>), ze względu na
          to aby serwer WWW wiedział z jakiej witryny przesłać odpowiedź.
        </p>
        <p>
          Protokół jest może trochę mało interaktwny przy takim połączeniu, ale
          np. usługi pocztowe są już bardziej skore do <em>rozmowy</em>.
        </p>
        <h2 id="10.2.networkservers">10.2. Serwery sieciowe</h2>
        <p>
          W dystrybucjach Linuksa możemy napodkać wiele serwerów, niektóre z
          nich działają w oparciu o sieć i oczekują zdarzeń pochodzących od
          zdalnych użytkowników. Serwery wewnątrz systemów to dość niszowa
          grupa, do których zalicza się tylko kilka demonów np. <em>cron</em>.
          Dlatego w mowie potocznej przyjęło się, że mówiąc o serwerach mamy
          na myśli serwery sieciowe. Poniżej znajduje się lista rodzajów
          serwerów wraz kilkoma przykładmi oprogramowania.
        </p>
        <ul>
          <li><strong>Serwery WWW:</strong> - <em>Apache</em>, <em>Nginx</em></li>
          <li><strong>Serwery pocztowe:</strong> - SMTP: <em>Postfix</em>,
              <em>Exim</em>; POP3/IMAP: <em>dovecot</em></li>
          <li><strong>Serwery plików:</strong> - CIFS (udziały Windows):
              <em>Samba</em>; FTP: <em>vsftpd</em>;
              NFS: <em>nfs-kernel-server</em></li>
          <li><strong>Serwery zdalnego dostępu:</strong> - SSH: 
	            <em>openssh</em>; RDP: <em>xrdp</em>.</li>
          <li><strong>Serwery sieciowe:</strong> - DHCP:
              <em>isc-dhcp-server</em>, <em>dnsmasq</em>; DNS:
              <em>bind9</em>, <em>dnsmasq</em></li>
          <li><strong>Usługa zdalnego wywołania procedury (RPC)</strong></li>
        </ul>
        <p>
          Aby bardziej zaznajomić się z serwerami sieciowymi, omówimy sobie
          po krótce jeden z nich. Z powyższej listy najciekawszym z nich
          jest znana implementacja protokołu SSH - <strong>openssh</strong>.
          Implementacji protokołu SSH jest
          kilka, jednak ta jest w najpowszechniejszym użytku obecna jest nawet
          w najnowszych wersjach MS Windows 10.
        </p>
        <h2 id="10.3.openssh">10.3. Serwer bezpiecznej powłoki - implementacja openssh</h2>
        <p>
          Demony sieciowe zawyczaj skupiają się na czynnościach wokół protokołu,
          który obsługują. Implementacja <em>openssh</em> ma za zadanie
          zapewnienie solidnego poziomu bezpieczeństwa zarówno dla zdalnej
          powłoki, transferu plików jak i innych połączeń za pomocą 
          <em>proxy</em> czy <strong>tunelowania</strong>.
        </p>
        <h3 id="10.3.1.sshcommand">10.3.1. Aplikacja klienta - polecenie ssh</h3>
        <p>
          Za pomocą polecenia <em>ssh</em> mamy dostęp do większości cudów
          jakie oferuje ta implementacja. Najprostszym jej wywołaniem jest
          podanie nazwy użytkownika następnie adresu zdalnego hosta, z którym
          chcemy się połączyć. Obie te wartości połączone są ze sobą za pomocą
          <em>małpy</em> (<strong>@</strong>). Po poprawnym znalezieniu hosta
          i połączeniu z jego demonem SSH (będzie o nim za chwile), zostaniemy
          poproszeni o hasło. Jeśli łączymy się z serwerem po raz pierwszy,
          Zostanie nam wyświetlona informacja na temat, że nie można
          zweryfikować autentyczności hosta. 
        </p>
<pre class="code-block">
xf0r3m@immudex:~$ ssh -p 2022 searx.morketsmerke.org
The authenticity of host '[searx.morketsmerke.org]:2022 ([82.117.231.222]:2022)' can't be established.
ECDSA key fingerprint is SHA256:ghhvjaz6T/qcsX9TiWN4UEV4fuiv6oqHxsD1bGB+40c.
Are you sure you want to continue connecting (yes/no/[fingerprint])? yes
Warning: Permanently added '[searx.morketsmerke.org]:2022,[82.117.231.222]:2022' (ECDSA) to the list of known hosts.
</pre>
        <p>
          W przypadku protokołu SSH, serwer musi się przedstawić za każdym
          razem gdy nawiązujemy z nim połączenie. Jeśli jest pierwsze
          połączenie z tym serwerem, to na komputerze klienta nie ma jeszcze
          danych autentykacji serwera (bez wdawania sie w zawiłe,
          kryptograficzne szczegóły) wówczas musimy się upewnić we własnym
          zakresie czy jest rzeczywiście ten serwer, z którym chcemy się
          połączyć, a nie np. próba wyłudzenia hasła. Po wyświetleniu się tego
          komunikatu zostaniemy zapytaniu czy chcemy kontynuować, jeśli
          odpowiedź jest twierdząca to dane autentykacyjne serwera zostaną
          zapisane w plikach na naszym komputerze i przy kolejnej próbie
          logowania poproszeni zostaniem wyłącznie o hasło.
        </p>
<pre class="code-block">
xf0r3m@immudex:~$ ssh -p 2022 searx.morketsmerke.org
xf0r3m@searx.morketsmerke.org's password:
</pre>
        <p>
          Na powyższym przykładzie podałem opcję
          <code class="code-inline">-p</code>, która pozwala na wkazanie
          nie standardowego portu (standardowy port to 22/TCP).
          Na tym przykładzie pominąłem, użytkownika. Jeśli go pominiemy
          <em>ssh</em> jako użytkownika przyjmie tego, który wydał polecenie.
        </p>
        <p>
          Domyślnie podczas logowania używa się haseł, ale jeśli mamy pod sobą
          kilka maszyn i wpisywanie do każdej hasła może być męczące. SSH daje
          nam możliwość uwierzytelnienia za pomocą kluczy kryptograficznych.
          Nie będę zagłębiał się charkterystykę kluczy kryptograficznych, ale
          istnieje możliwość wygenerowania pary plików (klucza publicznego oraz
          prywatnego), następnie załadowanie jednego z nich do maszyn, którymi
          administrujemy. Podczas generowanie pary kluczy, będzie można podać
          hasło chroniące klucz prywatny. Najlepiej, aby dodać to hasło.
          Wówczas będziemy mieć jedno hasło do wielu maszyn (niezależne, bo
          nawet jeśli główny administrator serwera zmieni nam hasło, to jeśli
          klucz nadal będzie w systemie, to nadal będziemy mieli możliwość
          zalogowania się do systemu.).
        </p>
        <p>
          Aby wygenerować klucze wydajemy następujące polecenie. Dodam tylko,
          że obecnie będziemy generować klucze algorytmu kryptograficznego
          <strong>RSA</strong>, są one domyślne dla SSH. Choć, nie które z
          systemów mogą ich nie przyjmować i wymagać innych rozdzajów. Więcej
          na temat generowanie kluczy znajduje się na stronie podręcznika 
          polecenia <strong>ssh-keygen</strong>.
        </p>
<pre class="code-block">
xf0r3m@immudex:~$ ssh-keygen
Generating public/private rsa key pair.
Enter file in which to save the key (/home/xf0r3m/.ssh/id_rsa):
Enter passphrase (empty for no passphrase):
Enter same passphrase again:
Your identification has been saved in /home/xf0r3m/.ssh/id_rsa
Your public key has been saved in /home/xf0r3m/.ssh/id_rsa.pub
The key fingerprint is:
SHA256:7N+WSF5OuOXiGh0hWr3hjMClfssGrn7Ofh8igPYpqcw xf0r3m@immudex
The key's randomart image is:
+---[RSA 3072]----+
|        .        |
|     . o .       |
|      + o +      |
|   . . = = +     |
|  o . + S =.     |
| . o + = oo.+    |
|  o o o BooO .   |
|o. . o.o.+=o=    |
|.E .o++..++o.    |
+----[SHA256]-----+
</pre>
        <p>
          Polecenie wydajemy bez żadnych opcji chcąc wygenerować parę kluczy 
          RSA. Ścieżkę zapisu klucza równięż pozostawiamy bez zmian, oczywiście
          jeśli mamy w planach ustawienie hasła klucz prywatnego. Jeśli nie
          to może warto było by wskażać jakie bezpieczne miejsce np.
          szyfrowaną partycję lub dysk.  Posiadając parę kluczy możemy je
          załadować do docelowych systemów.
        </p>
<pre class="code-block">
xf0r3m@immudex:~$ ssh-copy-id xf0r3m@172.26.38.226
/usr/bin/ssh-copy-id: INFO: Source of key(s) to be installed: "/home/xf0r3m/.ssh/id_rsa.pub"
/usr/bin/ssh-copy-id: INFO: attempting to log in with the new key(s), to filter out any that are already installed
/usr/bin/ssh-copy-id: INFO: 1 key(s) remain to be installed -- if you are prompted now it is to install the new keys
xf0r3m@172.26.38.226's password:

Number of key(s) added: 1

Now try logging into the machine, with:   "ssh 'xf0r3m@172.26.38.226'"
and check to make sure that only the key(s) you wanted were added
</pre>
        <p>
          Klucze możemy załadować do systemu za pomocą polecenia
          <code class="code-block">ssh-copy-id</code>. Działanie tego polecenia
          widzimy na powyższym przykładzie. To polecenie przyjmuje również
          te same opcje jak w przypadku polecenia <em>ssh</em>. Jeśli podaliśmy
          inną ścieżkę podczas generowania klucza to za pomoca opcji
          <em>-i</em> możemy skazać plik klucza publicznego 
          (plik z rozszerzeniem .pub). Natomiast jeśli chcemy się uwierzytelnić
          za pomocą klucza to przy opcji <em>-i</em> polecenia <em>ssh</em>
          podajemy plik klucza prywatnego (bez rozszerzenia).
        </p>
        <h3 id="10.3.2.sshd">10.3.2. Demon serwera - sshd</h3>
        <p>
          Jak możemy zdawać sobie z tego sprawę z demona nie korzysta się jak
          z aplikacji klienckiej. Nie wydajemy poleceń, żeby go uruchomić.
          Oczywiście możemy to zrobić, ale normalnie tego się nie robi. Demony
          uruchamiane są za pomocą plików jednostek (<em>systemd</em>). Dlatego,
          że obsługa demona
          różni się od obsługi klienta, w tym podrozdziale skupimy się głównie
          zmianie konfiguracji demona <em>openssh</em>, jednak nie będziemy się
          skupiać na wszystkich możliwych opcjach poniżej przedstawię tylko
          te, które mogą nam się przydać na obecnym poziomie
          <em>wtajemniczenia</em>. Opisy tych opcji przybliżą nam również nie
          co bardziej działanie samego SSH.
        </p>
        <p>
          Konfiguracja demona <em>openssh</em> znajduje się w pliku:
          <em>/etc/ssh/sshd_config</em>. W tym pliku wiele opcji jest
          wyłaczonych (ujęte w komentarz), oznacza to, że przechowują one
          domyślne wartości. Jeśli więc
          chcemy coś zmienić w konfiguracji daemona SSH, musimy usunąć
          początkowy symbol komentarz i zmienić wartość opcji.
        </p>
        <ul>
          <li><strong>Port</strong> - Czasami, aby nieco ukryć przed wścibstwem
              zmienia się domyślny port, aby nie każdy wiedział, że można się
              do tego systemu za pomocą SSH podłączyć. Obcnie nie przynosi to
              rezultatów. Bezpieczeniej jest wyłączyć logowanie za pomocą
              haseł.</li>
          <li><strong>LoginGraceTime</strong> - oczekiwanie na wpisanie hasła.
              Podczas podłączania się do serwera SSH oczekuje na wpisanie hasła
              i ten czas ma swój limit. Domyślnie są to 2 minuty. Po tym czasie
              mimo prawidłowo podanego hasła połączenie zostanie zerwane i
              trzeba się będzie logować ponownie.<li>
          <li><strong>PermitRootLogin</strong> - Zezwolenie na logowanie się
              jako superużytkownik. Jeśli dostęp do tego konta nie jest jakos
              bardzo potrzebny to możemy ustawić wartość tego pola na
              <em>no</em>. Ze względu na to, że znana jest jego potoczna nazwa
              często jego konto pada ofiarą ataków siłowych, skupionych na
              próbach odgadnięcia hasła (Przeciwdziałanie tego typu atakom,
              zostanie przedstawione w tym rozdziale).</li>
          <li><strong>PasswordAuthentication</strong> - zmiana wartości tej
              opcji na <em>no</em> zabroni używania haseł do logowania się.
              W użyciu pozostaną wówczas same klucze. Lepiej nie zmieniać tej
              opcji, do póki nie załadujemy swojego klucza.</li>
          <li><strong>X11Forwarding</strong> - dość ciekawa opcja pozwala
              uruchomić program okienkowy na serwerze, kontrolując go z
              poziomu klienta. Proces programu uruchomiany jest na serwerze,
              okno (np. przeglądarki, uruchamiane jest na komputerze klienta).
              Pozwala to na konfiguracje, aplikacji wymagającej połączenia z
              tej samej sieci co serwer lub z poziomu pętli zwrotnej, co nie
              zawsze jest fizycznie możliwe (serwery VPS). Uruchomienie takiego
              programu wymaga podania użycia przez klient opcji <em>-Y</em> lub
              <em>-X</em>.</li>
        </ul>
        <p>
          Oczywiście opcje z omawianego przez nas pliku są opisane na stronie
          podręcznika <code class="code-inline">man 5 sshd_config</code>. Po
          zapisaniu zmian w pliku konfiguracyjnym demona SSH, należy uruchomić
          go ponownie aby nasze zmiany zaczęły działać.
        </p>
<pre class="code-block">
xf0r3m@immudex:~$ sudo systemctl restart ssh.service
</pre>
        <h3 id="10.3.3.fail2ban">10.3.3. Zabezpieczenie fail2ban</h3>
        <p>
          Wystawiając otwarty port 22/TCP czyli SSH, możemy zauwać w plikach
          dzienników systemowych (plik <em>/var/log/btmp</em> - polecenie
          <em>lastb</em> - nieudane próby logowania) wiele prób logowania się,
          odgadywania nazwy użytkownika oraz hasła. Możemy wpaść na pomysł
          wyłączenia wyłaczenia logowania za pomocą hasła. Jest to pewne
          rozwiązanie, jednak:
        </p>
        <ul>
          <li>Logowanie wyłącznie za pomocą kluczy spowoduje, że połączenie z
              serwerem będzie możliwe z tylko i wyłącznie z komputerów,
              na których znajduje się klucz. Zdaje sobie z tego sprawę, że może
              być to dobre rozwiązanie. Oczywiście bezpieczeństo to niewygoda.
              Poza tym klucze można kopiować i
              przenościć, o ile zostały podjęte jakieś działania mające na celu
              zabezpieczenie klucza prywatnego.</li>
          <li>Ta metoda nie rozwiązuje pojawiających się w logach prób
              logowania. Mimo iż serwer jeśli nie podamy mu odpowiedniego 
              klucza
              zwróci informacje o braku dostępu. To sowiste pukanie do drzwi,
              gdzie nasz serwer odpowiada: "Nieczynne! Remanent." ;)</li>
        </ul>
        <p>
          Co jeśli serwer ma być podpięty do domeny, i umożliwiać logowania
          dużej ilości użytkowników? Wtenczas administrator będzie musiał
          spędzić trochę kariery na dodaniu tych wszystkich kluczy. A to
          nie koniec, ponieważ rotacje pracowników zdarzają się dość często.
          W tym wypadku nie możemy zablokować logowania za pomocą hasła.
        </p>
        <p>
          Istnieje kompromis między logowaniem za pomocą hasła a ograniczeniem
          odgadywania dostępu przez różnego rodzaju automaty. Jest nim
          <strong>fail2ban</strong>. Jest to usługa monitorująca próby
          uwierzytelnienia się i po przekroczeniu nie udanych prób odcinająca
          dostęp do usługi na jakiś czas. Usługa ta opiera swoje działanie na
          monitorowaniu komunikatów diagnostycznych oraz dynamicznym tworzeniu i
          usuwaniu reguł zapory sieciowej.
        </p>
        <p>
          Uwaga! Na Debianie fail2ban nie posiada w swoich zależnościach
          pakietu zapory, dlatego też należy pamiętać, żeby dopisać go podczas
          instalacji programu. Pakiet <em>fail2ban</em> znajduje się w
          repozytoriach.
        </p>
        <p>
          Aby <em>banowanie</em> miało skutek konfiguracja narzędzia musi
          znaleźć się w pliku <em>/etc/fail2ban/jail.conf</em>. Domyślnie ten
          plik zawiera bardzo dużo różnych opcji, sekcji oraz wartości.
          Poniżej umieściłem minimalną działającą konfigurację narzędzia dla
          SSH. <em>Fail2ban</em> może rownież działać z innymi usługami.
        </p>
<pre class="code-block">
[INCLUDES]
before = paths-debian.conf

[DEFAULT]
protocol = tcp
chain = &lt;known/chain&gt;
port = 0:65535

banaction = iptables-multiport
action = %(banaction)s[port="%(port)s", protocol="%(protocol)s", chain="%(chain)s"]

[sshd]
enabled = true
port = 2022
filter = sshd
maxretry = 3
findtime = 5m
bantime = 30m
backend = systemd
</pre>
        <p>
          W piewszej sekcji (<code class="code-inline">[INCLUDES]</code>)
          znajduje się jedna opcja wskazująca plik z konfiguracją scieżek
          przeznaczoną
          dla wybranej dystrybucji. Każda dystrybucja może zawierać w różnych
          miejscach komponenty potrzebne mu do działania stąd ten plik. Sama
          sekcja zawiera może zawierać dodatkowe konfiguracje, które mogą być
          interpretowane przez program przed interpretacją sekcji przeznaczonej
          dla wybranej usługi (opcja <code class="code-inline">before</code>).
          Sekcja <code class="code-inline">[DEFAULT]</code> rozpoczyna się
          od określenia domyślnej akcji podejmowanej podczas nadużycia oraz
          jej konfiguracji. Jak możemy się domyśleć po wartości opcji
          <code class="code-inline">banaction</code>, wstrzymanie możliwości
          logowania będzie opierać się reguły <em>iptables</em>. Sama wartość
          tej opcji jest wskazaniem pliku w katalogu
          <em>/etc/fail2ban/action.d</em>. W tym pliku możemy zobaczyć jak na
          podstawie wykonywanych przez <em>fail2ban</em> czynności układane są
          reguły <em>iptables</em>. Sekcja
          <code class="code-inline">[DEFAULT]</code> zawiera podsekcje
          dedykowane dla konkretnych usług. W naszym przypadku jest to demon
          SSH. W sekcji usługi znajdują się opcje definujące kryteria dotyczące
          blokowania dostępu podczas nadużycia. Zatem kolejno: 
        </p>
        <ul>
          <li><strong>enable</strong> - załączenie kontrolowania oraz
            blokowanie w przypadku nadużyć</li>
          <li><strong>port</strong> - port pod którym uruchomiona jest
            monitorowana usługa na naszym komputerze.</li>
          <li><strong>filter</strong> - jest wskazanie zbioru wzorców w
            postaci wyrażeń regularnych. <em>Fail2ban</em> wykorzystuje usługi
            dzienników systemowych do wykrywania prób uwierzytelnienia. Plik
            odpowiadający wartości tej opcji znajduje się w katalogu
            <em>/etc/fail2ban/filter.d</em>.</li>
          <li><strong>maxretry</strong> - ilość możliwych prób, przed
            zablokowaniem.</li>
          <li><strong>findtime</strong> - ilość czasu jaką należy odczekać od
            między próbami, aby uzyskać z powrotem wszystkie próby zdeklarowane
            w opcji <em>maxretry</em>. Wygląda to w ten sposób, że możemy
            po nieudanej próbie uwierzytelnienia zrezygnować z dalszych prób,
            ale jeśli spróbujemy ponownie przed upłynięciem tego czasu, to
            dalej liczba prób pozostanie nie zmieniona (pozostaną 2 próby).</li>
          <li><strong>bantime</strong> - ilość czasu blokady dostępu do usługi.</li>
          <li><strong>backend</strong> - źródło komunikatów logowania. Bez
            tej wartości sama usługa <em>fail2ban</em> nie wystartuje.
            <em>Systemd</em> może być dobry źródłem takich informacji.</li>
        </ul>
        <p>
          Tyle informacji wystarczy demonowi <em>fail2ban</em> do monitorowania
          i także przeciw działania próbą uzyskania dostępu do powłoki. Jeśli
          zmieniamy coś w plikach konfiguracyjnych to wówczas należy pamiętać
          o restartcie usługi. Po zastosowaniu tego rozwiązania będzie 
          zauważymy znaczny spadek nieudanych prób logowania. Każdy ma 3 próby
          jeśli wszystkie się nie powiodą adres IP, z którego nasz świadek
          jehowy puka zostanie zbanowany na 30 minut. Pozostaje również
          możliwość logowania się za pomocą hasła. 
        </p>
        <p>
          Nie ma metody, która jednoznacznie rozprawiwła by się z próbami
          uzyskania dostępu do SSH. Można za pomocą informacji w internecie
          ustawić czas blokady na stałe lub zwiększać go jeśli trafi się
          naprawdę natrętny osobnik, albo odciąć osiągalność demona SSH z
          internetu i wymagać do tego połączeń VPN.
        </p>
        <h3 id="10.3.4.othersshusage">10.3.4. Pozostałe metody użycia SSH</h3>
        <p>
          Najpopularniejsza implementacja protokołu bezpiecznej powłoki, to
          nie tylko jakby sama nazwa wskazywała dostęp do powłoki systemu w
          bezpieczny sposób, ale także bezpieczne przesyłanie plików za pomocą
          SSH. 
        </p>
        <p>
          Pierwszym z nich jest <strong>SCP</strong>, który tak jakby zwykłym
          poleceniem <em>cp</em>, ale przesyłającym plik za pomocą szyfrowanago
          kanału i rozszerzającym scieżki o dowolne Uniksy w internecie.
          Istotnym czynnikiem korzystania z SCP jest fakt, że musimy niestety
          znać zdalną ściezke dostępu do pliku.
        </p>
<pre class="code-block">
xf0r3m@immudex:~$ scp test.txt user@server:/usr/share/doc/test/test.txt
</pre>
        <p>
          Wraz z SCP dostępne jest bardziej interaktywne polecenie, które jest
          też protokołem - <strong>SFTP</strong>. W informatyce jest wiele jest
          rozwiązań tego skrótu, nas będzie interesować wyłącznie
          <em>SSH File Transfer Protocol</em>. Połaczenie SFTP realizowane jest
          na takiej same zasadzie jak SSH. Podajemy nazwę polecenia użytkownika
          oraz host, po jego zgłoszeniu się podajemy hasło. Wówczas zostaniem
          na zwrócony prompt <code class="code-block">sftp&gt;</code>.
        </p>
<pre class="code-block">
xf0r3m@vm-3eb3a0e:~$ sftp -P 2022 xf0r3m@192.168.122.76 
xf0r3m@192.168.122.76's password: 
Connected to 192.168.122.76
sftp&gt;
</pre>
        <p>
          Na powyższym przykładzie użyłem opcji 
          <code class="code-inline">-P</code>, która w przypadku SCP (to
          polecenie formalnie korzysta SFTP) oraz SFTP służą do określania
          portu. Opcja <em>-p</em>, służy do zachowania praw własności
          przesyłanych plików. Przy czym <em>-p</em> przy polecenie
          <em>ssh</em> służy określania portu zdalnego demona SSH.
          Bywa to czasami bardzo irytujące.
        </p>
        <p>
          Po zwróceniu znaku zachęty do dyspozycji mamym dostęp do części
          podstawowych poleceń takich jak: <em>ls</em>, <em>cd</em>, <em>mkdir</em>.
          Dodatkowo te wymienione i kilka dodatkowych mają swój <em>lokalny</em>
          odpowiednik poprzedzony literą <strong>l</strong> za pomocą tych
          poleceń możemy poruszać się po lokalnym systemie plików, bez
          przerywania połączenia na potrzeby na przykład, zmiany katalogu.
        </p>
        <p>
          Wymiana danych w przypadku polecenia SFTP, odbywa się poprzez
          polecenia takie jak: <strong>get</strong> (pobierz) lub
          <strong>put</strong>
          (wyślij), każde z tych poleceń zawiera opcję <em>-r</em> lub
          <em>-R</em>, co oznacza rekurencję. Niektóre implementacje tego
          protokołu wymagają, aby katalog istniał przed rekurencyjnym
          przesłaniem danych. Inne dostępne polecenia są opisane na stronie
          podręcznika: <code class="code-inline">man sftp</code>.
        </p>
        <p>
          Poza bezpieczym przesyłaniem plików pozostało jeszcze umieszczenie
          innego połączenia sieciowego wewnątrz połączenia SSH. Takie
          działanie nazywane jest <strong>tunelowaniem</strong>. Połączenie
          pierwotne pozwala na przenoszenie wewnątrz swoich pakietów danych
          wewnątrz innego połączenia. Mozliwości tuneli tworzonych za pomocą
          SSH 
          w implementacji <em>openssh</em> znajdują się w innym moim materiale:
          <a href="https://morketsmerke.github.io/articles/terminallog/laboratorium_sieci_VPN.html">Laboratorium sieci VPN</a>.
          Dodam tylko, że połaczenie SSH jest dość wrażliwe (jak każde
          zapewniające jakiś standard bezpieczeństwa) na jakość połączenia
          jeśli połączenie jest niewykorzystywane może zostać łatwo zerwane.
          Należy mieć na uwadze, że tunele SSH otwierają sesje powłoki, więc
          musimy posiadać dostęp do użytkownika, który może uruchomić dowolną
          powłokę, może być to równiez program, który będzie działać po
          zalogowaniu do momentu zakończenia połączenia, jeśli jest to zwykła
          powłoka np. BASH, to wówczas trzeba pomyśleć o prostym skrypcie,
          którego zadaniem będzie nieskończone przesyłanie danych wypisywanie
          czegoś w połowce (Pisanie skryptów powłoki, nie będzie obowiąkowym
          rodziałem tego materiału, dlatego umieszczę go na samym końcu.
          Możemy przejść do niego nawet teraz po skończeniu tego
          podrozdziału) lub użycie programu <strong>tmux</strong>, który jest
          multiplekserem terminala dodatkowo pozwala na podtrzymania połączenia
          SSH.
        </p>
        <h2 id="10.4.inetd">10.4. Demony internetowe - inetd, xinetd</h2>
        <p>
          Niektóre małe usługi sieciowe takie jak np. <em>telnetd</em> -
          demon usługi <em>telnet</em> czy klasyczna usługa FTP oraz wiele
          innych posiadają te same lub podobne wymagania dotyczące obsługi
          sieci, zatem żeby nie implementować tego samego kodu. Twórcy tych
          usług stworzyli superdemona on nazwie <strong>inetd</strong> i 
          najprościej rzecz ujmując jego zadaniem jest obsługa połączeń:
          otwieranie portów oraz przekierowywanie połączeń już do właściwych
          usług.
        </p>
        <p>
          Na przestrzenii lat działania tego rozwiązania powstała nowsza
          implementacja <strong>xinetd</strong> posiadająca lepsze mechanizmy
          obsługi oraz kontroli połączeń.
        </p>
        <p>
          Obecnie rzadko spotyka się działający demon <em>inet</em> lub
          <em>xinetd</em>, został on wyparty przez jednego z demonów
          <em>systemd</em>,
          a demony które obsługiwał obecnie posiadają własne implementacje
          obsługi połączeń, z biegiem lat rozszerzały swoje możliwości i
          finalnie stały się bardziej samodzielne. Wiele życzenia pozostawiaja
          również kwestie bezpieczeństwa, chociaż wiele rzeczy zostało
          poprawionych między oryginalną implementacją a <em>xinetd</em>.
        </p>
        <p>
          Inną równie archaiczną rzeczą jest <em>wrapper</em> TCP w postaci
          demona <strong>tcpd</strong>. Jego działanie przypomina nieco
          działanie filtra sieciowego. Był on wykorzystywany jeszcze zanim
          takie rozwiązania jak <em>iptables</em> zostały na stałe wdrożone
          jako swoisty standard i podstawowy poziom ochrony. Zanim ruch z
          <em>inetd</em> trafił do właściwego demona przechodził przez tą
          usługę. <em>Tcpd</em> rejestrował połączenie następnie konfrontował
          je z listami dostępu <em>/etc/hosts.allow</em> lub 
          <em>/etc/hosts.deny</em>, na podstawie informacji ustalonych przez
          <em>wrapper</em> ruch był dopuszczany do właściwego procesu lub nie. 
        </p>
        <p>
          Plikowe listy kontroli dostępu mogą być wykorzystywane w 
          dystrybucjach klasy <em>enterprise</em>, do ustalenia dostępu do
          wybranych
          komponentów systemu. Takim przykładem może być dostęp do <em>cron</em>
          (harmonogramu zadań). Więcej informacji znajduje się pod tym adresem:
          <a href="https://morketsmerke.github.io/articles/terminallog/RedHat_-_RHCSA.html#8.2.1.scheduleaccesscontrol">https://morketsmerke.github.io/articles/terminallog/RedHat_-_RHCSA.html#8.2.1.scheduleaccesscontrol</a> 
        </p>
        <h2 id="10.5.diagnostictools">10.5. Narzędzia diagnostyczne</h2>
        <p>
          Podczas analizownia działania protokołu HTTP, na samym końcu
          wspomniałem o innym sposobie połączenia się z serwerem WWW przy
          użyciu programu <em>telnet</em>. Program ten może być programem
          diagnostycznym w podczas sprawdzania uruchomienia i dostępności
          usługi. W większości dystrybucji program <em>telnet</em> trzeba
          będzie zainstalować z repozytorium. Jednak możemy w systemie
          naleźć co najmniej jedno narzędzie, które jest nam wstanie zwrócić
          jakieś informacje na temat usług sieciowych takim program jest
          już omawiany <strong>ss</strong>.
        </p>
        <p>
          Wynik działania programu <em>ss</em>, był już omawiany podczas
          omawiania transmisji TCP w warstwie transportowej. Ale poniżej
          znajdują się najważniejsze (dla celów diagnostycznych) opcje.
        </p>
        <ul>
          <li><strong>-t</strong> - informacje o połączeniach TCP</li>
          <li><strong>-u</strong> - informacje o połączeniach UDP</li>
          <li><strong>-l</strong> - wyświetla informacje o portach oczekujących
            na połączenie (nasłuchujących).</li>
          <li><strong>-a</strong> - wyświetla wszystkie dostępne połączenia w
            systemie</li>
          <li><strong>-n</strong> - wyłącza rozwiązywanie nazw (przyspiesza to
            wynik działania programu jeśli serwery DNS nie odpowiadają).</li>
          <li><strong>-4, -6</strong> - wyświetlenie informacji dotyczących
            protokołu IPv4 lub IPv6.</li>
        </ul>
        <h3 id="10.5.1.lsofcommand">10.5.1. Polecenie lsof</h3>
        <p>
          Jesli pamiętamy z rozdziału 8, polecenie <strong>lsof</strong> służy
          do wyświetlania otwartych plików w systemie. Z jego pomocą możemy
          również wyświetlić połączenia realizowane w systemie. Rola tego
          polecenia może przypominać <em>ss</em>, jednak polecenie <em>lsof</em>
          do działania w obrębie całego systemu wymagają uprawnień
          administratora, w przeciwnym razie polecenie wyświetli tylko i
          wyłącznie połączenia utworzne przez użytkownika, który wydał to
          polecenie. Aby móc wyświetlić połączenia sieciowe przy użyciu
          polecenia <em>lsof</em> należy użyć opcji <strong>-i</strong>, tak
          jak przedstawiono to na poniższym poleceniu.
        </p>
<pre class="code-block">
xf0r3m@vm-3d6b184:/media/xf0r3m/immudex_crypt0$ sudo lsof -i
COMMAND     PID    USER   FD   TYPE DEVICE SIZE/OFF NODE NAME
systemd       1    root   35u  IPv4  11469      0t0  TCP *:sunrpc (LISTEN)
systemd       1    root   36u  IPv4  11472      0t0  UDP *:sunrpc 
systemd       1    root   37u  IPv6  11475      0t0  TCP *:sunrpc (LISTEN)
systemd       1    root   38u  IPv6  11478      0t0  UDP *:sunrpc 
rpcbind     427    _rpc    4u  IPv4  11469      0t0  TCP *:sunrpc (LISTEN)
rpcbind     427    _rpc    5u  IPv4  11472      0t0  UDP *:sunrpc 
rpcbind     427    _rpc    6u  IPv6  11475      0t0  TCP *:sunrpc (LISTEN)
rpcbind     427    _rpc    7u  IPv6  11478      0t0  UDP *:sunrpc 
avahi-dae   476   avahi   12u  IPv4  13560      0t0  UDP *:mdns 
avahi-dae   476   avahi   13u  IPv6  13561      0t0  UDP *:mdns 
avahi-dae   476   avahi   14u  IPv4  13562      0t0  UDP *:33600 
avahi-dae   476   avahi   15u  IPv6  13563      0t0  UDP *:34773 
NetworkMa   675    root   26u  IPv4  14371      0t0  UDP vm-3d6b184.morketsmerke.org:bootpc-&gt;
DESKTOP-TMP2137.mshome.net:bootps 
cupsd       790    root    6u  IPv6  14463      0t0  TCP localhost:ipp (LISTEN)
cupsd       790    root    7u  IPv4  14464      0t0  TCP localhost:ipp (LISTEN)
cups-brow   860    root    7u  IPv4  15147      0t0  UDP *:631 
chronyd     883 _chrony    5u  IPv4  14538      0t0  UDP localhost:323 
chronyd     883 _chrony    6u  IPv6  14539      0t0  UDP localhost:323 
ssh       60722  xf0r3m    3u  IPv4 187934      0t0  TCP vm-3d6b184.morketsmerke.org:36440-&gt;
ip82-117-231-222.static.awhost.cloud:2022 (ESTABLISHED)
</pre>
        <p>
          Na powyższym przykładzie możemy zauważyć, że wyjście tego polecenia
          jest trochę bardziej podrasowanym wyjściem polecenia <em>ss</em>.
          Poza tym <em>lsof</em> daje nam możliwość przefiltrowania listy
          dostępnych połączeń. Ogólny format filtra wygląda następująco:
        </p>
<pre class="code-inline">
$ sudo lsof -i[wersja_IP][protokół]@[komputer]:[port]
</pre>
        <p>
          Oczywiście istnieje pełna dowolność w stosowaniu tych elementów, aby
          to pokazać przedstawię kilka użytecznych filtrów:
        </p>
<pre class="code-block">
xf0r3m@vm-3d6b184:/media/xf0r3m/immudex_crypt0$ sudo lsof -i4 -s TCP:LISTEN
COMMAND PID USER   FD   TYPE DEVICE SIZE/OFF NODE NAME
systemd   1 root   35u  IPv4  11469      0t0  TCP *:sunrpc (LISTEN)
rpcbind 427 _rpc    4u  IPv4  11469      0t0  TCP *:sunrpc (LISTEN)
cupsd   790 root    7u  IPv4  14464      0t0  TCP localhost:ipp (LISTEN)
</pre>
        <p>
          Powyższy przykład przestawia wyłącznie otwarte porty dla transmisji
          TCP. W tym przypadku uzyskanie stanu połączenia
          (<code class="code-inline">LISTEN</code>) wymaga podania dodatkowej
          opcji (<code class="code-inline">-s</code>) a ona ma swoją składnię
          dla wartości: <em>PROTOKOŁ:STAN</em>.
        </p>
<pre class="code-block">
xf0r3m@vm-3d6b184:/media/xf0r3m/immudex_crypt0$ sudo lsof -iTCP@searx.morketsmerke.org
COMMAND   PID   USER   FD   TYPE DEVICE SIZE/OFF NODE NAME
ssh     60722 xf0r3m    3u  IPv4 187934      0t0  TCP vm-3d6b184.mshome.net:36440-&gt;
ip82-117-231-222.static.awhost.cloud:2022 (ESTABLISHED)
</pre>
        <p>
          Ciekawy przypadek mamy tutaj. Ponieważ wśród połączeń TCP wyszukujemy
          hosta o konkretnej nazwie. Nie dostajemy informacji zwrotnej, że coś
          jest nie tak, wręcz przeciwnie uzyskujemy odpowiedź, na której
          nie widnieje nasza nazwa. Ta odpowiedź jest jak najbardziej
          prawidłowa.
          Adres <code class="code-inline">searx.morketsmerke.org</code> jest 
          odwzrowywany do 82.117.231.222, ale jeśli skorzystamy z zamiany 
          adresu IP na nazwę domenową wówczas otrzymamy taki oto wynik:
          <code class="code-inline">ip82-117-231-222.static.awhost.cloud</code>
          Więc jeśli adres <code class="code-inline">searx.morketsmerke.org</code>
          jest tożsamy z 
          <code class="code-inline">ip82-117-231-222.static.awhost.cloud</code>,
          co oznacza, że filtr jest jak najbardziej poprawny. Poniżej znajduje
          się ostatni już przykład:
        </p>
<pre class="code-block">
xf0r3m@vm-3d6b184:/media/xf0r3m/immudex_crypt0$ sudo lsof -i6UDP:323
COMMAND PID    USER   FD   TYPE DEVICE SIZE/OFF NODE NAME
chronyd 883 _chrony    6u  IPv6  14539      0t0  UDP localhost:323 
</pre>
        <h3 id="10.5.2.tcpdump">10.5.2. tcpdump</h3>
        <p>
          Innym narzędziem, dzięki któremu możemy śledzić ruch sieciowy jest
          <strong>tcpdump</strong>. Program ten działa na takiej zasadzie, że
          rejestruje każdy pakiet, który będzie pojawiać się na kartach
          sieciowych naszego komputera. Zakres działania urządzenia jest bardzo
          szeroki gdyż zbiera on zarówno pakiety aplikacji takie jak DNS czy
          inne jak komunikaty protokołu ARP.
        </p>
<pre class="code-block">
xf0r3m@vm-f48088c:/media/xf0r3m/immudex_crypt0$ sudo tcpdump 
tcpdump: verbose output suppressed, use -v[v]... for full protocol decode
listening on eth0, link-type EN10MB (Ethernet), snapshot length 262144 bytes
07:27:01.136396 IP DESKTOP-TMP2137.mshome.net.60948 &gt; 239.255.255.250.1900: UDP, length 175
07:27:01.238437 IP vm-f48088c.mshome.net.46759 &gt; DESKTOP-TMP2137.mshome.net.domain: 9527+ PTR? 250.255.255.239.in-addr.arpa.
(46)
07:27:01.244853 IP DESKTOP-TMP2137.mshome.net.mdns &gt; 224.0.0.251.mdns: 0 PTR (QM)? 250.255.255.239.in-addr.arpa.local.
(52)
07:27:01.247220 IP DESKTOP-TMP2137.mshome.net.mdns &gt; 224.0.0.251.mdns: 0 PTR (QM)? 250.255.255.239.in-addr.arpa.local.
(52)
07:27:01.250774 IP6 DESKTOP-TMP2137.morketsmerke.org.mdns &gt; ff02::fb.mdns: 0 PTR (QM)? 250.255.255.239.in-addr.arpa.local.
(52)
07:27:01.252918 IP6 DESKTOP-TMP2137.morketsmerke.org.mdns &gt; ff02::fb.mdns: 0 PTR (QM)? 250.255.255.239.in-addr.arpa.local.
(52)
07:27:02.142559 IP DESKTOP-TMP2137.mshome.net.60948 &gt; 239.255.255.250.1900: UDP, length 175
07:27:02.241843 IP DESKTOP-TMP2137.mshome.net.mdns &gt; 224.0.0.251.mdns: 0 PTR (QM)? 250.255.255.239.in-addr.arpa.local.
(52)
07:27:02.242557 IP6 DESKTOP-TMP2137.morketsmerke.org.mdns &gt; ff02::fb.mdns: 0 PTR (QM)? 250.255.255.239.in-addr.arpa.local.
(52)
</pre>
        <p>
          W moim przypadku zostało tylko złapanych kilka zapytań w przód (PTR)
          do usługi Multicast-DNS do serwera na którym hostuje maszynę
          wirtualną.
          Uruchamiając ten program od ręki, nie dokonując żadnych zmian w
          systemie wyłapiemy tylko pakiety adresowane do nas lub wysyłane
          przez nas. Teoretycznie powinniśmy przełączyć nasz interfejs w tryb
          nasłuchiwania (<em>promiscous mode</em>) możemy to zrobić za pomocą
          poniższego polecenia:
        </p>
<pre class="code-block">
xf0r3m@immudex:~$ sudo ip link set &lt;interfejs&gt; promisc on
</pre>
        <p>
          Niestety w obecnych konfiguracjach sieci to narzędzie może sprawdzić
          się głównie w sieciach bezprzewodowych do przechwycenia komunikatów
          warstwy łącza danych, chyba że sieć jest w pełni otwarta. Sieci
          kablowe są obecnie zbudowane na przełącznikach, a te powodują
          bezpośrednią komunikację w sieci, więc teoretycznie nie ma możliwości
          aby pakiety niezaadresowane do naszej karty do niej trafiły.
          Oczywście, tylko teoretycznie, bowiem inteligentne przełączniki
          (większość przełączników zarządzalnych) pozwalają na
          tzw. <em>port mirror</em>. Ustawienie portu w ten tryb oraz wybranie
          portu docelowego spowoduje, że to coś się pojawi na porcie docelowym
          trafi również to portu z ustawioną tą funkcją. Wówczas możemy
          monitorować ruch z jednego komputera, chyba że będzie kopiować ruch
          z portu, który łączy nasz przełącznik z pozostałą częścią sieci.
          Jednak wówczas będziemy monitorować jedynie ruch wychodzący i
          przychodzący do tego segmentu. Natomiast komunikacja między
          komputerami tego samego segmentu może pozostać dalej nie osiągalna.
        </p>
        <p>
          Nie mniej jednak jeśli już przyjdzie nam pracować z tym programem
          to musimy wiedzieć jego działania odbywa się na zasadzie filtrów.
          Filtry <em>tcpdump</em> składaja się (oczywiscię te proste) z
          elementów pierwotnych (z ang. <em>primitives</em>) oraz z operatorów
          takich jak <em>and</em>, <em>or</em> lub wykrzyknik 
          (<strong>!</strong>) powodujący negacje całego filtru. Poniżej
          znajduje się lista elementów pierwotnych:
        </p>
        <ul>
          <li><code class="code-inline">tcp</code> - transmisja TCP</li>
          <li><code class="code-inline">udp</code> - transmisja UDP</li>
          <li><code class="code-inline">ip4</code> - pakiety IPv4</li>
          <li><code class="code-inline">ip6</code> - pakiety IPv6</li>
          <li><code class="code-inline">port nr_portu</code> - port</li>
	        <li><code class="code-inline">host ip_komputera</code> - host</li>
          <li><code class="code-inline">net adres_podsieci</code> - sieć</li>
        </ul>
        <p>
          Tworząc filtr oparty na sieci jako wartość elementu
          <code class="code-inline">net</code> podajemy adres podsieci np.
          <em>192.168.8.0</em>. Poniższe polecenie wyświetli nam pakiety UDP,
          połączenia HTTPS oraz połączenia SSH.
        </p>
<pre class="code-block">
xf0r3m@immudex:~$ sudo tcpdump udp or port 443 or port 22
</pre>
        <p>
          To co zostało przedstawione powyżej to tylko mała część możliwosci
          filtrowania ruchu zbieranego przez <em>tcpdump</em>. Więcej
          informacji na temat filtrów możemy znaleźć na stronie podręcznika:
          <code class="code-inline">man pcap-filter</code> (<em>pcap</em> to
          biblioteka odpowidzialna zbieranie pakietów).
        </p>
        <p>
          <em>tcpdump</em> jest tekstowym odpowiednikiem podobnego narzędzia
          działającego w oknie - programu <strong>Wireshark</strong>.
        </p>
        <h3 id="10.5.3.netcat">10.5.3. Program netcat</h3>
        <p>
          Jest to program sieciowy o ogromnych możliwościach. Zwany często
          szwajcarskim scyzorykiem. Za jego pomoca możemy sprawdzić dostępność
          usługi, czy otworzyć port a następnie przekierować dane z polecenia
          na standardowe wyjście. Jesli ktoś się podłączy do tego i przekieruje
          standardowe wejście, na przykład za pomoca <strong>netcata</strong>.
          Wówczas klient będzie mógł wysyłać do serwera komunikaty tekstowe,
          które będą się wyświetlać w terminalu serwera. Serwer również będzie
          mógł wysyłać komunikaty wpisując bezpośrednio w to samo okno
          terminala, w którym działa proces. Na nasze szczęście program
          <em>nc</em> sam dokonuje takich przekierowań i wystarczy, że po
          jednej stronie uruchomimy serwer a po drugiej stronie podłączymy się
          do niego, wygląda to mniej więcej tak:
        </p>
<pre class="code-block">
xf0r3m@server:~$ nc -l 9595
test
test2
Server: To jest wiadomość testowa. Proszę o odpowiedź.
Klient: Odpowiedź na wiadomość testową.
xf0r3m@client:~$ nc -N 172.24.171.253 9595
test
test2
Server: To jest wiadomość testowa. Proszę o odpowiedź.
Klient: Odpowiedź na wiadomość testową.
</pre>
        <p>
          Na powyższym przykładzie zmieniłem nazwy hostów w znakach zachęty,
          aby było wiadomo kto jest kim w tej komunikacji. Do uruchomienia
          serwera na prawdę nie potrzeba wiele wystarczy podanie opcji
          <code class="code-inline">-l</code>, która powoduje nasłuchiwanie
          następnie ja podałem port, z tego co można wyczytać nas stronie
          podręcznika tego narzędzia, to że możemy pominąć opcję odpowiedzialną
          za wskazanie portu i podać sam numer portu oraz dodać do opcji adres
          IP interfejsu, na którym serwer ma nasłuchiwać w tym przypadku opcję
          opowiedzialną za ten funkcję też możemy pominąć.
        </p>
        <p>
          Opcja <code class="code-inline">-N</code> podana przez klienta
          powoduje, że jeśli wyślemy znak EOF (<em>End of File</em>, Ctrl+d),
          to połaczenie zostanie zakończone i serwerów również zakończy swoją
          pracę.
        </p>
        <p>
          Domyślnie otwieranymi portami są porty TCP, jeśli jednak chcemy użyć
          transmisji UDP należy podać <em>-u</em>.
        </p>
        <p>
          W przypadku programu <em>netcat</em> naprawdę warto zapoznać się z
          stroną podręcznika, po opisie wszystkich obsługiwanych opcji
          znajdują się przykłady zastosowania tego narzędzia.
        </p>
        <h3 id="10.5.4.nmap">10.5.4. Program nmap - skanowanie portów</h3>
        <p>
          Program <strong>nmap</strong> jest dość ważnym narzędzie w rękach
          większości administratorów, ma on masę możliwości jednak nas na
          tym etapię będzie interesować możliwość odpytania hosta na różnych
          portach i określenie czy możliwe jest połączenie z tymi portami.
          Ta czynność nosi nazwę <strong>skanowania portów</strong> i w
          niektórych sieciach bywa <em>nielegalna</em> (Więcej o tym w
          podrozdziale dotyczącym bezpieczeństwa). Istnieje wiele metod
          skanowania. A samo skanowanie może zostać rozszerzone np. o próbę
          zmuszenia usługi do powiedzenia czegoś więcej o sobie przez co
          można poznać jaki system operacyjny jest zainstalowany na hoście,
          którego porty skanujemy.
        </p>
        <p>
          Rodzajów skanowania jest kilka. Jednym z
          prostszych i szybszych jest SYN. Polega ono na wysłaniu pakietu
          inicjalizacji połączenia i kiedy uzyskamy odpowiedź na ten pakiet,
          możemy uznać (oczywiście tylko wedle tej metody), że port jest
          otwarty.
        </p>
<pre class="code-block">
xf0r3m@searx:~$ sudo nmap -sS ftp.morketsmerke.org
Starting Nmap 7.80 ( https://nmap.org ) at 2023-08-31 08:39 CEST
Nmap scan report for ftp.morketsmerke.org (195.164.150.92)
Host is up (0.040s latency).
Not shown: 993 filtered ports
PORT     STATE  SERVICE
80/tcp   open   http
113/tcp  closed ident
443/tcp  open   https
2000/tcp open   cisco-sccp
2022/tcp open   down
5060/tcp open   sip
9090/tcp open   zeus-admin

Nmap done: 1 IP address (1 host up) scanned in 4.43 seconds
</pre>
        <p>
          Na powyższym przykładzie przeskanowałem za pomocą metody
          SYN jeden ze swoich serwerów. Program podczas skanowania może działać
          znacznie dłużej niż tym przypadku w zależności od tego ile hostów
          ma do przeskanowania lub jaki ma zakres portów. Zatem po uruchomieniu
          skanowania zostanie nam przedstawiona tylko pierwsza linia. Po
          zakończeniu skanowania zostanie nam zwrócony raport. Pierwsza linia
          raportu zawienie nazwę hosta oraz jego adres IP.
(<code class="code-inline">Nmap scan report for ftp.morketsmerke.org (195.164.150.92)</code>)
          Następnie informacje o tym, że host jest dostępny opóźnieniach jakie
          mogą wystąpić podczas komunikacji.
          (<code class="code-inline">Host is up (0.040s latency).</code>)
          Trzecia linia zawiera informacje o niepokazywanych portach/usługach,
          ze względu na to, że nie udało się uzyskać od nich żadnej odpowiedzi.
          Nmap rozpoznaje trzy stany portu:
        </p>
        <ul>
          <li><strong>open</strong> - Port jest otwarty, komunikacja jest
            możliwa.</li>
          <li><strong>closed</strong> - Port jest zamknięty, komunikacja nie
            jest możliwa. Ten stan jest ustawiany kiedy strona zdalna
            odpowiedziała, że taki port nie jest czynny na tym hoście</li>
          <li><strong>filtered</strong> - Port jest filtrowany lub jego stan
            jest nieznany. Ten stan jest ustawiany kiedy minie okres ważności
            wysyłanych pakietów a strona skanująca nie dostanie żadnej
            odpowiedzi. Stan ten jest ustawiany także dla niedostępnych portów
            protokołu UDP ze zględu na charakterystykę tej transmisji.</li>    
        </ul>
        <p>
          Za pomocą skanowania portów możemy zauważyć różnicę miedzy akcjami
          <em>drop</em> oraz <em>reject</em>, pakietu zapory <em>iptables</em>.
          W przypadku akcji <em>drop</em>, stan portu będzie określony jako
          <em>filtered</em>, a w przypadku <em>reject</em> <em>closed</em>.
        </p>
        <p>
          Polecenie <em>nmap</em> poza wykrywanie dostępnych na hostach usług,
          może zostać wykorzystane do odkrywania hostów w sieci, za pomocą
          opcji <em>-sP</em> jako argument podając adres sieci w notacji
          CIDR.
        </p>
        <p>
          Opcji skanowania jest masa, funkcjonalność programu <em>Nmap</em>
          można rozszerzyć za pomoca skryptów Lua. Więc jeśli nie mielśmy
          styczności z tym programem warto się zapoznać stroną podręcznika.
        </p>
        <h2 id="10.6.rpc">10.6. Zdalne wywołanie procedury - RPC</h2>
        <p>
          <strong>RPC</strong> (ang. <em>Remote Procedure Call</em>), czyli
          zdalne wywołanie procedury to system, ktory ma umożliwić aplikacjom
          sieciowym uruchomienie funkcji znajdujących się na serwerze.
          Każdemu z tych programów przypisywany jest numer, dzięki któremu
          będzie można go wywołać. System ten znajduje się w niższych partiach
          warsty aplikacji.
        </p>
        <p>
          Aplikacje korzystające z RPC używają klasycznych portów transmisji
          warstwy transportowej takich jak: TCP czy UDP. Wymagają one natomiast
          jeszcze jednej usługi pośredniczącej mianowicie
          <strong>rpcbind</strong>. Jej zadaniem jest mapowanie portów TCP/UDP
          na numery programów RPC. Usługa <em>rpcbind</em> może być widoczna
          podczas skanowania. Za pomocą poniższego polecenie możemy sprawdzić
          czy jakiś program możemy uruchomić i za pomocą jakiej usługi.
        </p>
<pre class="code-block">
xf0r3m@vm-76925c3:~$ rpcinfo -p localhost
   program vers proto   port  service
    100000    4   tcp    111  portmapper
    100000    3   tcp    111  portmapper
    100000    2   tcp    111  portmapper
    100000    4   udp    111  portmapper
    100000    3   udp    111  portmapper
    100000    2   udp    111  portmapper
</pre>
        <p>
          Podobny wynik polecenia możemy uzyskać posiadając obsługę NFS w
          swoim systemie. Nie będę tutaj rozpisywał się na temat wyników
          tego polecenia. RPC to póki co nie nasza liga, nie mniej jednak
          warto wiedzieć że istnieje coś takiego. Poza NFS z RPC korzysta
          także usługa NIS (<em>Network Information Service</em>) oraz
          program monitorujący FAM (<em>File Access Monitor</em>) środowiska
          GNOME.
        </p>
        <h2 id="10.7.networksecurity">10.7. Zabezpieczenie sieci</h2>
        <p>
          Zabezpieczanie sieci to temat rzeka. Polega on na takim
          skonfigurowaniu elementów/warstw bezpieczeństwa
          hostów w sieci, aby zniechęcić potencjalnych atakujących do brania
          za cel naszych komputerów. Dystrybucje Linuksa sprawdzaja się
          głównie w środowiskach serwerowych i to one stają się najczęściej
          ofiarami ataków. Obecnie procesy przetwarzania informacji opieraja
          się w mniejszym bądź wiekszym stopniu na bazach danych, a te
          przechowują różne informacje. Dane wrażliwe firmy współdzelone na
          są na serwerach udostępniających pliki czy strony internetowe
          wszystkie te usługi opierają swoje działanie na dystrybucjach
          Linuksa. Udział innych systemów jest tutaj niszowy, chociaż to
          powoli zaczyna ulegać zmianie. 
          Oczywiście nie ma zabezpieczeń idealnych i jedynym
          bezpiczecznym sposobem przechowywania danych jest przechowywanie ich
          poza siecią. To jednak w mniejszym lub większym stopniu stanie się
          uciążliwe. Dlatego też poniżej znajduje się kilka zasasd, które
          pozwolą na podniesienie poziomu bezpieczeństwa naszych systemów.
        </p>
        <ul>
          <li><strong>Utrzymać w systemie minimalną liczbę usług sieciowych</strong>
            - jeśli nie wiemy do czego usługa służy najlepiej ją wyłączyć, aby
            wśród połaczeń sieciowych widniały tylko te usługi, które znamy.
            Ewentualnie jeśli stwierdzimy, że coś musi działać to spróbujmy
            ograniczyć nasłuchiwanie tej usługi wyłącznie do tego hosta 
            (pętli zwrotnej).</li>
          <li><strong>Filtrować tyle ruchu ile się tylko da</strong> -
            filtrowanie ruchu jest podstawowym elementem zabepieczającym
            system. Zapory sieciowe kształtują ruch i pozwalają kontrolować
            dostęp do naszych systemów. Najprostszą metodą jest zablokowanie
            całego ruchu przychodzącego i dopuszczenie tylko tego pasującego
            do naszych usług.</li>
        <li><strong>Śledzenie informacji o zagrożeniach</strong> - warto śledzić
            informacje na temat wykorzystywanych przez usług, czy nie ma
            jakiejś nowo odkrytej podatności. Tutaj warto przypomnieć o
            aktualizacji pakietów oprgramowania dystrybucji, samej dystrybucji
            oraz aplikacji z których korzystamy na tych serwerach.</li>
        <li><strong>Używanie dystrybucji z długoterminowym wsparciem</strong> 
            - Na serwerach używa się głównie stablinych dystrybucji takich jak
            systemy klasy <em>Enterprise</em>: Rocky czy Alma Linux. Innymi
            dystrybucjami są GNU/Linux Debian lub Ubuntu LTS. Systemy klasy
            <em>enterprise</em> mogą pochwalić się aż 10 letnim wsparciem
            podobnie Ubuntu. Debian posiada 5 letni okres wsparcia.</li>
        <li><strong>Ograniczenie ilość kont do minimum</strong> - tutaj
            sprawa jest prosta jeśli ktoś niepotrzebuje konta to się mu go
            nie zakłada. Wiele usług może potrzebować osobnego użytkownika
            do ograniczenia dostępu, to przy zakładniu takiego konta należy
            pamiętać aby ustawić mu odpowiednią powłokę.</li>
        <li><strong>Unikanie instalowania niepewnych pakietów</strong> - 
            Chodzi głównie o pakiety binarne, jednak można by to rozszerzyć
            o różne repozytoria stron trzecich.</li> 
        </ul>
        <p>
          Systemy uniksopodobne w tym i dystrybucje Linuksa mają to do siebie,
          że ich poziom bezpieczeństwa zależy od tego jaki jest nasz własny,
          nas jako ludzi. Jak bardzo mamy rozbudowaną wiedzę i umiejętności
          w tym temacie. Tak jest w przypadku wielu dystrybucji, jest to
          podyktowane wolnością użytkowników i nie chęcią do narzucania 
          komukolwiek
          czegokolwiek. Trochę inaczej sprawa ma się w przypadku systemów
          klasy <em>enterprise</em>, jak sama nazwa wskazuje często są one
          wyposażone w dodatkowe mechanizmy, aby mogły działać jak podstawa
          systemów produkcyjnych w przedsiębiorstwach, a kierowanie się
          powyższymi zasadami powinno ograniczyć ryzyko uzyskania pełnego
          dostępu do systemu. 
        </p>
        <h3 id="10.7.1.usualsecuritythreads">10.7.1. Typowe zagrożenia</h3>
        <p>
          Wśród ataków jakie można przeprowadzić na serwery z dystrybucją
          Linuksa możemy wyróżnić między innymi:  
        </p>
        <ul>
          <li><strong>Zdalny dostęp</strong> - jest to uzyskanie dostępu
            do maszyny. Pod tym określeniem możemy znależć pełen
            wachlarz różnych technik. Kiedyś było to przepełnienie bufora,
            obecnie możemy głównie wśród serwerów WWW oraz bazodanowych jedną
            z technik dostania się do systemu jest <em>sql injection</em>.
            Po zastosowaniu tych technik, atakujący może uzyskać dostęp do
            powłoki z poziomu użytkownika, który uruchamiana daną usługę.
            Jeśli takim użytkownikiem jest <em>superuser</em> wówczas atakujący
            przejmuje całkowicie kontrolę nad maszyną. Dlatego tak ważne jest
            aby jak najbardziej ograniczyć uprawnienia usług względem
            całego systemu. Skompromitowany system może być wykorzystywany
            do ataku na inne cele wewnątrz sieci lub w intenecie stając się
            przy tym cześcią sieci włamywaczy (<em>botnetu</em>) do prowadzenia
            dalszych działań
            takich jak ataki DDoS czy rozsyłanie spamu. Przy dużej liczbie
            usług stosuje się tzw. <strong>DMZ</strong>, jest najczęściej
            wydzielona podsieć, w której umieszcza się serwery mające
            świadczyć usługi w internecie. Ta podsieć najczęściej nie ma
            możliwości komunikacji z resztą sieci.</li>
          <li><strong>Ataki DoS</strong> - ataki odmowy usługi lub
            rozproszone ataki odmowy usługi. Atak tego typu jest bardzo prosty
            do zrealizowania. Każdy może go przeprowadzić. Polega on na
            zwiększonym korzystaniu z usługi do tego stopnia, że serwer nie
            będzie wstanie więcej świadczyć tej usługi. Zabezpieczeniem
            przed tego typu działaniami mogą być usługi pośredniczące, które
            mogą blokować szkodliwy ruch. Czasami uruchamiając jakąś stronę
            możemy spotkać się na początku ze stroną przedstawiającą logo
            dostawcy oraz usługę w stylu <em>Anti-(D)Dos</em>. Jeśli już
            dojdzie do takiego ataku, powstrzymanie go jest banalne.
            Wystarczy zablokować ruch na zaporze granicznej i zrestartować
            serwer blokowanej usługi</li>
          <li><strong>Złośliwe oprogramowanie</strong> - to zagrożenie może
            mniej dotyczyć naszych serwerów, ale nie powinnismy odrzucać
            takiej możliwości. Narażone na to mogą być serwery plików oraz
            serwery pocztowe. Generalnie systemy uniksopodobne są chronione
            przed różnym rodzajemy złośliwego opramowania samym faktem, że są
            mniej popularne, niż inne systemy. Nie mniej jednak <em>malware</em>
            dla dystrybucji Linuksa istnieje. Nawet jeśli te systemy nie są
            celem ataków wirusowych to mogą być ich nośnikiem. Dlatego też
            uruchamiając serwer pocztowy lub serwer do współdzielenia plików
            należało by go zaopatrzyć w jakiś program antywirusowy, którym
            może działać na naszej dystrybucji. Dostępnych jest wiele
            programów antywirusowych otwartoźródłowych z myślą o Uniksach.
          </li>
        </ul>
        <p>
          Omawiając zabezpieczanie sieci, moglismy się nie spodziewać
          informacji tego typu tutaj. W podrozdziale 10.5 zostały
          przedstawione dwa narzędzia <strong>netcat</strong> oraz
          <strong>nmap</strong>. Ich wykorzystywanie, w niektórych
          sieciach, może podnieść alarm o potencjalnej próbie włamania. Dlatego
          lepiej nie sprawdzać sieci którymi nie zarządzamy, ponieważ
          konsekwencje mogą być spore. Wydanie nawet pojedynczego polecenia
          ze skanowaniem, może zakończyć się oskarżeniem o włamanie.
        </p>
        <p>
          Jakby nie patrzeć najwieksze podatności systemów informatycznych
          siędzą przed ekranami urządzeń, które się z nimi łączą. W firmach
          mimo wysokiego poziomu zabezpieczeń kluczowych systemów, to za
          pomocą inżynierii społecznej (sztuki manipulowania ludźmi) można
          uzyskać dostęp systemów w nawet tak dobrze zabezpieczonej
          organizacji i to z minimalną wiedzą techniczną. Dlatego też mimo
          zabezpieczeń technicznych trzeba mieć się na baczności, np. kiedy
          czytamy wiadomość e-mail z prośbą otwarcia załącznika, albo że nasz
          komputer jest zarażony złośliwym oprogramowanie i możesz połączyć się
          z konsulatantem, który je usunie za darmo.
        </p>
        <h2 id="10.8.netsockets">10.8. Gniazda sieciowe</h2>
        <p>
          Omawiając warstwę aplikacji trzeba również wspomnieć o tym w jaki
          sposób procesy są wstanie brać udział w komunikacji sieciowej. W
          zależności od tego czy połączenie jest już zestawione to sprowadza
          się to skorzystania z dwóch wywołań systemowych <strong>recv</strong>
          oraz <strong>send</strong>. Proces chcąc skorzystać z tych wywołań
          musi odwołać się do połączenia za pomocą takie tworu jak
          <strong>gniazdo</strong>. Gniazda są wykorzystywane do uzyskania
          dostępu do sieci przy użyciu jądra. Proces wykorzystuje do określenia
          tego jak i kiedy komunikuje się on z siecią. Gniazda również biorą
          udział w komunikacji międzyprocesowej (IPC).
        </p>
        <p>
          W zależności od tego w jaki sposób proces chce uzyskac dostęp do
          sieci wówczas musi skorzystać z określonego rodzaju gniazda.
          Dla protokołu TCP używane jest gniazdo strumienia
          (<em>SOCK_STREAM</em>) a dla UDP wykorzystywane jest gniazdo
          datagramu (<em>SOCK_DGRAM</em>). Konfigracja gniazda wymaga ustalenia
          rodzaju gniazda, adresów IP, portów i protokołu warstwy transportowej.
          Gniazda zazwyczaj są konfigurowane przez procesów serwerów. Po
          ustaleniu tych informacji proces wykorzystuje standardowe metody
          obsługi sieci.
        </p>
        <p>
          Typowy serwer podczas swojego działania wykorzystuje dwa gniazda a
          nie jedno. Jeśli tak by było to wówczas serwery mogły świadczyć 
          usługi tylko punktowo. Jedne klient się podłączył to drugi musi
          czekać na zakończenie połączenia. Na szczęście jedno z gniazd
          służy do nasłuchiwania, jeśli proces nadrzędny wykryje na nim ruch
          to za pomocą wywołania systemowego <strong>accept</strong> akceptuje
          to połączenie i tworzy dla tego połączenia dedykowane gniazdo
          zapisu i odczytu. Po tej czynności za pomocą wywołania systemowego
          <strong>fork</strong> tworzy proces podrzędny do obsługi tego
          połączenia. Gniazdo nasłuchujące dalej będzie prowadzić nasłuch dla
          procesu nadrzędnego.
        </p>
        <p>
          Po skonfigurowaniu gniazda proces może prowadzić z nim interakcje
          zgodnie z rodzajem użytego gniazda.
        </p>
        <h2 id="10.9.unixsockets">10.9. Gniazda uniksowe</h2>
        <p>
          Gniazda uniksowe rodzaje gniazd szczególnie wykorzystywanym w
          komunikacji międzyprocesowej (IPC), wiele aplikacji bowiem jest
          projektowanych w architekturze klient-serwer (nawet te, które nie
          są sieciowe), a tego typu gniazda
          mogą się zachowywać jak gniazda sieciowe, mimo że nimi nie są i nie
          jest powiązana z nim żadana sieć. Możliwe jest również takie
          skonfigurowanie gniazd zachowywały się podobnie do protokołów 
          TCP/UDP. Przykładem wykorzystania tego typu gniazd jest komunikacja
          z systemem D-Bus (odpowiedzialnym za monitorowanie i reagowania na
          zdarzenia w systemie).
        </p>
        <p>
          Powodem popularności gniazd uniksowych jest możliwość utworzenia
          specjalnego pliku gniazda, które jak każdy plik w systemie będzie
          podlegać kontroli na podstawie klasycznych uniksowych
          uprawnień przez co inne procesy nie będą mieć dostępu do niego.
          Przykładem takiego pliku może być na przykład:
        </p>
<pre class="code-block">
xf0r3m@vm-eba25a2:~$ ls -al /run/rpcbind.sock
srw-rw-rw- 1 root root 0 09-01 07:04 /run/rpcbind.sock
</pre>
        <p>
          Inną sprawą jest wydajność, korzystając z gniazd uniksowych jądro
          nie musi używać podsystemu sieciowego. Sam proces programowania
          nie różni się zbytnio od gniazd sieciowych, dlatego też wiele
          aplikacji sieciowych również umożliwia połączenia za pomocą gniazd
          uniksowych. Przykładem takiej aplikacji może być przedstawiony
          na przykładzie <em>rpcbind</em>. 
        </p>
        <p>
          Za pomocą polecenia <em>lsof</em> z opcją <em>-U</em> możemy
          wyświetlić wszystkie uniksowe gniazda dostępne w systemie.
        </p>
<pre class="code-block">
xf0r3m@vm-eba25a2:/media/xf0r3m/immudex_crypt0$ sudo lsof -U
COMMAND     PID       USER   FD   TYPE             DEVICE SIZE/OFF   NODE NAME
systemd       1       root   10u  unix 0x00000000c0eae923      0t0  15927 /run/systemd/journal/stdout 
type=STREAM (CONNECTED)
systemd       1       root   17u  unix 0x00000000a1f6a748      0t0  11408 /run/systemd/notify type=DGRAM (CONNECTED)
systemd       1       root   18u  unix 0x0000000062a0c5b9      0t0  11409 type=DGRAM (CONNECTED)
systemd       1       root   19u  unix 0x00000000962057e3      0t0  11410 type=DGRAM (CONNECTED)
systemd       1       root   20u  unix 0x000000001183727b      0t0  11411 /run/systemd/private type=STREAM (LISTEN)
systemd       1       root   21u  unix 0x000000007042f6df      0t0  11413 /run/systemd/userdb/io.systemd.DynamicUser 
type=STREAM (LISTEN)
systemd       1       root   22u  unix 0x000000008bad806c      0t0  11414 /run/systemd/io.system.ManagedOOM
type=STREAM (LISTEN)
systemd       1       root   23u  unix 0x0000000096526742      0t0  20935 /run/systemd/journal/stdout
type=STREAM (CONNECTED)
systemd       1       root   24u  unix 0x00000000f0a1522b      0t0 182291 /run/systemd/journal/stdout
type=STREAM (CONNECTED)
</pre>
        <h1 id="11.networkfilesharing">11. Udostępnianie plików w sieci</h1>
        <p>
          Do tej pory zajmowaliśmy się siecią jako komponentem systemu
          pora skorzystać z niej jako z środka komunikacji. W wiekszości
          przypadków, ludzie wykorzystują sieć do dzielenia się informacjami
          a te moga przybrać formę pliku dowolnego formatu, a my poznamy
          metody w jaki sposób możemy przenieść pliki z jednego komputera
          na drugi za pośrednictwem sieci. Pominiemy jednak takie narzędzia jak
          SCP oraz SFTP, ponieważ były już one omawiane w poprzednim rodziale.
        </p>
        <h2 id="11.1.simplehttp">11.1. Proste udostępnienie z pośrednictwem WWW</h2>
        <p>
          Rozważmy taki scenariusz, że musimy udostępnić plik wielu osobom w
          tym samym laboratorium. Plik jest za duży, żeby przesłać go mailem,
          ale z użyciem poczty elektronicznej możemy przesłać link. Wówczas
          przeglądarki połaczą się z naszym komputerem i pobiorą udostępniony
          plik. Dla maksimum bezpieczeństwa możemy utworzyć specjalny folder
          dla tego pliku, przenieść/skopiować go to tam i będą wewnątrz go
          wydać następujące polecenie:
        </p>
<pre class="code-block">
xf0r3m@vm-d67b064:~$ python3 -m http.server
Serving HTTP on 0.0.0.0 port 8000 (http://0.0.0.0:8000/) ...
127.0.0.1 - - [08/Sep/2023 12:35:06] "GET / HTTP/1.1" 200 -
127.0.0.1 - - [08/Sep/2023 12:35:06] code 404, message File not found
127.0.0.1 - - [08/Sep/2023 12:35:06] "GET /favicon.ico HTTP/1.1" 404 -
127.0.0.1 - - [08/Sep/2023 12:35:25] "GET /newsfeed HTTP/1.1" 200 -
</pre>
        <p>
          Za pomocą wydanego przez nas polecenia z użyciem modułu języka
          programowania Python, uruchomiliśmy prosty serwer
          WWW. Serwer działa na wysokim porcie ze względu na uprawnienia.
          Zwykli użytkownicy nie mogą otwierać portów poniżej numeru 1023. 
          Domyślnie serwer startuje na porcie 8000, jeśli z jakiś przyczyn
          nie możemy użyć tego portu, to wówczas możemy podać mu inny wysoki
          port na końcu polecenia. Adres <code class="code-inline">0.0.0.0</code>
          oznacza każdy adres przypisany do tego komputera, oznacza to że
          mogę połączyć z tym serwerem przez pętlę zwrotną co własśnie
          uczyniłem, koncowo pobrałem plik
          <code class="code-inline">newsfeed</code>. Działanie serwera
          kończymy prostym Ctrl+c.
        </p>
        <h2 id="11.2.remotesync">11.2. Synchronizacja katalogu zdalnego - program rsync</h2>
        <p>
          Kolejny przykład udostępniania plików, wyłamuje się poza konwencję
          tego rozdziału, nie mniej jednak warto o nim wspomnieć. Może zostać
          po traktowany jako narzędzie do przesłania plików na serwer służący
          do ich udostępniania. Mowa tutaj o programie <strong>rsync</strong>.
          Jest on powszechnie wykorzystywany przez administratorów do
          przesyłania danych między Uniksami. Program wymaga istnienia na obu
          stronach komunikacji oraz dostępu do powłoki (rsync domyślnie
          wykorzystuje SSH). Program jeśli ma działać na zdalnym systemie
          zachowuje się podobnie do SCP, program może również działać na
          lokalnym systemie zastępując klasyczne polecenie <em>cp</em> i tak
          też to polecenie działa w prosty niemodyfikowany opcjami sposób.
          Opcje programu są w stanie dość mocno wpłynąc na jego zachowanie,
          że te dwa powyższe polecenie mogą stać się zbędne. Polecenie
          <em>rsync</em> może być również wykorzystywane to 
          kopiowania/przenoszenia w obrębie jednego komputera.
        </p>
        <p>
          Najprostsza składnia polecenia <em>rsync</em> wygląd następująco:
        </p>
<pre class="code-block">
xf0r3m@immudex:~$ rsync -r katalog_lokalny user@host:/sciezka/do/katalogu/zdalnego
</pre>
        <p>
          Polecenie to prześle cały katalog
          <code class="code-inline">katalog_lokalny</code> do katalogu zdalnego
          na serwerze. Na powyższym poleceniu użyłem opcji 
          <code class="code-inline">-r</code> (rekurencja), w przeciwnym razie
          nic nie zostanie przesłane.
        </p>
        <p>
          Podczas przekazywania ścieżek do polecenia (głównie ścieżki lokalnej)
          istnieje pewna zależność. Jeśli definiując scieżkę lokalną podamy na
          jej końcu ukośnik, to wówczas do katalogu zdalnego zostanie
          przekopiowana sama zawartość bez tworzenia początkowego katalogu.
        </p>
<pre class="code-block">
#Bez kończącego ukośnika:
xf0r3m@vm-331503c:/ic0$ rsync -r Repos2 /ic0/Dokumenty
# Katalog docelowy
xf0r3m@vm-331503c:~/Dokumenty$ ls -al
razem 12
drwxr-xr-x  3 xf0r3m xf0r3m 4096 09-18 09:52 .
drwxr-xr-x 11 xf0r3m xf0r3m 4096 09-18 09:12 ..
drwxr-xr-x  4 xf0r3m xf0r3m 4096 09-18 09:52 Repos2
xf0r3m@vm-331503c:~/Dokumenty$ ls -al Repos2/
razem 16
drwxr-xr-x 4 xf0r3m xf0r3m 4096 09-18 09:52 .
drwxr-xr-x 3 xf0r3m xf0r3m 4096 09-18 09:52 ..
drwxr-xr-x 5 xf0r3m xf0r3m 4096 09-18 09:52 Repos
drwxr-xr-x 2 xf0r3m xf0r3m 4096 09-18 09:52 .test

#Z kończącym ukośnikiem.
xf0r3m@vm-331503c:/ic0$ rsync -r Repos2/ /ic0/Dokumenty
xf0r3m@vm-331503c:~/Dokumenty$ ls -al
razem 16
drwxr-xr-x  4 xf0r3m xf0r3m 4096 09-18 09:58 .
drwxr-xr-x 11 xf0r3m xf0r3m 4096 09-18 09:12 ..
drwxr-xr-x  5 xf0r3m xf0r3m 4096 09-18 09:58 Repos
drwxr-xr-x  2 xf0r3m xf0r3m 4096 09-18 09:58 .test
</pre>
        <p>
          Na tę zależność należy uważać podczas kopiowania danych, ponieważ
          sam utworzony przez polecenie katalog może być istotny. Na powyższych
          przykładach użyłem polecenia <em>rsync</em> wewnątrz tego samego
          systemu. 
        </p>
        <p>
          Jak wcześniej wspominiałem dużą rolę w polecenie <em>rsync</em>
          odgrywają jego opcje. Poniżej znajduja się najważniejsze z nich.
        </p>
        <ul>
          <li><strong>--archive, -a</strong> - Tryb archiwalny. zachowanie
            większości atrybutów plików, poza ACL-kami, atrybutami specjalnymi
            takim jak <em>setuid</em>, czasu utworzenia oraz czasu ostatniego
            dostępu. W przypadku zastosowania tej opcji nie są kopiowane
            również dowiązania twarde. Wydanie opcji <em>-a</em> jest
            równoznaczne z wydaniem opcji serii opcji: <em>-rlptgoD</em>.</li>
          <li><strong>--update, -u</strong> - Aktualizacja. Powoduje, że
            <em>rsync</em> pomija istniejące już pliki na miejscu docelowym
            jeśli ich czas modyfikacji jest póżniejszy niż pliku źródłówego,
            jeśli czas modyfikacji jest równy wówczas program opiera swoje
            porównania na rozmiarze pliku.</li>
          <li><strong>--checksum -c</strong> - Sumy kontrolne. Zmienia sposób
            porównywania plików. Zamiast sprawdzać czas modyfikacji czy 
            rozmiar liczona jest suma kontrolna. Te metoda jest o wiele
            dokładniejsza, jednak wydłuża czas kopiowania oraz zużywa znacznie
            więcej zasobów.</li>
          <li><strong>--delete, --del</strong> - Oczyszanie katalogu. Usuwa
            z katalogu docelowego wszystkie pozostałe pliki, które nie były
            częścią tego transferu.
          <li><strong>--dry-run, -n</strong> - Testy. Pozwala na sprawdzenie
            czy nasze opcje i ścieżki zostały właściwie dobrane przed
            dokonaniem faktycznych zmian. Polecenie to wykonuje czynności
            <em>na sucho</em>, nie dokunując żadnych zmian w systemie.</li>
          <li><strong>--verbose, -v</strong> - zwiększenie ilości komunikatów
            diagnostycznych.</li>
          <li><strong>--compress, -z</strong> - Kompresja. Włącza kompresję
            podczas przesyłania danych.</li>
        </ul>
        <p>
          W tym materiale przedstawiono tylko, kilka opcji powszechnie
	        wykorzysywanych podczas korzystania z polecenia <em>rsync</em>.
          Obszerną wiedzę na ten temat zwiera strona podręcznika polecenia,
          zawierająca opisy wszystkich opcji oraz inne zagadnienia związane
          z programem.
        </p>
        <p>
          Ostatnią rzeczą związana z poleceniem jest przekazywanie do
          <em>rsync</em>
          poleceń związanych z SSH, w końcu ten program domyślnie korzysta z
          tego protokołu. Przekazanie opcji SSH wymaga użycia zmiennej powłoki.
        </p>
<pre class="code-block">
export RSYNC_RSH='-p 2022 -i id_rsa';
</pre>
        <p>
          W powyższym poleceniu użyto polecenia wbudowane 
          <code class="code-inline">export</code> w celu przeniesienia zmiennej
          do obszaru pamięci odpowiedzialnego za zmienne środowiskowe (będzie
          o tym w ostatnim rodziale materiału). Zmiennej nadano wartość
          składającą się z dwóch opcji polecenia SSH. <em>Rsync</em> będzie
          korzystać z tych informacji podczas zestawiania połączenia ze stroną
          zdalną.
        </p>
        <h2 id="11.3.filesharingentrance">11.3. Wprowadzenie do udostępniania plików</h2>
        <p>
          Operując w sieci lokalnej maszynami z dystrybucjami Linuksa,
          przyjdzie kiedyś pora, na to aby wykorzystać je do współdzielenia
          plików między użytkownikami, nie zależnie od tego jakiego systemu
          używają. Tutaj warto się zastanowić na tym między jakimi systemami
          będą one wymieniane oraz w jaki sposób użytkownicy łączą się z 
          naszymi
          serwerami. Czy łączą się bezpośrednio z siedziby firmy gdzie też
          znajdują się serwery czy też pracują zdalnie.
        </p>
        <p>
          Dlaczego o tym mówię, otóż istnieją metody lepiej i gorzej
          przystosowane
          do współdzielenia plików między różnymi systemami. Jedne są prostsze
          w obsłudze, ale np. nie posiadają żadnych metod uwierzytelniania,
          albo zostosowanie ich wymaga dodatkowych środków i nakładu pracy.
          Inne posiadają już pewne zabezpieczenia przed nieuprawnionym
          dostępem, ale nie są aż tak wydajne. Trzecią opcją są metody bardziej
          skupiające się na bezpieczeństwie, ale ich wydajność dość mocno
          kuleje. Oczywiście przy większym zangażowaniu można
          użyć tych metod w pozostałych środowiskach, a nie tylko w tych
          wymienionych, jednak warto mieć powyższe na uwadze oraz przyjąć do
          wiadomości fakt, że jeśli coś jest bardziej skomplikowane, to więcej
          składników tego czegoś może zawieść. Tym optymistycznym akcentem
          przjdziemy do pierwszej metody. 
        </p>
        <h2 id="11.4.samba">11.4. Współdzielenie plików między wszystkimi platformami</h2>
        <p>
          Jedną z metod współdzielenia plików między większością dostępnych
          platform na świecie jest pakiet <strong>Samba</strong>. Pakiet ten
          zawiera wszelkie niezbędne oprogramowanie do obsługi protokołu
          SMB (ang. <em>Server Message Block</em>) firmy Microsoft. Protokół
          ten w systemach MS Windows służy do udostępniania folderów w sieci.
          <em>Samba</em> jest natomiast implementacją protokołu SMB dla Uniksów
          (bo nie tylko dla samych dystrybucji Linuksa). Opis zagadnienia
          będzie składać sie głównie z opisu konfiguracji serwera. W niej
          zajmiemy się ogólną konfiguracją serwera, konfiguracją
          uwierzytelniania i użytkowników, udostępnianiem udziałów (katalogów)
          oraz udostępnianie drukarek. Zatem nie przedłużając:
        </p>
        <h3 id="11.4.1.generalsambaconfig">11.4.1. Ogólna konfiguracja serwera Samba</h3>
        <p>
          <em>Samba</em> to potężny demon, posiadający wiele zastosowań,
          na przykład po za konfiguracją udostępniania folderów oraz drukarek
          Samba może świadczyć usługi katalogowe (domenowe) dla systemów w
          sieci jeśli chcelibyć zarządzać wszystkimi komputerami w sieci. O
          konfiguracji Samby jako serwera domenowego <em>Active Directory</em>
          (usługi katalogowe w implementacji Microsoft-u) zrobiłem odrębny
          materiał i znajduje się pod tym linkiem: <a href="https://morketsmerke.github.io/articles/linux/samba_AD_DC_-_Instalacja.html">https://morketsmerke.github.io/articles/linux/samba_AD_DC_-_Instalacja.html</a>
          Pakiet <em>Samby</em> składa się głównie z dwóch programów. Głównego
          demona protokołu SMB <strong>smbd</strong> oraz demona protokołu
          <em>NetBIOS</em>, który jest protokołem pomocniczym dla SMB i
          zapewnia interfejs pozwalający na łączenie się aplikacji w innym
	        komputerami w sieci lokalnej. Istotną cechą jaką odgrywa
          <em>NetBIOS</em> jest używanie przyjaznej nazwy zamiast adresu.
          <!--[Źródło: https://pl.wikipedia.org/wiki/NetBIOS ]-->
          A odpowiadającym za niego demonem jest <em>nmbd</em>. Te informacje
          mogą być nam potrzebne podczas zarządzania <em>Sambą</em>, bowiem
          czasami trzeba zrestartować oba demony, aby pewne zmiany mogły wejść
          w życie.
        </p>
        <p>
          Plik konfiguracyjny na Debianie znajduje się w katalogu
          <em>/etc/samba</em>. Plik jest formatu XDG, czyli jest podzielny na
          sekcję (np. <em>[global]</em>) w sekcjach zawarte są opcje w formacie
          klucz-wartość (np. <em>workgroup = WORKGROUP</em>). Sama konfiguracja
          jest dość rozwleczona przez duża ilość opisów, pomocne rozwiazanie
          kiedy nad lub pod opcją mamy wyjaśnienie co dokładnie ona robi. Sama
          sekcja <code class="code-inline">[global]</code> podzielona jest 
          za pomocą komentarzy na podsekcje, w których znajdują się opcje np.
          dotyczące sieci czy uwierzytelniania. Zawartość tego pliku jest
          zależna od dystrybucji. Dlatego też na Debianie mamy w podsekcji
          <code class="code-inline">Browsing/Identification</code> mamy tylko
          opcję definiującą grupę roboczą.
        </p>
<pre class="code-block">
[global]

## Browsing/Identification ###
workgroup = WORKGROUP
</pre>
        <p>
          Jest to wskazanie grupy roboczej, której częścią ma być serwer
          <em>Samby</em>, najczęściej jest to 
          <code class="code-inline">WORKGROUP</code>, który jest wartością
          domyślną. Po tej opcji następuje Podsekcja sieciowa. W niej występują
          następujące opcje:
        </p>
<pre class="code-block">
#### Networking ####
;   interfaces = 127.0.0.0/8 eth0

;   bind interfaces only = yes
</pre>
        <p>
          Tutaj znajdują się tylko dwie opcje służą one kształtowaniu ruchu
          jaki może docierać do <em>Samby</em>. Za pomocą opcji 
          <code class="code-inline">interfaces</code> podajemy adresy sieci
          w notacji CIDR wraz z nazwami interfejsów, które będą mogły korzystać
          z serwera. Druga opcja
          <code class="code-inline">bind interfaces only</code> powoduje, że
          ruch do <em>Samby</em> będzie dopuszczony tylko ze zdefiniowanych za
          pomocą opcji <em>interfaces</em> sieci.
        </p>
<pre class="code-block">
#### Debugging/Accounting ####
   log file = /var/log/samba/log.%m
   max log size = 1000
   logging = file
   panic action = /usr/share/samba/panic-action %d
</pre>
        <p>
          W podsekcji <code class="code-block">Debugging/Accounting</code>
          znajdują się opcje odwiedzialne za konfiguracje rejestrowania
          komunikatów diagnostycznych i tak kolejno:
        </p>
        <ul>
          <li><strong>log file</strong> - ta opcja wskazuje nam konkretny plik
            z komunikatami diagnostycznymi połączeń. Nadanie tej opcji takiej
            wartości jak na przykładzie spowoduje, że dla każdego podłączonego
            do serwera komputera będzie tworzony osobny plik na komunikaty
            diagnostyczne.</li>
          <li><strong>max log size</strong> - ustawienie maksymalnego rozmiaru
            dla pojedynczego pliku z komunikatami diagnostycznymi wyrażone w
            KiB.</li>
          <li><strong>logging</strong> - ustawienie systemu logowania,
            domyślnie będą to pliki (<code class="code-inline">file</code>):
            <em>/var/log/samba/log.smbd</em> oraz <em>/var/log/samba/log.nmbd</em>
          </li>
          <li><strong>panic action</strong> - czynność wykonywana w momencie,
            kiedy w wyniku błedu dojdzie do zatrzymania demona. Domyślnie
            wysłany jest mail (wewnątrz systemu, do superużytkownika, ze
            rzutem procesu wygenerowanym przez debuger)
        </ul>
        <p>
          W ten sposób omówilismy sobie podstawowe opcje konfiguracji serwera
          <em>Samba</em>. 
        </p>
        <h3 id="11.4.2.sambaauthconfig">11.4.2. Konfiguracja uwierzytelniania użytkowników na serwerach Samba</h3>
        <p>
          Poniżej podsekcji dotyczącej komunikatów diagnostycznych znajduje się
          fragment pliku konfiguracyjneg dotyczący ustawień uwierzytelniania -
          <code class="code-inline">Authentication</code>, ta podsekcja zawiera
          ustawienia dostępu użytkowników do serwera. <em>Samba</em> może
          mieć odrębne hasła, niż te wykorzystywane przez użytkowników do
          dostępu do powłoki. Poniżej znajduje domyślna podsekcja
          uwierzytelniania dołączona pakietu <em>Samby</em> dostępnego na
          Debianie.
        </p>
<pre class="code-block">
####### Authentication #######
   server role = standalone server
   obey pam restrictions = yes
   unix password sync = yes
   passwd program = /usr/bin/passwd %u
   passwd chat = *Enter\snew\s*\spassword:* %n\n *Retype\snew\s*\spassword:* %n\n *password\supdated\ssuccessfully* .
   pam password change = yes
   map to guest = bad user
</pre>
        <p>
          Pierwsza z opcji jest rola serwera. Jeśli nasza <em>Samba</em> ma
          być serwerem plików to zostaje wartość wskazująca na samodzielny
          serwer (<code class="code-inline">standalone server</code>), kolejna
          opcja decyduje czy dostęp musi być zgodny z wymogami systemu PAM
          (<code class="code-inline">obey pam restrictions</code>). Trzecia
          opcja jest dość istotna
          (<code class="code-inline">unix password sync</code>). Dodając
          użytkownika do <em>Samby</em>, należy przypisać mu hasło. Te hasła
          mogą być w odrębnej bazie, ale mogą być również synchonizowane z 
          hasłami systemowymi. Ta opcja właśnie o tym decyduje. Czy hasła
          powinny być synchronizowane z systemowymi czy też nie. Nie ma
          jednoznacznej odpowiedzi czy <em>tak</em> czy <em>nie</em>. Wszystko
          zależy od potrzeb, tak jak wspomniałem o tym podczas wprowadzenia
          do współdzielenie plików. Warto natomiast znać konsekwencje takiego
          działania, włączenie synchonizacji haseł, zmieni hasło dostępu do
          systemu i najbezpieczniejszym rozwiązaniem będzie zablokowanie
          dostępu do powłoki dla użytkowników wyłącznie <em>Samby</em>,
          ponieważ hasła zapisane aby mieć łatwiejszy dostęp do udziałów
          <em>Samby</em> z platform nie Linuksowych można odzyskać.
          Dziś w dystrybucjach takich jak Debian, mimo iż ta opcja jest
          domyślnie włączona to i tak nie działa, ponieważ element
          podsystemu PAM, który kontrolował i obsługiwał cały ten proces
          został usunięty w z <em>Samby</em> w okolicach 2015 roku.
          Opcje poprzedzone frazą <code class="code-inline">passwd</code>,
          służą wskazaniu programu służącemu ustawianiu hasła
          (<code class="code-inline">passwd program</code>) oraz
          zdefiniowaniu komunikatów wyświelanych użytkownikowi podczas
          procesu zmiany hasła (<code class="code-inline">passwd chat</code>).
          Obecnie te opcje są <em>puste</em> (przynajmniej na Debianie), nie
          mają żadnego wpływu na działanie pakietu, ponieważ na dzień dziejszy
          synchronizacja haseł nie działa i nie zapowiada się aby kiedy
          kolwiek przywórcono tę funkcjonalność. W wspomniano o tych opcjach
          dla spójności opisu konfiguracji.
          Przedostatnia opcja
          (<code class="code-inline">pam password change</code>)
          służy kontroli wykorzystania PAM podczas zmiany hasła za pomocą
          klienta SMB niż w przypadku użycia programu zdefiniowanego w opcji
          <code class="code-inline">passwd program</code>. Ostatnia opcja
          definiuje kiedy należy zrzucić uprawnienia do połaczenia anonimowego.
          Domyślnie jest to stosowane, kiedy nie uda się pomyślnie
          uwierzytelnić użytkownika.
        </p>
        <p>
          Opcje uwierzytelniania otrzymały osobny podrozdział ze względu na to,
          że pełnią dość istotną rolę we współdzieleniu plików i zapewniają
          jakiś minimalny stopień bezpieczeństwa. Warto zwrócić uwagę na to, iż
          przedstawione tutaj są domyślymi ustawieniami zapożyczonymi
          bezpośrednio z pakietu <em>Samby</em> rozprowadzanego wraz z Debianem.
        </p>
        <h3 id="11.4.3.sambasharedcatalogs">11.4.3. Współdzielenie katalogów - udziały Samby</h3>
        <h4>Eksport katalogów domowych użytkowników</h4>
        <p>
          Jedną z najważniejszych cech, dla których ludzie korzystają z
          pakietu <em>Samba</em> jest współdzielenie katalogów, w których
          użytkownicy mogą dzielić się plikami z innymi w sieci. Innym
          zagadnieniem może być centralizacja katalogów domowych między
          użytkownikami wielu systemów uniksowych. 
        </p>
        <p>
          Pozostawiamy resztę opcji i przechodzimy do podsekcji
          <code class="code-inline">Share Definitions</code>. Tutaj
          kończy się sekcja <code class="code-inline">[global]</code>.
          Domyślnie w pliku konfiguracyjnym nie znajdują się żadne
          predefiniowane
          udziały więc na początek zajmiemy się exportem katalogów domowych.
        </p>
        <p>
          Za udostępnienie katalogów domowych odpowiada sekcja
          <code class="code-inline">[homes]</code>. Poniżej znajduje się
          sekcja eksportu katalogów domowych zapożyczona z domyślnego pliku
          konfiguracyjnego Debiana:
        </p>
<pre class="code-block">
[homes]
   comment = Home Directories
   browseable = no
   read only = yes
   create mask = 0700
   directory mask = 0700
   valid users = %S
</pre>
        <p>
          Sekcję rozpoczyna opcja <code class="code-inline">comment</code>,
          najzwyczajniej w swiecie jest opis. W nim możemy opisać zawartość
          czy wskazać właściciela, nie które programy (lub składniki programów)
          zajmujące się obsługą protokołu SMB w systemie mogą wykorzystać to
          pole do tworzenia opisów znalezionych udziałów. A odnośnie
          programów obsługujących protokół SMB to za widoczność udziału w
          nim odpowiedzialna jest opcja
          <code class="code-inline">browseable</code>. Tutaj (domyślnie)
          ustawiona jest na <code class="code-inline">no</code>, przez co
          udziału nie będzie widać w składnikach typu "Otoczenie sieciowe"
          (obecnie "Sieć") w eksploratorach plików. Wpływ następnej opcji na
          udział możemy się domyślić po samej nazwie 
          (<code class="code-inline">read only</code>)
          oraz ustawionej jej wartości (<code class="code-inline">yes</code>).
          Opcje zawierające frazę <code class="code-inline">mask</code>
          zawierają domyślne uprawnienia dla tworzonych plików
          (<code class="code-inline">create mask</code>) oraz katalogów
          (<code class="code-inline">directory mask</code>) i jak możemy
          zauważyć tylko właściciel będzie mieć jakie kolwiek uprawnienia.
          Ostatnią opcją jest (<code class="code-inline">valid users</code>),
          która określa jacy użytkownicy mają mieć dostęp do danego udziału.
          W przypadku eksportu katalogów domowych zamiast listy użytkowników
          używa się wartości <code class="code-inline">%S</code>, co powoduje,
          że nie musimy podawać listy wszystkich użytkowników, a wymusza to
          na użytkowniku stosowanie
          <code class="code-inline">\\SERVER\username</code> w momecie
          odwołania się do serwera. W przypadku Uniksów stosuje odwrotne
          ukośniki: <code class="code-inline">//SERVER/username</code>. W ten
          sposób wygląda eksportowanie katalogów domowych użytkowników. Dostęp
          katalogu domowego użytkownika wymaga podmontowania udziału lub
          skorzystania z klienta <em>Samby</em>. O czym będzie jeszcze w tym
          podrozdziale. 
        </p>
        <h4>Tworzenie udziałów Samba</h4>
        <p>
          W pliku konfiguracyjnym <em>Samby</em> każdy udział jest odrębną 
          sekcją. Nazwa udziału jest zarazem nazwą sekcji. Poniżej znajduje
          sie przykładowa sekcja definiująca udział.
        </p>
<pre class="code-block">
[nazwa_udziału]
path = sciezka/do/katalogu
comment = opis
guest ok = no
writeable = yes
printable = no
</pre>
        <p>
          Jak możemy zauważyć udostępnienie katalogu w sieci za pomocą
          pakietu <em>Samba</em> nie wymaga za dużo pracy. Na przykładzie
          pierwszym parametrem jest <code class="code-inline">path</code>,
          określa on ścieżkę do katalogu, który mamy zamiar udostępnić. Na
          temat opcji <code class="code-inline">comment</code> wspominałem
          w podczas opisu eksportu katalogów domowych. Opcja
          <code class="code-inline">guest ok</code> umożliwia udzielenie
          dostępu anonimowego do udziału. W tym przypadku dostęp w ten sposób
          jest zablokowany. Rzadko się zdarza generalnie aby dostęp anonimowy
          był wymagany, jeśli tak jest to najczęściej udział jest tylko
          odczytu. Chciaż spotkałem się z taką prośbą aby skonfigurować udział
          tak, aby każdy mógł w nim zapisać w nim swój plik.
          Opcja <code class="code-inline">writeable</code> konfiguruje czy na
          udziale będzie można zapisywać jakie kolwiek dane. Ostatnia opcja
          wprawdzie ma jedno głowne zadanie, wskazać <em>Sambie</em>, że ta
          sekcja to współdzielony katalog, a nie udostępiona drukarka dlatego,
          też ustawiono <em>drukowalne</em> jako <em>nie</em>. Nie ma potrzeby
          ustawiania opcji <em>browsable</em>, ponieważ domyślnie jest ona
          włączona. Chcąc zmienić ten stan, należy zapisać jej wystąpienie
          definicji udziału i ustawić wartość
          <code class="code-inline">no</code>. Oczywiście jeśli jest taka
          potrzeba możemy dodawać do definicji naszego udziału wiele innych
          poznanych tutaj opcji takich jak domyślne uprawnienia, zezwolenie
          na dostęp do tego udziału tylko dla wybranych użytkowników. Strona
          podręcznika jest pełna opcji, jedną z ciekawszych może być
          <code class="code-inline">veto files</code>, gdzie na podstawie
          wzorca możem zablokować udostępnianie konkretnych rodzajów plików.
          Na stronie podręcznika: <code class="code-inline">man 5 smb.conf</code>
          znajdziemy więcej informacji na temat tej opcji oraz wielu innych.
        </p>
        <h3 id="11.4.4.sambaprinters">11.4.4. Współdzielenie drukarek przy użyciu pakietu Samba</h3>
        <p>
          Istnieje możliwość, aby za pomocą pakietu <em>Samba</em> można dać
          możliwość drukowania użytkownikom innych platform na drukarkach
          podłączonych do systemów z dystrybucjami Linuksa. Samo drukowanie
          na dystrybucjach odbywa się za pomocą system <strong>CUPS</strong>,
          ale to nie temat na teraz. Zajmiemy się nim w poźniejszych rodziałach.
          Teraz zakładamy, że drukarki są podpiętę do naszego komputera, na
          którym hostowana jest <em>Samba</em> i z tego komputera możemy
          drukować.
        </p>
        <p>
          Dlaczego przyjąłem takie założenia, otóż drukowanie to jeden z
          cięższych tematów, ponieważ większość konsumenckich drukarek nie ma
          dobrego wsparcia dla dystrybucji Linuksa i korzystanie z nich to 
          swojego rodzju loteria. Dlatego może warto zajrzeć na stronę
          <a href="https://www.openprinting.org/printers">https://www.openprinting.org/printers</a>
          przed zakupem drukarki i jeśli ma działać pod którąś z dystrybucji
          to można rozważyć zakup 
          jedenego z dostępnych tam modeli. Chociaż może to niebyć w cale takie
          prostę, poniważ wiekszość tych urządzeń lata świetności ma już za
          sobą. Szkoda, bo za pomocą komputerów jednopłytkowych (takich jak
          <em>Raspberry Pi</em>) można by drukarki, które nie są sieciowe
          podłączyć do sieci.
        </p>
        <p>
          Nie mniej jednak. W domyślnej konfiguracji Debiana jest zdefiniowane
          współdzielenie drukarek. Obecne wersje <em>Samby</em> może nie
          zajmują się udostępnianiem drukarek, ale ich eksportem podobnie
          jak w przypadku katalogów domowych, przez co użytkownicy będą mieć
          dostęp do wszystkich drukarek podłączonych do naszego serwera
          <!--[Źródło: man 5 smb.conf]-->
          <em>Samby</em>. Poniżej znajduje się wycinek konfiguracji dotyczącej
          eksportu drukarek w Debianie:
        </p>
<pre class="code-block">
[printers]
   comment = All Printers
   browseable = no
   path = /var/tmp
   printable = yes
   guest ok = no
   read only = yes
   create mask = 0700
</pre>
        <p>
          Wszystkie występujące tutaj opcje, dobrze już znamy. Zastanawiająca
          może być wartość opcji <code class="code-inline">path</code>, która
          wskazuje na ścieżkę <code class="code-inline">/var/tmp</code>.
          <em>Samba</em> wymaga katalogu z możliwością zapisu przez pozostałych
          użytkowników wraz z ustawionym bitem <em>sticky</em>, a to jedyny
          obok, drugiego <em>/tmp</em> taki katalog. Problem z ogólnym
          katalogiem <em>/tmp</em> jest taki, że znajduje się na ramdysku.
          Posiada raczej małą objetość, a spływające od wielu użytkowników
          pliki do drukarek mogą wyczerpać szybko to miejsce.
        </p>
        <h3 id="11.4.5.addingsambausers">11.4.5. Dodawanie użytkowników Samby</h3>
        <p>
          Samba prowadzi odrębną bazę użytkowników wykorzystując do tego inne
          rodzaj szyfrowania. Dlatego też podczas "synchronizacji" (obecnie
          niedziałającej), wymaga wpisania hasła do <em>/etc/shadow</em>. Aby
          uzyskać dostęp do udziałów użytkownicy innych platform muszą mieć
          założone odrębne konta. Nazwy użytkowników kont <em>Samby</em> muszą
          odpowiadać tym Uniksowym, więc nie możemy utworzyć użytkownika
          mającego mieć dostęp tylko do udziałów, bez konta w systemie gdzie
          oprograwowanie do współdzielenia zasobów w systemie. Takie konto
          oczywiście możemy zabezpieczyć zmieniając domyślny program
          odpowiedzialny za uruchomienie zaraz po zalogowaniu. Użytkowników do
          <em>Samby</em> dodajemy za pomocą dostarczanego przez ten pakiet
          polecenia, musimy użyć opcji <em>-a</em> wskazującej na dodanie.
          Pominięcie tej opcji spowoduje, że będziemy zmieniać jedynie hasło.
          Do obsługi użytkowników <em>Samby</em> wymagane są uprawnienia
          administratora.
        </p>
<pre class="code-block">
xf0r3m@debian:/var$ sudo smbpasswd -a debian
[sudo] hasło użytkownika xf0r3m: 
New SMB password:
Retype new SMB password:
Added user debian.
</pre>
        <p>
          Tak naprawdę to tyle, konto użytkownika jest gotowe. Polecenie
          <code class="code-inline">smbpasswd</code> posiada o wiele wiecej
          funkcji niż tylko samo dodanie poniżej znajduje się lista opcji,
          które mogą pomóc w administrowaniu użytkownikami <em>Samby</em>.
        </p>
        <ul>
          <li><strong>-x</strong> - usunięcie użytkownika</li>
          <li><strong>-d</strong> - zablokowanie użytkownika</li>
          <li><strong>-e</strong> - odblokowanie użytkownika</li>
        </ul>
        <p>
          Warto pamietać o tym, że użytkownicy służą jedynie uwierzytelnianiu,
          natomiast autoryzacji do zapisu na jednym z udziałów należy dokonać
          z użyciem użytkowników uniksowych. Nie warto szukać przyczyn
          problemów z dostępem do elementów udziału w użytkownikach
          <em>Samby</em>. Na początku warto w ogóle sprawdzić czy udział jest
          dobrze ustawiony (<em>read only = no</em> oraz
          <em>writeable = yes</em>) oraz czy uprawnienia do udziału umożliwiają
          na zapis.
        </p>
        <h3 id="11.4.6.sambashareusage">11.4.6. Użycie protokołu samby</h3>
        <p>
          Kiedy nasz serwer SMB jest już skonfigurowany możemy przejść do
          konfiguracji klienta, a w zasadzie klientów. Ponieważ istnieje kilka
          metod na skorzystania z serwera <em>Samby</em>. 
        </p>
        <p>
          Pierwszym z nich jest skorzyststanie z przeglądarki sieciowej
          wbudowanej w menedżer plików, jeśli korzystamy z jednego z
          popularniejszych środowisk graficznych. Przycisk uruchamiający te
          funkcję znajduje się zazwycznaj po lewej stronie, najczęsciej nosi
          nazwę <em>Przeglądanie sieci</em> lub <em>Sieć</em>. Tutaj musimy
          przypomnieć sobie opcję <em>browseable</em>, która powodowała, że
          udziały były widoczne w tego typu komponentach. Domyślnie
          wyeksportowane katalogi domowe nie są w nich widoczne.
        </p>
        <p>
          Takie ukryte dla przeglądarek udziały są osiągalne na dwa sposoby.
          Pierwszym z nich jest zamontowanie udziału jak dysku wymienego, czy 
          partycji. Montowanie udziałów SMB wygląda podobnie, ale wymaga kilku
          dodatkowych opcji. Pierwszą z nich dość istotną jest wymagana w
          systemie obsługa protokołu SMB jako systemu plików. Taki system
          plików nosi nazwę <strong>CIFS</strong> i pakiety go obsługujący
          jest gotowy do zainstalowania w repozytorium dystrybucji
          (przynajmniej na GNU/Linux Debian - <em>cifs-utils</em>)
          Po zainstalowaniu pakietu, możemy wykorzystać polecenie <em>mount</em>
          do zamontowania udziału w systemie. Jak pamietamy montowanie
          systemów plików może wymagać uprawnień administratora.
        </p>
<pre class="code-block">
xf0r3m@vm-9585173:~$ sudo mount -t cifs //DEBIAN/xf0r3m homes_on_debian -o user=xf0r3m,uid=1001,gid=1001
Password for xf0r3m@//DEBIAN/xf0r3m: 
xf0r3m@vm-9585173:~$ sudo mount | grep '//DEBIAN/xf0r3m'
//DEBIAN/xf0r3m on /media/xf0r3m/immudex-crypt0/homes_on_debian type cifs 
(rw,relatime,vers=3.1.1,cache=strict,username=xf0r3m,uid=1001,noforceuid,
gid=1001,noforcegid,addr=172.18.227.14,file_mode=0755,dir_mode=0755,soft,
nounix,serverino,mapposix,rsize=4194304,wsize=4194304,bsize=1048576,
echo_interval=60,actimeo=1,closetimeo=1)
</pre>
        <p>
          Chcąc wykorzystać polecnie <code class="code-inline">mount</code>.
          Należy wskazać za pomocą opcji <code class="code-inline">-t</code>
          montowany system plików, następnie występuje adres udziału w
          przypadku dystrybucji Linuksa, ukosniki mają zwrot zgodny z tymi
          wykorzystywanymi w systemie
          (<code class="code-inline">//DEBIAN/xf0r3m</code>). Następnie
          występuje punkt montowania
          (<code class="code-inline">homes_on_debian</code>). Na samym końcu
          występuje specyficzne dla systemu
          <code class="code-inline">CIFS</code> opcje montowania, więc kolejno:
        </p>
        <ul>
          <li><code class="code-inline">user=xf0r3m</code> - nazwa użytkownika
            wskazywana do uwierzytelnienia się przed serwerem <em>Samby</em></li>
          <li><code class="code-inline">uid=1001</code> - mapowanie
            identyfikatora UID. Stosowane jest to gdy, użytkownicy posiadają
            inne UID-y na serwerze.</li>
          <li><code class="code-inline">gid=1001</code> - mapowanie
            identyfikatora grupy. Podobnie do opcji
            <code class="code-inline">uid</code> stosowane aby zapewnić
            odpowiednie prawa dostępu.</li>
        </ul>
        <p>
          Po wydaniu takiego polecenia, zostaniemy zapytani o hasło. Hasło
          również możemy w komponować w powyższe polecenie, za pomocą opcji
          <code class="code-inline">pass</code>. Jest to przydane gdy chcemy
          montować udziały samby podczas uruchamiania systemu
          (dodać wpis to pliku /etc/fstab). Jeśli po podaniu hasła zostanie
          nam zwrócony znak zachęty, wówczas oznacza to, że udział został
          poprawnie zamontowany. W przypadku problemów zostaniemy o tym
          poinformowani stosownym komunikatem. Dowód zamontowania możemy
          również otrzymać kiedy przefiltrujemy wyjście polecenia
          <code class="code-inline">mount</code> pod kątem występowania
          adresu udziału. Co uczyniono w drugim polecenie.
        </p>
        <p>
          Odłączenia udziału od systemu dokonujemy w ten sam sposób, co 
          z każdym innym system plików, za pomocą polecenia <em>umount</em>.
        </p>
<pre class="code-block">
xf0r3m@vm-9585173:~$ sudo umount homes_on_debian
</pre>
        <p>
          Po wydaniu tego polecenia udział zostanie odłączony od systemu.
        </p>
        <p>
          Innym sposobem jest dostęp do udziału SMB poza jego montowanie jest
          skorzystanie z dedykowanego klienta - <strong>smbclient</strong>.
          Korzystanie z niego przypomina trochę SFTP. Prawdopodobnie nie
          znajdziemy go domyślnie w systemie i trzeba będzie go zainstalować.
          Za pewne znajduje się on w repozytorium
          (na GNU/Linux Debian: <em>smbclient</em>). Po instalacji wydajemu
          poniższe polecenie.
        </p>
<pre class="code-block">
xf0r3m@vm-9585173:~$ smbclient -U xf0r3m //DEBIAN/xf0r3m
Password for [WORKGROUP\xf0r3m]:
</pre>
        <p>
          Jesli jesteśmy się w stanie połączyć z serwerem <em>Samby</em> to
          to zostanie nam zwrócony <em>prompt</em> z prośbą o hasło. Jeśli
          hasło jest poprawne otrzymamy o taki znak zachęty.
        </p>
<pre class="code-block">
Try "help" to get a list of possible commands.
smb: \&gt; 
</pre>
        <p>
          Lista dostępnych poleceń uzyskamy po przez wpisania polecenia
          <code class="code-inline">help</code>. Ta opcja może być przydatna,
          kiedy musimy skorzytać udziału <em>Samby</em> a nie możemy montować
          (np. wewnątrz kontenerów) lub nie mamy wystarczających uprawnień do
          podmontowania udziału.
        </p>
        <p>
          Oczywiście przedstawione poniżej dwa sposoby tyczą się głównie
          Uniksów, chciaż metoda z użyciem menedżera plików, również moze
          znaleźć zastosowanie oczywiście jesli posiadamy opowiednie 
          komponenty w swoim systemie. Jednak inne platformy jak głównie
          MS Windows będą wykorzystywać wyłącznie ją. Rzadko używa się
          <em>Samby</em> do wymiany danych między dwoma Uniksami są do tego...
          No właśnie, nie można jednoznacznie powiedzieć, że lepsze metody.
          Zatem będzie metoda bezpieczeniejsza ale mało wydajna i metoda
          mniej bezpieczna (można by powiedzieć, że domyślnie nie posiadająca
          żadnych mechanizmów bezpiczeństwa), ale za to bardziej wydajna.
        </p>
        <h2 id="11.5.sshfs">11.5. Bezpieczenie współdzielenie plików - SSHFS</h2>
        <p>
          Na podstawie informacji z poprzedniego rozdziału wiemy już, że przy
          użyciu protokołu SSH możemy przesyłac pliki służy do tego SFTP. Ale
          to nie wszystkie możliwości związane z obsługą plików przez ten
          protokół. Otóż możemy w lokalnym systemie zamontować katalog zdalny
          z wykorzystaniem SSH. Służy do tego <strong>SSHFS</strong>. Ta
          metody współdzielenia plików jest bezpieczna i łatwa w konfiguracji,
          SSHFS wymaga jedynie dostępu do protokołu SFTP. Ten system plików
          wykorzystuje ciekawą mechnikę o nazwię <strong>FUSE</strong>, która
          pozwala na zamontowanie <em>udziału</em> przez zwykłego użytkownika
          i nie wymaga żadnych dodatkowych uprawnień. Oczywiście jeśli coś ma
          tyle zalet, to albo musimieć równie dużo wad lub jedną dużą wadę,
          która nieco przekreśla popularność tej metody udostępniania plików.
          Jest nią wydajność, która jest wręcz mierna. Nie mniej jednak jest
          to chyba jeden z najbezpieczniejszych metod montowania katalogów
          zdalnych. Obsługa wymaga aby na komputerze klienta znajdowało się
          polecenie <em>sshfs</em> oraz <em>fusermount</em> są one dostarczane
          za pomoca pakietów (przynajmniej na Debianie): <em>fuse3</em> oraz
          <em>sshfs</em>. Montowanie katalogu odbywa się za pomocą poniższego
          polecenia.
        </p>
<pre class="code-block">
xf0r3m@vm-c1b9654:~$ sshfs xf0r3m@debian:/home/xf0r3m homes_on_debian -o reconnect
xf0r3m@debian's password: 
xf0r3m@vm-c1b9654:~$ mount | grep 'xf0r3m@debian'
xf0r3m@debian:/home/xf0r3m on /media/xf0r3m/immudex-crypt0/homes_on_debian type fuse.sshfs
(rw,nosuid,nodev,relatime,user_id=1001,group_id=1001)
</pre>
        <p>
          Tak zamontowany udział jest normalnie widocznym katalogiem w systemie.
          Jak byśmy montowali np. udział <em>Samby</em>. Jeśli katalog
          zdalny znajduje się w tej samej sieci lokalnej co klient to
          nie powinniśmy dostrzec żadnych problemów z wydajnością. Problem
          może okazać się gdy klient korzysta z niepewnego łącza jak jest np.
          transmisja danych w sieci komórkowej. Mimo wolnego transferu, możemy
          doświadczyć także zerwania połącznia co spowoduje, że nasz katalog
          stanie się nieosiągalny, zaradzić temu może opcja
          <code class="code-inline">reconnect</code> dołączona na końcu
          polecenia montowania.
        </p>
        <p>
          Po zakończeniu prac katalog należy odmontować z systemu. Jednak nie
          robi się tego za pomocą znanego nam polecenie <em>umount</em>. To
          polecenie jest zarezerwowane do obsługi klasycznego montowania z
          udziałem jądra. Tutaj montowaliśmy ograniczając się tylko do
          przestrzeni użytkownika. Do tego celu wykorzystamy drugie polecenie
          jakim jest <em>fusermount</em>.
        </p>
<pre class="code-block">
xf0r3m@vm-c1b9654:~$ fusermount -u /media/xf0r3m/immudex-crypt0/homes_on_debian 
xf0r3m@vm-c1b9654:~$ mount | grep 'xf0r3m@debian'
</pre>
        <p>
          Po wyniku działania drugiego polecenia, możemy żauważyć że montowany
          <em>udział</em> nie istnieje już w systemie.
        </p>
        <h2 id="11.6.nfs">11.6. Współdzielenie plików między dwoma Uniksami</h2>
        <p>
          Ostatnią metodą udostępniania plików, jest współdzielenie zasobów
          dyskowych między dwoma systemami uniksopodobnym. W systemach
          Microsoftu, również istnieje możliwość wykorzystania tego protokołu,
          jednak ze względów bezpieczeństwa jest on wykorzystywany głównie
          między systemami godnymi zaufania. A wykorzystywanym do tego
          protokołem jest <strong>NFS</strong> (<em>Network File System</em>).
          Wymiana danych między hostami za pomocą NFS nie jest szyfrowana
          więc zaleca się wykorzystanie VPN jeśli jest konieczność użycia
          tej metody między dwoma odległymi serwerami. Ten protokół również
          nieposiada, żadnych wbudowanych metod uwierzytelniania, poza jednym
          przypisaniem dostępu do udziału konkretnemu adresowi IP, ale również
          taki udział może być udostępniony całej sieci. Zatem najlepszym
          środowiskiem jest dla NFS była sieć SAN-owska
          (<em>Storage Area Network</em>) odseparowana fizycznie i logicznie
          od sieci LAN.
        </p>
        <p>
          W tym materiale ze względu na to, że maja to być wyłącznie podstawy
          obsługi dystrybucji linuksowych skupimy się tylko i wyłącznie na
          montowaniu udziału NFS w systemie. Jeśli chcialibyśmy skonfigurować
          serwer NFS, to możemy skorzystać z innego materiału, gdzie zostało
          to opisane pod tym adresem: <a href="https://morketsmerke.github.io/articles/terminallog/RedHat_-_RHCSA.html#17.nfs">https://morketsmerke.github.io/articles/terminallog/RedHat_-_RHCSA.html#17.nfs</a>
        </p>
        <p>
          Wykorzystanie NFS w naszym systemie wymaga oprogramowania, które
          trzeba zainstalować. Na Debianie pakiet nosi nazwę
          <em>nfs-common</em>. Po zainstalowaniu pakietu możemy przejść do 
          montowania naszego udziału w systemie. W tym przypadku nie musimy
          podawać żadnych dodatkowych informacji poleceniu <em>mount</em>,
          polecenie samo na podstawie wprowadzonego adresu serwera spróbuje
          połączyć się z wykorzystaniem protokołu NFS.
        </p>
<pre class="code-block">
xf0r3m@vm-c1b9654:~$ sudo mount debian:/home/xf0r3m homes_on_debian/
xf0r3m@vm-c1b9654:~$ mount | grep "debian:/home/xf0r3m"
debian:/home/xf0r3m on /media/xf0r3m/immudex-crypt0/homes_on_debian type nfs4
(rw,relatime,vers=4.2,rsize=262144,wsize=262144,namlen=255,hard,proto=tcp,
timeo=600,retrans=2,sec=sys,clientaddr=172.19.87.103,local_lock=none,
addr=172.19.82.231)
</pre>
        <p>
          Zwróćmy uwagę na prostę z jaką dokonuje się podłączenia udziału NFS
          na Uniksach. Dowód znajduje się w informacji zwróconej przez
          polecenie <code class="code-inline">mount</code>. Podobnie wygląda
          odmontowywanie. 
        </p>
<pre class="code-block">
xf0r3m@vm-c1b9654:~$ sudo umount homes_on_debian 
xf0r3m@vm-c1b9654:~$ mount | grep "debian:/home/xf0r3m"
</pre>
        <p>
          Sieciowy system plików został odłączony od naszego systemu.
        </p>
        <h2 id="11.7.currentmethodsoffilesharing">11.7. Jak wygląda współdzielenie plików dzisiaj?</h2>
        <p>
          Przedstawione tutaj metody nie są archaiczne. Są one wykorzystywane
          głównie w sieciach lokalnych. Są one wykorzystywane głównie wewnątrz
          organizacji co może mieć mało wspólnego ze zwykłym konsumenckim
          współdzieleniem plików. W dzisiejszych czas wszystko zależy od
          dostępności zasobów na żądanie. Chcąc mieć te same pliki na laptopie
          z dystrybucją Linuksa oraz np. na telefonie z system Android to
          wystarczy że skorzystamy z usług przechowywania danych jakie serwuje
          na Google w postaci <em>Google Drive</em>. Jednak ilość miejsca jest
          ograniczona do 15GB dla zwykłych użytkowników, oczywiście można
          poszukać innego dostawcy tego typu usług, bo i tak nalepszym
          narzędziem do korzystania z tego typu rozwiązań jest przeglądarka
          internetowa. Ceny są do siebie zbliżone. Jedyną taka usługą ze strony
          trzeciej godną uwagi wydaję się <em>Internxt</em> oferując np.
          plan dożywotni. Nie mniej jednak na uwagę zasługuje przchowywanie
          danych, które opiera się na szyfrowaniu oraz na polityce
          <em>zero-knowledge</em>, co oznacza, że nawet sami pracownicy nie są
          wstanie dowiedzieć się co tak naprawdę tam jest przechowywane. Inną
          metodą może być samodzielne hostowanie takich rozwiązań jak
          <em>Google drive</em> chociażby w postaci <em>Nextcloud</em>.
          W takim bądź przypadku spada na nas rola zorganizowania oraz
          utrzymania niezbędnej infrastruktury. Na koniec warto dodać, że
          najlepszą metodę współdzielenia plików określa poziom zaawansowania
          technicznego udostępniących pliki. Jedni potrzebują specjalnych
          rozwiązań i specjalnych aplikacji innych zadowoli SFTP oraz SSHFS.
        </p>
        <h1 id="12.userenv">12. Konfiguracja środowiska użytkownika</h1>
        <p>
          Chcąc przedstawić użytkownikom dostępnę środowiska często przedstawia
          się podział, na środowisko tekstowe (TUI/CLI) lub środowisko
          graficzne. Dla uproszczenia też zastosowuje tutaj ten podział.
          Ze względu na to, że istnieje bardzo duża liczba dostępnych
          <em>środowisk graficznych</em> oraz fakt, że jego obecność do
          normalnego działania systemu jest zbędna, w tym rodziale skupimy się
          głównie na <em>środowisku tesktowym</em>, a tym jest głównie powłoka.
        </p>
        <h2 id="12.1.shellsmode">12.1. Rodzaje powłok</h2>
        <p>
          W Obrębie konfiguracji środowiska tekstowego użytkownika, pojęcie
          <em>rodzaje powłok</em>, nie tyczy się programów powłoki takich jak
          BASH czy CSH. Tutaj zakładamy, że BASH jest naszą domyślną powłoką
          oraz że to jej używamy. Powłoka może <strong>interaktywna</strong>
          (korzystamy z niej domyślnie np. logując się do systemu.) lub
          <strong>nieinteraktywna</strong> (taki rodzaj powłoki uruchamiają
          skrypty [będzie o nich w ostatnim rozdziale]). Innym rodzajem
          podziału działania powłoki może być <strong>powłoka logowania</strong>
          oraz <strong>powłoka bez logowania</strong>
        </p>
        <p>
          Powłoka logowania uruchamiana jest za każdym razem kiedy,
          (najprościej rzecz ujmując) wymagane jest uprzednio uwierzytelnienie
          się  aby
          uruchomić sesję powłoki. Logując się jedeną z konsol na serwerze
          uruchamiamy interaktywną połokę logowania podobnie jest w przypadku
          połączeń zdalnych z wykorzystaniem protokołu SSH.
        </p>
        <p>
          Drugim rodzajem jest powłoka bez logowania, tyczy się ona głównie
          środowisk graficznych, bo tego rodzaju działanie powłoki jest
          zapewnianie programy typu <em>emulator terminala</em> oraz
          <em>multiplekser terminala</em> jak <strong>GNU Screen</strong> lub
          <strong>tmux</strong>.
        </p>
        <p>
          Określenie tego czy powłoką, którą używany jest powłoką logowania
          czy też bez logowania następuje poprzez analizę wartości zwróconej
          przez polecenie <code class="code-inline">echo $0</code>.
        </p>
<pre class="code-block">
xf0r3m@debian:~$ echo $0
-bash
xf0r3m@vm-6bee73e:~$ echo $0
bash
</pre>
        <p>
          Pierwsza powłoka została zinicjowana przez połączenie SSH na
          maszynie wirtualnej. W przypadku wartości zwróconej przez powyższe
          polecenie na tym hoście, nazwę powłoki poprzedza myślnik
          (<code class="code-inline">-</code>), co oznacza, że jest to powłoka
          logowania, wartość zmiennej bez myślnika, oznacza powłokę bez
          logowania. Druga powłoka została uruchomiona na drugiej karcie tego
          samego emulatora terminala, na którym pisze ten tekst.
        </p>
        <p>
          Istnieje mozliwość uruchomienia wielu kombinacji rodzajów powłoki,
          nawet możliwość uruchomienia nieinteraktywnej powłoki logowania.
        </p>
        <h2 id="12.2.userenvfiles">12.2. Pliki środowiska użytkownika</h2>
        <p>
          Dlaczego o tym wspominam, otóż różne rodzaje powłok mogą korzystać z
          różnych plików uruchomieniowych, z ktorych składa się środowisko
          użytkownika. Tych plików jest kilka, głównego podziału możemy
          doknac tylko i wyłącznie na podstawie <em>logowania</em> zatem:
        </p>
        <ul>
          <li><em>~/.profile</em> - powłoki logowania.</li>
          <li><em>~/.bashrc</em> - powłoki bez logowania</li>
        </ul>
        <p>
          Jak możemy wnioskować po obecności tyldy (<strong>~</strong>), te
          pliki są plikami użytkownika, chociaż w systemie może znaleźć się
          także wersja globalną. Tak jest w przypadku dysrybucji Debian,
          pliki znajdują się w katalogu <em>/etc</em>: <em>/etc/profile</em>
          lub
          <em>/etc/bash.bashrc</em>. W każdym systemie znajdują się te pliki.
          Pliki globalne posiadają kilka różnic od tych użytkowników. Ale my
          w ramach tego materiału skupiamy sie głównie
          <em>środowisku użytkownika</em> więc i na plikach użytkownika 
          poprzestaniemy. Tego typu pliki posiada każdy w swoim systemie
          więc nie mam sensu ich tutaj przytaczać w przykładach.
        </p>
        <p>
          Jeśli przyjrzymy się plikowi <em>~/.profile</em> to zauważymy, że
          wewnątrz ładowany jest plik <em>~/.bashrc</em>. Tak więc powłoka
          logowania zostanie zainicjowana również zgodnie z plikiem
          <em>~/.bashrc</em>. Na koniec do zmiennej zawierającej ścieżkę
          wyszukiwania poleceń dodane są lokalne katalogi, w których to
          użytkownik powinien przechowywać swoje pliki binarne. I to cały plik
          konfigurjący powłokę logowania. Znacznie bogatszym plikiem jest
          plik konfigurujący powłokę bez logowania. Wewnątrz niego znajdują
          się miedzy innymi:
        </p>
        <ul>
          <li>Konstrukcja dodająca polecenia do konfiguracji w przypadku
            powłoki nieinteraktywnej jak i interkatywnej.</li>
          <li>Domyślne ustawienia historii BASH.</li>
          <li>Ustawienie formatu oraz kolorów dla znaku zachęty na podstawie
            terminala na którym uruchomiona jest powłoka.</li>
          <li>Ustawienie aliasów polecenia <em>ls</em> włączających domyślne
            kolorowanie elementów.</li>
        </ul>
        <p>
          Generalnie plik <em>~/.bashrc</em> jest plikiem, który przechowuje
          informacje na temat:
        </p>
        <ul>
          <li>Aliasów.</li>
          <li>Zmiennej zawierającej ścieżkę wyszukiwania poleceń,</li>
          <li>Definicji wyglądu znaku zachęty,</li>
          <li>Domyślnego edytora (obecnie wykorzystywany jest do tego inny
            program, ale jesli nie jest obecny w systemie możemy skorzystać
            z dwóch zmiennych takich <em>EDITOR</em> oraz <em>VISUAL</em>),</li>
          <li>Programu stronicującego oraz jego domyślnego zachowania,</li>
          <li>Domyślnych uprawnień nadawanych nowotworzonym elementom
            (maska uprawnień).</li>
        </ul>
        <p>
          Jeśli potrzebujemy zmienić coś z powyższych zaganień to należy
          umieścić je w tym pliku.
        </p>
        <p>
          Generalnie jeśli chodzi o zmiany dokonywane w tych plikach, to
          raczej możemy pominąć plik <em>~/.profile</em>, ponieważ on sam
          sobie zawiera załączenie (polecenie <em>source</em>, będzie o nim
          w ostatnim rozdziale) pliku <em>~/.bashrc</em>. Więc wszystkie
          zmiany możemy zawrzeć w tym pliku. Nie należy tworzyć pliku na nowo
          został on przygotowany przez twórców dystrybucji i jest najlepiej
          dostosowany do tego co się w niej znajduje. Dodając jakie kolwiek
          zmiany do tych plików, musimy mieć na uwadzę wykonanie czynności,
          które chcemy umieści. Dłuższe wykonywanie poleceń w pliku
          <em>~/.bashrc</em> to dłuższe oczekiwanie na znak zachęty po
          zalogowaniu się lub uruchomieniu terminala. Dlatego też, za nim
          wdrożymy zmiany w plikach osobistych, warto przetestować je z
          użyciem dodatkowego użytkownika. Jeśli uznamy, że działanie zmian
          jest przez nas akceptowalne, to możemy je dodać do naszych plików.
        </p>
        <h2 id="12.3.extendinguserenv">12.3. Rozszerzenie domyślnego środowiska użytkownika</h2>
        <p>
          Korzystanie z włącznie konsol wirtualnych, może niebyć za bardzo
          ekscytującym doświadczeniem pod kątem wizualnym. Poza takim rzeczami
          jak przeglądanie zdjęć czy oglądanie filmów jesteśmy wstanie
          normalnie korzystać z takiego systemu. Ma to swoje wady i zalety.
          Jedną z nich możebyć wykorzystanie naprawdę archaicznego sprzętu, np.
          laptopów z początku wieku. Zrezygnowanie z środowiska graficznego
          może pomóc w wyrobieniu sobie przyzwyczajeń odnośnie pracy w 
          terminalu, nauke jednego z edytorów takich jak Vim, emacs lub inne.
          W teminalu możemy przeglądać strony internetowe pozbawione wszelkich
          pstrokatych dodatków, sam tekst, sama treść. Możemy przeglądać pocztę
          czy słuchać muzyki. Także wielu użytkownikom uniksów korzystanie z
          terminala wystarczy. Sam należę do takich osób, u których terminal
          to podstawowe narzędzie pracy i śmiało mogę obejść się bez środowiska
          graficznego. Jeśli już zdecydujemy się na to aby porzucić środowisko,
          to warto zaznajomić się z jednym z takich narzędzi jak
          <strong>tmux</strong> lub <strong>GNU Screen</strong>. Osobiście
          wolę <em>tmux</em>, jednak potrafi on sprawiać problemy czasami.
          W starszych wersjach zmiana katalogu głównego w sesji powłoki
          uruchomionej przez <em>tmux</em>, może powodować jej dziwne
          zachowanie, np. brak efektu działania klawisza backspace, mimo tego
          że znaki teoretycznie zostały usunięte. Jak wiemy mamy do dyspozycji
          kilka konsol. Jeśli zaś uruchomimy <em>tmux</em> to może zdefiniować
          sobie bardzo dużą ilość okien (tak jakby odrębna konsola), a je
          można jeszcze podzielić na mniejsze części. <em>Tmux</em> powzwala
          na kopiowanie i wklejanie przy użyciu innej metody dostępnej bez
          środowiska graficznego, co czyni go dość użytecznym programem.
        </p>
        <h1 id="13.userinterface">13. Interfejs użytkownika i drukowanie</h1>
        <p>
          Jeśli kiedyś przyjdzie nam korzystać z dystrybucji Linuksa poza,
          serwera, systemami wbudowanymi oraz innymi rozwiązaniami, w których
          do interakcji z systemem wykorzystujemy wyłącznie powłokę, spotkamy
          się z <strong>interfejsem graficznym użytkownika</strong>.
          Najprościej rzecz ujmując jest tak jakby <em>klasyczny</em> pulpit
          z wyświetlającymi się w okienkach programami. <em>Tak jakby</em>
          ponieważ na interfejs graficzny składa się bardzo duża ilość
          różnych elementów, które mogą się między sobą diametralnie różnić.
        </p>
        <p>
          Krótko scharakteryzujemy elementy, z których składa sie interfejs
          użytkownika. Ten rodział będzie dość mocno teoretyczny, więc jeśli
          nie interesuje nas czym jest <em>Wayland</em> czy
          <em>X Window System</em> lub magistrala <em>D-Bus</em> można przejść
          kolejnego rodziału.
        </p>
        <h2 id="13.1.uimajorelements">13.1. Elementy składowe interfejsu graficznego</h2>
        <p>
          Jak już wcześniej wspomniałem na interfejs graficzny użytkownika
          składa się duża ilość elementów. Te elementy moga być zostać
          pogrupowane na podstawie czym tak na prawdę są. Jesli powiem, że
          środowisko graficzne uzupełniają <em>widget</em>-y, to tymi
          <em>widget</em>-ami są po prostu aplikacje dostarczane jako
          zależności zadania instalacji wybranego środowiska. Środowiska
          oczywiście mogą się bez nich obejść jednak przyjemnosć korzystania
          z takiego pulpitu powoduje mieszane uczucia.
        </p>
        <h3 id="13.1.1.framebuffer">13.1.1. Bufory ramki</h3>
        <p>
          Na samym dole intefejsu użytkownika znajduje się zazwyczaj
          <strong>bufor ramki</strong> jest to obszar pamięci odczytywany
          przez układy graficzne i następnie przekazywany do wyświetlenia na 
          ekranie. Kilka bajtów reprezentuje jeden piksel. Podczas wyświetlania
          okien procesy na bierząco aktualizują zawartość bufora lub buforów
          (może ich być kilka, o czym się zaraz przekonamy) pamiętając przy
          tym aby nie nadpisać elementów innych okien (procesy programów
          wyświetlających się w oknie).
        </p>
        <h3 id="13.1.2.displayingmethods">13.1.2. Mechnizm wyświetlania</h3>
        <p>
          Ciężko jest sklasyfikować przedstawione poniżej elementy. Niby służą
          temu samemu to jednak posiadają wiele zasadniczych różnic, że trzeba
          się na chwilę zatrzymać i zastanowić na tym jak je sklasyfikować.
        </p>
        <h4>X Window System</h4>
        <p>
          System <em>X Window</em> bazuje na architekturze klient-serwer,
          serwer wyświetlania, nazywany również <em>serwerem X</em> jest
          tak jakby jądrem całego interfejsu użytkownika. <em>Serwer X</em>
          zarządza wszystkimi elementami związanymi z pulpitem przy czym nie
          narzucając jak coś powinno działać lub wyglądać. Klientem w tej
          releacji pozostaja wszelkie aplikacje, które chcą wyświetlić okna
          w systemie <em>X</em>. Po nawiązaniu połączenia z nim, aplikacja
          żąda wyświetlenia okna. W odpowiedzi uzyskamy informacje o
          docelowym położeniu okna oraz zostanie mu wskazany obszar pamięci
          przeznaczony na bufor ramki. Czasmi <em>serwer X</em> sam zajmuje
          się renderowaniem elementów graficznycznych.
        </p>
        <p>
          Ze względu na to, że <em>serwer X</em> bierze udział w tak wielu
          czynnościach, może stać się <em>wąskim gardłem</em> w pewnym
          momencie, chociaż <em>X Window System</em> jest aktywnie
          wykorzystywany od lat 80-tych, okazał się dość elastyczny aby móc
          obsługiwać elementy współczesnych interfejsów. 
        </p>
        <h4>Wayland</h4>
        <p>
          Protokół <em>Wayland</em> w przeciwieństwie do <em>X Window</em> jest
          nastawiony na decentralizację. Żadna centralny serwer nie bierze
          udziału w renderowaniu elementów graficznych. Każdy klient otrzymuje
          swój bufor ramki oraz <strong>składnik kompozycji</strong> łączący
          bufory ramki klienta do postacji akceptowanej przez bufor ramki
          ekranu, przy czym to zadanie jest wspierane sprzętowo co może
          podnieść wydajność.
        </p>
        <h4>Różnice między Wayland oraz X Window System</h4>
        <p>
          Generalnie to nie ma zbyt wielkich różnic między protokołem
          <em>Wayland</em> a system <em>X Window</em>. Aplikacje w obecnych
          środowiskach wykorzystując <em>X Window</em> nie oczekują na
          wspracie od serwera i same renderują bitmapę (zapisuja elementy
          graficzne w buforze ramki w postaci bajtów) i przesyłają ja
          <em>serwerowi X</em>. Serwer łaczy je ze sobą z wykorzystaniem
          rozszerzenia kompozycji, które jest dostępne w nim od kilku lat.
          Jedną z faktycznych różnic jest wymaganie biblioteki
          <strong>libinput</strong> służącej do kierowania danych wejściowych
          do klientów. Protokół nie wymaga tej biblioteki. Jednak jest ona
          w każdym dostęp środowisku. O mówimy ją sobie przy okzaji głębszego
          zapoznania się z system <em>X Window</em>. Kolejną rzeczą jest
          rola menedżera okien w wyświetlaniu interfejsu użytkownika.
        </p>
        <h3 id="13.1.3.windowmanager">13.1.3. Mendżery okien</h3>
        <p>
          Menedżer okna w interfejsie użytkownika zajmuje się renederowanie
          elementów dekoracyjnych, obsługuje kierowane do tych elementów
          zdarzenia wejściowe oraz informuje serwer o położeniu okien. Te
          zadania są wykonywane kiedy korzystamy z systemu <em>X Window</em>.
          Inaczej jest w przypadku protokołu <em>Wayland</em> tutaj menedżer
          okien pełni rolę serwera, składa bufory ramek, aby były zgodne
          z buforem przeznaczonym do wyświetlania oraz obsługuje przekazywanie
          urządzeń wejścia na kanale zdarzeń. Jest to jedna z różnic miedzy
          opisanymi wcześniej mechanizmami wyświetlania. Każdy z dostępnych
          interfejsów może mieć swój własny menedżer okien. Niektóre
          menedżery okien są traktowane jako pełne interfejsy użytkownika.
          Oczywiście jest błędne założenie, ponieważ takim gołym menedżerom
          okien, brakuje kilku elementów. Zazwyczaj jest nazwa potoczna dla
          zestawu programów składających się na środowiska użytkownika, lecz
          nie jest to pełno prawne środowisko graficzne jak GNOME czy KDE.
        </p>
        <h3 id="13.1.4.graphicalinterfacelibrary">13.1.4. Biblioteki interfejsu graficznego</h3>
        <p>
          Elementy interfejsów graficznych są często oparte o jedną z bibliotek,
          która wspiera tworznie różnego rodzaju przycisków, paneli,
          elementów dekoracyjnych czy projektowania okien. Wśród środowisk
          interfejsu użytkownika prym wiodą biblioteki standardu GTK+ oraz
          standardu Qt. Przyczym GTK+ jest wykorzystywany przez większą ilość
          środowisk.
        </p>
        <h3 id="13.1.5.graphicaluserinterfaces">13.1.5. Graficzny interfejs użytkownika</h3>
        <p>
          GUI obecnie są domyślnie określane jako całe środowisko
          użytkownika. Fakt, spinają one wiele cześci razem, np. są oparte o
          standard GTK+ lub Qt, często posiadają swój menedżer okien oraz
          menedżer wyświetlania (będzie o nim w dalszej części tego rozdziału)
          GUI zazwyczaj decydują o tym w jaki sposób wyświetlić elementy,
          decydują o wyglądzie wielu programów, dostaczaja swoje narzędzia np.
          takie jak emulator terminal, będąc jednym produktem składającym się
          z wielu składników. Warto poruszyć kwestię tego, że wielu
          użytkowników nie korzytsta z typowych GUI takich jak
          <em>GNOME</em>, <em>KDE</em> czy <em>XFCE</em>. Często wybierają oni
          menedżer okien, np. <em>Fluxbox</em> czy <em>IceWM</em> następnie
          dodają do tego menedżer wyświetlania, biblioteki oraz potrzebny im
          zestaw aplikacji. Tego typu rozwiązania powodują, mniejsze zużycie
          zasobów niż w przypadku użycia gotowych GUI, a to z kolei
          przekłada się to na konfort naszej pracy, niektóre czynności, które
          w przypadku gotowych GUI są automatyczne to w przypadku innych
          rozwiązań mogą wymagać dodatkowej konfiguracji. Oczywiście
          rozwiązania tego typu są pracochłonne, ale mogą przyspieszyć
          działanie systemu oraz umożliwić uruchomienie tak przygotowanego
          środowiska na
          słabszym sprzęcie, dzieki czemu możemy zaoszczędzic pieniądze.
          GUI mimo iż może być opartę o którąś z powyższych bibliotek, to
          potrafi być niezależne w domyśle od mechanizmu wyświetlania, wszystko
          zależy od twórców dystrybucji jak został skonfigurowany pakiet
          instalujący oraz konfigurujący domyślnie GUI.
        </p>
        <h3 id="13.1.6.guiapps">13.1.6. Aplikacje</h3>
        <p>
          Do tej pory korzystaliśmy z programów, które były uruchamien z
          poziomu konsoli/terminala. Posiadając środowisko graficzne mamy
          możliwość skorzystania z przeglądarek WWW, programów pocztowych i 
          wielu innych aplikacji. Oczywiście istnieją programy, dzięki którym
          możemy przeglądać strony internetowe (co prawda w postaci, czystego
          tekstu) lub czytać pocztę w terminalu. To jednak większa część tych
          programów jest projektowana z myślą o użytkownikach GUI upraszczając
          interakcje z nimi. Warto pamiętać jednak o tym, jednej z złotych
          zasad korzystania z jakiego kolwiek Uniksa. <em>Nie zawsze to GUI
          może być dostępne, a powłoka będzie zawsze w mniej lub bardziej
          rozbudowanej formie</em>
        </p>
        <h2 id="13.2.determinigdisplayserwer">13.2. Określenie mechanizmu wyświetlania</h2>
        <p>
          Wiele wiodących dystrybucji może automatycznie instalować środowisko
          użytkownika, bazując na zawartości obrazu płyty, z którego
          uruchomiliśmy nasz komputer. Wykorzystując ten system do testowania
          przykładów z tej książki, i czytając wyżej wymieniony podrozdział
          możemy zacząć się zastanawiać, z jakiego mechanizmu wyświetlania
          korzystamy w naszym w systemie. Do ustalenia informacji na temat
          wykorzystywanego przez nas serwera wyświetlania (tak wiem
          <em>Wayland</em> nie jest serwerem, ale tak będzie prościej do
          zrozumienia i tak pozostanie do końca tego materiału), wykorzystamy
          zmienną <code class="code-inline">$WAYLAND_DISPLAY</code>. Jeśli
          wyświetlenie jej zawartości zwróci jakieś informacje to oznacza, że
          możemy być nie mal pewni, że korzystamy z protokołu <em>Wayland</em>.
          Jeśli wyświetlenie jej zawrtości nie zwróci nic, to najpewniej nie
          jest ona w ogóle zainicjowana, co oznacza że korzystamy z serwera
          <em>X Window</em>.
        </p>
<pre class="code-block">
[xf0r3m@fedora39-sway ~]$ echo $WAYLAND_DISPLAY 
wayland-1
</pre>
        <h2 id="13.3.waylandprotocol">13.3. Protokół Wayland</h2>
        <p>
          <em>Wayland</em> jest protokołem pośredniczącym między menedżerem
	        kompozycji a klientem graficznym. Ten system nie posiada jednego
          dużego pakietu, ale bibliotekę protokołu, z której korzystają
	        klienci. Poza tym w skład protokołu wchodzi <strong>referencyjny</strong>
          menedżer kompozycji Weston, kilka klientów oraz programów 
          narzędziowych. 
        </p>
        <p>
          <em>Referencyjność Weston</em> polega na tym, że nie powinien być
          on wykorzystywany samodzielnie, natomiast posiada on wszelkie
          składniki składniki kompozycji i jego zadaniem jest zapewnienie 
          podstawowego
          interfejsu, który projektancji własnych menedżerów kompozycji mogą
          analizować i na podstawie tego poprawnie implementować kluczowe
          funkcje.
        </p>
        <h3 id="13.3.1.compositionmanager">13.3.1. Menedżer kompozycji</h3>
        <p>
          Korzystając z <em>Wayland</em>, możemy nie dokońca być świadomi tego
          z jakiego menedżera kompozycji korzystamy, każde wieksze środowisko
          wykorzystuje swoje rozwiązanie. Jednak zdobycie tych informacji z
          systemu jest dośc proste do realizacji. Menedżer kompozycji do
	        komunikacji z klietami wykorzystuje gniazdo uniksowe o nazwie
          <em>wayland-X</em>. Tę nazwę może kojarzyć z wartości z zwracanej
          przez zmienną <em>WAYLAND_DISPLAY</em>, bo tym tak dokładnie jest -
          nazwą ekranu. Przy użyciu polecenia <em>ss</em> wraz z opcjami
          <em>-xlp</em> wyświetlającymi gniazda uniksowe na których prowadzony
          jest nasłuch wraz procesami, odpowiedzialnymi za ten nasłuch.
        </p>
<pre class="code-block">
[xf0r3m@fedora39-sway ~]$ ss -xlp | grep 'wayland'
u_str LISTEN 0 1   /tmp/.X11-unix/X0        22765  * 0    users:(("Xwayland",pid=1153,fd=23))                                    
u_str LISTEN 0 128 /run/user/1000/wayland-1 22759  * 0                                                                           
u_str LISTEN 0 1   @/tmp/.X11-unix/X0 22764        * 0    users:(("Xwayland",pid=1153,fd=21)) 
</pre>
        <h3 id="13.3.2.libinput">13.3.2. Biblioteka libinput</h3>
        <p>
          Biblioteka <strong>libinput</strong> jest odpowiedzialna z uzyskanie
          od jądra danych wejściowych z urządzeń, np. znaków wprowadzanych na
          klawiaturze oraz ustandaryzowanie ich do danych protokołu. Mimo, iż
          te informacje mogą wydawać się nie ciekawe do omówienia to przy
          użyciu tej biblioteki możemy śledzić zdarzenia wejściowe:
        </p>
        <p>
          Zanim przjedziemy do śledzenia zdarzeń możemy za pomoca polecenia
          <em>libinput</em>, które jest powiązane z biblioteka <em>libinput</em>
          wyświetlić listę dostępnych w systemie urządzeń wejściowych.
        </p>
<pre class="code-block">
[xf0r3m@fedora39-sway ~]$ sudo libinput list-devices
...
Device:           AT Translated Set 2 keyboard
Kernel:           /dev/input/event1
Group:            3
Seat:             seat0, default
Capabilities:     keyboard 
Tap-to-click:     n/a
Tap-and-drag:     n/a
Tap drag lock:    n/a
Left-handed:      n/a
Nat.scrolling:    n/a
Middle emulation: n/a
Calibration:      n/a
Scroll methods:   none
Click methods:    none
Disable-w-typing: n/a
Disable-w-trackpointing: n/a
Accel profiles:   n/a
Rotation:         0.0
...
</pre>
        <p>
          Teraz kiedy orientujemy się jakie urządzenia są podłączone oraz
          w jaki sposób są widziane przez protokoł <em>Wayland</em> możemy
          przjeść do śledzenia zdarzeń.
        </p>
<pre class="code-block">
[xf0r3m@fedora39-sway ~]$ sudo libinput debug-events --show-keycodes
...
-event1   KEYBOARD_KEY            +8.267s	KEY_SPACE (57) pressed
  event1   KEYBOARD_KEY            +8.387s	KEY_SPACE (57) released
 event1   KEYBOARD_KEY            +12.993s	KEY_K (37) pressed
k event1   KEYBOARD_KEY            +13.113s	KEY_K (37) released
 event1   KEYBOARD_KEY            +15.175s	KEY_M (50) pressed
m event1   KEYBOARD_KEY            +15.283s	KEY_M (50) released
-event5   POINTER_MOTION_ABSOLUTE +18.768s	18.95/ 39.58
 event5   POINTER_MOTION_ABSOLUTE +18.770s	18.95/ 39.45
 event5   POINTER_MOTION_ABSOLUTE +18.782s	18.95/ 39.32
...
-event1   KEYBOARD_KEY            +20.305s	KEY_LEFTCTRL (29) pressed
 event1   KEYBOARD_KEY            +20.308s	KEY_C (46) pressed
</pre>
        <p>
          Po uruchomieniu mozemy poprzemieszczać kurs myszy lub poklikać kilka
          klawiszy na klawiaturze, w na wyjściu polecenia zobaczymy takie
          informacje jak te przedstawione na przykładzie.
        </p>
        <h3 id="13.3.3.waylandcompatibiltywithX">13.3.3. Zgodność Wayland z system X Window</h3>
        <p>
          Protokół <em>Wayland</em> jest w miarę świerzym (jak na postrzeganie
          czasu przez uniksy) podejściem jesli chodzi o wyświetlanie. Do tej
          pory większość okienkowych, mających uruchamiać się na dystrybucjach
          Linuksa, ale i nie tylko - system <em>X Window</em> jest
          również używany na innych uniksach, było projektowanych z myślą o 
          system <em>Xorg</em>. Zgodność natomiast między tymi dowoma systemami
          polega na dwóch podejściach.
        </p>
        <p>
          Podejście pierwsze polega na dostosowaniu aplikacji natywnie
          przygotowanej dla X. Aplikacje przygotowane z myślą o dystrybujach
          Linuksa często wykorzystują zestawy narzędzi dużych środowisk
          graficznych takich jak GNOME lub KDE. Te zestawy są przygotowane do
          działania z protokołem <em>Wayland</em>. Wiele podstawowych aplikacji
          zostało już dostosowanych w ten sposób. Różnice tutaj mogą polegąć
          na obsłudze elementów dekoracyjnych czy konfiguracji urządzeń
          wejściowych. Pozostaja jescze zależności wobec bibliotek związanych
          z systemem X.
        </p>
        <p>
          Innym rozwiązaniem jest uruchomienie aplikacji przeznaczonych dla
          <em>X</em> po przez warstwę zgodności, polegającą na uruchomieniu
          jako klienta <em>Wayland</em> całego serwera <em>X Window</em>.
          Nazwywane jest to serwerem <em>Xwayland</em> i jest domyślne
          działanie
          podczas sekwencji ładowania menedżera kompozycji. Wykorzystanie
          takiej warstwy wymaga przetłumaczenia zdarzeń wejściowych oraz
          utrzymania osbono buforów ramek okien. Metoda ta jest równiez nieco
          wolniejsza, ale często nie jest brane w ogóle pod uwagę.
        </p>
        <p>
          Oczywście odwrotnie to nie zadziała nie można uruchmaiać aplikacji
          dla <em>Wayland</em> pod system <em>X</em>, choć teoretycznie jest
          to możliwe. Możemy uruchomić menedżer kompozycji w oknie
          system <em>X</em>, jednak nie jest zalecane ze wzgledu na efekty
          uboczne, takie jak uruchomienie aplikacji w sesji <em>X Window</em>,
          a jej rzeczywiste pojawienie się w uruchomionej w oknie sesji
          <em>Wayland</em>.
        </p>
        <h2 id="13.4.xwindow">13.4. System X Window</h2>
        <p>
          W dość odgłegłych czasach jedną z cech systemu <em>X window</em> był
          dość duży gabaryt, bowiem pakiet ten zawierał poza serwerem
          wyświetlania biblioteki oraz kilka klientów. Te czasy na szczęście
          minęły dzięki upowszechnieniu się niezależnych środowisk graficznych
          takich jak GNOME czy KDE, wówczas można było skupić się na samym
          serwerze. Uproszczeniu uległa również biblioteka klientów.
        </p>
        <p>
          Działanie serwera <em>X Window</em> jest proste do namierzenia,
          wystarczy spojrzeć na listę procesów:
        </p>
<pre class="code-block">
xf0r3m@vm-65cd1fb:~$ ps -aux | grep 'Xorg'
root        1001  1.1  6.1 406772 119620 tty7    Ssl+ 10:59   0:32 /usr/lib/xorg/Xorg :0 
-seat seat0 -auth /var/run/lightdm/root/:0 -nolisten tcp vt7 -novtswitch
</pre>
        <p>
          Istotną wartością w linii polecenia uruchamiającego jest
          <code class="code-inline">:0</code>. Jest to oznaczenie
          <strong>wyświetlacza X</strong>. Wyświetlaczem <em>X</em> możemy
          nazwać całość obrazu jaki jest generowany przez serwer wyświetlania.
          Na to składają się wyświetlacze podłączone do karty graficznej lub
          do komputera. Najczęściej jednak <em>wyświetlacz X</em> odpowiada
          podłączonemu monitorowi. Jeśli już chcielibyśmy użyć podobnych metod
          do ustalanie mechanizmu wyświetlania jak w przypadku <em>Wayland</em>,
          to możemy skorzystać ze zmiennej DISPLAY. Wyświetli ona zapewne
          oznaczenie wyświetlacza oraz oznaczenie ekranu. Jeśli mamy
          podłączony do systemu tylko jeden fizyczny ekran, to zapewne
          wartość, tej zmiennej będzie wyglądać następująco.
        </p>
<pre class="code-block">
xf0r3m@vm-65cd1fb:~$ echo $DISPLAY
:0.0
</pre>
        <h3 id="13.4.1.displaymanagers">13.4.1. Menedżery wyświetlaczy</h3>
        <p>
          Korzystając z dystrybucji przeznacznonych na komputery biurkowe, 
          raczej
          nię będziemy sami uruchamiać serwera wyświetlania w jednej z
          wirtualnych konsoli. Po załadowaniu się systemu naszym oczom ukaże
          się okienko służące do logowania z jakimś obrazkiem w tle oraz
          umiesczonym w jednym z rogów przycisku wyboru sesji lub ustawień
          ułatwień dostępu. Menedżery wyświetlaczy mogą być częścią środowisk
          graficznych i to nie koniecznie tych dużych. Ponieważ środowisko
          LXDE, uważane za jedno z leżejszych posiada swój menedżer
          wyświeltacza. Jednak posiadanie dedykowanego menedżera jest raczej
          domeną, największych środowisk takich jak GNOME czy KDE. Istnieją
          również menedżery niezależne pozwalające uruchomić najróżniejsze
          środowiska czy menedżery okien. Jednym z nich jest
          <strong>lightdm</strong>, który nawet jest uruchomiony na komputerze
          na którym piszę ten materiał. Możemy to wywnioskować z widniejącej
          w poleceniu uruchomienia serwera <em>X</em> nazwy menedżera.
        </p>
        <p>
          Głównym zadaniem menedżerów wyświetlaczy jest uruchomienie serwera
          wyświetlania. Po uwierzytelnieniu, bądź od razu w przypadku
          ustawionego automatycznego logowania. Jednak samo uruchomienie
          serwera <em>X Window</em> nie jest jedynym zadaniem tego programu.
          Jeśli by tak było, to po zalogowaniu/włączeniu systemu dostalibyśmy
          czarny ekran z <em>x</em> zamiast kursora na środku ekranu. Jednym
          z zadań jest zainicjowanie sesji użytkownika, poprzez np.
          odpowiednie skonfigurowanie składników tego środowiska (np. włączenie
          wygaszacza ekranu, ochrony wzroku czy ustawienie tapety [nie które
          mendżery okien, funkcjonują w ten sposób]) i uruchomienie
          odpowiedniego menedżera okien będącego jednym z najważniejszych
          programów sesji użytkownika. Menedżery wyświetlania odpowiadają za
          szereg ciekawych funkcji, których możemy doświadczyć i dostosowac
          je do swoich potrzeb.
        </p>
        <h3 id="13.4.2.xwindownetworking">13.4.2. Właściwości sieciowe serwera X Window</h3>
        <p>
          Serwer <em>X Window</em> oferuje zdalny dostęp poprzez sieć.
          Rozwiązanie to jest podobne do, możliwe że znanych nam usług zdalnego
          pulpitu. Jednak ta usługa w obecnych czasach jest wyłaczona ze
          względów bezpieczeństwa - nie zapewnia poza uwierzytlenieniem żadnych
          zabepieczeń. Warto rozejrzeć się za jakimś innym dostępem, większość
          konfiguracji na Uniksach wykonamy z poziomu powłoki więc dostęp przez
          <em>secure shell</em> powinien wystarczyć. Mimo to jeśli na przykład
          potrzebujemy:
        </p>
        <ul>
          <li>Skonfigurować aplikację internetową, domyślnie otwierającą
            wysoki port na pętli zwrotnej. Możliwość wywołania tej aplikacji
            z poziomu naszego komputera odpada. Możemy zastosować opcję
            <em>-X</em> polecenia <code class="code-inline">ssh</code>.
            Ta opcja powoduje przekierowywanie
            klientów <em>X Window</em> uruchomionych na serwerze do komputera
            klienta SSH (powoduje wyświetlenie okna z aplikacją, często
            wykorzystywane do wyświetlenia okna przeglądarki, która uruchomiona
            jest faktycznie na serwerze i tam ma dostęp do sieci). Uruchomiona
            w ten sposób przeglądarka da dostęp do aplikacji.</li>
          <li>Uruchomić okno z programem na uruchomionej już sesji użytkownika.
            Posiadając dostęp do SSH oraz do użytkownika z uprawnieniami,
            którego uruchamiamy sesję środowiska graficznego możemy,
            uruchamiać na pulpicie okna <em>X Window</em>. Wymagane do tego
            jest posiadanie polecenia <em>xhost</em> oraz skonfigurowanie
            go poprzez pliki uruchomieniowe sesji środowiska graficznego
            użytkownika, najczęściej to w nich zapisywane są takie czynności
            jak ustawienia tapety dla nie których WM (<em>windows manager</em>).
            Tym plikami są: <em>~/.xinitrc</em>, <em>~/.xsession</em> lub
            <em>~/.xprofile</em> (dla, niektórych DM [<em>displays manager</em>]).
            Wewnątrz tych plików, musimy za pomocą polecenia <em>xhost</em>
            musimy nadać dostęp do swojej sesji użytkownika.
<pre class="code-block">
xhost +SI:localuser:&lt;nazwa_użytkownika&gt;
</pre>
            Taki użytkownik przenosząc zmienną <em>DISPLAY</em> z oznaczeniem 
            wyświetlacza <em>X</em>, uzyska dostęp do sesji użytkownika. Jeśli
            uruchomi program, który domyślnie otwiera okno ze swoją zawartością
            np. przeglądarkę, czytnik plików PDF to, to okno zostanie otwarte
            w sesji użytkownika, do którego użytkownik inicjujący program ma
            dostęp.
          </li>
        </ul>
        <p>
          Ze pomocą wyżej wymienionych sztuczek, możemych wchodzić w interakcje
          z serwerem wyświetlania <em>X window</em> na odległość. A jeśli
          naprawdę potrzebujemy zdalnego pulpitu, to warto użyć do tego np.
          takich protokół jak RDP lub VNC.
        </p>
        <h3 id="13.4.3.xwindowclients">Przegląd klientów X Window</h3>
        <p>
          Mogliśmy spodziewać się tego, że omawianie środowiska graficznego
          użytkownika może nie mieć nic wspólnego z wierszem polecenia, ale
          system <em>X Window</em> wychodzi nam na przekór, udostępniając kilka
          narzędzi, które pozwalają wyświetlenie informacji czy też diagnostykę.
          Jednym z takich narzędzi jest polecenie <em>xwininfo</em>. Polecenie
          to zwraca informacje na temat wybranego przez nas okna. Po
          uruchomieniu poprosi nas o wybranie okna za pomocą myszy o po
          kliknięciu na nie w terminalu zostaną nam zwrócone informacje o tym
          oknie.
        </p>
<pre class="code-block">
xf0r3m@vm-cffa62e:~$ xwininfo

xwininfo: Please select the window about which you
          would like information by clicking the
          mouse in that window.

xwininfo: Window id: 0x3400003 "Terminal - xf0r3m@vm-cffa62e: ~"

  Absolute upper-left X:  5
  Absolute upper-left Y:  158
  Relative upper-left X:  5
  Relative upper-left Y:  29
  Width: 817
  Height: 578
  Depth: 32
  Visual: 0x50c
  Visual Class: TrueColor
  Border width: 0
  Class: InputOutput
  Colormap: 0x3400002 (not installed)
  Bit Gravity State: NorthWestGravity
  Window Gravity State: NorthWestGravity
  Backing Store State: NotUseful
  Save Under State: no
  Map State: IsViewable
  Override Redirect State: no
  Corners:  +5+158  -202+158  -202-32  +5-32
  -geometry 100x30+0-27
</pre>
        <p>
          Innym ciekawym narzędziem może być polecenie <em>xlclients</em> wraz
          z opcją <em>-l</em>. Jego zadaniem jest wyświetlenie wszystkich
          klientów serwera <em>X Window</em>.
        </p>
        <h3 id="13.4.4.xwindowevents">13.4.4. Zdarzenia serwera X</h3>
        <p>
          Okna programów otrzymują dane wejściowe oraz informacje o stanie
          serwera <em>X</em> za pośrednictwem zdarzeń. Serwer <em>X</em>
          odbiera zdarzenia ze źródła następnie kieruje do dowolnego
          zainteresowanego klienta. System <em>X Window</em> daje nam możliwość
          eksperymentowania z zdarzeniami przy użyciu polecenia <em>xev</em>.
          Uruchomienie tego polecenia spowoduje otworzenie okna, po którym
          możemy jeździć kursorem i na nim klikać, natomiast w terminalu
          polecenie zajmie się obróbką tych zdarzeń i ich przedstawieniem
          użytkownikowi.
        </p>
<pre class="code-block">
xf0r3m@vm-cffa62e:~$ xev
ButtonPress event, serial 38, synthetic NO, window 0x3800001,
    root 0x529, subw 0x0, time 21524866, (41,103), root:(464,396),
    state 0x0, button 1, same_screen YES
...
MotionNotify event, serial 38, synthetic NO, window 0x3800001,
    root 0x529, subw 0x0, time 21526915, (49,104), root:(472,397),
    state 0x100, is_hint 0, same_screen YES

MotionNotify event, serial 38, synthetic NO, window 0x3800001,
    root 0x529, subw 0x0, time 21526998, (51,104), root:(474,397),
    state 0x100, is_hint 0, same_screen YES

MotionNotify event, serial 38, synthetic NO, window 0x3800001,
    root 0x529, subw 0x0, time 21527185, (52,104), root:(475,397),
    state 0x100, is_hint 0, same_screen YES

ButtonRelease event, serial 38, synthetic NO, window 0x3800001,
    root 0x529, subw 0x0, time 21527854, (52,104), root:(475,397),
    state 0x100, button 1, same_screen YES

MotionNotify event, serial 37, synthetic NO, window 0x3800001,
    root 0x529, subw 0x0, time 19437248, (99,87), root:(522,380),
    state 0x0, is_hint 0, same_screen YES
...
KeyPress event, serial 37, synthetic NO, window 0x3800001,
    root 0x529, subw 0x0, time 19448798, (194,226), root:(617,519),
    state 0x0, keycode 39 (keysym 0x73, s), same_screen YES,
    XLookupString gives 1 bytes: (73) "s"
    XmbLookupString gives 1 bytes: (73) "s"
    XFilterEvent returns: False

KeyRelease event, serial 37, synthetic NO, window 0x3800001,
    root 0x529, subw 0x0, time 19448918, (194,226), root:(617,519),
    state 0x0, keycode 39 (keysym 0x73, s), same_screen YES,
    XLookupString gives 1 bytes: (73) "s"
    XFilterEvent returns: False

KeyPress event, serial 37, synthetic NO, window 0x3800001,
    root 0x529, subw 0x0, time 19449093, (194,226), root:(617,519),
    state 0x0, keycode 40 (keysym 0x64, d), same_screen YES,
    XLookupString gives 1 bytes: (64) "d"
    XmbLookupString gives 1 bytes: (64) "d"
    XFilterEvent returns: False

KeyRelease event, serial 37, synthetic NO, window 0x3800001,
    root 0x529, subw 0x0, time 19449206, (194,226), root:(617,519),
    state 0x0, keycode 40 (keysym 0x64, d), same_screen YES,
    XLookupString gives 1 bytes: (64) "d"
    XFilterEvent returns: False

</pre>
        <p>
          Na przykładzie pokazano w przyciśniecie klawisza myszy, przesunięcie
          kursora z przytrzymanym klawiszem, następnie zwolnienie klawisza
          i przesunięcie kursora. Następnie naciśnięto dwa klawisze na
          klawiaturze. W polu <em>root</em> otrzymamy współrzędne kursora myszy
          na ekranie. Natomiast przed tym polem znajdują się współrzędne
          względem okna otwartego przez polecenie <em>xev</em>. W przypadku
          naciśniętych na klawiszy istotną informacją zwracaną przez to
          polecenie jest <code class="code-inline">keycode</code>, który
          pozwoli nam na zmianę mapowania klawiatury, co może być przydatne
          przy komputerach firmy Apple, zamieniając na ich klawiaturach
          klawisze <em>Command</em> z <em>Option</em>. W tych klawiaturach
          klawisz <em>Option</em> pełni rolę klawisza <em>Alt</em>, zatem
          po zmianie mapowania, klawiatura funkcjonalnie będzie przypinać
          każdą inną.
        </p>
        <p>
          Ciekawą opcją polecenia <em>xev</em> jest
          <code class="code-inline">-id identyfikator</code>. Pozwala ona na
          podanie identyfikatora okna (możną go uzyskać, za pomocą polecenia
          <code class="code-inline">xwininfo</code>), z którego polecenie
          <code class="code-inline">xev</code> będzie odczytywać zdarzenia.
        </p>
        <h3 id="13.4.5.settingxwindowpreferences">13.4.5. Ustawianie preferencji i dane wejściowe serwera X</h3>
        <p>
          System wyświetlania <em>Xorg</em> oraz jego serwer zapewniają kilka
          możliwych metod na zmianę preferencji, a niektóre z nich mogą nawet
          nie zadziałać. Jedną ze zmian jakie możemym chceć przeprowadzić jest
          wspomniana wcześniej zmiana mapowania, które można przeprowadzić na
          dwa sposoby, albo zmiany są małe i wprowadzane na obecnym mapowaniu
          przy użyciu polecenia 
          <code class="code-inline">xmodmap</code> albo utworzenie nowego
          mapowania, skompilowania go za pomocą polecenia
          <code class="code-inline">xkbcomp</code> oraz załadowania i
          aktywacji przy użyciu polecenia
          <code class="code-inline">setxkbmap</code>. Za pomocą tych poleceń
          możemy zmieniać mapowania większości klawiszy, jak i mamy możliwość
          definicji mapować dla każdej podłączonej klawiatury.
        </p>
        <p>
          Innym ustawieniem, które możemy chceć zmienić jest kolejność klawiszy
          przy myszy. W przypadku osób leworęcznych podstawowy przypisk (LPM,
          dla osób praworęcznych mieści skrajnie po lewej stronie) powinien
          znajdować sie po drugiej stronie urządzenia (skrajnie po prawej).
          Takiej zamiany możemy dokonać z pomocą
          <code class="code-inline">xinput</code>. Na poniższym przykładzie
          pokazano w jaki sposób dostosować myszkę dla osób leworęcznych. 
        </p>
<pre class="code-block">
xf0r3m@vm-cffa62e:~$ xinput --set-button-map <em>dev</em> 3 2 1
</pre>
        <p>
          Gdzie <code class="code-inline">dev</code> jest identyfikatorem
          urządzenia. Po podaniu informacji o urządzeniu wskazujemy kolejność
          klawiszy. Jednak skąd można wziąć taki identyfikator?
        </p>
        <p>
          Aby poznać urządzenia wejsciowe podłączone do komputera z dystrybucją
          linuksa, na której wykorzystywany jest serwer wyświetlania <em>X</em>,
          należy użyć wyżej wymienionego polecenia
          <code class="code-inline">xinput</code>.
        </p>
<pre class="code-block">
xf0r3m@vm-cffa62e:~$ xinput
⎡ Virtual core pointer                    	id=2	[master pointer  (3)]
⎜   ↳ Virtual core XTEST pointer              	id=4	[slave  pointer  (2)]
⎜   ↳ JUCHEN USB Keyboard                     	id=11	[slave  pointer  (2)]
⎜   ↳ JUCHEN USB Keyboard                     	id=12	[slave  pointer  (2)]
⎜   ↳ Logitech G502 HERO Gaming Mouse         	id=13	[slave  pointer  (2)]
⎜   ↳ Logitech G502 HERO Gaming Mouse Keyboard	id=14	[slave  pointer  (2)]
⎜   ↳ AlpsPS/2 ALPS GlidePoint                	id=17	[slave  pointer  (2)]
⎣ Virtual core keyboard                   	id=3	[master keyboard (2)]
    ↳ Virtual core XTEST keyboard             	id=5	[slave  keyboard (3)]
    ↳ Power Button                            	id=6	[slave  keyboard (3)]
    ↳ Video Bus                               	id=7	[slave  keyboard (3)]
    ↳ Power Button                            	id=8	[slave  keyboard (3)]
    ↳ Sleep Button                            	id=9	[slave  keyboard (3)]
    ↳ JUCHEN USB Keyboard                     	id=10	[slave  keyboard (3)]
    ↳ Dell WMI hotkeys                        	id=15	[slave  keyboard (3)]
    ↳ AT Translated Set 2 keyboard            	id=16	[slave  keyboard (3)]
    ↳ DELL Wireless hotkeys                   	id=18	[slave  keyboard (3)]
    ↳ JUCHEN USB Keyboard                     	id=19	[slave  keyboard (3)]
    ↳ Logitech G502 HERO Gaming Mouse Keyboard	id=20	[slave  keyboard (3)]
</pre>
        <p>
          W przypadku mojego komputera, klawiatury posiadają identyfikatory
          10 lub 19 oraz 16, w przypadku myszy (wskaźnika) jest to 13 oraz 17.
        </p>
        <p>
          Nie ma takiej potrzeby aby klienci mieli by nasłuchiwać zdarzeń na
          (w tym przypadku) na trzech lub większej ilości urządzeń.
          Wykorzystują oni natomiast pojedyncze urządzenia 
          <strong>rdzenia wirtualnego</strong>, dzięki temu możemy podłączyć
          i korzystać z więcej niż jednej klawiatury i więcej niż jednej
          myszy. Nie mniej jednak, klienci mogą korzystać z rozszerzenia
          <em>X Input Extension</em> w celu skupienia nasłuchiwania na jednym
          z nich, najczęsciej wiekszość z nich nie posiada w ogóle informacji
          o tym rozszerzeniu.
        </p>
        <p>
          Pozostałymi preferencjami to ustawienia może być tło ekranu
          nazywane potocznie tłem pulpitu, w tym przypadku możemy skorzystać
          z polecenia <code class="code-inline">xsetroot</code>, jednak
          nie działa ono we wszystkich przypadkach. Lepszym rozwiązaniem może
          być użycie zewnętrznego programu <em>feh</em>, które de facto jest
          przeglądarką plików graficznych; czy ustawienia wygaszacza ekranu
          lub funkcji DPMS (ang. <em>Display Power Management Signaling</em>)
          za pomocą polecenia <code class="code-inline">xset</code>. 
        </p>
        <h2 id="13.5.d-busservice">13.5. Usługa D-Bus</h2>
        <p>
          Usługa <strong>D-Bus</strong> jest mechanizm przekazywania
          komunikatów, umożliwia ona wymianę informacji między aplikacjmi
          klienta, wykorzystując do tego komunikację między procesową. Jednak
          aplikację wykorzystują ją do powiadamiania o zdarzeniach systemowych
          takich jaki np. podłącznie <em>pendrive</em>-a do komputera. Proces
          chcąc wykorzystać ją do nasłuchiwania zdarzeń muszą połączyć się
          na początku z <strong>centralnym koncentratorem</strong> - demonem
          <em>dbus-daemon</em> i zarejestrować w celu odbierania konkretych
          rodzajów komunikatów. Dla przykładku inny monitor
          <em>udisks-daemon</em> sprawdza stan systemu plików <em>udev</em>
          pod kątem zdarzeń dyskowych i następnie wysyła je do
          <em>dbus-daemona</em>, a on przesyła je dalej do aplikacji
          zaintersowanych zdarzeniami tego typu.
        </p>
        <h3 id="13.5.1.systemandsessiond-businstance">13.5.1. Instancja systemowa oraz instancja sessji</h3>
        <p>
          System <em>D-Bus</em> obecnie jest jedną z ważniejszych części 
          dystrybucji
          Linuksa - kanałami komunikacji <em>D-Bus</em> dysponuje 
          <em>systemd</em>, a ze względu na to, że jest on ściśle powiązany ze
          środowiskiem graficznym powoduje to konflikt natury projektowej.
          Rozwiązaniem okazało się podzielenie centralnego koncentratora na
          dwa osobne procesy - <strong>instancję systemową</strong>, która
          uruchamiana jest podczas rozruchu przez program typu <em>init</em>.
          Proces ten jest uruchamiany wówczas w raz z opcją <em>--system</em> i
          działa z uprawnieniami użytkowanika usługi D-Bus, a procesy mogą
          łączyć się z nią za pomocą uniksowego gniazda.
        </p>
        <p>
          Nie zależnie od instacji systemowej występuje
          <strong>instancja sesji</strong> która jest uruchamiana wyłącznie 
          w momencie startu środowiska graficznego i to z nią łączą się
          aplikacje.
        </p>
        <h3 id="13.5.2.d-busservicemessagesmonitoring">13.5.2. Monitorowanie komunikatów usługi D-Bus</h3>
        <p>
          W przypadku instancji systemowej, może dziać się nie wiele w
          zależności od sprzętu na jakim pracujemy. Nie mniej jednak do
          obserwacji komunikatów usługi <em>D-Bus</em> możemy wykorzystać
          dostępne polecenie takie jak 
          <code class="code-inline">dbus-monitor</code>
          Wybóru instancji dokonujemy za pomocą odpowiedniej opcji:
          instancja systemowa - <em>--system</em> oraz instancja sesji - 
          <em>--session</em>.
        </p>
        <p>
          Osobiście na swoim sprzęcie za pomocą monitorowania komunikatów
          <em>D-Bus</em> zauważyłem informacje odnośnie baterii oraz skanowania
          sieci bezprzewodowych przez mój komputer.
        </p>
<pre class="code-block">
xf0r3m@laptop-0b3697e:~$ dbus-monitor --system
...
signal time=1712415292.734476 sender=:1.39 -&gt; destination=(null destination) 
serial=3626 path=/org/freedesktop/UPower/devices/battery_BAT0; 
interface=org.freedesktop.DBus.Properties; member=PropertiesChanged
   string "org.freedesktop.UPower.Device"
   array [
      dict entry(
         string "UpdateTime"
         variant             uint64 1712415292
      )
      dict entry(
         string "Voltage"
         variant             double 8.388
      )
   ]
   array [
   ]
signal time=1712415307.335665 sender=:1.8 -&gt; destination=(null destination) 
serial=14104 path=/org/freedesktop/NetworkManager/Devices/3; 
interface=org.freedesktop.NetworkManager.Device.Wireless; member=AccessPointAdded
   object path "/org/freedesktop/NetworkManager/AccessPoint/794"
signal time=1712415307.335727 sender=:1.8 -&gt; destination=(null destination) 
serial=14105 path=/org/freedesktop/NetworkManager/Devices/3; 
interface=org.freedesktop.DBus.Properties; member=PropertiesChanged
   string "org.freedesktop.NetworkManager.Device.Wireless"
   array [
      dict entry(
         string "AccessPoints"
         variant             array [
               object path "/org/freedesktop/NetworkManager/AccessPoint/348"
               object path "/org/freedesktop/NetworkManager/AccessPoint/349"
               object path "/org/freedesktop/NetworkManager/AccessPoint/766"
               object path "/org/freedesktop/NetworkManager/AccessPoint/787"
               object path "/org/freedesktop/NetworkManager/AccessPoint/788"
               object path "/org/freedesktop/NetworkManager/AccessPoint/792"
               object path "/org/freedesktop/NetworkManager/AccessPoint/793"
               object path "/org/freedesktop/NetworkManager/AccessPoint/794"
            ]
      )
   ]
   array [
   ]
</pre>
        <p>
          W przypadku instancji sesji informacji jest znacznie więcej, wystarczy
          że zmienimy aktywne okno lub nacisniemy klawisz kontrol przy aktywnym
          terminalu.
        </p>
<pre class="code-block">
xf0r3m@laptop-0b3697e:~$ dbus-monitor --session
...
error time=1712415718.701034 sender=:1.119 -&gt; destination=:1.106 
error_name=org.xfce.Xfconf.Error.PropertyNotFound reply_serial=25086
   string "Właściwość „/shortcuts-no-menukey” nie istnieje na kanale „xfce4-terminal”"
method call time=1712415718.925428 sender=:1.106 -&gt; destination=:1.119 
serial=25087 path=/org/xfce/Xfconf; interface=org.xfce.Xfconf; member=GetProperty
   string "xfce4-terminal"
   string "/shortcuts-no-menukey"
error time=1712415718.926183 sender=:1.119 -&gt; destination=:1.106 
error_name=org.xfce.Xfconf.Error.PropertyNotFound reply_serial=25087
   string "Właściwość „/shortcuts-no-menukey” nie istnieje na kanale „xfce4-terminal”"
</pre>
        <h2 id="13.6.printing">13.6. Drukowanie</h2>
        <p>
          Drukowanie dokumentów w dystrybucjach linuksa, to wieloetapowy
          proces:
        </p>
        <p>
          Program odpowiedzialny za drukowanie może przekszatałcić
          drukowany dokument na format <em>PostScript</em>. Ten krok jest
          opcjonalny. W przypadku braku konwersji program przesyła dokument do
          serwera wydruku, dokument wówczas zostaje umieszczony w kolejce 
          wydruku. W momencie rozpoczęcia procesu drukowania serwer wydruku
          przesła dokument do filtra wydruku. W przypadku gdy dokument nie ma
          formatu <em>PostScript</em> filtr wydruku może dokonać konwersji.
          Jeśli drukarka nie obsługuje formatu <em>PostScript</em> to przy
          użyciu sterownika dokument zostaje skonwertowany do postaci
          odpowiedniej dla urządzenia drukującego. Ze sterownika drukarki
          zostają pobrane takie informacje jak źródło papieru czy ewentualny
          dupleks - zostają one dodane do dokumentu. Na koniec serwer wydruku
          wykorzystuje postprocesor aby wysłać dokument do drukarki.  
        </p>
        <p>
          Sam proces jest dość skomplikowany, ponieważ wykorzystuje się on w
          bardzo dużym stopniu na języku programowania <em>PostScript</em>.
          Język ten pełni rolę standardu drukowania w dystrybucjach Linuksa.
        </p>
        <h3 id="13.6.1.cups">13.6.1. CUPS</h3>
        <p>
          System wydruku w dystrybucjach jest CUPS, produkt firmy Apple, więc
          jest on także stosowany systemach macOS. Demonem tego system jest
          <em>cupsd</em>. W raz system drukowania mamy dostępne polecenie
          <code class="code-inline">lpr</code>, które może pełnić rolę prostego
          klienta pozwalającego na wysłanie plików do demona. 
        </p>
        <p>
          Istotną funkcją systemu CUPS jest implementacja protokołu IPP 
          (ang. Internet Print Protocol), wykorzystuje on port TCP/631 i jego
          działanie opiera się o transakcje podobne do protokołu HTTP. System
          CUPS można konfigurować za pomocą przeglądarki łącząc się z adresem
          <em>http://localhost:631</em>. Użytkownikiem administracyjnym jest
          root i hasło jest takie same jak do zalogowania się na tego
          użytkownika w systemie. Większość serwerów wydruku obsługuje
          protokół IPP, w tym również system MS Windows. Co umożliwia nam
          tworznie drukarek sieciowych, które nie są domyślnie sieciowe.
          To zadanie jednak wymaga nieco ingerencji, ponieważ domyślna
          konfiguracja nie jest zbyt bezpieczna.
        </p>
        <p>
          Konfiguracja drukarek w dystrybucjach Linuksa, jeśli mówimy tu o
          komputerze desktopowym zazwyczaj sprowadza się dodania drukarki
          przy użyciu specjalnego apletu w sekcji ustawień dla danego
          środowiska graficznego. Oczywiście, jak w przypadku większości
          zwykłego sprzętu dostępnego dla ogółu problemem mogą być sterowniki
          lub brak pliku PPD (wyjaśnienie czym jest plik PPD znajduje się
          w podrozdziale 13.6.2). Z własnego doświadczenia wiem, że
          z dystrybucjami Linuksa (przynajmniej z Debianem) dobrz działają
          drukarki firmy Kyocera (dawniej Kyocera-Mita) jeśli nie działają
          <em>plug and play</em> to zapewne dostępny jest sterownik
          własnościowy - w przypadku tych urządzeń problemem może być koszt
          tonera (są to urządzenia laserowe). Urządzeniem domowym, z które
          rzadko korzystam jest Canon Pixma TR4550 działa z Debianem
          <em>plug and play</em> dużym plusem jest tego urządzenia jest to,
          że te tusze nie zasychają (przynajmniej oryginalne). Z racji tego
          że to urządzenie wielofunkcyjne różnież jest możliwość skanowania
          przez pakiet <em>Sane</em>.
        </p>
        <h3 id="13.6.2.conversionsandprintfilters">13.6.2. Konwersja formatów i filtry wydruku</h3>
        <p>
          Większość tanich drukarek nie rozpoznaje formatów <em>PostScript</em>
          ani PDF, aby móc znich korzystać na dystrybucjach Linuksa niezbędna
          jest konwersja formatu do tego określanego przez drukarkę.
        </p>
        <p>
          System CUPS wysyła dokument do procesora RIP (ang. <em>Raster Image
          Processor</em>), aby wygenerować bitmapę. Procesor RIP zawsze stosuje
          program <em>Ghostscript</em> (<code class="code-inline">gs</code>) do
          realizowanie większości zadań. Czynność jest dość skomplikowana, gdyż
          bitmapa musi być dostowana do formatu drukarki. Sterowniki drukarki
          używane przez CUPS sprawdzają plik <strong>PPD</strong>
          (ang. <em>PostScript Printer Definition</em>) konkretnego urządzenia,
          aby określić takie ustawienia jak rozmiar papieru czy rozdzielczość.
        </p>
        <h1 id="14.programmingtools">14. Narzędzia programistyczne</h1>
        <p>
          Dystrybucje Linuksa, nie wymagają do podstawowej obsługi posiadania
          jakich kolwiek umiejętności programistycznych. Nie mniej jednak
          ten rodzaj systemów operacyjnych jest niezwykle często wybierany
          przez programistów, ze względu na swoją przejrzystość oraz obszerne
          udokumnetowanie.
        </p>
        <p>
          Odwiedzając tę stronę czy też czytając ten materiał, za pewne
          oczekujemy od naszych komputerów czegoś więcej niż wyświetlenie
          żądanej strony internetowej czy odtworzenie wybranego pliku wideo.
          Może nadejść taka sytuacja, w której będziemy mieli styczność z kodem
          źródłowym i to nie tylko języków interpretowanych (zostaną one
          omówione również) ale także języków takich jak C, C++ czy Java.
          Warto zapoznać się z narzędziami programistycznymi dostępnymi w
          dystrybucjach, aby czytając pliki README dostarczone do paczek z
          kodem czy innej jego dokumentacji wiedzieć co się robi i być może
          dostosować proces tworzenia plików wykonywalnych do własnych wymagań. 
        </p>
        <h2 id="14.1.ccompiler">14.1. Kompilator języka C</h2>
        <p>
          Za pomocą języka C, stworzono cały ten tematyczny obszar wokół,
          które oscyluje ten materiał. Wszystkie obecnie wykorzystywane Uniksy
          korzystają z języka C. Dlatego też warto wiedzieć na tym etapie, w
          jaki sposób możemy uruchomić program, który dostaniem w postaci
          zrozumiałej dla człowieka - w postaci kodu źródłowego (zwykłego
          tekstu). 
        </p>
        <p>
          W uproszczniu zamiana kodu źródłowego na postać wykonywalną przez
          komputer nosi nazwę <strong>kompilacji</strong>. Jednak jak się za
          chwilę okaże jest tylko połowa sukcesu (w większości przypadków).
          Obecnie w dystrybucjach Linuksa dostępne są dwa kompilatory
          <em>GNU C Compiler</em> (gcc) oraz <em>Clang/LLVM</em>. W tym
          materiale skupimy się na klasycznym kompilatorze <em>gcc</em>.
        </p>
        <p>
          Kompilator oraz inne narzędzia programistyczne mogą domyślnie nie
          występować w dystrybucjach. W przypadku Debiana czy Ubuntu wystarczy
          zainstalować za pomocą domyślnego menedżera pakietów pakiet
          <em>build-essential</em>, w przypadku rodziny dystrybucji opartych
          o Red Hat należy użyć grupy instalacyjnej <em>Development Tools</em>.
        </p>
        <p>
          W celu zobrazowania będę umieszczać w przykładach bardzo proste
          proste programy zapisane w języku C. Tak jak wspominałem, nie jest
          wymagana umiejętność programowania w żadnym z języków.
        </p>
<pre class="code-block">
#include &lt;stdio.h&gt;

int main() {
  printf("Hello, World!\n");
}
</pre>
        <p>
          Zapisany powyżej bardzo prosty program, zapisałem w pliku
          <em>hello.c</em>. Pliki kodu źródłowego języka C powinny mieć
          rozszerzenie <em>.c</em>. Chociaż wiemy, że w przypadku Uniksów nie
          to znaczenia, to dla utrzymania porządku w plikach, warto je pokrótce
          opisać za pomocą zwykłego rozszerzenia plików.
        </p>
        <p>
          Aby zamienić kod źródłowy na postać niskopoziomową wykonywalną przez
          nasz komputer musimy skompilować kod przy użyciu kompilatora.
          Program ten może być dostępny za pomocą poleceń <em>cc</em> lub
          <em>gcc</em>
        </p>
<pre class="code-block">
xf0r3m@vm-cac72df:~/C$ cc hello.c
</pre>
        <p>
          Polecenie to powinno zakończyć się, bez oznajmiania jakiego kolwiek
          działania na standardowym wyjściu. Wynikiem jego pracy jest
          pojawienie się tuż obok pliku <em>a.out</em>, który ma odpowiednii
          rodzaj uprawnień, aby móc go odrazu uruchomić - jest to plik
          wykonywalny, efekt działania kompilatora na powierzonym mu kodzie.
          Przekonać się możemy o tym wydając poniższe polecenie:
        </p>
<pre class="code-block">
xf0r3m@vm-cac72df:~/C$ ./a.out
Hello, World!
</pre>
        <p>
          Wcześnie uruchamiając kompilator nie podaliśmy mu poza kodem żadnych
          innych informacji. Jeśli chcemy, aby nasz plik wykonywalny miał
          bardziej odpowienią nazwę możemy ją podać jako wartość opcji
          <em>-o</em>.
        </p>
<pre class="code-block">
xf0r3m@vm-cac72df:~/C$ cc -o hello hello.c
xf0r3m@vm-cac72df:~/C$ ls
a.out  hello  hello.c
xf0r3m@vm-cac72df:~/C$ ./hello
Hello, World!
</pre>
        <h3 id="14.1.1.amanyfilecompilation">14.1.1. Kompilowanie wielu plików źródłowych</h3>
        <p>
          W przypadku pojednyczych programów takie działanie może wystarczyć,
          jednak rzadko się zdarza, aby programy były pojedynczymi plikami
          kodu źródłowego, zazwyczaj zawierają go znacznie, znacznie więcej.
          Sama praca z pojedynczym plikiem, może być niepożądana przez
          programistów jak i kompilatory mogą mieć problem z ich
          przetworzeniem.
        </p>
        <p>
          Główne składowe programów są najczęściej grupowane a w pojedynczych
          plikach umieszcza się ich poszczególne elementy. Kompilacja również
          wygląda nieco inaczej. Wymagane jest użycie opcji <em>-c</em> w celu
          utworzenia dla każdego ze składowych
          <strong>plików obiektowych</strong> -  zawierających kod obiektowy,
          który finalnie przyjmie formę pliku wykonywalnego. Załóżmy, że mamy
          tylko dwa pliki.
        </p>
        <p>
          <em>main.c</em>:
        </p>
<pre class="code-block">
void hello_call();
int main() {
  hello_call();
}
</pre>
        <p>
          <em>aux.c</em>:
        </p>
<pre class="code-block">
#include &lt;stdio.h&gt;

void hello_call() {
  printf("Hello, World!\n");
}
</pre>
        <p>
          Teraz dla każdego z plików źródłowych, musimy wygenerować pliki
          obiektowe. Pliki obiektowe są teoretycznie plikami wykonywalnymi
          ale brakuje w nich informacji pozwalających na dokończenie
          kompilacji. Sam system nie wie jak ma uruchomić pliki obiektowe,
          zazwyczaj na jeden program składa się wiele plików obiektowych.
        </p>
<pre class="code-block">
xf0r3m@vm-cac72df:~/C$ cc -c main.c
xf0r3m@vm-cac72df:~/C$ cc -c aux.c
xf0r3m@vm-cac72df:~/C$ ls
aux.c  aux.o  main.c  main.o
</pre>
        <p>
          W celu połaczenia plików obiektowych w plik wykonywalny użyjemy
          innego narzędzia, jakim jest <strong>konsolidator</strong>. Na
          systemach uniksowych nosi on nazwę <em>ld</em> i rzadko jest
          uruchamiany przez programistów samodzielnie. Kompilator wie w jaki
          sposób należy go uruchomić, dlatego też skorzystamy z jego pomocy.
          Mimo tego, że będziemy używać innego narzędzia to polecenie
          pozostaje to samo. Konsolidator może również występować pod nazwą
          <em>linker</em>.
        </p>
<pre class="code-block">
xf0r3m@vm-cac72df:~/C$ cc -o myprog main.o aux.o
xf0r3m@vm-cac72df:~/C$ ls
aux.c  aux.o  main.c  main.o  myprog
xf0r3m@vm-cac72df:~/C$ ./myprog
Hello, World!
</pre>
        <p>
          Dla celów dydaktycznych stworzyliśmy program składający z dwóch
          plików kodu źródłowego, zwykle jednak jest tego o wiele wiele więcej.
          Tutaj poszczególne czynności wykonaliśmy ręcznie. Jeśli w przypadku
          normalnego programu mielibyś to robić w ten sposób, zajęło by to
          masę czasu. Na szczęście nie trzeba robić tego ręcznie. Wykorzystamy
          do tego narzędzie GNU <strong>make</strong>, które omówimy sobie
          za chwilę.
        </p>
        <h3 id="14.1.2.linkingwithlibs">14.1.2. Konsolidacja z bibliotekami</h3>
        <p>
          Obecne systemy do utworzenia pełnoprawnego programu z plików
          obiektowych wymagają zbiorów wcześniej skompilowanych komponentów.
          Pliki obiektowe zawierające te zestawy nie są niczym innym jak
          <strong>bibliotekami</strong>, a w ich skład poza wspomnianymi już
          plikami wchodzą również pliki nagłówkowego, których używaliśmy już
          w kodzie programów przy użyciu dyrektywy <em>include</em>.
          Biblioteki dodawane są na etapie konsolidacji, ich użycie w trakcie
          tej czynności nazywane jest <strong>konsolidacją na bazie
          biblioteki</strong>. W przypadku kiedy podczas konsolidacji
          zapomnimy wspomnieć o bibliotece konsolidatorowi to zostaniem nam
          zwrócony błąd. Chociaż błedy związane z niewłaściwym odwołaniem się
          do biblioteki, może nie wynikać z naszych ustawień konsolidatora.
          Może to również być wynikiem braku zainstalownych bibliotek w
          systemie.
        </p>
        <p>
          Do wskazania bibliotek służy opcja <em>-l</em> kompilatora,
          oczywiście jeśli znajdują się one w domyślnej lokalizacji tj.
          <em>/lib</em> lub </em>/usr/lib</em> (chociaż w przypadku większości
          dystrybucji jest to ten sam katalog - kiedy program typu <em>init</em>
          to <em>systemd</em>), wystarczy podać jej nazwę. W przeciwnym razie
          musimy na początku wskazać ścieżkę, na której można znaleźć tą
          bibliotekę - za pomocą opcji <em>-L</em>, a następnie podać jej nazwę
          za pomocą wspomanianej już wcześniej opcji <em>-l</em>.
        </p>
        <p>
          Przekazując do konsolidatora (kompilatora) informacje o bibliotekach
          wartości opcji wraz z opcjami piszemy <strong>łącznie</strong>.
        </p>
<pre class="code-block">
$ cc -o badobject badobject.o -lcurses -L/usr/junk/lib -lcrud
</pre>
        <p>
          Podczas wyszukiwania bibliotek, przydatne może okazać się polecenie
          <em>locate</em>, niestety może nie być domyślne zainstalowane w
          systemie. Dodatkowo wywmaga ono aktualizacji bazy przy użyciu
          polecenia <em>updatedb</em>.
        </p>
        <p>
          Nasze proste programiki z przykładów, nie są pozbawione bibliotek.
          Tak jak już wcześnie wspominałem kompilator nie jest wstanie utworzyć
          pełnoprawnego pliku wykonywalnego. Konsolidator zawsze dołącza do
          utworzonego pliku obiektowego <strong>standardową bibliotekę języka
          C</strong> - <em>libc.a</em> - zawiera ona podstawowe komponenty
          języka C, jest ona zawsze dołączana chyba, że świadomie ją
          wykluczymy.
        </p>
        <h3 id="14.1.3.sharedlibraries">14.1.3. Biblioteki współużytkowane</h3>
        <p>
          Jak wiemy konsolidator zawsze dodaje do programów standardową
          bibliotekę języka C - <em>libc.a</em>. Ten plik jest
          <strong>biblioteką statyczną</strong>. Oznacza to, że konsolidator
          podczas tworzenia właściwego pliku wykonywalnego będzie kopiować do
          naszego pliku fragmenty kodu maszynowego z biblioteki, wówczas plik
          biblioteki nie będzie nam potrzeby do uruchomienia. 
        </p>
        <p>
          Tego typu rozwiązanie ma dwie dość znaczące wady. Pierwszą z nich są
          rozmiary
          bibliotek statycznych, a co za tym idzie rozmiary naszych programów
          oraz zajętosć pamięci operacyjnej podczas ich pracy. Drugą wadą, ale
          i nie kiedy zaletą, jest fakt przechowywanie kopii kodu biblioteki
          (oczywiście, określonych fragmentów), wewnątrz gotowego pliku
          wykonywalnego. Może być to wadą w momencie gdy, niektóre używane
          przez nas funkcje mogą okazać się niebezpieczenie i potrzebne będzie
          rekompilacja, a zaletą gdy twórcy przy okazji kolejnej wersji
          biblioteki zmieną coś, co nie dokońca będzie nam pasować lub zmiany
          będą zawierać błędy. Wówczas funkcje używane w naszym programie dalej
          pozostaną takie jakie powinny być według naszego projektu.
        </p>
        <p>
          Rozwiązaniem wyżej wymienionych są obecnie stoswane
          <strong>biblioteki współdzielone</strong>. Podczas konsolidacji z
          wykorzystaniem bibliotek współdzielonych, nie są kopiowane całe
          fragmenty kodu, a tylko odwołania do nazw w bibliotece. W tym
          przypadku biblioteka jest ładowana do pamięci w momencie gdy jest
          potrzebna. Dodatkową zaletą tego rozwiązania jest fakt, że procesy
          mogą współdzielić ze sobą obszar pamięci, w którym znajdują się
          biblioteki, aby nie ładować ich za każdym razem, gdy uruchamiamy
          jakiś program. 
        </p>
        <p>
          Czasami po aktualizacji pakietów naszej dystrybucji, nie które
          otwarte programy mogą zachowywać się dziwnie lub przestać odpowiadać,
          może dziać się to, ze względu na to iż manadżer pakietów
          zaktualizował wraz z oprogramowaniem pakiety bibliotek
          współdzielonych. Wówczas wystarczy ponowne uruchomienie systemu 
          (niektóre menedżery pakietów mogą same to zasugerować) i
          wszystko powinno wrócić do normy. Ta sama reguła tyczy się również
          jądra. Tutaj warto wspomnieć o różnicy między Uniksami a innymi
          systemami. W przypadku Uniksów, aktualizacja jest świadomym
          działaniem administracyjnym, wymagającym rozwagi oraz przemyślenia
          idących za nimi konsekwencji.
        </p>
        <p>
          Rozwiązanie bibliotek współdzielonych nie jest rozwiązaniem bez wad.
          Biblioteki współużytkowane mają nieco bardziej złożony proces obsługi,
          a i sam proces kompilacji staje się nieco bardziej skomplikowanym
          zadaniem. Chcąc wykorzystywać biblioteki w swoich programach musimy
          odpowiedzieć sobie na kilka pytań:
        </p>
        <ul>
          <li>Jakich bibliotek współużytkowanych potrzebuje nasz program i jak
            to sprawdzić?</li>
          <li>W jaki sposób wyszukiwane są tego typu biblioteki?</li>
          <li>W jaki sposób należy dokonać konsolidacji z bibliotekami
            współdzielonymi?</li>
          <li>Jakie mogą wyniknąć problemy podczas używania tych bibliotek i
            jak ich uniknąć?</li>
        </ul>
        <h4>Wypisywanie zależności od bibliotek współużytkowanych</h4>
        <p>
          Omawiajac kwestię bibliotek wspominalśmy miejsce ich położenia w
          systemie. We współczesnych dystrybucjach katalog <em>/lib</em> jest
          dowiązaniem symbolicznym do <em>/usr/lib</em>. Nie uświadczymy
          również zbyt wielu bibliotek statycznych. Większość znich to 
          do biblioteki współdzielone, których pliki mają rozszerzenie
          <em>.so</em>. Tego typu plików nawet w małym systemie, może być
          klikadziesiąt. Aby ustalić z jakich bibliotek korzysta konkretny
          program możemy użyć polecnia <strong>ldd</strong>.
        </p>
<pre class="code-block">
xf0r3m@vm-2339495:~/C$ ls
a.out  aux.c  aux.o  hello  hello.c  main.c  main.o  myprog
xf0r3m@vm-2339495:~/C$ ldd myprog
        linux-vdso.so.1 (0x00007fffc13dd000)
        libc.so.6 =&gt; /lib/x86_64-linux-gnu/libc.so.6 (0x00007f1a32d99000)
        /lib64/ld-linux-x86-64.so.2 (0x00007f1a32f94000)
</pre>
        <p>
          Polecenie <code class="code-inline">ldd</code> wymaga argumentu w
          postaci wskazania pliku wykonywalnego. Ten program zwróci nam
          wszystkie zależność od bibliotek podanego programu. Jak możemy
          zauważyć na powyższym przykładzie mimo tak prostego programu,
          linker dołacza standardową bibliotekę języka C, konsolidator
          dynamiczny
          (<code class="code-inline">ld-linux-x86-64.so.2</code>,
          opisany poniżej) oraz
          bibliotekę ułatwiającą wykonywanie wywołań systemowych
          (<code class="code-inline">linux-vdso.so.1</code>).
          <!-- Źródło: https://man7.org/linux/man-pages/man7/vdso.7.html -->
          <!-- Źródło: https://www.baeldung.com/linux/dynamic-linker -->
        </p>
        <p>
          Podczas konsolidacji nie podaje się pełnych ścieżek do bibliotek, aby
          zachować elastyczność. Zazwyczaj dostępne będą jedynie nazwy. Za
          odnalezienie bibliotek w systemie odpowiada właśnie
          <strong>konsolidator dynamiczny - ld.so</strong>
          (<code class="code-inline">/lib64/ld-linux-x86-64.so.2</code>).
          Przyjrzmy się linii standardowej biblioteki języka C. To co znajduje
          się po lewej stronie operatora (<code class="code-inline">=&gt;</code>)
          zostało odczytane z programu, natomiast to co znajduje się po
          po prawej stronie operatora, jest wynikiem pracy właśnie
          konsolidatora dynamicznego.
        </p>
        <h4>Odnajdywanie przez ld.so bibliotek współużytkowanych</h4>
        <p>
          Program <em>ld.so</em> posiada wewnątrz wstępnie skonfigurowaną
          <strong>ścieżkę wyszukiwania bibliotek</strong>. Do utworzenia tej
          wykorzystywana jest tzw. <em>składnica systemowa</em> - w pliku
          <em>/etc/ld.so.cache</em>. Zawiera ona informacje o bibliotekach
          współdzielonych i ich lokalizacji. Przyczym aby uwzględnić taką
          lokalizację należy podać ścieżkę do katalogu z bibliotekami w pliku
          konfiguracjnym składnicy - <em>/etc/ld.so.conf</em> lub w plikach
          wewnątrz katalogu <em>/etc/ld.so.conf.d</em>. Zawartość tego pliku
          zazwyczaj składa się ze ścieżek wskazujących na katalogi jakie należy
          dodać do składnicy. Poniżej znajduje się jeden z plików w katalogu
          <em>/etc/ld.so.conf.d</em>, zawierający listę ścieżek
        </p>
<pre class="code-block">
xf0r3m@vm-2339495:~/C$ cat /etc/ld.so.conf.d/x86_64-linux-gnu.conf
# Multiarch support
/usr/local/lib/x86_64-linux-gnu
/lib/x86_64-linux-gnu
/usr/lib/x86_64-linux-gnu
</pre>
        <p>
          Standardowe lokalizacje takie /usr/lib czy /lib, są domyślne i nie
          ma potrzeby ich dodawania do składnicy. Każda zmiana w pliku
          konfiguracyjnym wymaga przebudowania pliku samej składnicy,
          a dokonać tego możemy za pomocą poniższego polecenia:
        </p>
<pre class="code-block">
xf0r3m@vm-2339495:~/C$ sudo ldconfig -v
[sudo] hasło użytkownika xf0r3m:
ldconfig: Nie można wykonać stat na /usr/local/lib/x86_64-linux-gnu: Nie ma takiego pliku ani katalogu
ldconfig: Ścieżka `/usr/lib/x86_64-linux-gnu' podana więcej niż raz
(od /etc/ld.so.conf.d/x86_64-linux-gnu.conf:4 i /etc/ld.so.conf.d/x86_64-linux-gnu.conf:3)
ldconfig: Ścieżka `/lib/x86_64-linux-gnu' podana więcej niż raz
(od <builtin>:0 i /etc/ld.so.conf.d/x86_64-linux-gnu.conf:3)
ldconfig: Ścieżka `/usr/lib/x86_64-linux-gnu' podana więcej niż raz
(od <builtin>:0 i /etc/ld.so.conf.d/x86_64-linux-gnu.conf:3)
ldconfig: Ścieżka `/usr/lib' podana więcej niż raz
(od <builtin>:0 i <builtin>:0)
/usr/lib/x86_64-linux-gnu/libfakeroot: (od /etc/ld.so.conf.d/fakeroot-x86_64-linux-gnu.conf:1)
        libfakeroot-0.so -&gt; libfakeroot-tcp.so
/usr/local/lib: (od /etc/ld.so.conf.d/libc.conf:2)
/lib/x86_64-linux-gnu: (od /etc/ld.so.conf.d/x86_64-linux-gnu.conf:3)
        libzxcvbn.so.0 -&gt; libzxcvbn.so.0.0.0
        libzvbi.so.0 -&gt; libzvbi.so.0.13.2
        libzvbi-chains.so.0 -&gt; libzvbi-chains.so.0.0.0
        libzstd.so.1 -&gt; libzstd.so.1.5.5
        libzmq.so.5 -&gt; libzmq.so.5.2.5
        libzmf-0.0.so.0 -&gt; libzmf-0.0.so.0.0.2
        libzix-0.so.0 -&gt; libzix-0.so.0.4.2
        libzimg.so.2 -&gt; libzimg.so.2.0.0
        libzbar.so.0 -&gt; libzbar.so.0.3.0
        libz3.so.4 -&gt; libz3.so.4
</pre>
        <p>
          Opcja <code class="code-inline">-v</code> powoduje wyświetlenie
          bardziej szczegółowych komunikatów.
        </p>
        <p>
          Program <em>ld.so</em> może wykorzystać jeszcze jedno
          miejsce w celu znalezienia informacji na temat gdzie mogą znajdować
          się biblioteki - zmienną <strong>LD_LIBRARY_PATH</strong>. Nie
          we wszystkich systemach jest ona zdefiniowana i może zostać
          wykorzystana do wskazania niestandardowych bibliotek tuż przed
          uruchomieniem programu.
        </p>
        <p>
          Nie ma co za bardzo skupiać się na dodawaniu ścieżek do składnicy.
          Wprowadzone przez nas zmiany mogą doprowadzić do chaosu w systemie
          i powodować konflikty. Jeśli już musimy uzyć jakiejś niestandardowej
          biblioteki to należy już podczas kompilacji zadeklarować ją oraz
          jej lokalizację (w podrozdziale poniżej, pokazano jak to zrobić).
        </p>
        <h4>Konsolidacja programów z bibliotekami współużytkowanymi</h4>
        <p>
          Jeśli w kompilowanym programie używaliśmy jakiś niestandardowych
          bibliotek współużytkowanych, których próżno szukać w zasobach
          systemowych musimy podczas konsolidacji wskazać scieżkę oraz nazwę 
          biblioteki podczas uruchamiania kompilatora (tak jak robiliśmy to
          wcześniej - w przypadku bibliotek statycznych). Tutaj niezbędne
          będzie również wskazanie katalogu w celu dodania go do ścieżki
          wyszukiwania bibliotek. W tego typu przypadkach nie należy posługiwać
          się ustawieniami konsolidatora dynamicznego.
        </p>
        </p>
          Opcja, o której mowa to: <code class="code-inline">-Wl,-rpath</code>.
          Przykład poniżej może to zobrazować:
        </p>
<pre class="code-inline">
xf0r3m@laptop-5cfe659:~$ cc -o myprog myprog.o -Wl,rpath=/opt/pt/lib -L/opt/pt/lib -lnetstats
</pre>
        <p>
          Domyślny standardem dla plików wykonywalnych oraz bibliotek w
          dystrybucjach Linuksa jest <strong>ELF</strong> - <em>Executable and
          Linkable Format</em>, dzięki czemu możemy zmienić ścieżkę
          wyszukiwania bibliotek dla środowiska wykonawczego. Możemy tego
          dokonać za pomocą polecenia <em>patchelf</em>.
        </p>
        <h4>Problemy związane z bibliotekami współdzielonymi</h4>
        <p>
          Najczęściej występującym problemem związanym z bibliotekami
          współdzielonymi jest ich potencjalny brak w naszym systemie. Wówczas
          musimy szukać pakietów z końcówką <em>-dev</em> w nazwie i
          ześmiecać system gigabajtami niepotrzebnych plików. 
        </p>
        <p>
          Kolejną rzeczą może być, za długa wartość zmiennej
          <code class="code-inline">LD_LIBRARY_PATH</code>. Zawartość tej
          zmiennej jest odczytywana przez konsolidator, który następnie
          przeszukuje podane ścieżki pod kątem występowania bibliotek. Ta
          zmiana ma pierwszeństwo przez pozostałymi lokalizacjami, w których
          mogą wystąpić biblioteki w systemie. Dlatego też ustawienie jej
          globalnie gdzieś w systemie (np. w plikach konfiguracyjnych powłoki)
          może spowodować znaczy spadek wydajności systemu. Jeśli już musimy
          wskazać inną lokalizację bibliotek dla programów a nie chcemy
          ponownie kompilować (lub nie mamy takiej możliwości, brak kodu
          źródłowego), możemy utworzyć tzw. skrypt <em>opakowywujący</em> -
          manipulujący zawartością zmiennej
          <code class="code-inline">LD_LIBRARY_PATH</code> oraz uruchamiający
          żądany program. Przy czym zmienna zostanie zmieniona wyłącznie
          w obrębie procesu podpowłoki uruchomionego na potrzeby skryptu
          (Więcej o skryptach znajduje się w dodatku A). 
        </p>
        <p>
          Nie mniej jednak najlepszą ucieczką przez problemami związanymi  z
          bibliotekami jest ich wskazanie w procesie konsolidacji lub użycie
          bibliotek statycznych.
        </p>
        <h3 id="14.1.4.headersfiles">14.1.4. Pliki nagłówkowe</h3>
        <p>
          Aby programiści mogi skorzystać z bibliotek w swoich programach muszą
          się do nich w jakiś sposób odwołać. W języku C mogą wykorzystać do
          tego <strong>pliki nagłówkowe</strong> zawierający deklaracje typów
          oraz funkcji bibliotecznych. Jednym z takich plików, był <em>stdio.h</em>
          przedstawiany we wcześniejszych przykładach - ten plik nagłówkowy
          udostępniał nam funkcję <code class="code-inline">printf()</code>.
        </p>
        <p>
          Do wskazywania plików nagłówkowych służy dyrektywa
          <code class="code-inline">#include</code>. Czasami zdarza się, że
          programiści dodają omyłkowo jakiś plik nagłówkowy, który nie
          istnieje. Tego typu błędy zostają wyłapane już na poziomie kompilacji
          gdzie kod jest wstępnie analizowany.
        </p>
        <p>
          Oczywiście, może tak być, że wykorzystywane przez programistów
          pliki nagłówkowe nie znajdują się w standardowej lokalizacji dla
          tego rozdzaju plików w systemie (<em>/usr/include</em>). Jeśli tak
          jest to, możemy skorzystać z opcji kompliatora pozwalającą dodać
          podany katalog do ścieżki wyszukiwania plików nagłówkowych.
        </p>
<pre class="code-block">
xf0r3m@laptop-5cfe659:~$ cc -c -I/opt/pt/include netstats.c
</pre>
        <p>
          Istnieją dwie metody na dołączenie plików nagłówkowych do kodu
          programu. Różnice te są dość subtelne jednak mają dość duże
          znaczenie. 
        </p>
<pre class="code-block">
#include &lt;stdio.h&gt;
</pre>
        <p>
          Klasyczne dołączenie pliku nagłówkowego. Mówi on nam, że kompilator
          będzie przeszukiwać zasoby systemowego, aby użyć tego pliku na
          potrzeby kompilacji.
        </p>
<pre class="code-block">
#include "ip.h"
</pre>
        <p>
          Użycie podwójnych apostrofofów zamiast ostych nawiasów, spowoduje że
          kompilator przeszuka katalog z podanym kodem źródłowym w poszukiwaniu
          tak załączonego pliku nagłówkowego. Tak załączone pliki nagłówkowe
          muszą występować w tym samym folderze do kompilowany kod źródłowy.
          Jest to przydatne w przypadku, gdy korzystamy z własnych plików tego
          rodzaju. 
        </p>
        <h4>Preprocesor języka C</h4>
        <p>
          Wcześnie mówiliśmy o kompilatorze w kontekście odnajdywania plików
          nagłówkowych, jednak nie jest do dokońca prawdą. Preprocesor w
          przypadku języka C, zajmuje się dostoswaniem kodu pisanego przez
          człowiek dla kompilatora. Wykonuje on swoje działania na podstawie
          <strong>dyrektyw</strong> zapisywanych przez ludzi w kodzie dodając
          do niego kilka uproszczeń oraz skrótów. 
        </p>
        <p>
          Dyrektywy to nic innego jak instrukcje. Jednak, aby odróżniały się
          do instrukcji właściwego języka w C, poprzedza się znakiem
          krzyżyka (<strong>#</strong>). Taką dyrektywę poznaliśmy już, a jest
          nią dyrektywa <code class="code-inline">#include</code>. W języku C
          dostępne są trzy rodzaje dyrektyw:
        </p>
        <ul>
          <li><strong>Dołaczenia plików nagłówkowych</strong> - <em>#include</em>
            - nakazuja preprocesorowi dołaczyć do kodu źródłowego cały plik
            nagłówkowy.</li>
          <li><strong>Makra</strong> - <em>#define</em> - makra nakazują
            zmianę w kodzie nazwy makra np. <em>PI</em> na jej wartość np.
            <em>3.14</em>. Konwencja mówi, że nazwy makr zapisujemy wielkimi
            literami i nie należy przesadzać z ich stosowaniem. Nie są one
            również tożsame ze stałymi, które możemy znać innych języków
            programowania. Przykładem makra może być np.:
<pre class="code-block">
#define PI 3.14
</pre>
</li>
          <li><strong>Kompilacja warunkowa</strong> - <em>#ifdef</em>,
            <em>#if</em>, <em>#endif</em> - zwane rownież dyrektywami
            warunkowymi. Pozwalaja one kontrolować kompilację kodu źródłowego
            na podstawie występowania makr w preprocesorze
            (dyrektywa <em>#ifdef</em>) lub niezerowego <em>warunku</em>
            (dyrektywa <em>#if</em>). W przypadku gdy warunek nie jest
            spełniony, kod źródłowy między dyrektywami <em>#ifdef</em> oraz
            <em>#if</em> a <em>#endif</em> nie zostanie w ogóle skompilowany.
          </li>
        </ul>
        <p>
          Istotnym czynnikiem w wykorzystaniu makr a co za tym idzie kompilacji
          warunkowej jest możliwość przekazania makra do preprocesora za pomocą
          opcji <em>-D</em> kompilatora. Taka możliwość interakcji, na pewno
          bardziej wyjaśnia sens istnienia dyrektyw oraz samego preprocesora.
        </p>
        <p>
          Odnośnie samego preprocesora, to nie zna on żadnych elementów języka
          C. Jest on skupiony wyłącznie na makrach oraz pozostałych dyrektywach.
        </p>
        <h2 id="14.2.make">14.2. Narzędzie make</h2>
        <p>
          Do tej pory kompilacja składała się maksymalnie z dwóch plików i
          nie obejmowała żadnych bibliotek. Przy takich projektach kompilacją
          była szybka i przyjmna. Jednak w 99% przypadków z jakim możemy
          spotkać się raczej tak nie będzie folder będą zawierać podkatalogi
          a w nich sterty plików ręczna kompilacja, przy nie których
          mogła by zająć tygodnie jak nie lata. Dlatego też powstało narzędzie
          typu <strong>make</strong>. Narzędzie <em>make</em> ma za zadanie
          zarządzać procesem kompilacji. Mimo, że jest to potężny program to
          jest on dość prosty w działaniu. Jeśli gdzieś w paczkach z kodem
          znajdziemy plik <em>makefile</em> lub <em>Makefile</em> oznacza to
          możemy użyć programu <em>make</em> do kompilacji projektu.
        </p>
        <p>
          Działanie <em>make</em> polega na <strong>celu</strong> jaki chcemy
          osiągnąć, gdy je uruchamiamy. Takim celem najczęściej jest pliki
          wykonywalny, ale mogą to być również inne byty programistczne takie
          jaki pliki obiektowe. Same cele mogą się rozgałęziać być uzależnione
          od wyników działania innych celów. Cele tego rodzaju nazwyamy
          zależnościami.
        </p>
        <p>
          W czasie wykonywania celów, narzędzie postępuje zgodnie z
          <strong>regułą</strong> (ang. <em>rule</em>), która może np. określać
          sposób w jaki kod źródłowy ma zostać zmieniony na plik obiektowy.
          Sam <em>make</em> posiada już zdefiniowane reguły, ale możemy je
          dostosowywać do własnych potrzeb jak i również tworzyć własne.
        </p>
        <h3 id="14.2.1.examplemakefile">14.2.1. Przykładowy plik Makefile</h3>
        <p>
          Na podstawie dwóch plików z poprzedniego podrozdziału utworzyłem 
          przykładowy plik <em>Makefile</em>. Plik ten tworzy znany nam
          rownież plik <em>myprog</em>, który nie robi nic więcej poza
          wyświetleniem napisu <em>Hello, World!</em>. 
        </p>
<pre class="code-block">
xf0r3m@laptop-7bf2993:~/prog/C$ cat Makefile 

OBJS=aux.o main.o
all: myprog
myprog: $(OBJS)
	      $(CC) -o myprog $(OBJS)
</pre>
        <p>
          W pierwszej linii znajduje się definicja makra, która w tym
          przypadku wskazuje na dwie nazwy plików obiektowych
          (<code class="code-inline">OBJS=aux.o main.o</code>). W następnej
          linii znajduje się bowiem reguła
          (<code class="code-inline">all:</code>) reguły jak już wcześniej
          wspomniano określają sposób w jaki ma zostać zbudowany cel. W tym
          przypadku reguła <code class="code-inline">all:</code> wskazuje
          mogłoby się wydawać, że na nasz plik końcowy. Jest to poczęści
          prawda, ale zwróćmy uwagę na to, że poza
          <code class="code-inline">myprog</code> nie znajduje się nic innego.
          W jaki sposób narzędzie <em>make</em> ma wiedzieć jak zbudować ten
          ten program. Odpowiedź kryje się w linii niżej, bowiem 
          <code class="code-inline">myprog</code> jest <strong>celem</strong>,
          a co za tym idzie zależnością dla
          <code class="code-inline">all:</code>. W przypadku celu
          <code class="code-inline">myprog:</code> widzimy już jakieś konkrety:
          pierwszym jest odwołanie się do makra, jest ono rozwiązywane do
          nazw zapisanych na początku pliku <em>Makefile</em>, w pliku nie
          znajduje się żadne inne elementy systemu <em>Make</em> o tej nazwie
          tak więc ten cel jest od tych plików uzależniony. Warto dodać, że
          <em>Make</em> zakłada, że plki źródłowe znajdują się w tym samym
          katalogu co pliki <em>Makefile</em>. Uruchomienie polecenia
          <em>make</em> w tym katalogu prezentuje się następująco.
        </p>
<pre class="code-block">
xf0r3m@laptop-7bf2993:~/prog/C$ make
cc    -c -o aux.o aux.c
cc    -c -o main.o main.c
cc -o myprog aux.o main.o
</pre>
        <p>
          Poza tym co sami zapisaliśmy w pliku <em>Makefile</em> to nie
          wszystkie czynności jakie są wykonywane przez system <em>Make</em>.
          W <em>Makefile</em> użyliśmy plików obiektowych, zatem skąd narzędzie
          ma wiedzieć o tym, że ma wykorzystać pliki kodu źródłowego
          (<em>.c</em>), aby utworzyć pliki obiektowe (<em>.o</em>). Za tego
          typu czynności odpowiadają <strong>reguły wbudowane</strong>. Przez
          co osoby zajmujące się utworzeniem plików <em>Makefile</em> mogą
          od razu operować na właściwych plikach.
        </p>
        <p>
          Ostatnia linia pliku <em>Makefile</em> jest odpowiedzialna za 
          zbudowanie właściwego pliku wykonywalnego naszego programu.
          Po wcześniejszym przygotowaniu plików obiektowych z plików
          źródłowych odwołanie się do makra
          <code class="code-inline">$(OBJS)</code> staje się zwykłym
          podstawieniem argumentów do polecenia. Ta linia jest zwykłym
          poleceniem utworzonym na podstawie makr pliku <em>Makefile</em>.
          Każde polecenie w pliku <em>Makefile</em> musi zostać
          wprowadzone w nowej linii i poprzedzone
          znakiem tabulacji równym czterem znakom spacji.
          Makro <code class="code-inline">$(CC)</code>
          przechowywuje nazwę programu kompilatora C, w wiekszości przypadku
          jej wartość będzie ustawiona na <em>cc</em>.
        </p>
        <p>
          Jednym z najczęstszych błędów, jakie możemy doświadczyć na początku
          tworzenia plików <em>Makefile</em> jest:
        </p>
<pre class="code-block">
xf0r3m@laptop-7bf2993:~/prog/C$ make
Makefile:5: *** brakujący separator. Stop.
</pre>
        <p>
          Wynika to najczęściej ze złego ustawienia szerokości tabulacji w
          naszym edytorze. Ja korzystam z 2 spacji na 1 tab, ze względu na
          wytyczne <em>Makefile</em> musiałem zmienić swoje ustawienia.
        </p>
        <h3 id="14.2.2.updatemakedeps">14.2.2. Aktualizacjia zależności</h3>
        <p>
          Program make został zaprojektowany w taki sposób aby do realizacji
          określonego celu była wymagana jak najmniejsza ilość kroków. Tak
          więc nie uświadczymy ponownego budowania programu w momencie
          ponownego wydania polecenia <em>make</em>. Aczkolwiek jedną z zasad
          systemu <em>Make</em> jest to, że cele zawsze powinny być budowane
          wraz ze swoimi zależnościami. Taki komunikat otrzymamy gdy 
          wydamy polecenie <em>make</em> jeszcze raz.
        </p>
<pre class="code-block">
xf0r3m@laptop-7bf2993:~/prog/C$ make
make: Nie ma nic do zrobienia w 'all'.
</pre>
        <p>
          Natomiast jeśli chociażby zmienimy czas modyfikacji, któregoś z 
          plików kodu
          źródłowego za pomocą prostego polecenia <em>touch</em>. Wówczas plik
          obiektowy będzie starszy niż plik źródłowy i <em>Make</em> dokona
          budowy naszego programu ponownie.
        </p>
<pre class="code-block">
xf0r3m@laptop-7bf2993:~/prog/C$ touch aux.c
xf0r3m@laptop-7bf2993:~/prog/C$ make
cc    -c -o aux.o aux.c
cc -o myprog aux.o main.o
</pre>
        <p>
          Z tą róźnicą, że zaktualizowany zostanie wyłącznie ten plik, który
          został zmieniony oraz ponownie zostanie zbudowany końcowy plik
          wykonywalny.
        </p>
        <h3 id="14.2.3.makecommandargs">14.2.3. Argumenty i opcje wiersza poleceń programu make</h3>
        <p>
          Uzupełniając wywołanie programu <em>make</em> o różne opcje oraz
          argumenty możemy zmusić go do wykonani kilku przydatnych czynności.
          Najprostszym przykładem może być zmiana wartości makra <em>CC</em>,
          wskazując inny niż domyślny kompilator.
        </p>
<pre class="code-block">
$ make CC=clang
</pre>
        <p>
          Tak utworzone makra mogą być przydatne w trakcie testów. Szczególnie
          takie jak <em>CFLAGS</em> oraz <em>LDFLAGS</em>. Innym przypadkiem
          może być użycie programu <em>make</em> dla najprostrzych programów
          wówczas podajemy nazwe pliku bez rozszerzenia jako argument,
          a program zbuduje nam końcowy plik wynikowy o podanej nazwe. Zwróćmy
          uwagę, że nie ma potrzeby przygotowania pliku <em>Makefile</em>.
        </p>
<pre class="code-block">
$ make foo
cc  foo.o   -o foo
</pre>
        <p>
          Tego typu uruchmianie narzędzia <em>make</em> bedzie sprawdzać się
          w przypadku programów zapisanych w jednym pliku lub programów, w
          których jezykiem nie jest C. Jest to dobre rozwiązanie gdy dopiero
          rozpoczynamy pracę z danym językiem i nie wiem jeszcze jak działa
          kompilator czy inne narzędzia z nim związane. Jeśli nawet zbudowanie
          celu się niepowiedzie to i tak otrzymamy informację zwrotną co jest
          nie tak.
        </p>
        <p>
          Po za zmianami makr, możemy wykorzystać kilka przydatnych opcji
          takich jak:
        </p>
        <ul>
          <li><strong>-n</strong> - wypisuje polecenia wymagane do zbudowania
            programu, ale nie pozwala na ich wykonanie (taki <em>dry-run</em>).
          </li>
          <li><strong>-f <em>plik</em></strong> - nakazuje narzędziu
            <em>make</em> odczytać dane z podane pliku zamiast z pliku
            <em>Makefile/makefile</em>.</li>
        </ul>
        <h3 id="14.2.4.makestdmacrosandvars">14.2.4. Standardowe makra i zmienne</h3>
        <p>
          System <em>make</em> posiada wiele predefiniowanych zmiennych oraz
          makr. Sama różnica między makrami i zmiennymi jest trudna do
          określenia. Dlatego też przyjęło się, że makra są niezmienne przez
          cały okres trwania jakiegoś procesu. W tym przypadku nazwiemy tak
          wszystko co nie zmieni się od momemntu rozpoczęcia procesu
          budowania celów zawartych w pliku <em>Makefile</em>.
        </p>
        <p>
          Najczęsciej wykorzystywane makra to między innymi:
        </p>
        <ul>
          <li><strong>CFLAGS</strong> - opcje kompilatora C. <em>Make</em>
          przekazuje je kompilatorowi w czasie tworzenia kodu obiektowego z
          plików <em>.c</em>.</li>
          <li><strong>LDFLAGS</strong> - opcje przekazywane do konsolidatora w
          czasie tworzenia pliku wykonywalnego z plików obiektowych.</li>
          <li><strong>LDLIBS</strong> - w przypadku gdy niechcemy łączyć opcji
          nazw bibliotek ze ścieżką wyszukiwania zapisaną w makrze
          <em>LDFLAGS</em>, to można umieszcząć je w tym makrze.</li>
          <li><strong>CC</strong> - nazwa kompilatora języka C. Domyślnie jest
          to <em>cc</em>.</li>
          <li><strong>CPPFLAGS</strong> - opcje <em>preprocesora</em> języka
          C. Jeżeli w którymś momencie system <em>make</em> będzie wywoływał
          preprocesor, to przekaże mu podane w tym makrze opcje.</li>
          <li><strong>CXXFLAGS</strong> - opcje kompilatora języka C++.</li> 
        </ul>
        <p>
          Poza makrami w narzędziu <em>make</em> możemy korzystać ze zmiennych.
          Zmienne mogą zmienić się podczas budowania zdefiowanych celów w
          <em>Makefile</em>. Najczęściej jednak będziemy się spotykać ze
          zmiennymi zdefiniowanymi automatycznie w obrębie reguł celów. Oto
          trzy z nich:
        </p>
        <ul>
          <li><strong>$@</strong> - wewnątrz reguły, zmienna opisuje nazwę jej
            celu.</li>
          <li><strong>$&lt;</strong> - wewnątrz reguły, zmienna opisuje
            pierwszą zależność celu.</li>
          <li><strong>$*</strong> - zmienna rozwijana jest w <em>nazwę
            podstawową</em> aktualnego celu. Wczasie tworzenia celu
            <em>foo.o</em>, ta zmienna przechowuje nazwę <em>foo</em>.</li>
        </ul>
        <h3 id="14.2.5.makecommoncomptarget">14.2.5. Typowe cele kompilacji</h3>
        <p>
          W plikach <em>makefile</em> odpowiedzialnych za pokierowanie systemu
          <em>make</em> faktycznych programów użytkowych możemy spotkać wiele
          innych celów realizujących zadania niekoniecznie związane z
          kompilacją. Są one predefiniowane przez <em>make</em> i oto kilka z
          nich:
        </p>
        <ul>
            <li><strong>clean</strong> - ten cel usuwa wszystkie pliki obiektowe
            oraz pliki wykonywalne, dzięki temu będziemy mogli rozpocząć
            proces kompilacji od nowa.</li>
            <li><strong>distclean</strong> - cel podobny do <em>clean</em>,
            ale usuwa on wszystko co nie jest częścią oryginalnej dystrybucji
            w tym i plik <em>makefile</em>.</li>
            <li><strong>install</strong> - ten cel powoduje skopiowanie
            wszystkich plików, które w <em>Makefile</em> zostały oznaczone
            jako nięzbędne do zainstalowania w systemie. Operacja jest
            uznawana za dość niebezpieczną warto w tym przypadku zastosować
            opcję <em>-n</em>, która pozowoli nam zobaczyć co dokładnie
            będzie kopiowane do naszego systemu.</li>
            <li><strong>test</strong> lub <strong>check</strong> - cel pozwala
            sprawdzić czy po skompilowaniu wszystko działa jak należy.</li>
            <li><strong>depend</strong> - cel ten tworzy zależności
            wywołując kompilator ze specjalną opcją -M nakazującą mu sprawdzenie
            kodu. Cel ten nie jest już powszechnie używany, aczkolwiek mogą
            zdarzyć się projekty, które będą wymagać wywołanie tego celu.</li>
            <li><strong>all</strong> - najczęściej pierwszy cel w pliku
            <em>Makefile</em>. W wielu projektach będziemy spotykać się z
            potrzebą wywołanie tego celu, a nie samego pliku wykonywalnego.
            Wiele projektów składa się z wielu plików wykonywalnych i często
            nie ma tego jednego głównego. Natomiast użycie celu <em>all</em>
            pozwala na zbudowanie ich wszystkich w trakcie jednej czynności.
            </li>
        </ul>
        <h3 id="14.2.6.makefilesstyles">14.2.6. Organizowanie pliku Makefile</h3>
        <p>
          Istnieje wiele róznych stylów tworzenia plików <em>Makefile</em>,
          mimo tego stosowanych jest kilka ogólnych zasad. W pierwszej
          częsci pliku, najcześciej spotykane są (jako definiecje makr)
          opcje bibliotek oraz plików nagłówkowych po grupowanych wg.
          określonych pakietów.
        </p>
<pre class="code-block">
MYPACKAGE_INCLUDES=-I/usr/local/include/mypackage
MYPACKAGE_LIB=-L/usr/local/lib/mypackage -lmypackage
PNG_INCLUDES=-I/usr/local/include
PNG_LIB=-L/usr/local/lib -lpng
</pre>
        <p>
          Następnie zapisywane są makra z opcjami kompilatora oraz opcje
          konsolidatora każde z opcji zapisywane jest w osobnym makrze.
        </p>
<pre class="code-block">
CFLAGS=$(CFLAGS) $(X_INCLUDES) $(PNG_INCLUDES)
LDFLAGS=$(LDFLAGS) $(X_LIB) $(PNG_LIB)
</pre>
        <p>
          Po tych opcjach zapisywana jest hierarchia makr opisujących pliki
          obiektowe. Hierarchia ze względu na zależności.
        </p>
<pre class="code-block">
UTIL_OBJS=util.o
BORING_OBJS=$(UTIL_OBJS) boring.o
TRITE_OBJS=$(UTIL_OBJS) trite.o
PROGS=boring trite
</pre>
        <p>
          W pozostałej częsci plików występują już cele, które składają główne
          pliki wykonywalne. Jeśli trzeba przygować regułę dla pliku obiektowego
          należy ją umieścić zaraz nad regułą programu pliku wykonywalnego.
          Jeśli z tego pliku obiektowego korzysta więcej plików wykonywalnych
          niż ten jednen to trzeba je przenieść nad nie wszystkie.
        </p>
        <h2 id="14.3.lexandyacc">14.3. Lex i Yacc</h2>
        <p>
          Programy odczytujące pliki konfiguracyjne lub polecenia korzystają
          z takich narzędzi jak <strong>Lex</strong> oraz <strong>Yacc</strong>.
          Także możemy spotkać się z nimi podczas budowania niektórych
          projektów.
        </p>
        <ul>
          <li>Program <em>Lex</em> jest <strong>analizatorem leksykalnym</strong>,
          jego zadaniem jest przekształcenie tekstu w specjalne znaczniki
          opisane etykietami. Dostępną w dystrybucjach Linuksa implementacja
          programu <em>Lex</em> nosi nazwę <em>flex</em>. Korzystając tego
          programu będziemy musieli użyć opcji konsolidatora takich jak:
          <em>-ll</em> lub <em>-lfl</em>.</li>
          <li>Program <em>Yacc</em> jest to <strong>analizator składniowy</strong>.
          Jego zadaniem jest odczyt składni zgodnie z wcześniej ustaloną
          <em>gramatyką</em>. W dystrybucjach Linuksa dostępna jest
          <em>bison</em>, który może być kompatybilny z programem <em>yacc</em>
          w momencie gdy użyjemy opcji <em>-y</em>, natomiast dla konsolidatora
          będziemy musieli użyć opcji <em>-ly</em>.</li>
        </ul>
        <h2 id="14.4.scriptlanguages">14.4. Języki skryptowe</h2>
        <p>
          Kiedyś poza obsługą powłoki oraz programu <strong>awk</strong>
          użytkownik nie musiał znać żadanych innych skryptowych języków
          programowania, zmieniło się to wraz z rozpowszechnieniem się takich
          języków jak <strong>Perl</strong> a w poźniejszych latach
          <strong>Python</strong>. Niektóre z narzędzi systemowych zostały
          przepisane z klasycznego C do np. Pythona - na przykład narzędziem
          <em>whois</em>. Języki skryptowe obecnie przechylają szalę na swoją
          korzyść względem języków kompilowanych, mimo to zalety takich języków
          jak C oraz wpisanie się tego języka w rdzeń nauk komputerowych
          nie sposowoduje zaprzestania jego używania nawet w ciągu kilku
          następnych dziesięcioleci. Język ten jest językiem niskopoziomowym,
          wymagającym abstrakcyjnego myślenia i dość trudnym w jego bardziej
          zaawansowanym zastosowaniu, dlatego też większość młodszych
          programistów skupia się na językach skryptowych, w których można
          osiągnać podobne rezultaty mniejszym kosztem.
        </p>
        <p>
          W większości przypadków skrypty rozpoczynają się od wskazania
          interpretera poniższego skryptu. Takie wskaznie rozpoczyna się od
          od znaków <em>#!</em> (każdy plik tekstowy rozpoczynający się tych
          znaków uznawany jest za skrypt), po których bez przerwy występuje
          ścieżka
          wskazująca na właściwy program interpretera danego języka. Dla języka
          Perl, wskazanie interpretera prezentuje się w następujący sposób:
        </p>
<pre class="code-block">
#!/usr/bin/perl -w
</pre>
        <p>
          Natomiast dla języka Python wygląda to następująco:
        </p>
<pre class="code-block">
#!/usr/bin/env python
</pre>
        <p>
          W systemie może być dostępnych kilka wersji Pythona. Za pomocą tego
          rozdzaju wskazania wybieramy pierwszą wersję, która znajduje się
          na ścieżce wyszukiwania poleceń. Inną metodą na wskazanie
          interpretera Pythona jest: <em>#!/usr/bin/python3</em>, wskazująca
          konkretnie na jedną z 3 wersji Pythona, obecnie 3.12.
        </p>
        <p>
          Opiszemy sobie teraz kilka ważniejszych języków skryptowych.
        </p>
        <ul>
          <li><strong>Python</strong> - Python zapewnia nam bogaty zestaw
          funkcji pozwalających rozwiązać każdy problem związany np. z
          przetwarzeniem tesktu, obsługą baz danych czy sieci. Dostarcza on
          interaktywną powłokę, w które możemy linia po lini testować nasze
          rozwiązania. Język ten posiada on dość dobry model obiektowy.
          Jego zakres zastosowań jest obecnie bardzo szeroki, podobny do języka
          C, może poza programowaniem układowym oraz architekturą jąder
          systemowych czy sterowników urządzeń. Jest on prosty do nauki o ile
          nie posiada się naleciałości z innych języków takich jak np. C.</li>
          <li><strong>Perl</strong> - język skrytowy stworzony dla systemów
          Uniksowych. Język ten ma ogromne możliwości porównywalne z Pythonem,
          jednak nie jest on taki prosty w użyciu. Jego głównym zadaniem jest
          obróbka tekstu. Obecnie wiele narzędzi wykorzystuje jego możliwości
          np. znany wszystkim system kontroli wersji - <em>Git</em>.</li>
          <li><strong>PHP</strong> - jest językiem służacym do dynamicznego
          tworzenie treści na stronach internetowych. Można wykorzystać go
          do generowania stron hipertekstowych oraz do modyfikacji
          baz danych SQL.</li>
        </ul>
        <p>
          Innym wartym wspomnienia językiem jest <strong>m4</strong>
          odpowiedzialny z przetwarzanie makr. Dostępny jest on w systemie
          GNU <em>autotools</em>. Bierze udział w automatycznym generowaniu
          pliku <em>Makefile</em> (Wiecej w 15 rozdziale).
        </p>
        <h2 id="14.5.java">14.5. Język Java</h2>
        <p>
          Java podobnie do języka C jest językiem kompilowanym. Zapewnia on
          prostszą składnie oraz duże możliwości progrowamowania obiektowego.
          Dawniej służył on jako środowisko dla aplikacji internetowych, jednak
          obecnie zmieniło się na rzecz interpretowanego przez przeglądarki
          JavaScriptu. Nie mniej jednak możemy spotkać się z aplikacją Javy na
          na dystrybucjach Linuksa lub z potrzebą uruchomienia takowej. Dlatego
          też warto się zapoznać, chociaż w podstawowym stopniu z zapoznać się
          z obsługą projektów w tworzonych w tym języku.
        </p>
        <p>
          Java może być kompilowana w dwojaki sposób. Kompilator może
          przekształcić kod źródłowy do kodu maszynowego zgodnego z naszym
          systemem (tak samo, jak w przypadku języka C) lub może przetworzyć
          kod źródłowy na tzw. <strong>kod bajtowy</strong> interpretowany
          poźniej przez <em>wirtualną maszynę</em> Javy (interpreter). W
          Uniksach najczęściej będziemy się spotykać z kodem bajtowym - pliki
          z rozszerzeniem <em>.class</em>.
          Wszystkie niezbędne uruchomienia narzędzia znajdują się w pakiecie
          zwanym środowiskiem uruchomieniowym Javy (<em>JRE</em>). Jeśli mamy
          go zainstalowanego w systemie to do uruchomienia wystarczy wydać
          poniższe polecenie:
        </p>
<pre class="code-block">
$ java file.class
</pre>
        <p>
          Kod bajtowy może również występować w postaci skompresowanej,
          wówczas będziemy mieć doczynienia z plikami z rozszerzeniem 
          <em>.jar</em>. Je również możemy uruchomić w podobny sposób jak
          zwykły kod bajtowy wystarczy użyć opcji <em>-jar</em>, tak jak
          pokazano to na poniższym przykładzie.
        </p>
<pre class="code-block">
$ java -jar file.jar
</pre>
        <p>
          Czasami do wykorzystania programów Java będzie potrzebne zdefiniowanie
          dwóch zmiennych <strong>JAVA_HOME</strong> zawierającej ścieżkę do
          katalogu z instalacją JRE. Drugą zmienną jest <strong>CLASSPATH</strong>,
          zmienna ta zawiera nazwy katalogów przechowywujących pliki kodu
          bajtowego, których dany program może wymagać.
        </p>
        <p>
          Jesli zajdzie taka potrzeba, aby skompilować kod Javy to w zestaw
          narzędzi programistycznych JDK wchodzi w skład kompilator
          <strong>javac</strong>. Uruchmiamy go podobnie do interpretera.
          W skład JDK wchodzi również polecenie <em>jar</em>, które może
          kompresować kod bajtowy Javy.
        </p>
<pre class="code-block">
$ javac file.java
</pre>
        <h1 id="15.introducingtoccsourcecodesoftware">15. Wprowadzenie do kompilacji oprogramowania kodu źródłowego C</h1>
        <p>
          Jedną z wielu zalet dystrybucji Linuksa jako systemu operacyjnego
          jest fakt, że większość dostępnego na niego oprogramowania jest nie
          tyle darmowa co rozprowadzana poprzez archiwa zawierające kod
          źródłowy danego programu. Każdy może sobie go pobrać, użyć, dostosować,
          a nawet redystrybuować z uznaniem pierwotnego autora, jednak ten
          aspekt jest już kwestią licencji na jakiej dostarczany jest on do
          użytkowników. W ten sposób prezentuje się idea
          <strong>open source</strong> - otwartych źródeł.
        </p>
        <p>
          W zamierzchłych czasach gdy komputery znajdowały się w zasięgu
          uczelni wyższych, nawet oprogramowanie własnościowe było
          rozprowadzane przy użyciu kodu źródłowego. Dawniej chcać skorzystać z
          programu
          trzeba było wyposażyć się w zestaw narzędzi programistycznych aby
          móc w ogóle go uruchomić. Czy te czasy minęły? I tak i nie. Obecnie
          w wielu dystrybucjach częściej stosuje się paczki przygotowywane
          osoby związane z dystrybucją aniżeli archiwa kodu niezależnie
          rozprowadzane przez autora programu. Ma to oczywiście swoje wady oraz
          zalety. Tym rozdziale spróbujemy sobie przybliżyć w jaki sposób
          możemy zainstalować aplikację dostępną w postaci kodu źródłowego
          w naszym systemie.
        </p>
        <h2 id="15.1.softwarebuildsystems">15.1. Systemy do budowania oprogramowania</h2>
        <p>
          Jak pamietamy z poprzedniego rozdziału do automatycznego stworzenia
          pliku wykonywalnego dla naszej przykładowej aplikacji
          wykorzystaliśmy narzędzie <em>make</em>, narzędzie to wymaga pliku
          <em>Makefile</em>, w którym to zapisywane były cele, zależności czy
          różnego rodzaju makra. Jednym z systemów budowania oprogramowania
          dostępnym na Uniksy jest <strong>GNU autoconf</strong>. Zadaniem
          skryptów tego narzędzia jest przygotowanie plików <em>Makefile</em>
          na podstawie analizy docelowego systemu. System ten korzysta z
          istniejących już narzędzi takich jak <em>make</em>. Natomiast jeśli
          mieli byśmy opisać proces instalacji programów w C w Uniksach to
          wyglądałby on następująco:
        </p>
        <ol>
          <li>Rozpakowanie archiwum z kodem źródłowym.</li>
          <li>Konfigurowanie pakietu.</li>
          <li>Uruchomienie polecenie <em>make</em> lub innego polecenia
          służącego do kompilacji programów.</li>
          <li>Uruchomienie polecenie <em>make install</em> i instalacja
          programów.</li>
        </ol>
        <h2 id="15.2.sourcecodeunpack">15.2. Rozpakowywanie kodu źródłowego.</h2>
        <p>
          Oczywiście zdaje sobie sprawę, że chyba nie trzeba opisywać procesu
          rozpakowywania archiwów w Uniksach. Ten temat był już wałkowany na
          samym początku. Nie mniej jednak w przypadku kodu źródłowego, warto
          zachować pewną dozę niepewności. Otóż zadajmy sobie proste pytanie.
          Co odróżnia program przydatny od szkodliwego oprogramowania?
          Odpowiedź jest prosta. Czynności jakie on wykonuje. Na pewnej
          płaszczyźnie jedno i drugie to programy, które mogą
          być rozporowadzane w postaci kodu źrodłowego, który zostanie być może
          zostanie przez nas pobrany, skompilowany i zainstalowany w systemie.
          Najczęstszym tego typu oprogramowaniem są konie trojańskie. Dlatego
          też przed rozpakowaniem takiej paczki z kodem należy upewnić się
          co jest w środku. Opcja <strong>-t</strong> polecenia <em>tar</em>,
          pozwoli nam wyświetlić zawartość archiwum bez jego wcześniejszego
          rozpakowywania. Na co powinno się zwrócić uwagę? Otóż na taki
          drobiazg jak <strong>scieżka bezwzględna</strong>, przez co
          wypakowanie może nadpisać ważne systemowe pliki.
        </p>
        <p>
          W samych archiwach możemy natknąć się takie pliki jak README czy
          INSTALL. Te pliki mogą zawierać ważne informacje dotyczące
          ustawień narzędzi programistycznych, a nawet cała instrukcję krok po
          kroku jak skompilować i zainstalować ten program w naszym systemie. 
        </p>
        <h2 id="15.3.gnuautconf">15.3. GNU autoconf</h2>
        <p>
          Jeśli kiedyś uczyliśmy się jezyka C, to wiemy że jest on przenośny
          między systemami, jednak między systemami operacyjnymi czy
          platformami sprzętowymi instnieje tak wiele różnic, że najczęściej
          użycie pojedynczego pliku <em>Makefile</em> nie wykonana poprawnie
          budowania programu. Rozważano opcję utworzenia dla każdej platformy
          osobny plik <em>Makefile</em> jednak. To wspomniany wcześniej
          <em>GNU autoconf</em> stał się rozwiązaniem tego problemu.
        </p>
        <p>
          Projekty programistyczne przygotowane do współpracy z <em>GNU autoconf</em>
          zazwyczaj są dostarczane z plikami <em>configure</em>, <em>Makefile.in</em>
          oraz <em>config.h.in</em>. Pliki z rozszeniami <em>.in</em> są
          szablonami.
        </p>
        <p>
          Natomiast sama koncepcja jest dość prosta. Polega ona na uruchomieniu
          pliku <em>configure</em>, który sprawdzi system i dokona odpowiednich
          podstawień w pliku <em>Makefile.in</em>, tworząc odpowiedni plik
          <em>Makefile</em> dla uruchomionego systemu oraz platformy
          sprzętowej. Uruchomienie skryptu następuje w bardzo prosty sposób.
        </p>
<pre class="code-block">
$ ./configure
</pre>
        <p>
          W czasie działania skryptu zostanie nam wyświetlona duża ilość
          komunikatów diagonstycznych. Jeśli działanie skryptu zakończy się
          powodzeniem, to wówczas zostanie wygenerowany co najmniej jeden
          pliki <em>Makefile</em>, <em>config.h</em> oraz <em>config.cache</em>.
          Dzięki czemu nie ma potrzeby przeprowadzania wszystkich testów
          ponownie w przypadku kolejnego uruchomienia skryptu.
        </p>
        <h3 id="15.3.1.sampleusageofgnuautoconf">15.3.1. Przykładowe użycie systemu GNU autoconf</h3>
        <p>
          Dla przykładu uruchomimy sobie testowe budowanie jakieś małego
          projektu, aby nabrać nieco praktyki w systemie <em>GNU autoconf</em>
          zanim przejdziemy do jego ustawień. Dla przykładu wybrałem pakiet
          <em>GNU coreutils</em>, zawierający narzędzia poznane w drugim
          rozdziale. Paczkę z kodem źródłowym możemy pobrać z adresu:
          <a href="http://ftp.gnu.org/gnu/coreutils/">http://ftp.gnu.org/gnu/coreutils/</a>
          Kod należy pobrać, rozpakować a następnie skonfigurować. Żeby nie
          robić bałaganu w używanym systemie ustawimy jako katalog docelowy
          jeden z podkatalogów w naszym katalogu domowym.
        </p>
<pre class="code-block">
󱩊 xf0r3m@laptop-d71f06f/ coreutils-9.5/󰯆 ./configure --prefix=$HOME/mycoreutils
checking for a BSD-compatible install... /usr/bin/install -c
checking whether build environment is sane... yes
checking for a race-free mkdir -p... /usr/bin/mkdir -p
checking for gawk... no
checking for mawk... mawk
checking whether make sets $(MAKE)... yes
checking whether make supports nested variables... yes
checking whether make supports nested variables... (cached) yes
checking for gcc... gcc
checking whether the C compiler works... yes
checking for C compiler default output file name... a.out
...
config.status: executing po-directories commands
config.status: creating po/POTFILES
config.status: creating po/Makefile
</pre>
        <p>
          Po zakończeniu działania skryptu <em>configure</em>, zostaje
          wygenerowany na podstawie pliku <em>Makefile.in</em> właściwy dla
          naszego systemu plik <em>Makefile</em>. W tym wypadku nie pozostaje
          nam nic innego jak wydanie polecenia: <em>make</em>
        </p>
<pre class="code-block">
󱩊 xf0r3m@laptop-d71f06f/ coreutils-9.5/󰯆 make
  GEN      lib/alloca.h
  GEN      lib/arpa/inet.h
  GEN      lib/configmake.h
  GEN      lib/ctype.h
  GEN      lib/dirent.h
  GEN      lib/error.h
  GEN      lib/fcntl.h
...
  CC       lib/libcoreutils_a-copy-acl.o
  CC       lib/libcoreutils_a-set-acl.o
  CC       lib/libcoreutils_a-acl-errno-valid.o
  CC       lib/libcoreutils_a-acl-internal.o
  CC       lib/libcoreutils_a-get-permissions.o
  CC       lib/libcoreutils_a-set-permissions.o
...
  CCLD     src/chroot
  CC       src/hostid.o
  CCLD     src/hostid
  CC       src/timeout.o
  CC       src/operand2sig.o
  CCLD     src/timeout
  CC       src/nice.o
  CCLD     src/nice
  CC       src/who.o
  CCLD     src/who
  CC       src/users.o
  CCLD     src/users
  CC       src/pinky.o
  CCLD     src/pinky
...
  GEN      man/chroot.1
  GEN      man/hostid.1
  GEN      man/timeout.1
  GEN      man/nice.1
  GEN      man/who.1
  GEN      man/users.1
  GEN      man/pinky.1
  GEN      man/stty.1
...
make[2]: Leaving directory '/home/xf0r3m/Pobrane/coreutils-9.5'
Making all in gnulib-tests
make[2]: Entering directory '/home/xf0r3m/Pobrane/coreutils-9.5/gnulib-tests'
## ---------------------------------------------------- ##
## ------------------- Gnulib tests ------------------- ##
## You can ignore compiler warnings in this directory.  ##
## ---------------------------------------------------- ##
make  all-recursive
make[3]: Entering directory '/home/xf0r3m/Pobrane/coreutils-9.5/gnulib-tests'
Making all in .
make[4]: Entering directory '/home/xf0r3m/Pobrane/coreutils-9.5/gnulib-tests'
  CC       bench_md5-bench-md5.o
  CC       c-strcasestr.o
  CC       c32tob.o
  CC       ioctl.o
  CC       localename.o
...
make[4]: Leaving directory '/home/xf0r3m/Pobrane/coreutils-9.5/gnulib-tests'
make[3]: Leaving directory '/home/xf0r3m/Pobrane/coreutils-9.5/gnulib-tests'
make[2]: Leaving directory '/home/xf0r3m/Pobrane/coreutils-9.5/gnulib-tests'
make[1]: Leaving directory '/home/xf0r3m/Pobrane/coreutils-9.5'
</pre>
        <p>
          Powyższy przykład może być nieco bardziej obszerny, ponieważ
          zamieściłem w nim fragmenty kolejnych etapów jakie wykonuje narzędzie
          <em>make</em>. Teoretycznie możemy już wydadwać polecenie: 
          <em>make install</em>, ale na początku zobaczymy sobie jakie pliki
          będą chciały się zainstalować (uruchamiając tym samym polecenie
          <em>make</em> w trybie <em>dry-run</em>).
        </p>
<pre class="code-block">
󱩊 xf0r3m@laptop-d71f06f/ coreutils-9.5/󰯆 make -n install
make  install-recursive
make[1]: Entering directory '/home/xf0r3m/Pobrane/coreutils-9.5'
...
dot_seen=no; \
target=`echo install-recursive | sed s/-recursive//`; \
case "install-recursive" in \
  distclean-* | maintainer-clean-*) list='po . gnulib-tests' ;; \
  *) list='po . gnulib-tests' ;; \
esac; \
for subdir in $list; do \
  echo "Making $target in $subdir"; \
  if test "$subdir" = "."; then \
    dot_seen=yes; \
    local_target="$target-am"; \
  else \
    local_target="$target"; \
  fi; \
  (CDPATH="${ZSH_VERSION+.}:" &amp;&amp; cd $subdir &amp;&amp; make  $local_target) \
  || eval $failcom; \
done; \
if test "$dot_seen" = "no"; then \
  make  "$target-am" || exit 1; \
fi; test -z "$fail"
Making install in po
make[2]: Entering directory '/home/xf0r3m/Pobrane/coreutils-9.5/po'
...
</pre>
        <p>
          Dodanie opcji <code class="code-inline">-n</code> do polecenia
          <em>make</em> spowoduje wyświetlenie poleceń wykonywanych przez
          narzędzie <em>make</em> do zrealizowania celu
          <code class="code-inline">install</code>. Po sprawdzeniu poleceń,
          możemy wydać polecenie <code class="code-inline">make install</code>.
        </p>
<pre class="code-block">
󱩊 xf0r3m@laptop-d71f06f/ coreutils-9.5/󰯆 make install
make  install-recursive
make[1]: Entering directory '/home/xf0r3m/Pobrane/coreutils-9.5'
Making install in po
make[2]: Entering directory '/home/xf0r3m/Pobrane/coreutils-9.5/po'
installing af.gmo as /home/xf0r3m/mycoreutils/share/locale/af/LC_MESSAGES/coreutils.mo
installing af.gmo link as /home/xf0r3m/mycoreutils/share/locale/af/LC_TIME/coreutils.mo
installing be.gmo as /home/xf0r3m/mycoreutils/share/locale/be/LC_MESSAGES/coreutils.mo
installing be.gmo link as /home/xf0r3m/mycoreutils/share/locale/be/LC_TIME/coreutils.mo
installing bg.gmo as /home/xf0r3m/mycoreutils/share/locale/bg/LC_MESSAGES/coreutils.mo
...
make[2]: Leaving directory '/home/xf0r3m/Pobrane/coreutils-9.5/po'
Making install in .
make[2]: Entering directory '/home/xf0r3m/Pobrane/coreutils-9.5'
make[3]: Entering directory '/home/xf0r3m/Pobrane/coreutils-9.5'
 /usr/bin/mkdir -p '/home/xf0r3m/mycoreutils/bin'
  src/ginstall -c src/ginstall '/home/xf0r3m/mycoreutils/bin/./install'
  src/ginstall -c src/chroot src/hostid src/timeout src/nice src/who src/users src/pinky src/stty
...
make[4]: Entering directory '/home/xf0r3m/Pobrane/coreutils-9.5/gnulib-tests'
make[5]: Entering directory '/home/xf0r3m/Pobrane/coreutils-9.5/gnulib-tests'
make[5]: Leaving directory '/home/xf0r3m/Pobrane/coreutils-9.5/gnulib-tests'
make[4]: Leaving directory '/home/xf0r3m/Pobrane/coreutils-9.5/gnulib-tests'
make[3]: Leaving directory '/home/xf0r3m/Pobrane/coreutils-9.5/gnulib-tests'
make[2]: Leaving directory '/home/xf0r3m/Pobrane/coreutils-9.5/gnulib-tests'
make[1]: Leaving directory '/home/xf0r3m/Pobrane/coreutils-9.5'
</pre>
        <p>
          Po podaniu za pomocą opcji <em>--prefix</em> miejsca docelowego
          dla programów, narzędzie <em>make</em> zainstalowało
          zbudowane pliki wykonywalne we wskazanym w opcji katalogu. A tak
          prezentuje się zawartość tego katalogu:
        </p>
<pre class="code-block">
󱩊 xf0r3m@laptop-d71f06f/ coreutils-9.5/󰯆 ls -l ~/mycoreutils/
razem 0
drwxr-xr-x 2 xf0r3m xf0r3m 2160 04-30 18:49 bin
drwxr-xr-x 3 xf0r3m xf0r3m   60 04-30 18:49 libexec
drwxr-xr-x 5 xf0r3m xf0r3m  100 04-30 18:49 share
</pre>
        <h3 id="15.3.2.installationviapackagestool">15.3.2. Instalacja za pomocą narzędzia do tworzenia pakietów</h3>
        <p>
          Istnieje możliwość instalacji kompilowanego oprogramowania w taki
          sposób, aby można było je kontrolować za pomocą mendżera paketów
          dystrybucji. Dystrybucjami, w których najprościej jest wykonać to
          zadanie są te oparte na Debianie, ze względu na prostotę tworzenia
          pakietów <em>.deb</em>. W tym celu posłużymy się narzędziem
          <strong>checkinstall</strong>.
          Domyślnie może nie występować w naszym systemie, ale możliwe jest
          ono do zainstalowania z repozytorium. Na chwilę obecną to program
          zawiera błąd i aby móc zbudować pakiet należy podać opcję:
          <strong>--fstrans=0</strong>. Jeśli nie chcemy aby pakiet
          automatycznie instalował się w naszym systemie podajemy opcje:
          <em>--install=no</em>. Podczas tworzenia pakietu wymagane będzie
          podanie opisu naszęgo pakietu oraz sprawdzenie czy skrypt dobrze
          odczytał takie informacje jak nazwa pakietu, jego wersja czy
          docelowa architektura. Te informacje można poprawić. Po zatwierdzeniu
          tych informacji pakiet zostaje zbudowany. Po zakończeniu budowania
          będzie go można zainstalować za pomocą polecenia <em>dpkg</em>.
        </p>
<pre class="code-block">
󱩊 xf0r3m@vm-83a53d4/ coreutils-9.5/󰯆 checkinstall --install=no --fstrans=0
</pre>
        <h3 id="15.3.3.configureoptions">15.3.3. Opcje skyptu configure</h3>
        <p>
          Po za zaprezentowaną opcją <em>--prefix</em>, która zmienia katalog
          docelowy dla instalacji oprogramowania w systemie, skrypt
          <em>configure</em> posiada wiele innych przydatnych opcji. Sam skrypt
          posiada opcję <em>--help</em>, jednak informacji jest na tyle dużo,
          że cięzko znaleźć tę jedną potrzebną, dlatego poniżej zamieszczam
          kilka najważniejszych z nich:
        </p>
        <ul>
          <li><strong>--bindir=<em>katalog</em></strong> - pliki wykonywalne
            będą instalowane w podanym <em>katalogu</em>.</li>
          <li><strong>--sbindir=<em>katalog</em></strong> - programy systemowe
            będą instalowane w podanym <em>katalogu</em>.</li>
          <li><strong>--libdir=<em>katalog</em></strong> - biblioteki
            wykonywalne będą instalowane w podanym <em>katalogu</em>.</li>
          <li><strong>--disable-shared</strong> - opcja ta zakazuje tworzenia
            bibliotek współdzielonych. Ta opcja może pomóc w zapobiegnięciu
            problemów z bibliotekami współdzielonymi.</li>
          <li><strong>--with-<em>pakiet</em>=<em>katalog</em></strong> - ta
            opcja służy do wskazania bibliotek zainstalowanych w
            niestandardowej lokalizacji. Jednak nie wszystkie skrypty
            rozpoznają te opcję.</li>
        </ul>
        <h3 id="15.3.4.configureenv">15.3.4. Zmienne środowiskowe</h3>
        <p>
          Za pomocą skryptu <em>configure</em> możemy przekazać do narzędzia
          <em>make</em> makra dla kompilatora, konsolidatora czy preprocesora
          języka C. Skonfigurowanie zmiennych środowiskowych przed
          uruchomieniem skryptu daje nam możliwość dostosowywania kompilacji
          do własnych potrzeb. 
        </p>
        <p>
          Zmienne środowiskowe możemy podawać w tym samy wierszu
          polecenia przed uruchomieniem skryptu:
        </p>
<pre class="code-block">
$ CPPFLAGS=-DDEBUG ./configure
</pre>
        <p>
          Lub jako jego opcje:
        </p>
<pre class="code-block">
$ ./configure CPPFLAGS=-DDEBUG
</pre>
        <p>
          Na powyższych przykładach przedstawiłem zmienną środowiskową
          preprocesora, ale również dostępna jest <em>LDFLAGS</em>
          (zmienna środowiskowa konsolidatora) oraz <em>CFLAGS</em> (zmienna
          środowiskowa kompilatora). Ich wartości są identyczne jak opcje,
          które przekazywaliśmy do wyżej wymienionych programu - o czym warto
          pamiętać.
        </p>
        <h3 id="15.3.5.gnuautoconfcreatedtargets">15.3.5. Cele tworzone przez GNU autoconf</h3>
        <p>
          Po za standardowymi celami takimi jak <em>all</em> czy <em>install</em>,
          skrypt <em>configure</em> w pliku <em>Makefile</em> tworzy kilka
          innych celów. Oto, niektóre z nich, część z nim została już opisana
          w poprzednim rozdziale.
        </p>
        <ul>
          <li><strong>make clean</strong></li>
          <li><strong>make distclean</strong></li>
          <li><strong>make check</strong></li>
          <li><strong>make install-strip</strong> - ten cel działa podobnie
            standardowego <em>make install</em>, jednak usuwa tablice symboli
            oraz informacje dla debugera z utworzonych bibliotek oraz plików
            wykonywalnych. Zainstalowany w ten sposób pakiet oprogramowania
            zabiera mniej miejsca na dysku.</li>
        </ul>
        <h3 id="15.3.6.gnuautoconflogfile">15.3.6. Plik dziennika systemu GNU autoconf</h3>
        <p>
          Jeśli podczas pracy skryptu <em>configure</em> zdarzy się coś
          nieprzewidzianego jakiś błąd lub problem, to wówczas możemy posłużyć
          się plikiem dziennika tworzonym podczas pracy skryptu. Plik zowie się
          <em>config.log</em> i zewzględu na to, że zawierać bedzie on wiele
          danych to najlepiej jest go przeglądać od końca (po otwarciu pliku
          za pomocą narzędzia <em>less</em> naciskamy <strong>G</strong>
          (<em>Shift+g</em>), przeniesie nas to na koniec pliku.).
        </p>
        <h3 id="15.3.7.pkg-configtool">15.3.7. Narzędzie pkg-config</h3>
        <p>
          Narzędzie <strong>pkg-config</strong> zostało zaprojektowane w celach
          rozprowadzania informacji o lokalizacji bibliotek, plików
          nagłówkowych, a także opcji wymaganych do poprawnego skompilowania i
          skonsolidowania programu. Składnia tego polecenie prezentuje się
          w następujący sposób:
        </p>
<pre class="code-block">
$ pkg-config opcje pakiet1 pakiet2 ... pakietN
</pre>
        <p>
          Przykładowo jeśli do konsolidacji naszego programu potrzebujemy
          dodać bibliotekę kompresującącą możemy wydać poniższe zapytanie.
          W odpowiedzi otrzymamy opcję, którą należy dodać do argumentów
          konsolidatora.
        </p>
<pre class="code-block">
󱩊 xf0r3m@laptop-69924a2/ ~/󰯆 pkg-config --libs zlib
-lz 
</pre>
        <p>
          Za pomocą opcji <em>--list-all</em> możemy wyświetlić informacje na
          temat wszystkich bibliotek, o których informacje mogą być dostępne
          przez <em>pkg-config</em>, co już może sugerować nam, że nie
          wszystkie biblioteki są dostępne w jego zasobach.
        </p>
<pre class="code-block">
󱩊 xf0r3m@laptop-69924a2/ ~/󰯆 pkg-config --list-all
blkid                          blkid - Block device id library
dbus-1                         dbus - Free desktop message bus
egl                            EGL - EGL library and headers
expat                          expat - expat XML parser
form                           form - ncurses 6.4 add-on library
formw                          formw - ncurses 6.4 add-on library
geoclue-2.0                    Geoclue - The Geoinformation Service
...
</pre>
        <p>
          Działanie programu <em>pkg-config</em> opiera sie o pliki
          <em>.pc</em>, które mogą być rozprowadzane w pakietach naszej
          dystrybucji w momencie instalacji bibilioteki, oczywiście zarządca
          pakietu musi utworzyć taki plik. Polecenie przeszukuje katalog
          <em>lib/pkg-config</em> swojego przedrostka instalacji (prefiksu),
          jeśli np. jego prefiksem jest <em>/usr</em>, to będzie on
          przeszukiwać katalog <em>/usr/lib/pkg-config</em>.
        </p>
        <p>
          Jeśli chcemy dodać do zasobów <em>pkg-config</em> bibliotekę o
          niestandardowym miejscu instalacji, to możemy wykorzystać do tego
          dwie metody. Pierwsza z nich jest zwykłą kopią pliku <em>.pc</em>
          do domyślnego katalogu narzędzia lub utworzenie dowiązania
          symbolicznego. Drugą opcją jest uzupełnienie zmiennej
          <em>PKG_CONFIG_PATH</em>, o dodatkowy katalog. Jednak to rozwiązanie
          niesprawdza się w obrębie całego systemu.
        </p>
        <h2 id="15.4.manualinstallationprosandcons">15.4. Zalety i wady ręcznej instalacji</h2>
        <p>
          Na poziomie podstawowym obsługi systemów Linuksowych, nikt nie
          pownien od was wymagać umiejętności ręcznej instalacji oprogramowania
          w systemie. Raczej będziemy polegać na tym co oferują nam repozytoria
          dystrybucji. Obecnie dostawcy różnych programów często przygotowują
          pakiety systemu zarządzania oprogramowaniem dla wielu wiodących
          dystrybucji, dlatego też ręczna instalacja spada do rangi pewnego
          rodzaju niszy. Budowanie może zająć naprawdę wiele czasu i nie
          zawsze mozemy osiągnąć żądany skutek. Chcemy skompilować jakiś
          program, okazuje się że brakuje nam bibliotek w takiej wersji, więc
          musimy przeprowadzić kompilację bibliotek w takiej wersji w ten
          sposób nasza praca związana tym zagadnieniem się nawarstwia.
          Weźmy pod uwagę też sprzęt. Nie każdy dysponuje potężną maszyną,
          która będzie wstanie kompilować duże programy w ciągu kilku minut.
          Większość użytkowników dystrybucji Linuksa, do których adresowany
          jest ten materiał, raczej korzysta z budżetowego laptopa z marketu.
          Ucieczka do MS Windows, w celu polepszenia swoich doświadczeń z
          komputerem, bez reklam czy najważniejszej rzeczy w tym systemie czyli
          aktualizacji. Tak więc kompilacja na takim sprzęcie może zająć
          dłuższą chwilę, co sprawia, że budowanie od podstaw oprogramowania
          traktowane jest raczej jako ostateczność.
        </p>
        <p>
          Nie mniej jednak taka instalacja oprogramowania w systemie nie jest
          bez zalet. Najważniejszymi z nich jest dostarczenie do naszych
          systemów najnowszych wersji programów, dostosowanie ich możliwości
          oraz funkcjonalności przy użyciu opcjonalnych bibliotek czy samych
          opcji kompilacji do naszych potrzeb. Nawet lepiej, istnieją całe
          dystrybucje, które opierają się tylko i wyłącznie o ręczną instalację
          lub zawierają takie programy do zarządzania oprogramowaniem, które i
          tak koniec końców sprowadzania się do ręcznej instalacjacji
          przeprowadzonej w nieco bardziej bezobsługowy sposób.
        </p>
        <p>
          Oczywiście zachęcam do ręcznej instalacji, tylu programów ilu się da.
          Dzięki temu uczymy się, poznajemy te programy. Domyślnym miejscem
          przeznaczonym na ręczną instalację jest katalog <em>/usr/local</em>.
        </p>
        <h2 id="15.5.usingpatches">15.5. Stosowanie poprawek</h2>
        <p>
          Poprawki są nieodłącznym elementem życia oprogramowania. Są one 
          dystrybuowane za pomocą takich narzędzi jak system kontroli
          wersji <em>Git</em>. Mogą one wprowadzać szereg zmian do kodu
          źródłowego, poprawiać błedy lub uzupełaniać oprogramowanie o nowa
          funkcjonalność. Poprawki tworzone są zapomocą polecenia
          <strong>diff</strong>. Poniżej znajduje się nagłówek pliku poprawki
          wprowadzający zamiany, które obecnie czytasz do tego materiału.
        </p>
<pre class="code-block">
diff --git a/articles/terminallog/Linux.Podstawy.html b/articles/terminallog/Linux.Podstawy.html
index 464a32d..09c06a7 100644
--- a/articles/terminallog/Linux.Podstawy.html
+++ b/articles/terminallog/Linux.Podstawy.html
@@ -12597,6 +12597,212 @@ 
</pre>
        <p>
          Wszysktie linie, które są dodatkowo wprowadzena oznaczne symbolem
          plusa (<strong>+</strong>) najczęściej koloru zielonego. Jeśli nasz
          terminal obsługuje kolory. Natomiast usunięcia oznaczane są za
          pomocą symbolu minusa (<strong>-</strong>) najczęściej koloru
          czerwonego. Linie z minusem (linie na czerwono) zawierają również
          treść, która występowała w pliku przed wprowadzeniem zmian. Warto
          mieć to na uwadze.
        </p>
        <p>
          Pliki poprawek są tworzone za pomocą polecenia <em>diff</em>,
          natomiast instalowane są za pomocą polecenia <strong>patch</strong>.
          Przyczym podczas instalacji poprawek istotne jest dobre ustawie 
          katalogu roboczego w folderze z kodem źródłowym. Załóżmy, że mamy
          plik
          poprawki, który obejmuje plik <em>src/plik.c</em>. Wówczas taki
          plik poprawki należy nałożyć w katalogu nadrzędnym katalogu
          <em>src</em>, wydając poniższe polecenie:
        </p>
<pre class="code-block">
$ patch -p0 &lt; plik_poprawki
</pre>
        <p>
          Opcja <code class="code-inline">-p0</code> usunie dokładnie 0
          poprzedzających ukośników ze ścieżki odczytanej w poprawce aby
          zlokalizować plik. Jest to tyle istotne, ponieważ mogą występować
          różnice w lokalizacji instalacji na komputerze osoby tworzącej
          taką poprawkę a jej stosującej. Rozważmy taki przykład, że pliku
          poprawki widnieje taka ścieżka jak: <em>patches-3.42/src/plik.c</em>.
          W naszej instalacji nie ma tego katalogu <em>patches-3.42</em>, to
          aby zastosować poprawkę musimy przejść do katalogu zawierającego
          katalog <em>src</em> i wydać następujące polecenie:
        </p>
<pre class="code-block">
$ patch -p1 &lt; plik_poprawki;
</pre>
        <h1 id="16.virtualisation">16. Wirtualizacja</h1>
        <p>
          Same pojęcie tego, że coś jest <em>wirtualne</em> odnosi się do
          translacji warstwy bazowej do postaci uproszczonego interfejsu, z
          którego może korzystać wielu odbiorców. Z pojęciem wirtualizacji
          zapoznaliśmy się pośrednio przy poznawaniu zagadnienia
          pamięci wirtualnej, oferującej procesom duży odizolowany obszar
          pamięci operacyjnej. W tym przpadku skupimy się nieco szerszym
          aspekcie możliwości wirtualizacyjnych pozwalających na tworzenie
          izolowanych środowisk umożliwiających uruchomienie wielu systemów
          operacyjnych bez powstawania konfliktu miedzy nimi.
        </p>
        <h2 id="16.1.virtualmachines">16.1. Maszyny wirtualne</h2>
        <p>
          Maszyny wirtualne obejmują całość sprzętu komputerowego za pomocą
          oprogramowania. Wydzielane są zasoby fizycznego hosta oraz
          tworzone nowe urządzenia aby powstała zupełnie nowa maszyna. Z
          terminu <em>maszyna wirtualna</em>, korzysta się od wielu lat,
          dlatego też w celach rozróżnienia (przecież spotkaliśmy się z
          maszyną wirtualną Javy) dla maszyn tworzących izolowane środowiska
          zdolne do uruchamiania systemów operacyjnych, które podwzględem
          programowym nie różnią się niczym od fizycznych komputerów używa
          się sformuowania <strong>systemowa maszyna wirtualna</strong>.
        </p>
        <p>
          Żeby tego było mało, to możemy wróżnić jeszcze maszyny oparte
          całkowicie na oprogramowaniu, czyli <strong>emulatory</strong>. Przy
          użyciu tego rozwiązania możemy uruchamiać np. programy nieprzeznaczone
          domyślnie na wykorzystywaną przez nas architekturę. Dla przykładu
          mamy obecnie dostępne emulatory konsol do gier czy smartfonów.
        </p>
        <h3 id="16.1.1.hypervisors">16.1.1 Hipernadzorcy</h3>
        <p>
          Programy pozwalające nam na kontrolowanie maszyn wirtualnych i
          wchodzenie w interakcje z nimi (chociażby po to, aby zainstalować
          system operacyjny) nazywane jest <strong>hipernadzorcą</strong>.
          Istnieją dwa typy oprogramowania hipernadzorcy. 
          Z <strong>typem 2</strong>, każdy
          mógł mieć styczność są to takie środowiska virtualizacji jak
          Oracle VirtualBox czy VMware Player lub Workstation. Hipernadzorcami
          drugiego typu jest najczęściej oprogramowanie instalowane
          <strong>zawierające pełen pakiet wirtualizacji</strong>. Inaczej jest
          w przypadku <strong>typu 1</strong>, gdzie instalujemy na fizycznym
          komputerze
          specjalny system operacyjny pełniący rolę hipernadzorcy. Pozostają
          również rozwiązania zawieszone pomiędzy pierwszym a drugim typem,
          np. rozwiązanie KVM z dystrybucji Linuksa. Pozwala ono zamienić
          normalną dystrybucję w hipernadzorcę typu 1.
        </p>
        <p>
          Po omówieniu roli hipernadzorcy, możemy wprowadzić odpowiednią
          nomenklaturę dla zagadnienia maszyn wirtualnych. Mianowicie komputer,
          który udostępnia maszyny wirtualne lub ma możliwość ich tworzenia
          nazywany jest <strong>hostem</strong>, natomiast maszyna wirtualna
          <strong>gościem</strong>.
        </p>
        <h3 id="16.1.2.vmhardware">16.1.2. Sprzęt maszyny wirtualnej</h3>
        <p>
          Istnieje wiel różnic między sprzętem fizycznym a tym z którego
          korzystają maszyny - wirtualny. Wynikają one najczęściej z 
          umożliwienia gościom bardziej bezpośredniego dostępu do zasobów
          hosta. Wykorzystywany jest mechnizm <strong>parawirtualizacji</strong>,
          który pozwala na pomięcie sprzetu wirtualnego między składnikami
          wirtualizacji (hostem a gościem). Tego typu rozwiązanie najczęściej
          stosowane jest w przypadku urządzeń blokowych (pamięci masowych)
          oraz interfejsów sieciowych.
        </p>
        <p>
          Niezależnie od wykorzystywanych mechanizmów, celem wirtualizacji
          zawsze będzie takie dostosowanie zasobów, a żeby gośćie mogli
          trakotować te urządzenia jak swóje własne. Zapewni to stabilność
          działania uruchmianego na maszynach oprogramowanie, to dzięki tego
          typu rozwiązaniom możemy np. normalnie alokować przestrzeń pamięci
          masowych, czy formatować partycje.
        </p>
        <p>
          Innym ważnym zagadnieniem związanym z maszynami wirtualnymi jest
          dostęp do procesora. Jak pamiętamy w systemie operacyjnym mamy dwa
          trybu dostępu do procesora. Tryb <em>jądra</em> - pozwalający na
          wykonanie dowolnych czynności oraz tryb <em>użytkownika</em> -
          najprościej rzecz ujmując - ograniczony. Jeśli mamy uruchmiać na
          maszynach systemy operacyjne, to hipernadzorcy powinni być
          uruchamiani w trybie jądra. I tu jest mały problem, tryb jądra jest
          zarezerwowany <strong>tylko dla jądra</strong>. Hipernadzorca
          działa w trybie użytkownika (jak każdy inny proces, po za procesami
          jądra). Jedną z koncepcji, która działa przez jakiś czas było
          wychwytywanie przez hipernadzorcę wszystkich ograniczonych instrukcji
          i emulowanie ich działania. To rozwiązanie zostało wyparte przez
          rozszerzenia procesorów <strong>VT-x</strong> (Intel) oraz
          <strong>AMD-V</strong> (AMD), które udostępniają odpowiednie zestawy
          instrukcji, które zapewniają gościom bardziej swobodny dostęp do
          procesora.
        </p>
        <h3 id="16.1.3.vmusege">16.1.3. Użycie maszyn wirtualnych</h3>
        <p>
          Jak wielkrotnie było wspomniane w tym rozdziale maszyny wirtualne
          tworzą odizolowanie środowisko, zatem ich zastosowaniami mogą być
          wszelkiego rodzaju testy. Np. jeśli korzystamy z dystrybucji Linuksa
          na naszych komputerach codziennego użytku, to mogliśmy wykorzystać
          maszyny wirtualne to testowania przykładów z tego materiału, lub
          np. dostosowania konfiguracji systemowych do własnych potrzeb. Wiele
          systemów wirtualizacji posiada mechnizm <strong>migawek</strong>,
          które umożliwiają zapisanie stanu maszyny i poźniej ewentualnego
          cofnięcia się do tego zapisu w razie ewentualnych problemów.
        </p>
        <p>
          Drugim zastosowaniem maszyn może byc sztywne wydzielenie zasobów dla
          konkretnych środowisk. Przydzielenie takiej a takiej ilośći pamięci
          operacyjnej, tyle i tyle rdzeni procesora oraz takiej wielkości
          dysk twardy znajdujący się np. na macierzy.
        </p>
        <h2 id="16.2.containers">16.2. Kontenery</h2>
        <p>
          Kontenery w przeciwieństwie do maszyn wirtualnych nie są tak
          odizolowane od systemu hosta. Często są wykorzystywane jako prostsza
          alternatywa. Kontenery korzystają z rozwiązań dostępnych już
          w systemie, aby zapewnić swój rodzaj wirtualizacji. Najczęściej
          korzystają z możliwości zmiany katalogu głównego (<em>chroot</em>)
          oraz określenia limitów jądra (<em>rlimit</em>).
          <strong>Kontener</strong> można określić jako ograniczone środowisko
          uruchomieniowe przeznaczone dla zbioru procesów. Oznacza to, że mogą
          one nie mieć dostępu do niczego poza obrębem swojego środowiska.
          Tego typu wirtualizację określa się mianem
          <strong>wirtualizacji na poziomie systemu operacyjnego</strong>. 
        </p>
        <p>
          Kontenery uruchomione w systemie hosta, będą wspołdzielić ze sobą
          jądro jego bazowego systemu, bez znaczenia jaka dystrybucja jest
          uruchomiona w kontenerze. Procesy przestrzeni użytkownika mogą
          pochodzić z wielu różnych dystrybucji w przypadku kontenerów.
        </p>
        <p>
          Kontenery są ograniczne za pomocą kilku opcji jądra, przez co one:
        </p>
        <ul>
          <li>Mają własne grupy <em>cgroup</em></li>
          <li>Mają własne urządzenia i systemy plików</li>
          <li>Nie mogą uzyskać dostępu do jakichkolwiek innych procesów w
            w systemie ani prowadzić z nimi interakcji.</li>
          <li>Mają własne interfejsy sieciowe</li>
        </ul>
        <p>
          Mimo iż jest to możliwe, rzadko kto zadaje sobie tyle trudu aby
          poustawiać te wszystkie aspekty ręcznie. Dlatego też korzysta się
          z uproszczonych systemów konteneryzacji takich jak
          <strong>Docker</strong>. Nie mniej jednak za pomocą takie systemu
          LXC mamy możliwość własnoręcznego skonfigurowania tych
          zagadanień. W tym rozdziale nacisk położono na <em>Docker</em>, ale 
          system LXC również po krótce omowiono.
        </p>
        <h3 id="16.2.1.dockerandpodman">16.2.1. Docker i Podman</h3>
        <p>
          <em>Docker</em> jest jednym z podstawowych narzędzi kontenerowych, 
          jest on 
          bardzo łatwy do instalacji z strony projektu. Wymaga do korzystania
          z kontenerów procesu serwera oraz przywilejów superużytkownika aby
          uzyskać dostęp do opcji jądra.
        </p>
        <p>
          Alternatywą dla <em>Dockera</em> jest <strong>Podman</strong>. Nie
          wymaga on
          do swojego działania procesu serwera. <em>Podman</em> może zostać
          uruchomiony
          z uprawnieniami zwykłego użytkownika (ang. <em>rootless</em>),
          wówczas stosowane są inne mechanizmy do uzyskania izolacji. Jeśli
          uruchomimy <em>Podman</em> z uprawnieniami administratora to użyje on
          rozwiązań stosowanych przez <em>Docker</em>. <em>Podman</em> jest
          kompatybilny pod
          względem wiersza polecenia z <em>Dockerem</em>. Oczywiście występują
          różnice
          w implementacji, szczególnie gdy <em>Podman</em> działa z 
          uprawnieniami
          zwykłego użytkownika. Jeśli gdzieś zajdzie taka potrzeba rożnice
          między tymi systemami zostaną one wyraźnie zaznaczone.
        </p>
        <p>
          W tym materiale skupie się na <em>Docker</em>-ze. <em>Podman</em>-a z
          resztą już omawiałem
          w tym rozdziale materiału o RHCSA: <a href="https://morketsmerke.github.io/articles/terminallog/RedHat_-_RHCSA.html#23.containers">https://morketsmerke.github.io/articles/terminallog/RedHat_-_RHCSA.html#23.containers</a>
        </p>
        <h3 id="16.2.2.dockerusage">16.2.2. Użycie Dockera</h3>
        <p>
          Zamieszczony w tym podrozdziale przykład użycia <em>Docker</em>-a 
          przestawia
          podstawowe elementy ukazujące działanie kontenerów. Na początku
          niezbędne może być utworzenie obrazu składającego się z systemu
          plików oraz innych elementów definiujących kontener. Obraz ten będzie
          bazować na obrazie pobranym z repozytorium. Jest to standardowe
          zachowanie. Przez sam <strong>obraz</strong> można rozumieć jako
          system plików kontenera. Obraz naszego kontenera przygotujemy do 
          uruchomienia za pomocą
          pliku <em>Dockerfile</em>. Oczywiście nie zawsze takie działanie
          jest wymagane, ponieważ moglibyśmy utworzyć kontener ręcznie,
          zalogować się do jego powłoki i zainstalować powłokę BASH. Za pomocą
          pliku <em>Dockerfile</em> utworzymy obraz, z którego będziemy mogli
          uruchamiać wiele kontenerów.
        </p>
<pre class="code-block">
xf0r3m@debian:~/lp_test$ cat Dockerfile 
FROM alpine:latest
RUN apk add bash
CMD ["/bin/bash"]
</pre>
        <p>
          Po zapisaniu zmian w pliku <em>Docker</em>-a, wydajemy poniższe 
          polecenie.
          Opcja <code class="code-inline">-t lp_test</code> wskazuje na
          identyfikator obrazu. Później łatwiej będzie go zlokalizować,
          ewentualnie wykorzystać do utworzenia nowego kontenera.
        </p>
<pre class="code-block">
xf0r3m@debian:~/lp_test$ docker build -t lp_test .
Sending build context to Docker daemon  2.048kB
Step 1/3 : FROM alpine:latest
latest: Pulling from library/alpine
4abcf2066143: Pull complete 
Digest: sha256:c5b1261d6d3e43071626931fc004f70149baeba2c8ec672bd4f27761f8e1ad6b
Status: Downloaded newer image for alpine:latest
 ---&gt; 05455a08881e
Step 2/3 : RUN apk add bash
 ---&gt; Running in ad8a95239176
fetch https://dl-cdn.alpinelinux.org/alpine/v3.19/main/x86_64/APKINDEX.tar.gz
fetch https://dl-cdn.alpinelinux.org/alpine/v3.19/community/x86_64/APKINDEX.tar.gz
(1/4) Installing ncurses-terminfo-base (6.4_p20231125-r0)
(2/4) Installing libncursesw (6.4_p20231125-r0)
(3/4) Installing readline (8.2.1-r2)
(4/4) Installing bash (5.2.21-r0)
Executing bash-5.2.21-r0.post-install
Executing busybox-1.36.1-r15.trigger
OK: 10 MiB in 19 packages
Removing intermediate container ad8a95239176
 ---&gt; 72784ac891aa
Step 3/3 : CMD ["/bin/bash"]
 ---&gt; Running in 5571f05ede12
Removing intermediate container 5571f05ede12
 ---&gt; 9abc76076917
Successfully built 9abc76076917
Successfully tagged lp_test:latest
</pre>
      <p>
        Zwróćmy uwagę na informacje zwracane przez <em>Docker</em> podczas
        przetwarzania
        pliku <em>Dockerfile</em>. Na początku pobierany jest oficjalny
        obraz kontenera dystrybucji Alpine Linux
        (id: <code class="code-inline">05455a08881e</code>) na jego podstawie
        tworzony jest kontener
        (id: <code class="code-inline">ad8a95239176</code>) w którym to
        uruchamiany jest proces menedżera pakietów, które zdaniem jest
        zainstalowanie powłoki BASH
        (<code class="code-inline">RUN apk add bash</code>), jest to druga
        linia pliku <em>Dockerfile</em>. Na podstawie tego kontenera
        tworzony jest obraz (id: <code class="code-inline">72784ac891aa</code>).
        Następnie z tego obrazu tworzony jest kontener, który uruchamia proces
        powłoki (id: <code class="code-inline">5571f05ede12</code>). Ten 
        kontener finalnie posłuży nam za wzorzec dla naszego obrazu - wyniku
        pliku <em>Dockerfile</em>. Po między kolejnymi czynnościamy odczytanymi
        z pliku, pośrednie kontenery są usuwane. Wynik działania polecenia
        możemy również zobaczyć na liście dostępnych obrazów. Dostęp do niej
        możemy uzyskać za pomocą polecenia:
        <code class="code-inline">docker images</code>. 
      </p>
<pre class="code-block">
xf0r3m@debian:~/lp_test$ docker images
REPOSITORY    TAG       IMAGE ID       CREATED         SIZE
lp_test       latest    9abc76076917   5 minutes ago   11.6MB
alpine        latest    05455a08881e   3 months ago    7.38MB
</pre>
        <p>
          Na uruchomienie naszego kontenera mamy dwa sposoby:
          <strong>nieinteraktywny</strong>, który dobry byłby gdybyśmy mieli
          uruchomić jakiś skrypt powłoki. Próba uruchomienia naszego kontenera
          w tym trybie wygląda w następujący sposób:
        </p>
<pre class="code-block">
xf0r3m@debian:~/lp_test$ docker run lp_test
xf0r3m@debian:~/lp_test$
</pre>
        <p>
          Ze względu na to, że nie było żadnego polecenia dla powłoki, proces
          zamknął się natychmiastowo. Na potwierdzenie możemy wyświetlić listę
          wszystkich procesów (kontenerów), nawet wykonanych za pomocą 
          polecenia <code class="code-inline">docker ps -a</code>, polecenie
          bez opcji <code class="code-inline">-a</code> spowoduje wyświetlenie
          działających kontenerów.
        </p>
<pre class="code-block">
xf0r3m@debian:~/lp_test$ docker ps -a
CONTAINER ID   IMAGE         COMMAND       CREATED              STATUS                          PORTS     NAMES
d4e8739ee569   lp_test       "/bin/bash"   2 seconds ago        Exited (0) 2 seconds ago                  modest_ardinghelli
6f5067c97eb9   lp_test       "/bin/bash"   About a minute ago   Exited (0) About a minute ago             great_tharp
</pre>
        <p>
          Jak możemy wywnioskować po pierwszym wpisie, to coś się działo.
          Jednak nie wiele z tego użyliśmy. Jeśli chcelibyśmy uruchomić
          kontener w drugim trybie <strong>interaktywnym</strong> to wówczas
          musimy do podpolecenia <code class="code-inline">run</code> dodać 
          opcje
          <em>-it</em>, czyli <em>-i</em> - praca interaktywna oraz <em>-t</em>
           - podłączenien terminala.
        </p>
<pre class="code-block">
xf0r3m@debian:~/lp_test$ docker run -it lp_test
1d87aa6e43e7:/#
</pre>
        <p>
          Dopóki pozostawimy tę sesje powłoki uruchomioną, doputy kontener
          pozostanie uruchiomy. A w ten sposób prezentuje się lista procesów,
          które są uruchomione na kontenerze:
        </p>
<pre class="code-block">
1d87aa6e43e7:/# ps
PID   USER     TIME  COMMAND
    1 root      0:00 /bin/bash
  203 root      0:00 ps
</pre>
        <p>
          Proces uruchomionej powłoki (a co za tym idzie, kontenera) możemy
          rownież zobaczyć wyświetlając listę procesów hosta:
        </p>
<pre class="code-block">
root        2369  0.0  0.1   2612  2360 pts/0    Ss+  14:42   0:00 /bin/bash
</pre>
        <p>
          Za tego typu zachowanie odpowiedzialna jest jedna z opcji jądra
          wykorzystywana na potrzeby kontenerów - <strong>przestrzenie nazw</strong>
          Dzięki tej funkcji proces może utworzy zupełnie nowy zestaw
          identyfikatorów dla siebie oraz swoich procesów potomnych zaczynając
          do PID-u 1. Procesy te będą wówczas miały dostęp tylko do tego
          identyfikatora.
        </p>
        <p>
          Jeśli mamy na to ochotę to po skończonej zabawie możemy usunąć
          nieaktywne już kontenery za pomocą polecenia
          <code class="code-inline">docker rm identyfikator</code>:
        </p>
<pre class="code-block">
xf0r3m@debian:~/lp_test$ docker ps -a
CONTAINER ID   IMAGE         COMMAND       CREATED       STATUS                      PORTS     NAMES
1d87aa6e43e7   lp_test       "/bin/bash"   2 hours ago   Exited (0) 19 minutes ago             mystifying_gauss
31808ed62e2a   hello-world   "/hello"      3 hours ago   Exited (0) 3 hours ago                elegant_davinci
xf0r3m@debian:~/lp_test$ docker rm 1d87aa6e43e7
1d87aa6e43e7
xf0r3m@debian:~/lp_test$ docker ps -a
CONTAINER ID   IMAGE         COMMAND    CREATED       STATUS                   PORTS     NAMES
31808ed62e2a   hello-world   "/hello"   3 hours ago   Exited (0) 3 hours ago             elegant_davinci
</pre>
        <h4>Nakładkowy system plików</h4>
        <p>
          Inną funkcją jądra wykorzystywaną przez kontenery jest
          <strong>nakładkowy system plików</strong>. Opcja ta pozwala na
          utworzenie systemu plików po przez połącznie istniejących katalogów
          jako warstw, wówczas zmiany przechowywane są w jednym miejscu.
          Ten mechanizm składa się z trzech warstw:
        </p>
        <ul>
          <li><strong>Dolnego katalogu</strong> (<em>lowerdir</em>) - 
            zawierającego bazowy system plików.</li>
          <li><strong>Górnego katalogu</strong> (<em>upperdir</em>) -
            zawierającego
            wszelkie zmiany dokonane na bazowym systemie plików w trakcie
            działania systemu.</li>
          <li><strong>Katalogu roboczego</strong> (<em>workdir</em>) -
            katalog przejściowy, w którym sterownik systemu plików realizuje
            swoje działania przed zapisaniem zmian w górnym katalogu.</li>
        </ul>
        <p>
          W przypadku <em>Podmana</em> bez uprawnień, wykorzystywany nakładkowy
          system plików w wersji FUSE.
        </p>
        <h4>Obsługa sieci</h4>
        <p>
          W przypadku <em>Docker</em>-a istnieje kilka metod na zapewnienie
          łączności kontenerom. Najczęściej stosowanym rozwiązaniem jest
          sieć z mostem wykorzystującym siecią przestrzeń nazw (<em>netns</em>).
          Serwer <em>Docker</em>-a tworzy w systemie hosta interfejs sieciowy
          zazwyczaj o nazwie <em>docker0</em> przypisanym pierwszym adresie
          z podsieci prywatnej 172.17.0.0/16 - 172.17.0.1/16. Ten interfejs
          wykorzystywany do komunikacji miedzy hostem a kontenerami.
          <em>Docker</em> wykorzystuje dodatkowe interfejsy w sieciowej
          przestrzeni nazw oraz mechnizm NAT aby zapewnić kontenerom dostęp do 
          sieci zewnętrznych (w tym sieci lokalnej) hosta, w tym do Internetu.
        </p>
        <p>
          <em>Podman</em> bez uprawnień wykorzystuje natomiast interfejsy TAP
          oraz
          mechanizmy przekazujące w postaci daemona <em>slirp4netns</em>, aby
          uzyskać dostęp do sieci zewnętrznych. To rozwiązanie ma jeden
          minus, kontenery niestety nie mogą łączyć się ze sobą.
        </p>
        <h3 id="16.2.3.lxc">16.2.3. LXC</h3>
        <p>
          LXC jest to jeden z najstarszych systemów konteneryzacji dostępnych
          na dystrybucje Linuksa. Pierwsze wersje <em>Docker</em>-a operały się
          o ten pakiet. Niekiedy termin ten jest używany do odniesienia się
          do mechanizmów jądra pozwalających na obsługę kontenerów, jak i
          biblioteki oraz pakietu narzędzi wykorzystywanych do ich tworzenia
          oraz modyfikowania.
        </p>
        <p>
          Pakiet LXC nie nadaje się dla osób, które nie czują się biegłe w
          administracji kontenerami oraz nie posiadają odpowiedniej wiedzy
          jak działają poszczególe mechanizmy systemów konteneryzacji. LXC
          wymaga dość sporego zakresu ręcznej konfiguracji. Wymagane jest
          utworzonie np. dla kontenerów interfejsów sieciowych czy zapewnienie
          mapowania identyfikatorów użytkowników. Wartym wspomnienia faktem
          odnośnie kontenerów LXC, jest fakt że zawierają one najwięcej
          elementów z dystrybucji, np. program typu <em>init</em>.
        </p>
        <p>
          Kontenery LXC są bardziej elastyczne pod kątem dostosowania do
          różnych wymagań. Jeśli ktoś będzie mieć ochotę pobawić się LXC,
          To zapraszam na stronę wiki projektu Debian, gdzie jest opisane
          w jaki sposób zainstalować LXC. Obecnie jednak nie musimy się
          tym przejmować ponieważ w wersji stablinej Debiana możliwy do
          zainstalowania jest pakiet <strong>LXD</strong>, który podczas
          inicjalizacji wykona większość tej konfiguracji pakietu LXC za nas
          Trzeba tylko odpowiedzieć na kilka pytań instalatora. Pakiet LXD
          został odłączony od projektu <em>linuxcontainers.org</em> i stał się
          produktem firmy Canonical Inc. w repozytorium <em>backports</em>
          wersji stabilnej znajduje się pakiet <strong>Incus</strong>, który
          jest forkiem LXD dalej rozwijanym przez społeczność.
        </p>
        <h2 id="16.3.venv">16.3. Wirtualizacja oparta na środowisku uruchomieniowym</h2>
        <p>
          Inny rodzaj wirtualizacji może bazować na typie środowiska aplikacji.
          W tym przypadku nie wykorzystuje się innych mechanik niż izolacja i
          to tylko określonej aplikacji. Celem takie działania jest zapewnie
          spójności między środowiskiem języka programowania wykorzystywanym
          przez ważne kompenenty systemu operacjnego, a zapewnieniem możliwości
          uruchomienia żądanej przez nas aplikacji. Głównie ma to zastosowanie
          przy Pythonie, i to jego wykorzystamy do przedstawienia tego rodzaju
          wirtualizacji.
        </p>
        <p>
          Przed uruchomieniem takiego środowiska, należy upewnić się, że mamy
          zainstalowanym pakiet (w Debianie): <em>python3-venv</em> jeśli tak
          to możemy przjeść do stworzenia środwiska wirtualnego.
        </p>
<pre class="code-block">
xf0r3m@vm-f99031d:~$ python3 -m venv test-env
</pre>
        <p>
          Polecenie zakończy swoje działanie bez żadnego komunikatu, jeśli
          faktycznie utworzył to środwisko wirtualne, to powiniśmy zobaczyć
          katalog o nazwie - w moim przypadku -
          <code class="code-inline">test-env</code>, a wewnątrz niego
          powinniśmy znaleźc kilka katalogów systemowych:
        </p>
<pre class="code-block">
xf0r3m@vm-f99031d:~/test-env$ ls
bin  include  lib  lib64  pyvenv.cfg
</pre>
        <p>
          Aby środowisko mogło zadziałać należy je aktywować za pomocą
          poniższego polecenia:
        </p>
<pre class="code-block">
xf0r3m@vm-f99031d:~$ . test-env/bin/activate
(test-env) xf0r3m@vm-f99031d:~$
</pre>
        <p>
          O fakcie, że znajdujemyu się wewnątrz środowiska może świadczyć
          zmieniony znak zachęty. W ten sposób uzyskaliśmy czyste środowsko
          uruchomieniowe dla aplikacji w Pythonie. Możemy je smiało również
          wykorzystać do programowania, czy testowania modułów z repozytorium
          narzędzia <em>pip</em>. W celu opuszczenia do dyspozycji mamy
          polecenie będące funkcją powłoki - 
          <code class="code-inline">deactivate</code>
          Polecenie to przywrócić zmienne środowiskowe oraz ustawienie powłoki
          do stanu sprzed uruchomienia skryptu
          <code class="code-inline">deactivate</code>. Na podobnej zasadzie
          działa polecenie <code class="code-inline">activate</code>.
        </p>
<pre class="code-block">
(test-env) xf0r3m@vm-f99031d:~$ deactivate 
xf0r3m@vm-f99031d:~$ 
</pre>
        <p>
          Oczywiście nie wszystkie języki programowania, będą miały możliwość
          utworzenia takie środowiska wirtualnego. W przypadku Pythona jest
          najprostsze do osiągniecia.
        </p>
        <h1 id="17.summary">Podsumowanie</h1>
        <p>
          Rozdziałem o wirtualizacji zakończyliśmy ten materiał. Nosi on tytuł
          <em>Linux. Podstawy.</em>, jednak czytelnik po jego lekturze może
          dojść do wniosku, że wiele informacji zostało opisanych nadwyraz
          szczegołowo, za brakło przykładów faktycznie przezentujących podstawy.
          Jednak ciężko jest sklasyfikować <em>podstawy</em>. Gdzie kończą się
          <em>podstawy</em> a zaczyna się wiedza bardziej zaawansowana? W tym
          materiale, takie faktyczne podstawy znajdują się w pierwszych dwóch
          rozdziałach, a te tematy <em>zaawansowane</em> zostały omówione w
          dość powierzchownie, aby wyłącznie nakreślić użytkownikowi jak pewne
          mechanizmy funkcjonują w dystrybucjach Linuksa i wrazie potrzeby
          pogłebienia informacji na dany temat, móc napisać odpowiednie
          zapytanie do wyszukiwarki lub wiedzieć o czym się pisze tworząc wątek
          na jakimś tematycznym forum z prośbą o pomoc. Tematy te również mogą
          być traktowe, jako wyłącznie przedstawie danego zagadnienia, aby
          czytelnik mógł stwierdzić czy ten akurat temat go interesuje.
          Ze względu na to, że materiał był tworzony na przestrzeni kilku lat.
          A tak dokładnie to 3. I w trakcie materiał źródłowy, z którego
          korzystałem został zaktualizowany, można zauważyć rozbierzności
          w sposobie oraz ilości przedstawianych treści między różnymi
          rozdziałami.
        </p>
        <h2 id="17.1.whatnext">17.1. Co dalej?</h2>
        <p>
          Dobry rozszerzeniem tego materiału, ale już od bardziej
          usystematyzowanej, bardziej praktycznej formy jest materiał o 
          <a href=""https://morketsmerke.github.io/articles/terminallog/RedHat_-_RHCSA.html>RHCSA</a>.
          Mimo iż tutaj używałem wyłącznie GNU/Linux Debian, nie mniej jednak
          mechnizmy zawarte w Red Hat, mają swoje odpowiedniki w takich
          systemach jak właśnie Debian. Poniżej pozostał jeszcze dodatek
          zawierający podstawy programowania w powłoce BASH. O nieco bardziej
          zaawansowanym wykorzystaniu tej powłoki powstawał osobny
          <a href="https://morketsmerke.github.io/articles/terminallog/BASH_bushido.html">materiał</a>
        </p>
        <h1 id="18.appendixa">18. Dodatek A. Podstawy programowania skryptów w powłoce BASH</h1>
        <p>
          Jak już wspomniałem w 14 rozdziale do zrozumienia tego materiału
          nie są potrzebne żadne umiejętności programistyczne. Dlatego też
          przeniosłem rozdział o tworzeniu skrytów powłoki na sam jego koniec
          do roli dodatku.
        </p> 
        <p>
          Wśród Uniksów mamy dostępne kilka rodzajów powłok. Najczęściej będą
          to powłoki BASH oraz KSH (wykorzystywana w środowiskach BSD). Obecnie
          w wielu dystrybucjach możemy spotkać się z ewolucją kwestii domyślnej
          powłoki a przynajmniej dla naszego domyślnego użytkownika. Co raz
          częściej możemy spotkać się z takimi powłokami jak ZSH oraz FISH są
          one następcami powłoki BASH, zawierającymi wiele udogodnień
          pozwalających na łatwiejsze tworzenie poleceń. Obecnie na
          popularności zyskuje projekt o nazwie <em>nu-shell</em> jest to
          nowy rodzaj połoki zmieniający dotychczasowe doświadczenia z nią
          związane. Nie mniej jednak informacje przedstawione w tym rozdziale
          będą działać w powłoce BASH oraz z pewnymi ograniczeniami i potrzebą
          dostosowania w powłoce KSH. Dostosowanie tych informacji do innych
          programów powłoki pozostawiam wam. 
        </p>
        <h2 id="18.1.bashscriptsbasics">18.1. Podstawy tworzenia skryptów</h2>
        <p>
          Podczas tworzenia skryptu powłoki, warto miec uwadze to że ma się
          do dyspozycji <strong>powłokę</strong>, na drugiej karcie lub
          drugim oknie. Przed utworzeniem skryptu można przetestować, niektóre
          pomysły zanim zostaną one zapisane w skrypcie. Może być to 
          szczególnie przydatne, gdy działanie skryptu może byc destrukcyjne - 
          np. skrypt coś usuwa. Sprawdzenie tego czy nasze pomysły maja w
          ogóle sens, pozwala zaoszczędzić czas podczas debugowania skryptu.
          Może nam się wydawać, że pewne konstrukcje powłoki są cieżkie do
          zapisania w postaci polecenia. Tak może faktycznie być, ale weźmy
          pod uwagę to, że te konstrukcje mają szczególnie zaznaczony początek
          i koniec. Jeśli powłoka nie napotka odpowiedniego słowa kluczowego w
          wprowadzonym wierszu polecenie wówczas przejdzie w tryb wielolinii,
          w którym to będzie można kontynuować wprowadzanie polecenia.
        </p>
        <h3 id="18.1.1.beginingofscript">18.1.1. Początek skryptu</h3>
        <p>
          Jak może pamiętamy z podrozdziału o językach skryptowych na początku
          każdego skryptu umieszczamy linię wskazującą jednoznacznie na
          program interpretujący zawartość skryptu. W przypadku skryptów
          powłoki ta linia wygląda następująco:
        </p>
<pre class="code-block">
#!/bin/bash
</pre>
        <p>
          W dobrym tonie jest pozostawienie jednej linii odstępu do wskazania
          interpretera a treści skryptu. Nie raz możemy spotkać się takim
          zapisem jak:
        </p>
<pre class="code-block">
#!/bin/sh
</pre>
        <p>
          W tym przypadku możemy to dwojako interpretować, albo interpreterem
          skryptu jest klasyczna powłoka <em>Bourne</em>-a, albo autor zakłada,
          że domyślnym programem dostarczającym powłokę jest BASH, a plik
          <em>/bin/sh</em> jest tylko dowiązaniem symboliczym do
          <em>/bin/bash</em>. W przypadku Debiana, <em>/bin/sh</em> jest
          dowiązaniem do powłoki <em>DASH</em> bedąca tworem podobnym do
          <em>KSH</em>. Takie skrypty zazwyczaj wykorzysują proste polecenie
          oraz instrukcje bez specyficznych dla BASH mechanizmów. 
        </p>
        <h3 id="18.1.2.simplescript">18.1.2. Prosty skrypt.</h3>
        <p>
          Na potrzeby tego podrozdziału stworzymy pierwszy skrypt składający
          się z jednego polecenia <strong>echo</strong>. Polecenie to służy
          do wyświetlania ciągów znaków podanych jako argumenty. Polecenie to
          posiada kilka przydatnych opcji, których opisy znajdują się na
          stronie podręcznika.
        </p>
<pre class="code-block">
#!/bin/bash

echo "Hello, World!";
</pre>
        <p>
          Te dwie linie nalezy zapisać w pliku. Możemy dopisać rozszerzenie
          <em>.sh</em>, wówczas nasz edytor będzie kolorować składnię skryptu.
          Obecnie edytor mogą uruchamiać odpowiednie kolorowanie składni
          na podstawie zawartości pliku. <em>Vim</em> działa na takiej zasadzie.
          Plik należy zapisać i zamknąć następnie otworzyć go ponownie.
        </p>
        <h3 id="18.1.3.runascript">18.1.3. Uruchomienie skryptu</h3>
        <p>
          Uruchomienie skryptu powłoki BASH może odbyć się na dwa sposóby:
          bezpośrednio z wiersza polecenia oraz pośrednio podając ścieżkę do
          skryptu poleceniu <em>bash</em>. Uruchomienie bezpośrednie wymaga
          nadania plikowi uprawnień do wykonywania. Wówczas takie uruchomienie
          wygląda następująco:
        </p>
<pre class="code-block">
$ ls -al test.sh
-rw-r--r-- 1 xf0r3m xf0r3m 35 05-10 12:08 test.sh
$ ./test.sh
-bash: ./test.sh: Brak dostępu
$
$ chmod +x test.sh
$ ./test.sh
Hello, World!
</pre>
        <p>
          Teraz jeśli odbiorę uprawnienia wykonywania dla tego pliku to i tak
          będę wstanie go uruchomić, poprzez uruchomienie pośrednie.
        </p>
<pre class="code-block">
$ chmod -x test.sh
$ ls -al test.sh
-rw-r--r-- 1 xf0r3m xf0r3m 35 05-10 12:08 test.sh
$ bash test.sh
Hello, World!
</pre>
        <p>
          Oczywiście te uruchomienia poza poleceniami się niczym innym nie
          różnią. W momencie uruchomienia skryptu, dochodzi to startu procesu
          podpowłoki, który wykonuje kolejno jedno po drugim polecenie zapisane
          w pliku skryptu. Efekty uruchomienia tych sposóbów są identyczne.
        </p>
        <h3 id="18.1.4.scriptdebug">18.1.4. Debugowanie skryptów.</h3>
        <p>
          W przypadku skryptów użycie słowa debugowanie jest określeniem
          nadwyrost, nie mniej jednak możliwe jest śledzenie tego co robi
          skrypt, poprzez wywołanie procesu powłoki wraz z opcją
          <strong>-x</strong>, mozna to zarówno zrealizować przez uruchomienie
          pośrednie jak i bezpośrednie. Jednak raczej stosuje się tylko
          uruchomienie pośrednie. Nikt nie chce aby jego standardowe wyjście
          zalała fala informacji z np. każdą wartością zmiennej zadeklarowanej
          w skrypcie.
        </p>
<pre class="code-block">
#!/bin/bash -x
...
$ bash -x test.sh
+ echo 'Hello, World!'
Hello, World!
</pre>
        <p>
          Każdy znak plusa (<strong>+</strong>), oznacza że dane polecenie
          zostało uruchomione w podpowłoce. Więcej niż jeden taki symbol może
          mówić nam, że mamy doczynienia z wyrażeniem okrągłych nawiasów lub
          z podstawieniem polecenia. Obie te konstrukcje zostaną omówione w tym
          rozdziale.
        </p>
        <p>
          Teraz kiedy wyjaśniliśmy sobie w jaki sposób utworzyć, uruchomić oraz
          w wrazie problemów wyświetlić więcej szczegółów w celu namierzenia
          błedu. Możemy poznać podstawowe instrukcje.
        </p>
        <h2 id="18.2.basicshellinstructions">18.2. Podstawowe instrukcje powłoki.</h2>
        <p>
          Głównym celem jaki przyświeca tworzeniu skryptów powłoki jest
          automatyzacja powtarzalnych zadań wykonywanych w powłoce dystrybucji
          Linuksa. Zatem jej najprostszą oraz najbardziej złożoną instrukcją
          będzie najzwyklejszy uruchamiany przez nią program. Możemy dla
          przykładu umieścić w skrypcie z poprzedniego podrozdziału polecenie
          <em>ls</em>.
        </p>
<pre class="code-block">
$ cat test.sh
#!/bin/bash -x

echo "Hello, World!";
ls
</pre>
        <p>
          Same polecenie <code class="code-inline">echo</code> jest instrukcją
          powłoki, co za tym idzie poleceniem skryptu.
        </p>
        <p>
          Jak możemy zauwazyć na powyższym przykładzie linia z instrukcją
          <code class="code-inline">echo</code>, kończy się średnikiem
          (<strong>;</strong>)a linia z <code class="code-inline">ls</code>
          nie. Generalnie średnik nie jest wymagany na końcu
          linii. W ten sposób BASH interpretując skrypt wie gdzie się kończy
          polecenie. Jeśli zaś linia musi zawierać dwa polecenia, to należy
          umieszczać między poleceniami średnik. Jest jeszcze kilka przypadków
          gdy należy stosować średniki, ale przypomnę o tym w sposobnym
          momencie. Jeśli poza BASH-em programujemy w C lub w PHP, gdzie te
          średniki są wymagane to nie ma przeszkód aby je stosować.
        </p>
        <h3 id="18.2.1.variables">18.2.1. Zmienne</h3>
        <p>
          Instrukcje programowania dostarczane w wraz powłoka BASH pozwalające
          na pisanie skrytów, są pełnoprawnym językiem programowania. Jak każdy
          inny język potrzebuje on konstrukcji, które pozwolą mu na pracę z
          danymi. Tak najprostszą z konstrukcji znaną także w innych językach
          są <strong>zmienne</strong> - kontenery na dane, ułatwiające
          zapisanie toku myślenia w postaci algorytmu. W programowaniu ma to
          swoje odzwierciedlenie na pamięci, pozwalajac przypisać do
          niewielkich obszarów pamięci, identyfikatory aby móc odwołać się, w
          kodzie źródłowym do ich zawartości.
        </p>
        <p>
          W BASH-u (będę używać tego określenia, na programowanie skryptów 
          powłoki BASH. Myślę że upowszechniło się na tyle, że śmiało możemy
          powiedzieć o programowaniu w BASH-u.) zmienne są definiowane w
          prosty sposób. Podajemy nazwę zmiennej (identyfikator), następnie
          znak równości (<strong>=</strong>) po tym znaku podajemy wartość.
          Ważne jest aby <strong>nie robić przerw</strong> między tymi
          elementami, wówczas nazwa zmiennej zostanie potraktowana jako
          polecenie (nazwa programu do uruchomienia).
        </p>
<pre class="code-block">
var=1;
</pre>
        <p>
          Do tak zdefiniowanej zmiennej możemy się odwołać poprzedzając nazwę
          zmiennej znakiem dolara (<strong>$</strong>).
        </p>
<pre class="code-block">
echo "$var";
</pre>
        <p>
          Polecenie <code class="code-inline">echo</code> wyświetli zawartość
          zmiennej <code class="code-inline">var</code> na standardowym
          wyjściu.
        </p>
        <h3 id="18.2.2.comments">18.2.2. Komentarze</h3>
        <p>
          Ciągi znaków oznaczone jako <strong>komentarze</strong> po przez
          umieszczenie na ich początku krzyżyka (<strong>#</strong>) są
          całkowicie ignorowane przez powłokę w trakcie wykonywania skryptu.
        </p>
<pre class="code-block">
# To jest komentarz
#Tresc komenentarza może przylegać do krzyzyka
# lub może być miedzy nimi odstep
</pre>
        <p>
          Komentarze mają służyć wyłącznie programiście. Ich zadaniem jest
          możliwość dodawania notatek do kodu, w celu np. wyjaśnienia zawiłego
          bloku kodu.
        </p>
        <h3 id="18.2.3.pipelines">18.2.3. Potoki</h3>
        <p>
          <strong>Potoki</strong> czy inaczej <em>polecenia potokowe</em> są
          to ciągi poleceń połączonych ze sobą za pomocą mechnizmów
          wejścia-wyjścia.
        </p>
<pre class="code-block">
cat /etc/passwd | grep 'xf0r3m' | sed 's,/bin/bash,/bin/sh,'
</pre>
        <p>
          W powyższym poleceniu, dane wejściowe programu
          <code class="code-inline">cat</code> pochodzą z pliku, ale dane
          wejściowe polecenia <code class="code-inline">grep</code> pochodzą
          już ze standardowego wyjścia polecenia 
          <code class="code-inline">cat</code>. Zawartość pliku zostaje
          przekazana na standardowej wejscie drugiego polecenia, które 
          wyszukuje odpowiedniego wzorca. Ta sama sytuacja tyczy się ostatniego
          polecenia (<code class="code-inline">sed</code>). Potoki konstrułuje
          się przy użyciu znaku potoku lub znaku kreski pionowej
          (<strong>|</strong>).
        </p>
        <p>
          Potoki są przydatne gdy musimy przetworzyć w jakiś sposób dane,
          wówczas sprowadzamy je do postaci strumienia. Każde z poleceń na
          potoku wykonuje swoją działkę i przekazuje je dalej, aż trafiają one
          do zmiennej lub na standardowej wyjście powłoki. Z prostej analogii
          wygląda to trochę jak praca na linii produkcyjnej.
        </p>
        <p>
          Powyższy przykład ma duży potencjał optymalizacyjny swoją drogą,
          ponieważ pierwsze polecenie można pominąć i podać pliki od razu
          poleceniu <code class="code-inline">grep</code>.
        </p>
        <h3 id="18.2.4.commandsubstitution">18.2.4. Podstawienie polecenia</h3>
        <p>
          Mając omówione zmienne oraz potoki, to warto może połączyć ze sobą
          te zagadnienia i zadać pytanie: w jaki sposób można zapisać w 
          zmiennej dane przetwarzane przez potok?
        </p>
        <p>
          Chcąc zapisać wynik działania potoku do zmiennej, należy wykorzystać
          mechanizm zwany <strong>podstawieniem polecenia</strong>. Działa on
          na takiej zasadzie, że w momencie napotkania tego mechnizmu przez
          podpowłokę uruchamiana jest kolejna podpowłoka wykonująca polecenia
          zapisane w tym przypadku w potoku w podstawieniu polecenia. Po
          zakończeniu wartość zwracana jest przekazywana do zmiennej.
          Podstawienie polecenia może mieć dwie postacie, można wykorzystać
          lewe cudzysłowy (<strong>``</strong>) lub parę okrągłych nawiasów
          poprzezdzonych znakiem dolara (<strong>$()</strong>). Obie te formy
          są poprawne. Do niedawna istniała jedynie wersja z cudzysłowami.
        </p>
<pre class="code-block">
var=$(grep 'xf0r3m' | sed 's,/bin/bash,/bin/sh,');
# lub:
var=`grep 'xf0r3m' | sed 's,/bin/bash,/bin/sh,'`;
</pre>
        <h3 id="18.2.5.subshellsubstitution">18.2.5. Wyrażenie nawiasów okrągłych</h3>
        <p>
          Wyrażenie nawiasów okrągłych lub podstawienie podpowłoki, umożliwia
          nam oddzielenie wykonania pewnych poleceń od głównego procesu
          podpowłoki wykonującego skrypt. Użycie tego mechinizmu sprawdza się
          do zapisania, poleceń w zwykłym nawiasie okrągłym.
        </p>
<pre class="code-block">
(cd ytfzf &amp;&amp; make install doc)
</pre>
        <p>
          Jest to szczególnie przydane, gdy musimy trzymać kurczowo jakiś
          lokalizacji w systemie plików, a niektóre czynności tak jak
          instalacja projektu pokazana na powyższym przykładzie wymaga 
          zmiany tej
          ścieżki. Ścieżka może zostać zmieniona w podpowłoce i wykonanie 
          czynności
          również. Nie będzie to miało wpływu na główny nurt działania skryptu.
        </p>
        <h3 id="18.2.6.quotation">18.2.6. Znaki cytowania</h3>
        <p>
          Jak było prawdopodobnie wspomniane o znakach cytowania w drugim
          rozdziale. W BASH-u do dyspozycji mamy 3 rodzaje cudzysłowów:
        </p>
        <ul>
          <li>Lewy cudzysłów - (<strong>`</strong>) - jeden z operatorów
            podstawienie polecenia.</li>
          <li>Pojedynczy cudzysłów - (<strong>'</strong>) - cytowanie dosłowne,
            wszystko zapisane pomiędzy tymi znakami zostanie potraktowane jako
            ciąg znaków. BASH nie będzie próbować interpretować, żadnych
            treści w tym i instrukcji.</li>
          <li>Podwójny cudzysłów - (<strong>"</strong>) - cytowanie niedosłowne,
            Występujące wewnątrz odwłania do zmiennych czy podstawienia
            polecenia oraz inne mechnizmy i instrukcje zostaną przez BASH
            zinterpretowane i wykonane, wówczas wyniki działania BASH-a
            uzupełnią zapisany ciąg znaków.</li>
        </ul>
        <p>
          Należy o tym pamiętać! Że cudzysłowy w powłoce są rozróżniane i mają
          różne funkcje. Szczególnie może mieć to znaczenie przy takich
          poleceniach jak <em>sed</em> czy <em>grep</em>.
        </p>
        <h3 id="18.2.7.positionalparams">18.2.7. Parametry pozycyjne</h3>
        <p>
          Przekazanie do skryptu informacji jest jak najbardziej możlwe,
          oczywiście możemy zrobić to jak przypadku innych języków - podczas
          działania programu poprosić o podanie danych wejściowych. Możemy
          również użyć mechanizmy <strong>parametrów pozycyjnych</strong>,
          które pozwolą nam na przekazanie danych wejściowych podczas
          uruchamiania skryptu.
        </p>
<pre class="code-block">
$ ./test.sh foo bar
</pre>
        <p>
          Dostęp do tak przekazanych danych można uzyskać poprzez odwłanie się
          do numeru parametru:
        </p>
<pre class="code-block">
#!/bin/bash

echo "1: $1";
echo "2: $2";
#

$ ./test.sh foo bar
1: foo
2: bar
</pre>  <p>
          Parametry pozycyjne są czesto wykorzysywane do implementowania
          opcji skryptów. Paramentrów jest maksymalnie 10 (chociaż jest mozliwe
          jest uzyskanie dostępu do parametrów powyżej 10 za pomocą mechanizmu
          <em>wyrażenia parametru</em>.
        </p>
        <p>
          Dostęp do całej listy parametrów pozycyjnych możemy uzyskać na dwa
          sposoby. Oba są warte poznania. Pierwszym z nich jest lista
          parametrów, w której każdy jest osobnym elementem. Dostęp do niej
          uzyskujemy poprzez - <strong>$@</strong> - tego typu odwołanie się.
          Innym sposobem dostęp do parametrów jako pojedynczego ciagu znaków,
          wówczas wszysktie paramety są jednym elementem. Dostęp do parametrów
          w ten sposób osiągamy poprzez - <strong>$*</strong>.
        </p>
        <h3 id="18.2.8.parameterexpression">18.2.8. Wyrażenie parametru</h3>
        <p>
          Wyrażenie parametru posiada w BASH-u kilka funkcji. Jednak chyba
          najważniejszą oraz tą, która wymaga zapamiętania jest separacja
          nazwy zmiennej od pozostałych elementów, jest to szczególnie
          przydatne gdy scieżki w instrukcjach zawierają zmienne.
          Wyrażenie parametru jest przedstawiane za pomocą pary nawiasów
          klamrowych poprzezdzonych znakiem dolara (<strong>${}</strong>)
          pomiędzy nawiasami zapisuje się nazwę zmiennej, już bez znaku
          dolara.
        </p>
<pre class="code-block">
wget https://ftp.server.com/example/${ARCH}/${VERSION}/file.tgz
</pre>
        <p>
          Oczywiście poza funkcją separacyjną wyrażenie parametru kilka innych
          zastosowań, jedno już zostało tutaj wymienione, jest to dostęp do
          parametrów pozycyjnych powyżej 10-tej pozycji. Pozostałe są dostępne
          na stronie podręcznika powłoki BASH.
        </p>
        <h3 id="18.2.9.exitcode">18.2.7. Exitcode - wartość zwracana przez program</h3>
        <p>
          Niektóre narzędzie wykorzystywane przez nas do pracy w dystrybucjach
          Linuksa, zostają przez nas uruchomione i zaraz po tym zostaje nam
          zwrócony znak zachęty. I tak naprawdę to nie wiemy czy program
          wykonał swoje zadanie pomyślnie czy też nie. Nie mniej jednak
          większość programów działających na Uniksach zwraca takzwany kod
          wyjścia.
        </p>
        <ul>
          <li><strong>0</strong> - program poprawnie wykonał swoje zadanie.</li>
          <li><strong>!0</strong> - (wartość inna niż 0), podczas działania
            program nie mógł poprawnie wykonać swoich zadań z różnych
            powodów.</li>
        </ul>
        <p>
          W przypadku wartości nie zerowych programiści mają cały wachlarz
          możliwości na opisanie co poszło nie tak, zwracając kod wyjścia
          inny niż 0. Do dyspozycji mają od 1 - 255 możliwości. Kod wyjścia
          <strong>1</strong> jest najczęściej wykorzystywany jako błąd ogólny
          i ta wartość jest najczęsciej zwracana przez programy. Programy
          raczej sporadycznie korzystają z pozostałych wartości, oczywiście
          wszystko pozostaje w rękach programistów. 
        </p>
        <h2 id="18.3.condtionalexpressions">18.3. Wyrażenia warunkowe</h2>
        <p>
          Rozpoczynając omawianie wyrażeń warunkowych, warto sobie wyjaśnić,
          że w BASH-u nie operujemy na wartościach logicznych. Na wartościach
          logicznych operują polecenia wykonujące sprawdzenie danego wyrażenia
          warunkowego. Na podstawie wyniku tego wyrażnia narzędzia te
          <strong>generują kod wyjścia</strong>: <em>0</em> - dla
          <strong>prawdy</strong> i <em>1</em> - dla <strong>fałszu</strong>.
          Warto mieć to na uwadzę, aby podczas debugowania nie zastanawiać się
          dlaczego nasz warunek zwraca 0, a wykonywany jest blok kodu dla 
          prawdy.
        </p>
        <h3 id="18.3.1.conditionalinstructions">18.3.1. Instrukcje warunkowe</h3>
        <p>
          Instrukcjami warunkowymi możemy nazwać polecenia, które zwrócą nam
          odpowiedni kod wyjścia na podstawie testu logicznego podanego jako
          argument. Zazwyczaj zapisanie takie testu nie różni się niczym od
          zapisania warunku w innych językach. 
        </p>
        <p>
          W BASH-u do dyspozycji mamy takie instrukcje jak <strong>[</strong>,
          <strong>test</strong>, <strong>[[</strong>. Pierwsze dwie instrukcje
          są identyczne i najczęściej instrukcja <em>[</em> jest
          przedstawiana jako alias instrukcji <em>test</em>, która występuje
          nie tylko BASH-u, ale w większości powłok Uniksowych. Inną instrukcją
          jest <em>[[</em> jest klasyczny <em>test</em> jednak jego
          funkcjonalność została rozszerzona, jednym z takich rozszerzeń jest
          sprawdzenie czy np. podany ciąg znaków pasuje do nazwy wieloznacznej.
          Instrukcji <em>[[</em> nie będziemy tutaj omawiać.
        </p>
        <p>
          Instrukcje warunkowe do wykonania warunku logicznego potrzebujemy
          dwóch operandów oraz operatora lub jednego operandu oraz operatora,
          ponieważ wśród operacji warunkowych istnieją operacje
          jednoargumentowe. Zazwyczaj przeprowadzane są one ścieżkach
          wskazujących plik lub katalog. Takich jak na przykład:
        </p>
<pre class="code-block">
[ -f $HOME/testfile.txt ]
</pre>
        <p>
          Ten warunek sprawdzi czy plik
          <code class="code-inline">$HOME/testfile.txt</code> jest zwykłym
          plikiem.
        </p>
        <p>
          Warunki, które wymagają dwóch operatorów, to zazwyczaj takie jakie
          znamy z lekcji matematyki: a &gt; b, d &lt;= e itd. Przyczym tutaj
          warto przypomnień, że zapis instrukcji warunkowych (warunków), jest
          jednocześnie zapisem polecenia, tak więc nie można użyć znaków
          mniejszości (<strong>&lt;</strong>) czy większości 
          (<strong>&gt;</strong>),
          zamiast nich musimy używać specjalnie przygotowanych na tę okazję
          zamienników:
        </p>
        <ul>
          <li><strong>-lt</strong> - mniejsze niż,</li>
          <li><strong>-gt</strong> - większe niż,</li>
          <li><strong>-eq</strong> - równe,</li>
          <li><strong>-ne</strong> - nierówne.</li>
        </ul>
        <p>
          Nie będę tutaj wszysktich wypisywał, wszystkie operatory wraz tymi
          jednoargumentowymi znajdziemy na stronie podręcznika polecenia
          <em>test</em> lub na stronie podręcznika powłoki BASH w sekcji
          <em>CONDITIONAL EXPRESSIONS</em>. Mimo to warto zaznaczyć, że te
          wyżej wymienione operatory wymagają całkowitych (liczb całkowitych)
          operandów, a przyrównanie ciągów znaków wymaga pojednyczego znaku
          równości (<strong>=</strong>), a nie dwóch jak w przypadku innych 
          języków. Warto mieć to uwadze.
        </p>
        <p>
          Instukcje warunkowe na podstawie przekazanych przez programistę
          warunków, zwracaja kod wyjscia, który najczęściej interpretowany jest
          przez konstrukcje warunkowe.
        </p>
        <h3 id="18.3.2.if">18.3.2. Konstrukcje warunkowa - if</h3>
        <p>
          Konstrukcje warunkowe są elementem kontrolnym w programowaniu.
          Ich zadaniem jest wykonanie określonych instrukcji determinowanych
          na podstawie przekazanej instrukcji warunkowej. I najprostszym tego
          typu konstrukcją jest <em>if-then-else</em>.
        </p>
        <p>
          Konstrukcja <em>if-then-else</em>, jest podstawową konstrukcją
          warunkową opartą o wynik jednej instrukcji warunkowej oraz 
          zawierającą dwa bloki kodu, dla prawdy oraz fałszu.
        </p>
<pre class="code-block">
if warunek; then
  #Blok kodu dla prawdy
else
  #Blok kodu dla fałszu
fi
</pre>
        <p>
          Konstrukcja rozpoczyna się od słowa kluczowego
          <code class="code-inline">if</code>, oznacza on początek konstrukcji,
          następnie obok znajduje się <code class="code-inline">warunek</code>,
          warunek może być instrukcją warunkową, ale może być rownież
          poleceniem lub jego podstawieniem - czymś co jest nam wstanie
          zwrócić kod wyjścia. Po warunku <strong>obowiązkowo występuje średnik</strong>,
          następnie słowo kluczowe <code class="code-inline">then</code>
          otwierające blok kodu dla sytuacji, w której warunek zwrócił kod
          wyjścia <strong>równy 0</strong> (potocznie nazywany prawdą). Po
          tym bloku występuje słowo kluczowe
          <code class="code-inline">else</code> otwierając tym samym blok
          kodu dla każdej innej wartości kodu wyjścia, która nie jest zerem.
          Na samym końcu znajduje się słowo kluczowe
          <code class="code-inline">fi</code>, zamykające blok <em>else</em>
          oraz całą konstrukcję.
        </p>
        <p>
          Konstrukcję <em>if-then-else</em> można rozszerzyć o dodatkowy
          blok warunkowy <em>elif</em>. W momencie interpretacji takiej
          konstrukcji BASH sprawdzi na początek warunek przy <em>if</em>
          następnie przy <em>elif</em> i jeśli oba te warunki
          zwrócą niezerowy kod wyjścia, wtedy zostaną wykonane instrukcje
          zapisane w bloku <em>else</em>. Warto dodać, że nie ma limitu w
          ilości dodatkowych warunków (<em>elif</em>) tworząc przy tym całą
          kaskadę. Ponizej znajdue się przykład poglądowy przezentujący
          konstrukcję <em>if-then-elif-else</em>:
        </p>
<pre class="code-block">
if warunek; then
  #Blok dla prawdy warunku;
elif warunek2; then
  #Blok dla prawdy warunku2;
else
  #Blok dla fałszu obu warunków;
fi
</pre>
        <h3 id="18.3.3.case">18.3.3. Konstrukcja warunkowa - case</h3>
        <p>
          Inny rodzajem konstrukcji warunkowej, jest konstrukcja
          <strong>case</strong>, działa ona trochę na innej zasadzie niż
          konstrukcja <em>if-then-else</em>. Nie mam tutaj klasycznego warunku,
          a jedynie zmienna, która jest porównywana z zapisanymi przez
          programistę wartościami (<em>przypadkami</em>). Przypadki definiują
          bloki kodu, w momencie gdy wartość zmiennej jest równa wartości
          danego przypadku wówczas BASH wykona instrukcje zapisane w bloku
          tego przypadku.
        </p> 
<pre class="code-block">
case $alphabet in
  'a') echo "A";;
  'b') echo "B";;
esac
</pre>
        <p>
          Zmienna <code class="code-inline">alphabet</code> będzie kolejno
          porównywana z przypadkami <code class="code-inline">'a'</code>
          <code class="code-inline">'b'</code>. Jeśli zostanie odnaleziony
          odpowiedni przypadek, wówczas zostanie uruchomiony odpowiedni blok
          kodu. Zwróćmy uwagę na to, że bloki kodu poszczególnych przypadków
          zakończone są podwójnym średnikiem, jest to wymagane, a jego
          pominięcie spowoduje błąd powłoki.
        </p>
        <p>
          Konstrukcja <em>case</em> posiada przypadek uniwersalny
          wykorzystywany gdy zmienna nie pasuje, do żadnego z przypadków.
          Wartość takiego przypadku zapisuje się symbolem gwiazdki
          (<strong>*</strong>).
        </p>
<pre class="code-block">
case $alphabet in
  'a') echo "A";;
  'b') echo "B";;
   *) echo "To nie jest litera alfabetu";;
esac
</pre>
        <p>
          W przypadku konstrukcji <em>case</em>, bloki kodu mogą nie być aż
          tak widoczne. Niemniej jednak blok rozpoczyna się od wskazania
          wartości przypadku i obejmuje wszystkie instrukcje, aż do napotkania
          podwójnego średnika. Samo wskazanie wartości przypadku nie musi się
          ograniczać do pojednczej wartości, ale może zawierać warianty.
        </p>
<pre class="code-block">
case $alphabet in
  'a'|'A') echo "A";;
  'b') echo "B";;
   *) echo "To nie jest litera alfabetu";;
esac
</pre>
        <p>
          Konstrukcja <em>case</em>, stosowana jest głównie po to aby nie
          tworzyć kaskady konstrukcji <em>if-then-elif-else</em>. Każda
          konstrukcja <em>case</em>, kończy się słowem kluczowym
          <strong>esac</strong>.
        </p>
        <h2 id="18.4.loops">18.4. Pętle</h2>
        <p>
          Pętle w programowaniu służa wykonywaniu powtarzalnych czynności
          pod pewnym warunkiem. W bloku pętli element warunku
          (najprawdopodobniej) ulega zmianie, tak aby pętla zakończyła się
          i interpretacja programu wróciła na właściwy tor. Jeśli tak się nie
          dzieje, to wówczas mamy doczynienia z nieskończoną pętlą, tego typu
          konstrukcje nie zawsze muszą oznaczać błąd programisty, mogą być one
          pożądne, w zależności co znajduje się w ich bloku kodu. W BASH-u
          dość często wykorzystywane są dwa rodzaje pętli.
        </p>
        <h3 id="18.4.1.whileloop">18.4.1. Pętla while</h3>
        <p>
          Pętla <em>while</em> jest podstawowm rodzajem pętli, który potrzebuje
          do działania spełnionego warunku, wówczas uruchamiana jest
          sekwencja poleceń znajdujące sie w bloku tek pętli. W przypadku tego
          rodzaju pętli istotne jest utworzenie <strong>licznika</strong> - 
          zmiennej, która będzie kontrolować ilość powtórzeń pętli. Licznik
          zmieniany jest zazwyczaj, gdzieś na samym końcu pętli lub jego
          zmiana jest użależniona od określonego warunku. Ze względu na to, iż
          warunek pętli musi być prawdą, aby mogła ona w ogóle rozpocząć
          działanie - licznik musi zostać zdefiniowany przed pętlą. Poniżej
          znajduje się przykładowa konstrukcja pętli <em>while</em> 
          wyświetlająca kwadraty pierwszych 10 dodatnich liczb.
        </p>
<pre class="code-block">
count=1
while [ $count -le 10 ]; do
  pow=$(expr $count \* $count);
  echo "${count}: $pow";
  count=$(expr $count + 1);
done
</pre>
        <p>
          Pętla <em>while</em>, rozpoczyna się od słowa kluczowego
          <code class="code-inline">while</code>, po którym następuję
          warunek. Warunek (jak sama nazwa pętli może wskazywać) musi być
          spełniony, aby pętla się uruchomiła, bez tego pętla nie wykona się
          ani razu. Warunek operuje na klasycznych instrukcjach warunkowych.
          Co pozwala stwierdzić, że pętla <em>while</em> działa na takiej
          samej zasadzie jak konstrukcja <em>if</em>. Po warunku obowiązkowo
          występuje średnik, blok kodu zawierającego instrukcje do wykonania w
          pętli otwiera słowo kluczowe <code class="code-inline">do</code>.
          Po tym słowie umiesczana jest sekwencja poleceń, która będzie
          wykonywana dopóki warunek będzię spełniony (będzie zwracać prawdę).
          Blok kodu pętli, kończy się słowem kluczowym
          <code class="code-inline">done</code>.
        </p>
        <h3 id="18.4.2.forloop">18.4.2. Pętla for</h3>
        <p>
          Pętla <em>for</em> działa na odmiennej zasadzie niż pętla
          <em>while</em>. W tym przypadku zamiast warunku, mamy listę oraz
          jej element (zmienną). Pętla wykonuje swoje działanie do momentu, aż
          skończą się elementy na liście. Elementy te są przypisywane do
          zmiennej i następnie uruchamiany jest blok kodu pętli. Za pomocą
          zmiennej możemy odwłać się do elementu ustawionego dla tego
          przebiegu pętli. Poniżej znajduje się przykładowa pętla <em>for</em>
          realizująca to samo zadanie co pętla <em>while</em>.
        </p>
<pre class="code-inline">
for i in 1 2 3 4 5 6 7 8 9 10; do
  echo "${i}: $(expr $i \* $i)";
done
</pre>
        <p>
          W tym przypadku lista została zapisana z ręki (<em>hardcoded</em>).
          Jednak tutaj panuje duża elastyczność, listę możemy przekazać zmienną
          lub w postaci podstawienia polecenia. Wykonanie zadania zostało
          skompresowane do pojedynczej linii.
        </p>
        <h3 id="18.4.3.otherloops">18.4.3. Inne pętle oraz instrukcje sterujące</h3>
        <p>
          Poza omówionymi wyżej pętlami, BASH oferuje jeszczę pętlę
          <em>do-while</em>, której cechą charakterystyczną jest fakt, iż
          wykona się co najmniej raz, ponieważ sprawdzanie warunku występuje
          poniżej bloku kodu pętli, kiedy zostaną wykonane jej instrukcje
          wówczas będzie można określić czy warunek zwraca kod wyjścia 0 czy
          też inny.
        </p>
        <p>
          Kolejną z pętli jest <em>select</em>, która na
          podstawie listy wyświetla menu, oddając wykonanie programu pod
          interaktywną decyzję użytkownika. Użytkownik wybierając odpowiedni
          numer ustawia wartość przedstawioną w tym przypadku do zmiennej,
          do której można się odwołać w bloku pętli. Powtarzalność tej
          konstrukcji, polega na tym, że będzie ona ciągle pytać użytkownika o
          wybór do momentu, aż nie przerwiemy wykonania całego skryptu lub
          w kodzie pętli zaimplementujemy warunek, że jeśli została
          wybrana powiedzmy litera 'q', to zakończ pętle. Poniższy przykład
          wyświetla nazwy kolorów dostępnych do wyświetlenia w powłoce,
          po wybraniu koloru, zostanie wyświetlona jego próbka.
        </p>
<pre class="code-block">
colors="black red green yellow blue purple cyan white";
select i in $colors; do
  case $i in
    'black') cc=0;;
    'red') cc=1;;
    'green') cc=2;;
    'yellow') cc=3;;
    'blue') cc=4;;
    'purple') cc=5;;
    'cyan') cc=6;;
    'white') cc=7;;
  esac
  echo -e "${i}: \e[1;4${cc}m      \e[0m";
done
</pre>
        <p>
          Instrukcjami wpływającymi na działanie pętli w BASH-u są instrukcje:
          <strong>break</strong> oraz <strong>continue</strong>.
          Instrukcja <em>break</em> służy przerwaniu wykonania pętli i
          przejściu do instrukcji znajdującej się tuż za pętlą, inaczej jest
          w przypadku instrukcji <em>continue</em>. Instrukcja ta powoduje
          zresetowanie przebiegu pętli - wykonanie wraca do sprawdzenia
          warunku i rozpoczęcia wykonania bloku kodu od nowa.
        </p>
        <h2 id="18.5.functions">18.5. Funkcje</h2>
        <p>
          Funkcje w BASH-u służą temu samemu celowi co w innych językach
          programowania - udostępnieniu fragmentów kodu realizującego
          powtarzalne zadania, aby nie trzeba było ich przepisywać.
          Dopasowuje się algorytm tak, aby mógł działać z podanymi z zewnątrz
          danymi, ponieważ funkcję uruchamia się w taki sam sposób jak
          polecenie. 
        </p>
        <h3 id="18.5.1.fdefinitionandexecution">18.5.1. Definicja oraz wywołanie funkcji</h3>
        <p>
          Definicja funkcji wymaga użycia specjalnej konstrukcji
          <strong>function</strong>. Przykładową definicję zamieszczono
          poniżej:
        </p>
<pre class="code-block">
function square () {
  echo "$(expr $1 \* $1)";
}
</pre>
        <p>
          Definicja funkcji wymaga słowa kluczowego
          <code class="code-inline">function</code> następnie nazwy funkcji
          oraz pary okrągłych nawiasów (<strong>()</strong>). Sekcję bloku
          kodu funkcji wskazują nawiasy klamrowe (<strong>{}</strong>).
          Dane z zewnątrz zostały zaimplementowane pod postacią parametrów
          pozycjnych. Oczywiście, może nam się wydawać, że definiowanie
          funkcji dla pojednczego polecenia może nie końca mieć sens,
          nie mniej jednak takie działanie może posłużyć jako ustawienie
          <strong>aliasu</strong>, dla czynności, które mozna zapisać w 
          krótki i prosty sposób, nie tłumaczący jednak dokońca jaka operacja
          jest wykonywana.
        </p>
        <p>
          Funkcje tak jak już wspominałem, są wywoływane jak polecenia. Tak
          więc chcąc wywołać wcześniej zdefiniowaną funkcję należy zapisać
          <strong>pod jej definicją</strong> następujące polecenie:
        </p>
<pre class="code-block">
square 4;
</pre>
        <h3 id="18.5.2.includescripts">18.5.3. Dołączanie plików skryptów</h3>
        <p>
          Korzystając z możliwości tworzenia funkcji może się okazać, że jest
          ich całkiem spora ilość i dużo lepszym sposobem na zarządzanie nimi
          jest przeniesienie do innego pliku. Wówczas aby móc dalej korzystać
          z tych funkcji muszą być one dostępne dla skryptu, w którym będą
          wywoływane. W BASH-u nie mamy takich poleceń jak <em>include</em> czy
          <em>import</em>. Tutaj musimy posłużyć się <strong>wywołaniem skryptu
          w tym samym proces powłoki</strong>, dzięki temu obszar pamięci
          będzie taki sam, więc dla intepretera wykonującego główny skrypt
          wczytane z innego pliku funkcję będą dostępne, przez co główny
          skrypt będzie wstanie z nich skorzystać.
        </p>
        <p>
          Dołaczenie dodatkowego skryptu można zrealizować na dwa sposoby.
          Wykonują one tę samą operację i różnią się tylko zapisem. Do wyboru
          mamy polecenie <strong>source</strong> oraz zwykłą kropkę
          (<strong>.</strong>).
        </p>
<pre class="code-block">
source functions.sh
#lub:
. functions.sh
</pre>
        <p>
          Drugi sposób nie jest tożsamy z takim zapisem jak:
          <code class="code-inline">./functions.sh</code>. Tym przypadku
          kropka została użyta jako element ścieżki. My będziemy
          wykorzystywać ją jako polecenie.
        </p>
        <h2 id="18.6.otherusefulltools">18.6. Inne przydatne narzędzia</h2>
        <p>
          Tworząc skryptu w BASH-u, za pewne będziemy pracować z tekstami.
          Takim zadaniem  może być wyciągnięcie z pliku <em>feed</em>-u RSS
          adresu odnośnika do najnowszej wersji oprogramowania, którego
          używamy. Jest to jedno z kilku przykładów, do których będziemy
          potrzebowali narzędzi, które mogą być wykorzystywane w wielu
          skryptach.
        </p>
        <h3 id="18.6.1.cut">18.6.1 Polecenie cut</h3>
        <p>
          Polecenie <strong>cut</strong> może być wykorzystywane do
          ekstrakcji podciągu znaków z innego ciągu. W tym przypadku jego
          działanie będzie opierać się na wskazaniu ogranicznika za pomocą
          opcji <em>-d</em>, przez co ciag znaków - najczęsciej przekazany na
          standardowej wejście (polecenie <em>cut</em> często jest umieszczane
          w potoku) - podzielony zostaje na pola, które możemy wybrać podając
          numer tego pola liczony od początku ciągu. Tutaj warto zazanaczyć,
          że część ciągu do wystąpienia pierwszego ogranicznika, będzie
          pierwszym polem. Dostęp do pól uzyskujemy za pomocą opcji
          <em>-f</em>
        </p>
<pre class="code-block">
...| cut -d " " -f 2 |...
</pre>
        <h3 id="18.6.2.awk">18.6.2. AWK</h3>
        <p>
          Samo narzędzie AWK jest języka programowania operującym na tekstach.
          Nie mniej jednak, nie będziemy skupiać się na szczegółach tego
          narzędzia. Wykorzystamy jedną z jego funkcjonalności. Wspomniane
          wcześniej rozwiązanie związane z poleceniem <em>cut</em>
          ma jedną zasadniczą wadę, możemy miec problem z określeniem
          żądanego pola, w momencie gdy znak ogranicznika występuje po sobie
          kilka razy. Najczęściej jest tak z białymi znakami
          (spacją oraz znakami tabulacji). Wówczas możemy skorzystać z pól
          prezentowanych przez narzędzie AWK, pola tego narzędzia są tak
          naprawdę kolumnami, więc należy zadbać o odseparowanie konkretnej
          linii.
          Tutaj podział jest prosty, każda kolumna rozpoczyna się od każdego
          innego znaku nie będącego tabulatorem lub spacją. Numer kolumny
          podajemy po znaku dolara, tak jak na poniższym przykładzie.
        </p>
<pre class="code-block">
... | awk '{printf $1}' | ...
</pre>
        <p>
          Narzędzie zbierze wszystkie ciągi występujące w tej kolumnie w jeden
          ciąg bez żadnych przerw. Dodając trzy znaki, możemy zamienić ten
          nieczytelny ciąg znaków, chociażby w listę dla pętli <em>for</em>.
        </p>
<pre class="code-block">
... | awk '{printf $1" "}' | ...
</pre>
        <h3 id="18.6.3.sed">18.6.3. sed</h3>
        <p>
          <strong>Sed</strong>, czyli edytor strumienia
          (ang. <em><strong>s</strong>tream <strong>ed</strong>itor</em>), jest
          nieinteraktywnym edytorem tekstu opierającym się na wydawaniu
          pojedynczych poleceń. Za jego pomocą możemy wstawiać do plików
          poszczególne linie lub je zmieniać stosując znaną metodę
          <em>find and replace</em>. Sed działa zarówno na plikach jak i 
          strumieniu danych wejściowych. 
        </p>
        <p>
          W plikach może zajść taka potrzeba, aby zmienić pewien zapis tylko
          w jednej linii, to wskazanie tej wybranej linii może odbyć się na
          dwa sposoby: za pomocą wyrażenia regularnego lub podając konkretny
          numer linii. Wyrażenie regularne sprawdzi się przy kilku liniach, w
          przypadku jednej konkretnej, wystarczy podać jej numer. 
        </p>
        <p>
          Przy początkach naszej pracy ze skryptami, najczęściej będziemy
          wykorzystywać raczej opcje <em>find and replace</em>, nie mniej
          jednak specyficzna składania polecenia <em>sed</em> wymaga, aby
          chociażby pokazać jak wyglądają polecenia <em>insert</em>,
          <em>append</em> czy <em>print</em>.
        </p>
        <h4>Polecenie sed - <em>insert</em></h4>
        <p>
          Polecenie <em>insert</em> wstawia podaną wartość w konkretną linię
          podaną przez wyrażenie regularne lub numer linii.
        </p>
<pre class="code-block">
$ sed '21i Lorem ipsum dolor sit amet, consectetur adipiscing elit' plik.txt
</pre>
        <p>
          Na powyższym przykładzie <code class="code-inline">i</code> oznacza
          właśnie polecenie <em>insert</em>. Przed poleceniem znajduje się
          numer linii, który w przypadku narzędzia <em>sed</em> pisany jest
          łącznie wraz ze wskazniem konkretnego polecenia. Po poleceniu
          występuje wartość, która ma zostać zapisana w pliku.
        </p>
        <p>
          Polecenie to domyślnie zwrócić na standardowe wyjście całą zawartość
          pliku z podmienioną linią, ponieważ jest to edytor strumienia to 
          musi on otworzyć plik i działać na nim w pamięci. Aby nasze zamiany
          faktycznie miały jakiś skutek musimy dodać opcję <em>-i</em>.
        </p>
        <p>
          Podobnie jest poleceniem <em>append</em> - <strong>a</strong>,
          również wymaga ono opcji <em>-i</em>. Składania tego polecenia
          jest identyczna z <em>insert</em>, zmianie ulega tylko literka
          wskazująca polecenie, nie mniej jednak zasada działania jest 
          trochę inna.
          Otóż to polecenie dopisze pod wskazaną linią, podaną wartość. W
          przypadku naszego przykładu, podana wartość znalazła by się w 22
          linii.
        </p>
        <h4>Polecenie sed - print</h4>
        <p>
          Za polecenie <em>print</em> odpowiedzialna jest litera <strong>p</strong>
          nie ma w tym nic dziwnego, warto jednak zaznaczyć, że
          polecenie to przyjmuje zakres linii do wyświetlania np. jesli
          chcemy wyświetlić linie od 1 do 12, to wówczas możemy skorzystać z 
          poniższego polecenia: 
        </p>
<pre class="code-inline">
$ sed '1,12p' test.txt
</pre>
        <p>
          Tutaj istotną rolę pełni cytowanie. Jeśli checielibyśmy wyświetlić
          linie od 100 do końca pliku, to polecenie <em>sed</em> mogło by
          wyglądać w ten sposób: <code class="code-inline">'100,$p'</code>.
          No dobrze, a jeśli początek zakresu jest zapisany w zmiennej to
          polecenie powinno wyglądać mniej więcej tak
          <code class="code-inline">"$a,$p"</code>. Problem w tym, że dolna
          granica zakresu, rownież zostanie zinterpretowana jako zmienna. W tej
          sytuacji należy zacytować sam znak dolara.
        </p>
<pre class="code-inline">
$ sed "$a,\$p" test.txt
</pre>
        <p>
          Natomiast jeśli w zmiennej znajduje się dolna granica ciągu, to aby
          oddzielić odwołanie się do zmienne od polecenia <em>print</em> należy
          użyć funkcji powłoki BASH, jaką jest wyrażenie parametru.
        </p>
<pre class="code-inline">
$ sed "1,${a}p" test.txt
</pre>
        <h4>Polecenie sed - find and replace</h4>
        <p>
          Do funkcji programu <em>sed</em>, <em>find and replace</em>
          przypisana jest litera <strong>s</strong>. Domyślna składnia jest
          następująca:
        </p>
<pre class="code-inline">
$ sed "s/ala/ola/" test.txt
</pre>
        <p>
          Po poleceniu <code class="code-inline">s</code> występuje separator,
          następnie wartość poszukiwana, znów separator oraz nowa wartość,
          która zastąpi wartość poszukiwania, na końcu polecenia znów występuje
          separator. Polecenie zamieni pierwsze wystąpienie ciągu
          <code class="code-inline">ala</code> na ciąg
          <code class="code-inline">ola</code>.
        </p>
        <p>
          W przypadku tego polecenia <em>sed</em> jest bardzo elastyczny.
          Ponieważ równie dobrze jako separator możemy użyć innych znaków.
          Znak ukośnika (<strong>/</strong>) wykorzystywany jest w ścieżkach,
          a one są jednymi z częściej zmienianych elementów konfiguracyjnych
          w Uniksach. Jako separatora możemy użyć zarówno: małpy
          (<strong>@</strong>) jak i przecinka (<strong>,</strong>).
        </p>
        <p>
          Ostatni separator nie musi kończyć polecenia. Ponim zaś występują
          modyfikatory. Jednym z takich modyfikatorów jest <strong>g</strong>.
          Ten modyfikator powoduje, że wszystkie znalezione występienia
          szukanej frazy zostaną zastąpione.
        </p>
        <p>
          Podobnie polecenie <code class="code-inline">s</code> nie musi
          rozpoczynać polecenia. Polecenie <em>s</em> zarówno jak
          <em>i</em> czy <em>a</em> może zostać sprecyzowane do konkretnej
          linii lub grupy elementów pasujących do wyrażenia regularnego.
        </p>
        <h3 id="18.6.4.wc">18.6.4. wc</h3>
        <p>
          Polecenie <strong>wc</strong> 
          (ang. <em><strong>w</strong>ord <strong>c</strong>ount</em>), jest
          poleceniem, które zadaniem jest liczenie linii, znaków czy też słów,
          podanych za pomocą pliku czy też ze strumienia standardowego wejścia.
          Wykorzystanie polecenia <em>wc</em>, może być całkiem przydatne w
          momencie gdy musimy ustalić np. granicę dla pętli <em>while</em>.
          Najczęsciej stoswane jest liczenie linii 
          (za pomoca opcji <em>-l</em>), czasami może się przydać liczenie
          znaków (za pomocą opcji <em>-c</em>) oraz słów
          (za pomocą opcji <em>-w</em>).
        </p>
        <h2 id="18.7.summary">18.7. Podsumowanie</h2>
        <p>
          W tym rozdziale poznaliśmy podstawy tworzenia skryptów powłoki, które
          pomogą nam automatyzować zadania wykonywana w powłoce. Nie piszę
          tutaj, konkretnych nazw. Ponieważ jeśli zagłebimy się w temat, to
          BASH zebrał najlepsze funkcje oraz rozwiązania z innych powłok i 
          zaimplementował u siebie. Oczywiście sam BASH nie jest nowym
          rozwiązaniem, ponieważ powstał już 1987 roku. Innymi stosowanymi
          rozwiązaniami są takie powłoki jak <em>zsh</em> czy <em>fish</em>.
          Inny ciekawy rozwiązaniem jest projekt <em>nu shell</em>,
          przestawiający troche inne podejście. Zachęcam do zapoznania się
          z projektem. Jeśli jednak twardo będziemy obstawać, przy BASH-u
          (ma to swoje zalety, większość dystrybucji wykorzystuje jednak BASH,
          więc lepiej mieć to samo środowisko w domu jak i na serwerze w
          pracy). To można zapoznać się z dodatkowymi materiałami:
        </p>
        <ul>
          <li><a href="https://morketsmerke.github.io/articles/terminallog/BASH_bushido.html">Wiele przydatnych sztuczek w BASH-u</a></li>
          <li><a href="https://tldp.org/LDP/Bash-Beginners-Guide/html/index.html">Podręcznik do powłoki BASH dla początkujących.</a></li>
          <li><a href="https://https://tldp.org/LDP/abs/html/index.html">Podręcznik do zaawansowanych skryptów BASH-u.</a></li>
        </ul>
      </div>
					</body>
	</html>
